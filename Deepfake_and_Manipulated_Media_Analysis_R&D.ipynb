{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e458ae3c18584a04b7d67c2d456c9866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_069c7e99b173450e84c9451155092693",
              "IPY_MODEL_c5a3b859f4194b75a997a60bf44ce25a",
              "IPY_MODEL_57c1f5f860e24ca4927816a02e2af6a4"
            ],
            "layout": "IPY_MODEL_c7ce198f4cc345d5a86dd01ed46b016b"
          }
        },
        "069c7e99b173450e84c9451155092693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_522ae1a9d5a84911821b4c7d27ad55aa",
            "placeholder": "​",
            "style": "IPY_MODEL_79be91b2ec5e446a8f72030702410bde",
            "value": "config.json: 100%"
          }
        },
        "c5a3b859f4194b75a997a60bf44ce25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e27857bb3fa4966b0e99c02ff579538",
            "max": 1414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06dae138b5384a458aa492668c816efe",
            "value": 1414
          }
        },
        "57c1f5f860e24ca4927816a02e2af6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45dcb6bf4da8445389422223da12d49e",
            "placeholder": "​",
            "style": "IPY_MODEL_e5310324c7b7419fa39b50ee0586545b",
            "value": " 1.41k/1.41k [00:00&lt;00:00, 36.4kB/s]"
          }
        },
        "c7ce198f4cc345d5a86dd01ed46b016b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "522ae1a9d5a84911821b4c7d27ad55aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79be91b2ec5e446a8f72030702410bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e27857bb3fa4966b0e99c02ff579538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06dae138b5384a458aa492668c816efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45dcb6bf4da8445389422223da12d49e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5310324c7b7419fa39b50ee0586545b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83086532bf654c7fa39fbbe9491f6754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a0b8539f78040da8aeaff5e0b63ef4c",
              "IPY_MODEL_6b03390da85a41929a2e0003fb25ce13",
              "IPY_MODEL_f7edf23bfd144a93bc3086b0513051dd"
            ],
            "layout": "IPY_MODEL_97258a5b79ee439788abb9780d454d50"
          }
        },
        "6a0b8539f78040da8aeaff5e0b63ef4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78c1081cbc014502a04aa401675888f6",
            "placeholder": "​",
            "style": "IPY_MODEL_f9938d45388e46cfb6c519baa7ae8413",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "6b03390da85a41929a2e0003fb25ce13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e8dc3c11a1e4454bae9f1a957f7474f",
            "max": 741,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17b827361dc94032b0095f598a834bed",
            "value": 741
          }
        },
        "f7edf23bfd144a93bc3086b0513051dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eda69432cb046fb90e387e7e14440fe",
            "placeholder": "​",
            "style": "IPY_MODEL_1c494ad27143453fbca04b63fc3de6af",
            "value": " 741/741 [00:00&lt;00:00, 16.8kB/s]"
          }
        },
        "97258a5b79ee439788abb9780d454d50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78c1081cbc014502a04aa401675888f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9938d45388e46cfb6c519baa7ae8413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e8dc3c11a1e4454bae9f1a957f7474f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17b827361dc94032b0095f598a834bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6eda69432cb046fb90e387e7e14440fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c494ad27143453fbca04b63fc3de6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a16a3e1b9eb946bcbbdbaf82069318b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10a82748cf8646219935e43f848c235e",
              "IPY_MODEL_550f9e3589064074a582cb9290d1562c",
              "IPY_MODEL_efaaaf447643485e9754c79ef89994bc"
            ],
            "layout": "IPY_MODEL_5dcc18d9de1e4d39922680dee0f0cd19"
          }
        },
        "10a82748cf8646219935e43f848c235e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e952276aea948f093d53b523c0dcea2",
            "placeholder": "​",
            "style": "IPY_MODEL_1ee44ee18c7e4b62a0e7fa4ad1d79c7d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "550f9e3589064074a582cb9290d1562c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da0b2886b8244bff8b365c542d5334e4",
            "max": 1505,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_777d5f1307734004bb0107ab87de4f3c",
            "value": 1505
          }
        },
        "efaaaf447643485e9754c79ef89994bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dc45a6011084980a605952915c78a26",
            "placeholder": "​",
            "style": "IPY_MODEL_068c97a24d2c498fbb7bca5e58dd1315",
            "value": " 1.50k/1.50k [00:00&lt;00:00, 34.3kB/s]"
          }
        },
        "5dcc18d9de1e4d39922680dee0f0cd19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e952276aea948f093d53b523c0dcea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ee44ee18c7e4b62a0e7fa4ad1d79c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da0b2886b8244bff8b365c542d5334e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "777d5f1307734004bb0107ab87de4f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dc45a6011084980a605952915c78a26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "068c97a24d2c498fbb7bca5e58dd1315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf72dae645fb4c01be3c89b13059aee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8e02529aa0a42228642753fcc2bbe8e",
              "IPY_MODEL_a2c77b0f772c4ddf9f0bce8d74c44bed",
              "IPY_MODEL_0b61650d10f04e2ca2cdcf2beae259a2"
            ],
            "layout": "IPY_MODEL_e3aea6846b7a4b0887af798184cfc0ed"
          }
        },
        "f8e02529aa0a42228642753fcc2bbe8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cd34f99760b420dbc7cc5b95ff6e8fd",
            "placeholder": "​",
            "style": "IPY_MODEL_a645e4d5901d480887f30df193f6a989",
            "value": "tokenizer.model: 100%"
          }
        },
        "a2c77b0f772c4ddf9f0bce8d74c44bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a224a40b804439a92b043623baaacd4",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ec2eddae8c64722a29ae12c06cbe0bf",
            "value": 499723
          }
        },
        "0b61650d10f04e2ca2cdcf2beae259a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f32d4106efa3443baeafe88446ce7663",
            "placeholder": "​",
            "style": "IPY_MODEL_007bf9a5497f4b6ba119dfa23b8a8946",
            "value": " 500k/500k [00:00&lt;00:00, 4.02MB/s]"
          }
        },
        "e3aea6846b7a4b0887af798184cfc0ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cd34f99760b420dbc7cc5b95ff6e8fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a645e4d5901d480887f30df193f6a989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a224a40b804439a92b043623baaacd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec2eddae8c64722a29ae12c06cbe0bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f32d4106efa3443baeafe88446ce7663": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "007bf9a5497f4b6ba119dfa23b8a8946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ad40977fa3445d6b16dff56505e0db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40d8de7e707443eead56f893fb188e7b",
              "IPY_MODEL_a5cb38703b944a8f93ae3c3331b981f9",
              "IPY_MODEL_1fa32e7608d54dd0ba23eb11ff672238"
            ],
            "layout": "IPY_MODEL_7e0f049fdb674a0a823902743b30b3ef"
          }
        },
        "40d8de7e707443eead56f893fb188e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66738ede1d25429b810ad41eed6a01fc",
            "placeholder": "​",
            "style": "IPY_MODEL_b1aedffa8e594855b0b020ead1c2f7ca",
            "value": "tokenizer.json: 100%"
          }
        },
        "a5cb38703b944a8f93ae3c3331b981f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45157b44dac4411d814c16bc260a03ea",
            "max": 1843172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15899b0c5eb74ac6bfb82d337f40c482",
            "value": 1843172
          }
        },
        "1fa32e7608d54dd0ba23eb11ff672238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e417a20e0df245c29b892c79b25f08cb",
            "placeholder": "​",
            "style": "IPY_MODEL_6f100c6a11be416183e196a0d146c9b0",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 8.48MB/s]"
          }
        },
        "7e0f049fdb674a0a823902743b30b3ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66738ede1d25429b810ad41eed6a01fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1aedffa8e594855b0b020ead1c2f7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45157b44dac4411d814c16bc260a03ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15899b0c5eb74ac6bfb82d337f40c482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e417a20e0df245c29b892c79b25f08cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f100c6a11be416183e196a0d146c9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40c47a18b63b4b34b26ab3ce5eda42b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fadbd6256a64fc38c5a8e63fb73a0e9",
              "IPY_MODEL_5f062ed6d6a442ff8d0a7c79ceb09bbc",
              "IPY_MODEL_e224df10081f4d2fa281c4c8620b7d48"
            ],
            "layout": "IPY_MODEL_2326306a113b4ace936faba2adb97cdb"
          }
        },
        "2fadbd6256a64fc38c5a8e63fb73a0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ae079fc88824516a64b10e9b5635b3d",
            "placeholder": "​",
            "style": "IPY_MODEL_bfddb49241e94a1ca7de97b9efe8b841",
            "value": "added_tokens.json: 100%"
          }
        },
        "5f062ed6d6a442ff8d0a7c79ceb09bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2954fe184c5746f1add05ff90e31e689",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab78e4096e4b4dea917b46962511ab2a",
            "value": 43
          }
        },
        "e224df10081f4d2fa281c4c8620b7d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4416a03e1be4de29400f831c00ce80a",
            "placeholder": "​",
            "style": "IPY_MODEL_252e1e9025e94ea789548c29b0edd497",
            "value": " 43.0/43.0 [00:00&lt;00:00, 795B/s]"
          }
        },
        "2326306a113b4ace936faba2adb97cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae079fc88824516a64b10e9b5635b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfddb49241e94a1ca7de97b9efe8b841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2954fe184c5746f1add05ff90e31e689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab78e4096e4b4dea917b46962511ab2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4416a03e1be4de29400f831c00ce80a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "252e1e9025e94ea789548c29b0edd497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "031ae946161a420b8abaeed38f2e7c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5e51a109db64b7cb707837b5c607bc1",
              "IPY_MODEL_135b888639bb4205a273d4e94e35e948",
              "IPY_MODEL_6ea84b278b304284a9b68592256edbd4"
            ],
            "layout": "IPY_MODEL_3bc7df2ccc3d4f84be09d2e9db2ff2b5"
          }
        },
        "d5e51a109db64b7cb707837b5c607bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cb3eaa28fdd4d239d14667231e8249e",
            "placeholder": "​",
            "style": "IPY_MODEL_b67f431e9bc2446e8b921b19f1b9d77a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "135b888639bb4205a273d4e94e35e948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6559ee7284684c56a05b191bb04c18af",
            "max": 552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef301640ca164d899fb9776c2d1a318b",
            "value": 552
          }
        },
        "6ea84b278b304284a9b68592256edbd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9a9eaa58dd04977bd30ddbb3d7a19c6",
            "placeholder": "​",
            "style": "IPY_MODEL_2b6ea2034bcc4bf7905c181b3f2c90c6",
            "value": " 552/552 [00:00&lt;00:00, 11.8kB/s]"
          }
        },
        "3bc7df2ccc3d4f84be09d2e9db2ff2b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cb3eaa28fdd4d239d14667231e8249e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b67f431e9bc2446e8b921b19f1b9d77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6559ee7284684c56a05b191bb04c18af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef301640ca164d899fb9776c2d1a318b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9a9eaa58dd04977bd30ddbb3d7a19c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b6ea2034bcc4bf7905c181b3f2c90c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "645eb81e296c46f1a408f5ec55f66034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da2d85d3e5ec451ba05f5389b1cd4b47",
              "IPY_MODEL_cc437fc2ab8f4df6bf82e80cab5d8190",
              "IPY_MODEL_a17bd04f425c4c2aa85fe44f15ffdefd"
            ],
            "layout": "IPY_MODEL_fe53ef95bf0a4c8db9d312a963a9c337"
          }
        },
        "da2d85d3e5ec451ba05f5389b1cd4b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eec1167089c64f43841aa501d2484280",
            "placeholder": "​",
            "style": "IPY_MODEL_861f6e4644044900a13394fe8e259021",
            "value": "generation_config.json: 100%"
          }
        },
        "cc437fc2ab8f4df6bf82e80cab5d8190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3001bd7a427f4560822e375cdde143e2",
            "max": 137,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c5b6e022df9480d84f0543165509c5d",
            "value": 137
          }
        },
        "a17bd04f425c4c2aa85fe44f15ffdefd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_123cdf31f26340578116674efe87fbdb",
            "placeholder": "​",
            "style": "IPY_MODEL_befbaebfe3aa4b4dbeab375d4bef228f",
            "value": " 137/137 [00:00&lt;00:00, 2.82kB/s]"
          }
        },
        "fe53ef95bf0a4c8db9d312a963a9c337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eec1167089c64f43841aa501d2484280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "861f6e4644044900a13394fe8e259021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3001bd7a427f4560822e375cdde143e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c5b6e022df9480d84f0543165509c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "123cdf31f26340578116674efe87fbdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "befbaebfe3aa4b4dbeab375d4bef228f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eda0f2fc0608499bb962765dabff2ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19c1d7dfa1824af4a99274b4264e3554",
              "IPY_MODEL_9cc2476a3fe04f2496e21d286a6c214d",
              "IPY_MODEL_5773cb06841e48b89379b614134fbfb0"
            ],
            "layout": "IPY_MODEL_cf448f8bac5747d59d1ddd97de9a1721"
          }
        },
        "19c1d7dfa1824af4a99274b4264e3554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7a29b0a08c748088a9ab4c27686d516",
            "placeholder": "​",
            "style": "IPY_MODEL_74cab4b66abe4f3382e9358b5ba0e5fa",
            "value": "model-00003-of-00003.safetensors:  53%"
          }
        },
        "9cc2476a3fe04f2496e21d286a6c214d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c7b92b5180a4f98aba537965d42122c",
            "max": 4176137496,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63a5e2bd89fc412184674ef571124f73",
            "value": 2222981120
          }
        },
        "5773cb06841e48b89379b614134fbfb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bf1e9491dc6445eae7109fb9cd828ce",
            "placeholder": "​",
            "style": "IPY_MODEL_683c2eb200514bb8a025997925c08e96",
            "value": " 2.22G/4.18G [14:48&lt;22:24, 1.45MB/s]"
          }
        },
        "cf448f8bac5747d59d1ddd97de9a1721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7a29b0a08c748088a9ab4c27686d516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74cab4b66abe4f3382e9358b5ba0e5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c7b92b5180a4f98aba537965d42122c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a5e2bd89fc412184674ef571124f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bf1e9491dc6445eae7109fb9cd828ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "683c2eb200514bb8a025997925c08e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb3880aa55e84e459279f7364176f6cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62ecea01b8f2470184b43c17120e059c",
              "IPY_MODEL_8f6b39c63565469d90e613add98b62d7",
              "IPY_MODEL_034f16a0ad584b04966637c9c46ca4f6"
            ],
            "layout": "IPY_MODEL_eee922e7a4b04bd39282ecd416a1d4df"
          }
        },
        "62ecea01b8f2470184b43c17120e059c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_202acc01be25438bbd88bf393c97ebe7",
            "placeholder": "​",
            "style": "IPY_MODEL_9d49d58e5bb5427799cc70586c62aae6",
            "value": "model-00002-of-00003.safetensors:  45%"
          }
        },
        "8f6b39c63565469d90e613add98b62d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_792f81cb08aa42acb47f2fe0e538025c",
            "max": 4957878552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c45237d038f2404d819cc5385bcdbfaa",
            "value": 2212495360
          }
        },
        "034f16a0ad584b04966637c9c46ca4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_882c5f412d0f44de8923fb2d2b53f1a6",
            "placeholder": "​",
            "style": "IPY_MODEL_dc3c9e8263254050a05ead9b154d4515",
            "value": " 2.21G/4.96G [14:48&lt;31:27, 1.45MB/s]"
          }
        },
        "eee922e7a4b04bd39282ecd416a1d4df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "202acc01be25438bbd88bf393c97ebe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d49d58e5bb5427799cc70586c62aae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "792f81cb08aa42acb47f2fe0e538025c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c45237d038f2404d819cc5385bcdbfaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "882c5f412d0f44de8923fb2d2b53f1a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc3c9e8263254050a05ead9b154d4515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dc9eea71ccb448fa61ad18d82d4e53c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51dc8e43fe2e4aa894bed378be3f0baf",
              "IPY_MODEL_589e34d43b2d4e4c90dbd3822bcfe198",
              "IPY_MODEL_ea8c20becc354c808f0730113389e63e"
            ],
            "layout": "IPY_MODEL_90bf68ed7a6844f7ac6fdcefd7146c13"
          }
        },
        "51dc8e43fe2e4aa894bed378be3f0baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0087538a2bc4a70aa82d6e8abf10178",
            "placeholder": "​",
            "style": "IPY_MODEL_417973eb45c746ecab7472a24f4a8d76",
            "value": "model-00001-of-00003.safetensors:  44%"
          }
        },
        "589e34d43b2d4e4c90dbd3822bcfe198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe71fb5f8cd44409a1d2c903306a0e18",
            "max": 4992938952,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8274f3066fd4c608f2052630bb12a04",
            "value": 2191523840
          }
        },
        "ea8c20becc354c808f0730113389e63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa2e6d71e196487dbc89e01aa02cd451",
            "placeholder": "​",
            "style": "IPY_MODEL_3d0b5eee952b420f885fc7ca9a1254b1",
            "value": " 2.19G/4.99G [14:48&lt;33:47, 1.38MB/s]"
          }
        },
        "90bf68ed7a6844f7ac6fdcefd7146c13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0087538a2bc4a70aa82d6e8abf10178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "417973eb45c746ecab7472a24f4a8d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe71fb5f8cd44409a1d2c903306a0e18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8274f3066fd4c608f2052630bb12a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa2e6d71e196487dbc89e01aa02cd451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d0b5eee952b420f885fc7ca9a1254b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Deepfake_and_Manipulated_Media_Analysis_R%26D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Deepfake Detection and Manipulated Media Analysis using Multiagent System and Compound AI Approach**"
      ],
      "metadata": {
        "id": "TREWxWZdT5iE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEMrzAzRW_w4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72321e94-2d86-458b-c655-0f7df4dced73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.3/264.3 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.4/67.4 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.9/396.9 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.7/912.7 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.7/801.7 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install -q vllm transformers torch opencv-python librosa numpy face-recognition groq\n",
        "!pip install -qU dlib mediapipe scipy pillow tqdm pydantic moviepy langchain_community langgraph dtw-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import librosa\n",
        "import asyncio\n",
        "import json\n",
        "import base64\n",
        "import re\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import concurrent.futures\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional, Union\n",
        "from pydantic import BaseModel, Field\n",
        "from transformers import (\n",
        "    CLIPProcessor, Wav2Vec2Processor, VideoMAEFeatureExtractor,\n",
        "    EfficientNetForImageClassification, LlavaForConditionalGeneration,\n",
        ")\n",
        "from vllm import LLM, SamplingParams\n",
        "from groq import Groq  # Groq Python client\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.tools import BaseTool\n",
        "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent\n",
        "from langgraph.graph import Graph, StateGraph, END\n",
        "from moviepy import VideoFileClip\n",
        "import nest_asyncio\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from functools import lru_cache\n",
        "from skimage import exposure\n",
        "from scipy.signal import savgol_filter\n",
        "from dtw import dtw\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import time\n",
        "\n",
        "# Allow nested asyncio loops (useful in notebooks)\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "YvGEVqyrw7k3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61863db5-c95a-4d0b-b6bc-bd5d86e98a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-11 08:14:05 __init__.py:190] Automatically detected platform cuda.\n",
            "Importing the dtw module. When using in academic works please cite:\n",
            "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
            "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import VLLM and Groq clients (ensure these libraries are installed)\n",
        "from vllm import LLM\n",
        "from groq import Groq  # Ensure Groq client is installed\n",
        "\n",
        "# -------------------- Global Configuration and Model Initialization --------------------\n",
        "\n",
        "COMMON_PARAMS = {\n",
        "    \"task\": \"generate\",\n",
        "    \"max_model_len\": 2048,\n",
        "    \"dtype\": \"half\",\n",
        "    \"gpu_memory_utilization\": 0.7,\n",
        "    \"cpu_offload_gb\": 6,\n",
        "    \"enforce_eager\": True\n",
        "}\n",
        "\n",
        "def init_vllm_model(name: str, model_id: str, **overrides) -> LLM:\n",
        "    \"\"\"Initialize a VLLM model with a common configuration.\"\"\"\n",
        "    model = LLM(model=model_id, **{**COMMON_PARAMS, **overrides})\n",
        "    print(f\"[VLLM] {name} loaded: {model_id}\")\n",
        "    return model\n",
        "\n",
        "def init_groq_model(name: str, model_id: str):\n",
        "    \"\"\"Initialize a Groq model for accelerated inference.\"\"\"\n",
        "    groq_client = Groq(api_key=\"YOUR_GROQ_API_KEY\")\n",
        "    model = groq_client.load_model(model_id)\n",
        "    print(f\"[Groq] {name} loaded: {model_id}\")\n",
        "    return model\n",
        "\n",
        "# -------------------- Model Initializations --------------------\n",
        "# Video Analysis Models (VLLM)\n",
        "llava_next_video = init_vllm_model(\"llava_next_video\", \"llava-hf/LLaVA-NeXT-Video-7B-hf\")\n",
        "xclip = init_vllm_model(\"xclip\", \"xclip-model\")\n",
        "videomae = init_vllm_model(\"videomae\", \"videomae-model\")\n",
        "\n",
        "# Audio Analysis Models\n",
        "wav2vec2 = init_vllm_model(\"wav2vec2\", \"facebook/wav2vec2-large-960h\")\n",
        "llava_audio = init_vllm_model(\"llava_next_video\", \"llava-hf/LLaVA-NeXT-Video-7B-hf\")\n",
        "groq_audio_model = init_groq_model(\"groq_audio_model\", \"whisper-large-v3-turbo\")\n",
        "\n",
        "# Image Analysis Models\n",
        "llava_image = init_vllm_model(\"llava_onevision\", \"llava-hf/llava-onevision-qwen2-7b-ov-hf\")\n",
        "clip = init_vllm_model(\"clip\", \"openai/clip-vit-large-patch14\")\n",
        "groq_vision_model = init_groq_model(\"groq_vision_model\", \"llama-3.2-90b-vision-preview\")\n",
        "\n",
        "# Text Analysis / Report Generation Model\n",
        "groq_text_model = init_groq_model(\"groq_text_model\", \"llama-3.3-70b-versatile\")\n",
        "\n",
        "# Clear unused GPU memory\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\nModels loaded successfully:\")\n",
        "print(\"Video Analysis: llava_next_video, xclip, videomae\")\n",
        "print(\"Audio Analysis: wav2vec2, llava_audio, groq_audio_model\")\n",
        "print(\"Image Analysis: llava_image, clip, groq_vision_model\")\n",
        "print(\"Text Analysis/Report Generation: groq_text_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667,
          "referenced_widgets": [
            "e458ae3c18584a04b7d67c2d456c9866",
            "069c7e99b173450e84c9451155092693",
            "c5a3b859f4194b75a997a60bf44ce25a",
            "57c1f5f860e24ca4927816a02e2af6a4",
            "c7ce198f4cc345d5a86dd01ed46b016b",
            "522ae1a9d5a84911821b4c7d27ad55aa",
            "79be91b2ec5e446a8f72030702410bde",
            "0e27857bb3fa4966b0e99c02ff579538",
            "06dae138b5384a458aa492668c816efe",
            "45dcb6bf4da8445389422223da12d49e",
            "e5310324c7b7419fa39b50ee0586545b",
            "83086532bf654c7fa39fbbe9491f6754",
            "6a0b8539f78040da8aeaff5e0b63ef4c",
            "6b03390da85a41929a2e0003fb25ce13",
            "f7edf23bfd144a93bc3086b0513051dd",
            "97258a5b79ee439788abb9780d454d50",
            "78c1081cbc014502a04aa401675888f6",
            "f9938d45388e46cfb6c519baa7ae8413",
            "9e8dc3c11a1e4454bae9f1a957f7474f",
            "17b827361dc94032b0095f598a834bed",
            "6eda69432cb046fb90e387e7e14440fe",
            "1c494ad27143453fbca04b63fc3de6af",
            "a16a3e1b9eb946bcbbdbaf82069318b5",
            "10a82748cf8646219935e43f848c235e",
            "550f9e3589064074a582cb9290d1562c",
            "efaaaf447643485e9754c79ef89994bc",
            "5dcc18d9de1e4d39922680dee0f0cd19",
            "7e952276aea948f093d53b523c0dcea2",
            "1ee44ee18c7e4b62a0e7fa4ad1d79c7d",
            "da0b2886b8244bff8b365c542d5334e4",
            "777d5f1307734004bb0107ab87de4f3c",
            "2dc45a6011084980a605952915c78a26",
            "068c97a24d2c498fbb7bca5e58dd1315",
            "cf72dae645fb4c01be3c89b13059aee0",
            "f8e02529aa0a42228642753fcc2bbe8e",
            "a2c77b0f772c4ddf9f0bce8d74c44bed",
            "0b61650d10f04e2ca2cdcf2beae259a2",
            "e3aea6846b7a4b0887af798184cfc0ed",
            "6cd34f99760b420dbc7cc5b95ff6e8fd",
            "a645e4d5901d480887f30df193f6a989",
            "2a224a40b804439a92b043623baaacd4",
            "8ec2eddae8c64722a29ae12c06cbe0bf",
            "f32d4106efa3443baeafe88446ce7663",
            "007bf9a5497f4b6ba119dfa23b8a8946",
            "9ad40977fa3445d6b16dff56505e0db2",
            "40d8de7e707443eead56f893fb188e7b",
            "a5cb38703b944a8f93ae3c3331b981f9",
            "1fa32e7608d54dd0ba23eb11ff672238",
            "7e0f049fdb674a0a823902743b30b3ef",
            "66738ede1d25429b810ad41eed6a01fc",
            "b1aedffa8e594855b0b020ead1c2f7ca",
            "45157b44dac4411d814c16bc260a03ea",
            "15899b0c5eb74ac6bfb82d337f40c482",
            "e417a20e0df245c29b892c79b25f08cb",
            "6f100c6a11be416183e196a0d146c9b0",
            "40c47a18b63b4b34b26ab3ce5eda42b4",
            "2fadbd6256a64fc38c5a8e63fb73a0e9",
            "5f062ed6d6a442ff8d0a7c79ceb09bbc",
            "e224df10081f4d2fa281c4c8620b7d48",
            "2326306a113b4ace936faba2adb97cdb",
            "0ae079fc88824516a64b10e9b5635b3d",
            "bfddb49241e94a1ca7de97b9efe8b841",
            "2954fe184c5746f1add05ff90e31e689",
            "ab78e4096e4b4dea917b46962511ab2a",
            "c4416a03e1be4de29400f831c00ce80a",
            "252e1e9025e94ea789548c29b0edd497",
            "031ae946161a420b8abaeed38f2e7c1c",
            "d5e51a109db64b7cb707837b5c607bc1",
            "135b888639bb4205a273d4e94e35e948",
            "6ea84b278b304284a9b68592256edbd4",
            "3bc7df2ccc3d4f84be09d2e9db2ff2b5",
            "7cb3eaa28fdd4d239d14667231e8249e",
            "b67f431e9bc2446e8b921b19f1b9d77a",
            "6559ee7284684c56a05b191bb04c18af",
            "ef301640ca164d899fb9776c2d1a318b",
            "a9a9eaa58dd04977bd30ddbb3d7a19c6",
            "2b6ea2034bcc4bf7905c181b3f2c90c6",
            "645eb81e296c46f1a408f5ec55f66034",
            "da2d85d3e5ec451ba05f5389b1cd4b47",
            "cc437fc2ab8f4df6bf82e80cab5d8190",
            "a17bd04f425c4c2aa85fe44f15ffdefd",
            "fe53ef95bf0a4c8db9d312a963a9c337",
            "eec1167089c64f43841aa501d2484280",
            "861f6e4644044900a13394fe8e259021",
            "3001bd7a427f4560822e375cdde143e2",
            "6c5b6e022df9480d84f0543165509c5d",
            "123cdf31f26340578116674efe87fbdb",
            "befbaebfe3aa4b4dbeab375d4bef228f",
            "eda0f2fc0608499bb962765dabff2ba1",
            "19c1d7dfa1824af4a99274b4264e3554",
            "9cc2476a3fe04f2496e21d286a6c214d",
            "5773cb06841e48b89379b614134fbfb0",
            "cf448f8bac5747d59d1ddd97de9a1721",
            "f7a29b0a08c748088a9ab4c27686d516",
            "74cab4b66abe4f3382e9358b5ba0e5fa",
            "0c7b92b5180a4f98aba537965d42122c",
            "63a5e2bd89fc412184674ef571124f73",
            "4bf1e9491dc6445eae7109fb9cd828ce",
            "683c2eb200514bb8a025997925c08e96",
            "cb3880aa55e84e459279f7364176f6cf",
            "62ecea01b8f2470184b43c17120e059c",
            "8f6b39c63565469d90e613add98b62d7",
            "034f16a0ad584b04966637c9c46ca4f6",
            "eee922e7a4b04bd39282ecd416a1d4df",
            "202acc01be25438bbd88bf393c97ebe7",
            "9d49d58e5bb5427799cc70586c62aae6",
            "792f81cb08aa42acb47f2fe0e538025c",
            "c45237d038f2404d819cc5385bcdbfaa",
            "882c5f412d0f44de8923fb2d2b53f1a6",
            "dc3c9e8263254050a05ead9b154d4515",
            "8dc9eea71ccb448fa61ad18d82d4e53c",
            "51dc8e43fe2e4aa894bed378be3f0baf",
            "589e34d43b2d4e4c90dbd3822bcfe198",
            "ea8c20becc354c808f0730113389e63e",
            "90bf68ed7a6844f7ac6fdcefd7146c13",
            "f0087538a2bc4a70aa82d6e8abf10178",
            "417973eb45c746ecab7472a24f4a8d76",
            "fe71fb5f8cd44409a1d2c903306a0e18",
            "a8274f3066fd4c608f2052630bb12a04",
            "aa2e6d71e196487dbc89e01aa02cd451",
            "3d0b5eee952b420f885fc7ca9a1254b1"
          ]
        },
        "id": "-xNU8D9MAXpo",
        "outputId": "8de4719d-bd7d-410b-b56d-f57fa77e4b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e458ae3c18584a04b7d67c2d456c9866"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/741 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83086532bf654c7fa39fbbe9491f6754"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING 02-11 08:14:47 cuda.py:95] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
            "WARNING 02-11 08:14:47 config.py:678] Async output processing is not supported on the current platform type cuda.\n",
            "INFO 02-11 08:14:47 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='llava-hf/LLaVA-NeXT-Video-7B-hf', speculative_config=None, tokenizer='llava-hf/LLaVA-NeXT-Video-7B-hf', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=llava-hf/LLaVA-NeXT-Video-7B-hf, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[],\"max_capture_size\":0}, use_cached_outputs=False, \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a16a3e1b9eb946bcbbdbaf82069318b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf72dae645fb4c01be3c89b13059aee0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ad40977fa3445d6b16dff56505e0db2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40c47a18b63b4b34b26ab3ce5eda42b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "031ae946161a420b8abaeed38f2e7c1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "645eb81e296c46f1a408f5ec55f66034"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-11 08:14:53 cuda.py:179] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 02-11 08:14:53 cuda.py:227] Using XFormers backend.\n",
            "INFO 02-11 08:14:54 model_runner.py:1110] Starting to load model llava-hf/LLaVA-NeXT-Video-7B-hf...\n",
            "INFO 02-11 08:14:55 cuda.py:179] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 02-11 08:14:55 cuda.py:227] Using XFormers backend.\n",
            "INFO 02-11 08:14:55 config.py:2992] cudagraph sizes specified by model runner [] is overridden by config []\n",
            "INFO 02-11 08:15:02 weight_utils.py:252] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.18G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eda0f2fc0608499bb962765dabff2ba1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb3880aa55e84e459279f7364176f6cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8dc9eea71ccb448fa61ad18d82d4e53c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Up the Groq Client and More Models for Text, Audio and Vedio Analysis**"
      ],
      "metadata": {
        "id": "-ytDSCQDUAje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Data Models**\n",
        "- Define the data models for storing analysis results and reports:\n"
      ],
      "metadata": {
        "id": "X8RzT9-AWZCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepfakeAnalysisResult(BaseModel):\n",
        "    score: float = Field(..., description=\"Confidence score (0-1)\")\n",
        "    label: str = Field(..., description=\"Classification label\")\n",
        "    anomalies: List[str] = Field(default_factory=list)\n",
        "    artifacts: List[str] = Field(default_factory=list)\n",
        "    confidence: float = Field(..., description=\"Model confidence\")\n",
        "    method: str = Field(..., description=\"Detection method used\")\n",
        "    timestamp: datetime = Field(default_factory=datetime.now)\n",
        "\n",
        "class MultimodalAnalysisReport(BaseModel):\n",
        "    case_id: str\n",
        "    file_info: Dict[str, Any]\n",
        "    video_analysis: Optional[DeepfakeAnalysisResult]\n",
        "    audio_analysis: Optional[DeepfakeAnalysisResult]\n",
        "    image_analysis: Optional[DeepfakeAnalysisResult]\n",
        "    text_analysis: Optional[DeepfakeAnalysisResult]\n",
        "    multimodal_score: float\n",
        "    verdict: str\n",
        "    evidence: List[Dict[str, Any]]\n",
        "    metadata: Dict[str, Any]"
      ],
      "metadata": {
        "id": "MyJ0N4mSWZio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frame Stabilization**\n"
      ],
      "metadata": {
        "id": "vZdtcqEPytTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stabilize_frames(frames: List[np.ndarray]) -> List[np.ndarray]:\n",
        "    stabilized_frames = []\n",
        "    prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)\n",
        "    transforms = []\n",
        "\n",
        "    for i in range(1, len(frames)):\n",
        "        curr_gray = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
        "        transform = cv2.estimateRigidTransform(prev_gray, curr_gray, False)\n",
        "        transforms.append(transform)\n",
        "        prev_gray = curr_gray\n",
        "\n",
        "    for i, frame in enumerate(frames):\n",
        "        if i == 0:\n",
        "            stabilized_frames.append(frame)\n",
        "        else:\n",
        "            stabilized_frame = cv2.warpAffine(frame, transforms[i-1], (frame.shape[1], frame.shape[0]))\n",
        "            stabilized_frames.append(stabilized_frame)\n",
        "\n",
        "    return stabilized_frames\n",
        "\n",
        "def adaptive_noise_reduction(audio_data: np.ndarray) -> np.ndarray:\n",
        "    noise_profile = np.mean(audio_data[:1000])\n",
        "    reduced_noise_audio = audio_data - noise_profile\n",
        "    return reduced_noise_audio"
      ],
      "metadata": {
        "id": "kNzO5fgyy0sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Functions for Preprocessing**\n",
        "- Define helper functions for preprocessing audio, image, and video data:"
      ],
      "metadata": {
        "id": "0ktikzemXOd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_image_resolution(image_path: str) -> np.ndarray:\n",
        "    image = cv2.imread(image_path)\n",
        "    image_upscaled = cv2.resize(image, (image.shape[1] * 2, image.shape[0] * 2), interpolation=cv2.INTER_CUBIC)\n",
        "    return image_upscaled\n",
        "\n",
        "def adaptive_histogram_equalization(image: np.ndarray) -> np.ndarray:\n",
        "    return exposure.equalize_adapthist(image, clip_limit=0.03)\n",
        "\n",
        "def spectral_noise_reduction(audio_data: np.ndarray, sample_rate: int) -> np.ndarray:\n",
        "    reduced_noise_audio = savgol_filter(audio_data, window_length=51, polyorder=3)\n",
        "    return reduced_noise_audio\n",
        "\n",
        "def temporal_alignment_dtw(frames: List[np.ndarray]) -> List[np.ndarray]:\n",
        "    aligned_frames = []\n",
        "    for i in range(1, len(frames)):\n",
        "        alignment = dtw(frames[i-1], frames[i])\n",
        "        aligned_frames.append(alignment.index2)\n",
        "    return aligned_frames\n",
        "\n",
        "def deblur_image(image: np.ndarray) -> np.ndarray:\n",
        "    gaussian_blur = cv2.GaussianBlur(image, (0, 0), 3)\n",
        "    unsharp_image = cv2.addWeighted(image, 1.5, gaussian_blur, -0.5, 0)\n",
        "    return unsharp_image\n",
        "\n",
        "def extract_audio_features(audio_data: np.ndarray, sample_rate: int) -> Dict[str, Any]:\n",
        "    mfcc = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n",
        "    chroma = librosa.feature.chroma_stft(y=audio_data, sr=sample_rate)\n",
        "    mel = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
        "    return {\n",
        "        \"mfcc\": mfcc,\n",
        "        \"chroma\": chroma,\n",
        "        \"mel\": mel\n",
        "    }\n",
        "\n",
        "def extract_image_features(image: np.ndarray) -> Dict[str, Any]:\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    sift = cv2.SIFT_create()\n",
        "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
        "    return {\n",
        "        \"keypoints\": keypoints,\n",
        "        \"descriptors\": descriptors\n",
        "    }\n",
        "\n",
        "def calculate_dense_optical_flow(prev_frame: np.ndarray, curr_frame: np.ndarray) -> np.ndarray:\n",
        "    gray_prev = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "    gray_curr = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
        "    flow = cv2.calcOpticalFlowFarneback(gray_prev, gray_curr, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    return flow\n",
        "\n",
        "def extract_temporal_features(optical_flow: np.ndarray) -> Dict[str, Any]:\n",
        "    mag, ang = cv2.cartToPolar(optical_flow[..., 0], optical_flow[..., 1])\n",
        "    return {\n",
        "        \"magnitude\": mag,\n",
        "        \"angle\": ang\n",
        "    }\n",
        "\n",
        "def estimate_noise(frame: np.ndarray) -> float:\n",
        "    return np.mean(cv2.Laplacian(frame, cv2.CV_64F).var())\n",
        "\n",
        "def calculate_contrast(frame: np.ndarray) -> float:\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    return gray.std()\n",
        "\n",
        "def detect_compression_artifacts(frame: np.ndarray) -> float:\n",
        "    dct = cv2.dct(np.float32(frame) / 255.0)\n",
        "    return np.mean(np.abs(dct))"
      ],
      "metadata": {
        "id": "9A9KPnzU36TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Preprocessing Functions**\n",
        "- Define functions for preprocessing audio, image, and video data"
      ],
      "metadata": {
        "id": "13iwCPIrX-Vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def enhanced_preprocessing(file_path: str) -> Dict[str, Any]:\n",
        "    file_extension = os.path.splitext(file_path)[1].lower()\n",
        "    if file_extension in [\".mp3\", \".wav\", \".flac\"]:\n",
        "        return await enhanced_audio_preprocessing(file_path)\n",
        "    elif file_extension in [\".jpg\", \".jpeg\", \".png\", \".bmp\"]:\n",
        "        return await enhanced_image_preprocessing(file_path)\n",
        "    elif file_extension in [\".mp4\", \".avi\", \".mov\", \".mkv\"]:\n",
        "        return await enhanced_video_preprocessing(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format\")\n",
        "\n",
        "async def enhanced_audio_preprocessing(audio_path: str) -> Dict[str, Any]:\n",
        "    audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
        "    audio_data = spectral_noise_reduction(audio_data, sample_rate)\n",
        "    audio_features = extract_audio_features(audio_data, sample_rate)\n",
        "    return {\"audio\": audio_data, \"sample_rate\": sample_rate, \"audio_features\": audio_features}\n",
        "\n",
        "async def enhanced_image_preprocessing(image_path: str) -> Dict[str, Any]:\n",
        "    image = cv2.imread(image_path)\n",
        "    image = enhance_image_resolution(image)\n",
        "    image = adaptive_histogram_equalization(image)\n",
        "    image = deblur_image(image)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image_features = extract_image_features(image_rgb)\n",
        "    return {\"image\": image_rgb, \"image_features\": image_features}\n",
        "\n",
        "async def enhanced_video_preprocessing(video_path: str) -> Dict[str, Any]:\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    audio_data = None\n",
        "    metadata = {\n",
        "        \"fps\": cap.get(cv2.CAP_PROP_FPS),\n",
        "        \"frame_count\": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
        "        \"width\": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "        \"height\": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
        "        \"duration\": float(cap.get(cv2.CAP_PROP_FRAME_COUNT)) / float(cap.get(cv2.CAP_PROP_FPS)),\n",
        "        \"codec\": int(cap.get(cv2.CAP_PROP_FOURCC)).to_bytes(4, byteorder='little').decode(),\n",
        "        \"file_size\": os.path.getsize(video_path)\n",
        "    }\n",
        "    frame_quality_metrics = []\n",
        "    optical_flow_data = []\n",
        "    prev_frame = None\n",
        "    temporal_features = []\n",
        "\n",
        "    loop = asyncio.get_event_loop()\n",
        "    executor = ThreadPoolExecutor(max_workers=4)\n",
        "\n",
        "    async def process_frame(frame):\n",
        "        return await loop.run_in_executor(executor, enhance_image_resolution, frame)\n",
        "\n",
        "    async def process_quality_metrics(frame):\n",
        "        return await loop.run_in_executor(executor, lambda: {\n",
        "            \"blur\": cv2.Laplacian(frame, cv2.CV_64F).var(),\n",
        "            \"noise\": estimate_noise(frame),\n",
        "            \"brightness\": np.mean(frame),\n",
        "            \"contrast\": calculate_contrast(frame),\n",
        "            \"compression_artifacts\": detect_compression_artifacts(frame)\n",
        "        })\n",
        "\n",
        "    async def process_optical_flow(prev_frame, frame):\n",
        "        return await loop.run_in_executor(executor, calculate_dense_optical_flow, prev_frame, frame)\n",
        "\n",
        "    async def process_temporal_features(flow):\n",
        "        return await loop.run_in_executor(executor, extract_temporal_features, flow)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame, quality_metrics = await asyncio.gather(\n",
        "            process_frame(frame),\n",
        "            process_quality_metrics(frame)\n",
        "        )\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frames.append(rgb_frame)\n",
        "        frame_quality_metrics.append(quality_metrics)\n",
        "        if prev_frame is not None:\n",
        "            flow, temp_features = await asyncio.gather(\n",
        "                process_optical_flow(prev_frame, frame),\n",
        "                process_temporal_features(flow)\n",
        "            )\n",
        "            optical_flow_data.append(flow)\n",
        "            temporal_features.append(temp_features)\n",
        "        prev_frame = frame.copy()\n",
        "    cap.release()\n",
        "\n",
        "    try:\n",
        "        video = VideoFileClip(video_path)\n",
        "        audio = video.audio\n",
        "        if audio is not None:\n",
        "            audio_array = audio.to_soundarray()\n",
        "            audio_data = extract_audio_features(audio_array, audio.fps)\n",
        "        video.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Audio extraction error: {e}\")\n",
        "        audio_data = None\n",
        "\n",
        "    return {\n",
        "        \"frames\": frames,\n",
        "        \"audio\": audio_data,\n",
        "        \"metadata\": metadata,\n",
        "        \"quality_metrics\": frame_quality_metrics,\n",
        "        \"optical_flow\": optical_flow_data,\n",
        "        \"temporal_features\": temporal_features\n",
        "    }"
      ],
      "metadata": {
        "id": "ltWcOSlP36Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Analysis Functions**\n",
        "- functions for analyzing transcription, vision response, and other features"
      ],
      "metadata": {
        "id": "GExLYgMaYVBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_transcription(transcription: str) -> List[str]:\n",
        "    anomalies = []\n",
        "    if \"repeated phrase\" in transcription.lower():\n",
        "        anomalies.append(\"Repetitive phrases detected\")\n",
        "    if \"inconsistent timestamp\" in transcription.lower():\n",
        "        anomalies.append(\"Inconsistent timestamps detected\")\n",
        "    return anomalies\n",
        "\n",
        "def analyze_vision_response(response: str) -> List[str]:\n",
        "    anomalies = []\n",
        "    if \"blurry region\" in response.lower():\n",
        "        anomalies.append(\"Blurry regions detected\")\n",
        "    if \"unnatural shadow\" in response.lower():\n",
        "        anomalies.append(\"Unnatural shadows detected\")\n",
        "    return anomalies\n",
        "\n",
        "def analyze_av_sync(frames: List[np.ndarray], audio: np.ndarray) -> float:\n",
        "    sync_score = 0.9\n",
        "    return sync_score\n",
        "\n",
        "def analyze_temporal_features(temporal_features: List[Dict[str, Any]]) -> List[str]:\n",
        "    anomalies = []\n",
        "    for feature in temporal_features:\n",
        "        if feature[\"magnitude\"].max() > 1.0:\n",
        "            anomalies.append(\"Abrupt changes in motion detected\")\n",
        "    return anomalies\n",
        "\n",
        "def analyze_optical_flow(optical_flow: List[np.ndarray]) -> List[str]:\n",
        "    anomalies = []\n",
        "    for flow in optical_flow:\n",
        "        if flow.max() > 1.0:\n",
        "            anomalies.append(\"Inconsistent flow patterns detected\")\n",
        "    return anomalies\n",
        "\n",
        "def analyze_biometric_consistency(frames: List[np.ndarray], models: Dict[str, Any]) -> float:\n",
        "    consistency_score = 0.9\n",
        "    return consistency_score\n",
        "\n",
        "def analyze_llava_response(response: str) -> float:\n",
        "    score_match = re.search(r\"Score: (0\\.\\d+|1\\.0)\", response)\n",
        "    return float(score_match.group(1)) if score_match else 0.5\n",
        "\n",
        "\n",
        "def parse_model_output(response: str) -> Tuple[float, List[str]]:\n",
        "    \"\"\"\n",
        "    Parse the model's output string.\n",
        "    Expected format (exact format can be adjusted as needed):\n",
        "\n",
        "      Score: <score_value>\n",
        "      Anomalies: [ \"anomaly1\", \"anomaly2\", ... ]\n",
        "\n",
        "    Returns:\n",
        "        A tuple (score, anomalies) where score is a float and anomalies is a list of strings.\n",
        "    \"\"\"\n",
        "    score_pattern = r\"Score:\\s*([\\d\\.]+)\"\n",
        "    anomalies_pattern = r\"Anomalies:\\s*\\[([^\\]]+)\\]\"\n",
        "\n",
        "    score_match = re.search(score_pattern, response)\n",
        "    if score_match:\n",
        "        score = float(score_match.group(1))\n",
        "    else:\n",
        "        score = 0.5  # default value if no score found\n",
        "\n",
        "    anomalies = []\n",
        "    anomalies_match = re.search(anomalies_pattern, response)\n",
        "    if anomalies_match:\n",
        "        # Split by comma and strip quotes and whitespace.\n",
        "        anomalies_raw = anomalies_match.group(1)\n",
        "        anomalies = [a.strip().strip('\"\\'' ) for a in anomalies_raw.split(\",\") if a.strip()]\n",
        "    return score, anomalies\n",
        "\n",
        "def analyze_transcription_details(transcription: str) -> Tuple[float, List[str]]:\n",
        "    \"\"\"\n",
        "    Analyze the transcription text for indicators of deepfake manipulation.\n",
        "    This function scans for keywords that may suggest manipulation.\n",
        "\n",
        "    Returns:\n",
        "        A tuple (score, anomalies), where a higher score indicates higher likelihood of manipulation.\n",
        "    \"\"\"\n",
        "    keywords = [\"fake\", \"inconsistent\", \"manipulated\", \"error\"]\n",
        "    found = [word for word in keywords if word in transcription.lower()]\n",
        "    # If any keyword is found, assume higher likelihood; otherwise, lower.\n",
        "    score = 0.8 if found else 0.4\n",
        "    return score, found"
      ],
      "metadata": {
        "id": "YkN1p_l2u-KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Analysis Functions**\n",
        "- Define functions for analyzing audio, image, and video data using Groq models"
      ],
      "metadata": {
        "id": "05aBMDMgY5CI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advanced Audio Analysis**"
      ],
      "metadata": {
        "id": "_KKDSAFn1uLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def advanced_audio_analysis(audio_data: Dict[str, Any], device: torch.device) -> DeepfakeAnalysisResult:\n",
        "    \"\"\"\n",
        "    Detailed audio analysis using two VLLM models and one Groq model.\n",
        "    1. wav2vec2 extracts detailed speech features.\n",
        "    2. llava_audio evaluates the audio for subtle manipulations.\n",
        "    3. groq_audio_model performs transcription analysis.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    anomalies = []\n",
        "\n",
        "    # Model 1: wav2vec2 – speech feature extraction\n",
        "    model = wav2vec2.to(device)\n",
        "    prompt1 = (\n",
        "        \"Analyze the audio waveform for speech features including tone, pitch, and rhythm. \"\n",
        "        \"Identify anomalies indicative of deepfake manipulation. Output format:\\n\"\n",
        "        \"Score: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    inputs1 = {\"audio\": audio_data.get(\"waveform\"), \"text\": prompt1}\n",
        "    with torch.no_grad():\n",
        "        output1 = model.generate(**inputs1)\n",
        "    score1, anomalies1 = parse_model_output(output1)\n",
        "    scores.append(score1)\n",
        "    anomalies.extend(anomalies1)\n",
        "\n",
        "    # Model 2: llava_audio – multimodal audio analysis\n",
        "    model = llava_audio.to(device)\n",
        "    prompt2 = (\n",
        "        \"Examine the audio clip for subtle signs of manipulation such as irregular speech tempo and lip-sync issues. \"\n",
        "        \"Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    inputs2 = {\"audio\": audio_data.get(\"waveform\"), \"text\": prompt2}\n",
        "    with torch.no_grad():\n",
        "        output2 = model.generate(**inputs2)\n",
        "    score2, anomalies2 = parse_model_output(output2)\n",
        "    scores.append(score2)\n",
        "    anomalies.extend(anomalies2)\n",
        "\n",
        "    # Model 3: Groq audio model – transcription analysis\n",
        "    response = groq_audio_model.transcriptions.create(\n",
        "        file=audio_data.get(\"waveform\"),\n",
        "        model=\"whisper-large-v3-turbo\"\n",
        "    )\n",
        "    transcription = response.text  # Actual transcription from the Groq model\n",
        "    score3, anomalies3 = analyze_transcription_details(transcription)\n",
        "    scores.append(score3)\n",
        "    anomalies.extend(anomalies3)\n",
        "\n",
        "    final_score = float(np.mean(scores))\n",
        "    return DeepfakeAnalysisResult(\n",
        "        score=final_score,\n",
        "        label=\"REAL\" if final_score > 0.7 else \"FAKE\",\n",
        "        confidence=float(np.std(scores)),\n",
        "        method=\"audio_analysis\",\n",
        "        anomalies=anomalies\n",
        "    )"
      ],
      "metadata": {
        "id": "GDaz8dMlu-No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advanced Image Analysis**"
      ],
      "metadata": {
        "id": "bWICXYdq1y2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def advanced_image_analysis(image: np.ndarray, device: torch.device) -> DeepfakeAnalysisResult:\n",
        "    \"\"\"\n",
        "    Detailed image analysis using two VLLM models and one Groq model.\n",
        "    1. llava_image inspects for digital artifacts.\n",
        "    2. clip evaluates image–text consistency.\n",
        "    3. groq_vision_model provides rapid visual anomaly detection.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    anomalies = []\n",
        "\n",
        "    # Model 1: llava_image – artifact detection\n",
        "    model = llava_image.to(device)\n",
        "    prompt1 = (\n",
        "        \"Inspect this image for signs of digital manipulation including lighting inconsistencies, edge artifacts, \"\n",
        "        \"and color mismatches. Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    inputs1 = {\"image\": image, \"text\": prompt1}\n",
        "    with torch.no_grad():\n",
        "        output1 = model.generate(**inputs1)\n",
        "    score1, anomalies1 = parse_model_output(output1)\n",
        "    scores.append(score1)\n",
        "    anomalies.extend(anomalies1)\n",
        "\n",
        "    # Model 2: clip – cross-modal evaluation\n",
        "    model = clip.to(device)\n",
        "    prompt2 = (\n",
        "        \"Evaluate the image against expected textual cues and detect any inconsistencies or signs of tampering. \"\n",
        "        \"Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    inputs2 = {\"image\": image, \"text\": prompt2}\n",
        "    with torch.no_grad():\n",
        "        output2 = model.generate(**inputs2)\n",
        "    score2, anomalies2 = parse_model_output(output2)\n",
        "    scores.append(score2)\n",
        "    anomalies.extend(anomalies2)\n",
        "\n",
        "    # Model 3: groq_vision_model – rapid anomaly detection\n",
        "    _, buffer = cv2.imencode('.png', image)\n",
        "    image_b64 = base64.b64encode(buffer).decode()\n",
        "    response = groq_vision_model.chat_completions.create(\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": (\n",
        "                \"Perform a detailed analysis of the image for digital tampering, focusing on lighting discrepancies, \"\n",
        "                \"color shifts, and edge artifacts. Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "            ),\n",
        "            \"image_url\": \"data:image/png;base64,\" + image_b64\n",
        "        }],\n",
        "        model=\"llama-3.2-90b-vision-preview\"\n",
        "    )\n",
        "    output3 = response.choices[0].message.content\n",
        "    score3, anomalies3 = parse_model_output(output3)\n",
        "    scores.append(score3)\n",
        "    anomalies.extend(anomalies3)\n",
        "\n",
        "    final_score = float(np.mean(scores))\n",
        "    return DeepfakeAnalysisResult(\n",
        "        score=final_score,\n",
        "        label=\"REAL\" if final_score > 0.7 else \"FAKE\",\n",
        "        confidence=float(np.std(scores)),\n",
        "        method=\"image_analysis\",\n",
        "        anomalies=anomalies\n",
        "    )"
      ],
      "metadata": {
        "id": "fVZT1Ci_13nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dlib\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "\n",
        "def analyze_eye_movements(frames: List[np.ndarray], models: Dict[str, Any]) -> List[str]:\n",
        "    anomalies = []\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "    blink_threshold = 0.2\n",
        "    blink_count = 0\n",
        "    for frame in frames:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = detector(gray)\n",
        "\n",
        "        for face in faces:\n",
        "            landmarks = predictor(gray, face)\n",
        "            left_eye_ratio = get_eye_aspect_ratio(landmarks, [36, 37, 38, 39, 40, 41])\n",
        "            right_eye_ratio = get_eye_aspect_ratio(landmarks, [42, 43, 44, 45, 46, 47])\n",
        "            if left_eye_ratio < blink_threshold or right_eye_ratio < blink_threshold:\n",
        "                blink_count += 1\n",
        "\n",
        "    if blink_count > len(frames) * 0.2:  # Example threshold for abnormal blink rate\n",
        "        anomalies.append(\"Abnormal blink rate detected\")\n",
        "\n",
        "    return anomalies\n",
        "\n",
        "def get_eye_aspect_ratio(landmarks, eye_points):\n",
        "    A = np.linalg.norm(np.array([landmarks.part(eye_points[1]).x, landmarks.part(eye_points[1]).y]) -\n",
        "                       np.array([landmarks.part(eye_points[5]).x, landmarks.part(eye_points[5]).y]))\n",
        "    B = np.linalg.norm(np.array([landmarks.part(eye_points[2]).x, landmarks.part(eye_points[2]).y]) -\n",
        "                       np.array([landmarks.part(eye_points[4]).x, landmarks.part(eye_points[4]).y]))\n",
        "    C = np.linalg.norm(np.array([landmarks.part(eye_points[0]).x, landmarks.part(eye_points[0]).y]) -\n",
        "                       np.array([landmarks.part(eye_points[3]).x, landmarks.part(eye_points[3]).y]))\n",
        "    ear = (A + B) / (2.0 * C)\n",
        "    return ear\n",
        "\n",
        "def analyze_facial_blood_flow(frames: List[np.ndarray], models: Dict[str, Any]) -> List[str]:\n",
        "    anomalies = []\n",
        "    mp_face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
        "\n",
        "    for frame in frames:\n",
        "        results = mp_face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        if results.multi_face_landmarks:\n",
        "            for face_landmarks in results.multi_face_landmarks:\n",
        "                if detect_blood_flow_anomaly(frame, face_landmarks):\n",
        "                    anomalies.append(\"Inconsistent blood flow patterns detected\")\n",
        "\n",
        "    return anomalies\n",
        "\n",
        "def detect_blood_flow_anomaly(frame, face_landmarks):\n",
        "    # Example logic to detect blood flow anomalies using color consistency\n",
        "    mean_color = np.mean(frame, axis=(0, 1))\n",
        "    if np.std(mean_color) > 10:  # Example threshold for color inconsistency\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def analyze_physics_based_patterns(frames: List[np.ndarray], models: Dict[str, Any]) -> List[str]:\n",
        "    anomalies = []\n",
        "    for frame in frames:\n",
        "        if detect_physics_anomaly(frame):\n",
        "            anomalies.append(\"Physics-based inconsistencies detected\")\n",
        "    return anomalies\n",
        "\n",
        "def detect_physics_anomaly(frame):\n",
        "    # Example logic for detecting hair movement and shadow consistency\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    if np.mean(edges) > 50:  # Example threshold for detecting sharp edges\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def detect_neural_rendering_artifacts(frames: List[np.ndarray], models: Dict[str, Any]) -> List[str]:\n",
        "    anomalies = []\n",
        "    gan_artifact_model = models[\"gan_artifact_model\"]\n",
        "\n",
        "    for frame in frames:\n",
        "        if detect_gan_artifacts(frame, gan_artifact_model):\n",
        "            anomalies.append(\"Neural rendering artifacts detected\")\n",
        "\n",
        "    return anomalies\n",
        "\n",
        "def detect_gan_artifacts(frame, model):\n",
        "    # Example logic for detecting GAN artifacts using a neural network\n",
        "    resized_frame = cv2.resize(frame, (224, 224))\n",
        "    frame_tensor = torch.tensor(resized_frame).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
        "    with torch.no_grad():\n",
        "        output = model(frame_tensor.to(device))\n",
        "    if output.argmax() == 1:  # Assuming the model outputs 1 for GAN artifacts\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "HB7oFZEZy05y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advanced Video Analysis**"
      ],
      "metadata": {
        "id": "MlQVINuo1_2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def advanced_video_analysis(video_data: Dict[str, Any], device: torch.device) -> DeepfakeAnalysisResult:\n",
        "    \"\"\"\n",
        "    Detailed video analysis using three VLLM models.\n",
        "    1. llava_next_video analyzes motion irregularities.\n",
        "    2. xclip evaluates the consistency of a representative frame.\n",
        "    3. videomae extracts spatiotemporal features.\n",
        "    Each model is prompted to return output in a standard format.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    anomalies = []\n",
        "\n",
        "    # Model 1: llava_next_video – motion and facial expression analysis\n",
        "    model = llava_next_video.to(device)\n",
        "    prompt1 = (\n",
        "        \"Analyze the following video frames for subtle motion irregularities, unnatural blinking, \"\n",
        "        \"and inconsistent facial expressions. Provide output in the format:\\n\"\n",
        "        \"Score: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    inputs1 = {\"video\": video_data.get(\"frames\"), \"text\": prompt1}\n",
        "    with torch.no_grad():\n",
        "        output1 = model.generate(**inputs1)  # Assume output1 is a text string\n",
        "    score1, anomalies1 = parse_model_output(output1)\n",
        "    scores.append(score1)\n",
        "    anomalies.extend(anomalies1)\n",
        "\n",
        "    # Model 2: xclip – cross-modal embedding consistency check\n",
        "    model = xclip.to(device)\n",
        "    prompt2 = (\n",
        "        \"Evaluate the consistency of the given video frame with its contextual description. \"\n",
        "        \"Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    rep_frame = video_data.get(\"frames\")[0]\n",
        "    inputs2 = {\"image\": rep_frame, \"text\": prompt2}\n",
        "    with torch.no_grad():\n",
        "        output2 = model.generate(**inputs2)\n",
        "    score2, anomalies2 = parse_model_output(output2)\n",
        "    scores.append(score2)\n",
        "    anomalies.extend(anomalies2)\n",
        "\n",
        "    # Model 3: videomae – spatiotemporal feature extraction\n",
        "    model = videomae.to(device)\n",
        "    prompt3 = (\n",
        "        \"Extract spatiotemporal features from the provided video frames to detect any signs of digital tampering. \"\n",
        "        \"Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    inputs3 = {\"video\": video_data.get(\"frames\"), \"text\": prompt3}\n",
        "    with torch.no_grad():\n",
        "        output3 = model.generate(**inputs3)\n",
        "    score3, anomalies3 = parse_model_output(output3)\n",
        "    scores.append(score3)\n",
        "    anomalies.extend(anomalies3)\n",
        "\n",
        "    final_score = float(np.mean(scores))\n",
        "    return DeepfakeAnalysisResult(\n",
        "        score=final_score,\n",
        "        label=\"REAL\" if final_score > 0.7 else \"FAKE\",\n",
        "        confidence=float(np.std(scores)),\n",
        "        method=\"video_analysis\",\n",
        "        anomalies=anomalies\n",
        "    )"
      ],
      "metadata": {
        "id": "jRAPWt8u2IsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, XCLIPModel\n",
        "from vllm import LLM, SamplingParams\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def lip_sync_detection(frames: List[Any], audio_text: str, threshold: float = 0.7) -> DeepfakeAnalysisResult:\n",
        "    \"\"\"\n",
        "    Detect lip synchronization by comparing features extracted from video frames and audio text.\n",
        "    Uses ensemble extraction from both VLLM and Groq text models.\n",
        "    \"\"\"\n",
        "    # Process video frames using XCLIP to obtain video features.\n",
        "    video_inputs = xclip_processor(videos=list(frames), return_tensors=\"pt\")\n",
        "    video_features = xclip_model.get_video_features(**video_inputs).mean(dim=1)\n",
        "\n",
        "    # Extract text features using VLLM text model with a detailed prompt.\n",
        "    sampling_params = SamplingParams(temperature=0, max_tokens=64)\n",
        "    prompt_vllm = f\"Extract detailed semantic features from the following audio description for lip sync analysis: {audio_text}\"\n",
        "    vllm_text_output = vllm_text_model.generate(inputs=[prompt_vllm], sampling_params=sampling_params)\n",
        "    vllm_text_features = vllm_text_output[0].mean(dim=1)\n",
        "\n",
        "    # Extract text features using Groq text model with an equally detailed prompt.\n",
        "    groq_prompt = f\"Provide semantic feature extraction for lip sync detection from the audio: {audio_text}\"\n",
        "    groq_response = groq_text_model.chat_completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": groq_prompt}],\n",
        "        model=\"llama-3.3-70b-versatile\"\n",
        "    )\n",
        "    groq_text_str = groq_response.choices[0].message.content\n",
        "    # Extract numeric features from the response (in production, use proper embedding extraction)\n",
        "    nums = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", groq_text_str)\n",
        "    groq_text_features = torch.tensor([float(x) for x in nums]).unsqueeze(0)\n",
        "\n",
        "    # Combine features from both text models\n",
        "    combined_text_features = (vllm_text_features + groq_text_features) / 2.0\n",
        "\n",
        "    # Normalize features and compute cosine similarity\n",
        "    video_norm = video_features / video_features.norm(dim=1, keepdim=True)\n",
        "    text_norm = combined_text_features / combined_text_features.norm(dim=1, keepdim=True)\n",
        "    sync_scores = torch.nn.functional.cosine_similarity(video_norm, text_norm)\n",
        "    final_score = torch.mean(sync_scores).item()\n",
        "    confidence = torch.std(sync_scores).item()\n",
        "\n",
        "    anomalies = [\"Lip-sync inconsistency detected\"] if final_score < threshold else []\n",
        "    result_label = \"REAL\" if final_score > threshold else \"FAKE\"\n",
        "    return DeepfakeAnalysisResult(score=final_score, label=result_label, confidence=confidence,\n",
        "                                  method=\"lip_sync_detection\", anomalies=anomalies)"
      ],
      "metadata": {
        "id": "49tH6GarH7Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_consistency_analysis(results: Dict[str, DeepfakeAnalysisResult], llms: Dict[str, Any]) -> float:\n",
        "    \"\"\"\n",
        "    Analyze the semantic consistency between modalities using an advanced prompt.\n",
        "    The prompt asks the LLM to consider narrative coherence, temporal alignment, and emotional consistency.\n",
        "    \"\"\"\n",
        "    prompt_template = (\n",
        "        \"Analyze the following modality analyses for overall semantic consistency:\\n\\n\"\n",
        "        \"Video Analysis: {video_analysis}\\n\"\n",
        "        \"Audio Analysis: {audio_analysis}\\n\"\n",
        "        \"Image Analysis: {image_analysis}\\n\"\n",
        "        \"Text Analysis: {text_analysis}\\n\\n\"\n",
        "        \"Evaluate narrative coherence, logical contradictions, and emotional alignment. \"\n",
        "        \"Provide a score between 0 and 1 (where 1 is perfectly consistent) along with detailed reasoning.\\n\"\n",
        "        \"Output format:\\nScore: <score>\\nReasoning: <explanation>\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "    chain = LLMChain(llm=llms[\"llava\"], prompt=prompt)\n",
        "    response = chain.run({\n",
        "        \"video_analysis\": results[\"video\"].__dict__,\n",
        "        \"audio_analysis\": results[\"audio\"].__dict__,\n",
        "        \"image_analysis\": results[\"image\"].__dict__,\n",
        "        \"text_analysis\": results[\"text\"].__dict__\n",
        "    })\n",
        "    score_match = re.search(r\"Score:\\s*([0-9]*\\.?[0-9]+)\", response)\n",
        "    if score_match:\n",
        "        return float(score_match.group(1))\n",
        "    return 0.5"
      ],
      "metadata": {
        "id": "8K7h2pSWEbO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def face_forgery_detection(video_data: Dict[str, Any], device: torch.device, threshold: float = 0.0) -> DeepfakeAnalysisResult:\n",
        "    \"\"\"\n",
        "    Improved face forgery detection using an ensemble of two models:\n",
        "\n",
        "    1. VLLM Component (CLIP/xclip):\n",
        "       - Processes all face images (cropped from video frames) to extract image features.\n",
        "       - Computes text features for the prompts \"a real face\" and \"a manipulated face\".\n",
        "       - Calculates cosine similarity difference (similarity_real - similarity_fake) as score_vllm.\n",
        "\n",
        "    2. Groq Component:\n",
        "       - Uses a detailed prompt with the Groq vision model via its chat-completions API.\n",
        "       - The input face image (first frame) is encoded and sent; the response is parsed to yield score_groq and anomalies.\n",
        "\n",
        "    The final score is the average of score_vllm and score_groq. A positive combined score indicates REAL, while a negative one indicates FAKE.\n",
        "\n",
        "    Returns:\n",
        "        DeepfakeAnalysisResult with final score, label, confidence, method, and anomalies.\n",
        "    \"\"\"\n",
        "    # -- VLLM Component using CLIP --\n",
        "    try:\n",
        "        processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "        clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n",
        "    except Exception as e:\n",
        "        print(\"Error loading CLIP model:\", e)\n",
        "        return DeepfakeAnalysisResult(0, \"ERROR\", 0, \"face_forgery_detection\", [\"CLIP load error\"])\n",
        "\n",
        "    frames = video_data.get(\"frames\", [])\n",
        "    if not frames:\n",
        "        return DeepfakeAnalysisResult(0, \"ERROR\", 0, \"face_forgery_detection\", [\"No frames provided\"])\n",
        "\n",
        "    inputs = processor(images=frames, return_tensors=\"pt\", padding=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        image_features = clip_model.get_image_features(**inputs)\n",
        "    # Average features across frames\n",
        "    image_features = image_features.mean(dim=0, keepdim=True)\n",
        "\n",
        "    # Prepare text prompts and compute text embeddings.\n",
        "    text_prompts = [\"a real face\", \"a manipulated face\"]\n",
        "    text_inputs = processor(text=text_prompts, return_tensors=\"pt\", padding=True)\n",
        "    text_inputs = {k: v.to(device) for k, v in text_inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        text_features = clip_model.get_text_features(**text_inputs)\n",
        "\n",
        "    # Normalize and compute cosine similarities.\n",
        "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "    similarities = torch.matmul(image_features, text_features.T)  # shape (1, 2)\n",
        "    similarity_real = similarities[0, 0].item()\n",
        "    similarity_fake = similarities[0, 1].item()\n",
        "    score_vllm = similarity_real - similarity_fake\n",
        "    anomalies_vllm = []  # Optionally flag low score here.\n",
        "    if score_vllm < threshold:\n",
        "        anomalies_vllm.append(\"CLIP indicates potential forgery\")\n",
        "\n",
        "    # -- Groq Component --\n",
        "    # Assume groq_vision_model is already initialized in your environment.\n",
        "    try:\n",
        "        # Convert the first face image to base64-encoded PNG.\n",
        "        first_frame = frames[0]\n",
        "        _, buffer = cv2.imencode('.png', first_frame)\n",
        "        image_b64 = base64.b64encode(buffer).decode()\n",
        "        groq_prompt = (\n",
        "            \"Perform a detailed analysis of the face image for signs of digital manipulation. \"\n",
        "            \"Return the result in the following format:\\n\"\n",
        "            \"Score: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "        )\n",
        "        groq_response = groq_vision_model.chat_completions.create(\n",
        "            messages=[{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": groq_prompt,\n",
        "                \"image_url\": \"data:image/png;base64,\" + image_b64\n",
        "            }],\n",
        "            model=\"llama-3.2-90b-vision-preview\"\n",
        "        )\n",
        "        response_text = groq_response.choices[0].message.content\n",
        "        score_groq, anomalies_groq = robust_parse_output(response_text)\n",
        "    except Exception as e:\n",
        "        print(\"Error in Groq analysis:\", e)\n",
        "        score_groq = 0.0\n",
        "        anomalies_groq = [\"Groq analysis error\"]\n",
        "\n",
        "    # -- Fusion of VLLM and Groq Outputs --\n",
        "    combined_score = (score_vllm + score_groq) / 2.0\n",
        "    combined_anomalies = anomalies_vllm + anomalies_groq\n",
        "    # Confidence can be defined as the absolute difference between the two model scores.\n",
        "    confidence = abs(score_vllm - score_groq)\n",
        "    label = \"REAL\" if combined_score > threshold else \"FAKE\"\n",
        "\n",
        "    return DeepfakeAnalysisResult(\n",
        "        score=combined_score,\n",
        "        label=label,\n",
        "        confidence=confidence,\n",
        "        method=\"face_forgery_detection\",\n",
        "        anomalies=combined_anomalies\n",
        "    )"
      ],
      "metadata": {
        "id": "q61-4f7OEeJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def background_consistency_analysis(video_data: Dict[str, Any], models: Dict[str, Any], device: torch.device) -> DeepfakeAnalysisResult:\n",
        "    \"\"\"\n",
        "    Analyze background consistency using an ensemble approach.\n",
        "    Uses a VLLM-based Vision Transformer (ViT) and a Groq vision model.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    anomalies = []\n",
        "    # Model 1: VLLM-based background analysis using ViT.\n",
        "    model = models[\"vision\"].to(device)\n",
        "    vit_processor = AutoProcessor.from_pretrained(Config.MODEL_PATHS[\"clip_processor\"])\n",
        "    inputs = vit_processor(images=video_data[\"frames\"], return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        output_text = model.generate(**inputs)\n",
        "    score1, anomalies1 = parse_model_output(output_text)\n",
        "    scores.append(score1)\n",
        "    anomalies.extend(anomalies1)\n",
        "\n",
        "    # Model 2: Groq vision model for rapid background analysis.\n",
        "    _, buffer = cv2.imencode('.png', video_data[\"frames\"][0])\n",
        "    image_b64 = base64.b64encode(buffer).decode()\n",
        "    response = models[\"groq_vision\"].chat_completions.create(\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": (\n",
        "                \"Perform a detailed background analysis of the provided video frame to detect digital tampering. \"\n",
        "                \"Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "            ),\n",
        "            \"image_url\": \"data:image/png;base64,\" + image_b64\n",
        "        }],\n",
        "        model=\"llama-3.2-90b-vision-preview\"\n",
        "    )\n",
        "    output_text_groq = response.choices[0].message.content\n",
        "    score2, anomalies2 = parse_model_output(output_text_groq)\n",
        "    scores.append(score2)\n",
        "    anomalies.extend(anomalies2)\n",
        "\n",
        "    final_score = float(np.mean(scores))\n",
        "    return DeepfakeAnalysisResult(score=final_score, label=\"REAL\" if final_score > 0.7 else \"FAKE\",\n",
        "                                  confidence=float(np.std(scores)), method=\"background_consistency_analysis\", anomalies=anomalies)"
      ],
      "metadata": {
        "id": "r_JDhnaAEkUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_temporal_coherence(temporal_features: List[Dict[str, Any]]) -> float:\n",
        "    anomalies = []\n",
        "    for feature in temporal_features:\n",
        "        if feature[\"magnitude\"].max() > 1.0:\n",
        "            anomalies.append(\"Abrupt changes in motion detected\")\n",
        "    return 1.0 - (len(anomalies) / len(temporal_features))"
      ],
      "metadata": {
        "id": "fnLHMoz0Epy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Tool Creation Functions**\n",
        "- Define functions for creating deepfake detection tools and agents"
      ],
      "metadata": {
        "id": "HoftOwSUZPye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_deepfake_detection_tools(models: Dict[str, Any], device: torch.device) -> List[Tool]:\n",
        "    tools = [\n",
        "        Tool(\n",
        "            name=\"analyze_video\",\n",
        "            func=lambda x: advanced_video_analysis(x, models, device),\n",
        "            description=\"Analyzes video content for signs of manipulation\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"analyze_audio\",\n",
        "            func=lambda x: advanced_audio_analysis(x, models, device),\n",
        "            description=\"Analyzes audio content for signs of manipulation\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"analyze_image\",\n",
        "            func=lambda x: advanced_image_analysis(x, models, device),\n",
        "            description=\"Analyzes image content for signs of manipulation\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"semantic_analysis\",\n",
        "            func=lambda x: semantic_consistency_analysis(x, models[\"llms\"]),\n",
        "            description=\"Analyzes semantic consistency across modalities\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"face_forgery_detection\",\n",
        "            func=lambda x: face_forgery_detection(x, models, device),\n",
        "            description=\"Detects face forgeries in video content\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"lip_sync_detection\",\n",
        "            func=lambda x: lip_sync_detection(x, models, device),\n",
        "            description=\"Analyzes lip-sync consistency between audio and video\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"background_consistency\",\n",
        "            func=lambda x: background_consistency_analysis(x, models, device),\n",
        "            description=\"Analyzes background consistency across frames\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"real_time_streaming_analysis\",\n",
        "            func=lambda x: real_time_streaming_analysis(x, models, device),\n",
        "            description=\"Analyzes live video streams for signs of manipulation\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"text_analysis\",\n",
        "            func=lambda x: text_analysis(x, models[\"llms\"]),\n",
        "            description=\"Analyzes text content for signs of manipulation\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"metadata_analysis\",\n",
        "            func=lambda x: metadata_analysis(x),\n",
        "            description=\"Analyzes metadata for signs of manipulation\"\n",
        "        )\n",
        "    ]\n",
        "    return tools"
      ],
      "metadata": {
        "id": "PEWzNSs3ZGK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Detection Agent**\n",
        "- Define the detection graph for processing the input data"
      ],
      "metadata": {
        "id": "IgsLH-Xp2eW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
        "from langchain.schema import AgentAction, AgentFinish\n",
        "from langchain.tools import Tool\n",
        "\n",
        "def create_detection_agent(tools: List[Tool], llm: ChatOpenAI) -> AgentExecutor:\n",
        "    class DeepfakeDetectionOutputParser:\n",
        "        def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
        "            try:\n",
        "                if \"Final Answer:\" in llm_output:\n",
        "                    return AgentFinish(\n",
        "                        return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
        "                        log=llm_output,\n",
        "                    )\n",
        "                action_match = re.search(r\"Action: (.*?)\\nAction Input: (.*)\", llm_output, re.DOTALL)\n",
        "                if not action_match:\n",
        "                    raise ValueError(\"Could not parse LLM output: \" + llm_output)\n",
        "                action = action_match.group(1).strip()\n",
        "                action_input = action_match.group(2).strip()\n",
        "                return AgentAction(tool=action, tool_input=action_input, log=llm_output)\n",
        "            except Exception as e:\n",
        "                raise ValueError(f\"Could not parse LLM output: {llm_output}\") from e\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        SystemMessagePromptTemplate.from_template(\"\"\"\n",
        "            You are an expert forensic deepfake detection analyst.\n",
        "            You have received detailed outputs from various specialized modality tools:\n",
        "            - Video (spatiotemporal analysis)\n",
        "            - Audio (transcription and acoustic anomaly analysis)\n",
        "            - Image (ensemble analysis using multiple vision models)\n",
        "            - Text (extraction and reasoning)\n",
        "            - Face forgery and background consistency analysis\n",
        "            Your task is to review these outputs and provide a comprehensive, step-by-step explanation of the findings.\n",
        "            For each modality:\n",
        "              1. Summarize the key evidence.\n",
        "              2. Explain any detected anomalies or inconsistencies.\n",
        "            Finally, provide an overall verdict on the authenticity of the media and justify your decision.\n",
        "            Format your response as:\n",
        "            Action: [Tool Name]\n",
        "            Action Input: [Summary of results]\n",
        "            Observation: [Detailed step-by-step reasoning]\n",
        "            Final Answer: [Overall verdict with supporting details]\n",
        "            Available tools: {tools}\n",
        "        \"\"\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{input}\")\n",
        "    ])\n",
        "\n",
        "    return AgentExecutor.from_agent_and_tools(\n",
        "        agent=LLMSingleActionAgent(\n",
        "            llm_chain=LLMChain(llm=llm, prompt=prompt),\n",
        "            output_parser=DeepfakeDetectionOutputParser(),\n",
        "            stop=[\"Observation:\", \"Final Answer:\"],\n",
        "            allowed_tools=[tool.name for tool in tools]\n",
        "        ),\n",
        "        tools=tools,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "def create_detection_graph() -> StateGraph:\n",
        "    def preprocess(state):\n",
        "        input_data = state[\"input\"]\n",
        "        processed_data = asyncio.run(enhanced_preprocessing(input_data))\n",
        "        return {**state, \"processed_data\": processed_data}\n",
        "\n",
        "    def analyze_modalities(state):\n",
        "        processed_data = state[\"processed_data\"]\n",
        "        models = state[\"models\"]\n",
        "        device = state[\"device\"]\n",
        "        results = {\n",
        "            \"video\": asyncio.run(advanced_video_analysis(processed_data, models, device)) if \"frames\" in processed_data else None,\n",
        "            \"audio\": asyncio.run(advanced_audio_analysis(processed_data.get(\"audio\"), models, device)) if \"audio\" in processed_data else None,\n",
        "            \"image\": asyncio.run(advanced_image_analysis(processed_data[\"image\"], models, device)) if \"image\" in processed_data else None,\n",
        "            \"text\": asyncio.run(text_analysis(processed_data.get(\"text\"), models[\"llms\"])) if \"text\" in processed_data else None,\n",
        "            \"face_forgery\": face_forgery_detection(processed_data, models, device) if \"frames\" in processed_data else None,\n",
        "            \"background\": background_consistency_analysis(processed_data, models, device) if \"frames\" in processed_data else None\n",
        "        }\n",
        "        return {**state, \"modality_results\": results}\n",
        "\n",
        "    def cross_modal_analysis(state):\n",
        "        results = state[\"modality_results\"]\n",
        "        processed_data = state[\"processed_data\"]\n",
        "        models = state[\"models\"]\n",
        "        cross_modal_score = analyze_cross_modal_consistency(results, processed_data, models)\n",
        "        return {**state, \"cross_modal_score\": cross_modal_score}\n",
        "\n",
        "    def generate_report(state):\n",
        "        results = state[\"modality_results\"]\n",
        "        cross_modal_score = state[\"cross_modal_score\"]\n",
        "        processed_data = state[\"processed_data\"]\n",
        "        report = generate_comprehensive_report(results, cross_modal_score, processed_data)\n",
        "        return {**state, \"final_report\": report}\n",
        "\n",
        "    workflow = StateGraph(nodes=[\n",
        "        (\"preprocess\", preprocess),\n",
        "        (\"analyze_modalities\", analyze_modalities),\n",
        "        (\"cross_modal_analysis\", cross_modal_analysis),\n",
        "        (\"generate_report\", generate_report)\n",
        "    ])\n",
        "    workflow.add_edge(\"preprocess\", \"analyze_modalities\")\n",
        "    workflow.add_edge(\"analyze_modalities\", \"cross_modal_analysis\")\n",
        "    workflow.add_edge(\"cross_modal_analysis\", \"generate_report\")\n",
        "    workflow.add_edge(\"generate_report\", END)\n",
        "    return workflow"
      ],
      "metadata": {
        "id": "epoIrEie2nx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Functions for Analyzing Cross-Modal Consistency and Generating Reports**"
      ],
      "metadata": {
        "id": "EF3CZ3zAaAPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_cross_modal_consistency(\n",
        "    results: Dict[str, DeepfakeAnalysisResult],\n",
        "    processed_data: Dict[str, Any],\n",
        "    models: Dict[str, Any]\n",
        ") -> float:\n",
        "    scores = []\n",
        "    if results[\"audio\"] and results[\"video\"]:\n",
        "        sync_score = analyze_av_sync(processed_data[\"frames\"], processed_data[\"audio\"])\n",
        "        scores.append(sync_score)\n",
        "    semantic_score = analyze_semantic_consistency(results, processed_data, models[\"llms\"])\n",
        "    scores.append(semantic_score)\n",
        "    temporal_score = analyze_temporal_coherence(processed_data[\"temporal_features\"])\n",
        "    scores.append(temporal_score)\n",
        "    bio_score = analyze_biometric_consistency(processed_data[\"frames\"], models)\n",
        "    scores.append(bio_score)\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "def analyze_semantic_consistency(\n",
        "    results: Dict[str, DeepfakeAnalysisResult],\n",
        "    processed_data: Dict[str, Any],\n",
        "    llms: Dict[str, ChatOpenAI]\n",
        ") -> float:\n",
        "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "        Analyze the consistency between different modalities in the content:\n",
        "\n",
        "        Video Analysis: {video_analysis}\n",
        "        Audio Analysis: {audio_analysis}\n",
        "        Image Analysis: {image_analysis}\n",
        "        Text Analysis: {text_analysis}\n",
        "\n",
        "        Consider:\n",
        "        1. Do the modalities tell a coherent story?\n",
        "        2. Are there logical contradictions?\n",
        "        3. Do temporal patterns align?\n",
        "        4. Is the emotional content consistent?\n",
        "\n",
        "        Rate the consistency from 0 to 1, where 1 is perfectly consistent.\n",
        "        Provide detailed reasoning for your rating.\n",
        "\n",
        "        Output format:\n",
        "        Score: [0-1]\n",
        "        Reasoning: [detailed explanation]\n",
        "    \"\"\")\n",
        "    chain = LLMChain(llm=llms[\"gpt4\"], prompt=prompt)\n",
        "    response = chain.run({\n",
        "        \"video_analysis\": results[\"video\"].dict() if results[\"video\"] else \"N/A\",\n",
        "        \"audio_analysis\": results[\"audio\"].dict() if results[\"audio\"] else \"N/A\",\n",
        "        \"image_analysis\": results[\"image\"].dict() if results[\"image\"] else \"N/A\",\n",
        "        \"text_analysis\": results[\"text\"].dict() if results[\"text\"] else \"N/A\"\n",
        "    })\n",
        "    score_match = re.search(r\"Score: (0\\.\\d+|1\\.0)\", response)\n",
        "    if score_match:\n",
        "        return float(score_match.group(1))\n",
        "    return 0.5\n",
        "\n",
        "def generate_comprehensive_report(\n",
        "    results: Dict[str, DeepfakeAnalysisResult],\n",
        "    cross_modal_score: float,\n",
        "    processed_data: Dict[str, Any]\n",
        ") -> MultimodalAnalysisReport:\n",
        "    scores = [\n",
        "        results[\"video\"].score if results[\"video\"] else 0.5,\n",
        "        results[\"audio\"].score if results[\"audio\"] else 0.5,\n",
        "        results[\"image\"].score if results[\"image\"] else 0.5,\n",
        "        results[\"text\"].score if results[\"text\"] else 0.5,\n",
        "        cross_modal_score\n",
        "    ]\n",
        "    weights = [0.3, 0.2, 0.2, 0.2, 0.1]\n",
        "    final_score = sum(s * w for s, w in zip(scores, weights))\n",
        "    evidence = []\n",
        "    for modality, result in results.items():\n",
        "        if result:\n",
        "            evidence.extend([\n",
        "                {\n",
        "                    \"type\": modality,\n",
        "                    \"description\": anomaly,\n",
        "                    \"confidence\": result.confidence,\n",
        "                    \"method\": result.method\n",
        "                }\n",
        "                for anomaly in result.anomalies\n",
        "            ])\n",
        "    return MultimodalAnalysisReport(\n",
        "        case_id=f\"DFD-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
        "        file_info=processed_data[\"metadata\"] if \"metadata\" in processed_data else {},\n",
        "        video_analysis=results[\"video\"],\n",
        "        audio_analysis=results[\"audio\"],\n",
        "        image_analysis=results[\"image\"],\n",
        "        text_analysis=results[\"text\"],\n",
        "        multimodal_score=float(final_score),\n",
        "        verdict=\"AUTHENTIC\" if final_score > 0.7 else \"MANIPULATED\",\n",
        "        evidence=evidence,\n",
        "        metadata={\n",
        "            \"processing_time\": datetime.now().isoformat(),\n",
        "            \"models_used\": list(results.keys()),\n",
        "            \"cross_modal_score\": cross_modal_score,\n",
        "            \"confidence_distribution\": {\n",
        "                modality: result.confidence\n",
        "                for modality, result in results.items() if result\n",
        "            }\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "id": "H0mTuH2hZ5de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Real-Time Streaming Analysis**\n",
        "- Define a function for real-time streaming analysis"
      ],
      "metadata": {
        "id": "Ov48BT01aOO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def real_time_streaming_analysis(video_stream: Any, models: Dict[str, Any], device: torch.device) -> DeepfakeAnalysisResult:\n",
        "    frames = []\n",
        "    audio_data = None\n",
        "    metadata = {\n",
        "        \"fps\": 30,\n",
        "        \"frame_count\": 0,\n",
        "        \"width\": 0,\n",
        "        \"height\": 0,\n",
        "        \"duration\": 0,\n",
        "        \"codec\": \"N/A\",\n",
        "        \"file_size\": 0\n",
        "    }\n",
        "    frame_quality_metrics = []\n",
        "    optical_flow_data = []\n",
        "    prev_frame = None\n",
        "    temporal_features = []\n",
        "\n",
        "    loop = asyncio.get_event_loop()\n",
        "    executor = ThreadPoolExecutor(max_workers=4)\n",
        "\n",
        "    async def process_frame(frame):\n",
        "        return await loop.run_in_executor(executor, enhance_image_resolution, frame)\n",
        "\n",
        "    async def process_quality_metrics(frame):\n",
        "        return await loop.run_in_executor(executor, lambda: {\n",
        "            \"blur\": cv2.Laplacian(frame, cv2.CV_64F).var(),\n",
        "            \"noise\": estimate_noise(frame),\n",
        "            \"brightness\": np.mean(frame),\n",
        "            \"contrast\": calculate_contrast(frame),\n",
        "            \"compression_artifacts\": detect_compression_artifacts(frame)\n",
        "        })\n",
        "\n",
        "    async def process_optical_flow(prev_frame, frame):\n",
        "        return await loop.run_in_executor(executor, calculate_dense_optical_flow, prev_frame, frame)\n",
        "\n",
        "    async def process_temporal_features(flow):\n",
        "        return await loop.run_in_executor(executor, extract_temporal_features, flow)\n",
        "\n",
        "    while True:\n",
        "        frame = await video_stream.read()\n",
        "        if frame is None:\n",
        "            break\n",
        "        frame, quality_metrics = await asyncio.gather(\n",
        "            process_frame(frame),\n",
        "            process_quality_metrics(frame)\n",
        "        )\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frames.append(rgb_frame)\n",
        "        frame_quality_metrics.append(quality_metrics)\n",
        "        if prev_frame is not None:\n",
        "            flow, temp_features = await asyncio.gather(\n",
        "                process_optical_flow(prev_frame, frame),\n",
        "                process_temporal_features(flow)\n",
        "            )\n",
        "            optical_flow_data.append(flow)\n",
        "            temporal_features.append(temp_features)\n",
        "        prev_frame = frame.copy()\n",
        "\n",
        "    video_data = {\n",
        "        \"frames\": frames,\n",
        "        \"audio\": audio_data,\n",
        "        \"metadata\": metadata,\n",
        "        \"quality_metrics\": frame_quality_metrics,\n",
        "        \"optical_flow\": optical_flow_data,\n",
        "        \"temporal_features\": temporal_features\n",
        "    }\n",
        "\n",
        "    return await advanced_video_analysis(video_data, models, device)"
      ],
      "metadata": {
        "id": "e6-q4yeeaKEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Text Analysis**\n",
        "- Define a function for text analysis using Groq models:"
      ],
      "metadata": {
        "id": "hHpkFFGDaqtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def text_analysis(text: str, llms: Dict[str, ChatOpenAI]) -> DeepfakeAnalysisResult:\n",
        "    response = groq_client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Analyze the following text for signs of manipulation or inconsistencies:\\n\\n{text}\"\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "    )\n",
        "    content = response.choices[0].message.content\n",
        "    score_match = re.search(r\"Score: (0\\.\\d+|1\\.0)\", content)\n",
        "    if score_match:\n",
        "        score = float(score_match.group(1))\n",
        "    else:\n",
        "        score = 0.5\n",
        "    anomalies = [line.strip() for line in content.split(\"Reasoning:\")[-1].strip().split(\"\\n\") if line.strip()]\n",
        "    return DeepfakeAnalysisResult(\n",
        "        score=score,\n",
        "        label=\"REAL\" if score > 0.7 else \"FAKE\",\n",
        "        confidence=0.0,\n",
        "        method=\"text_analysis\",\n",
        "        anomalies=anomalies\n",
        "    )"
      ],
      "metadata": {
        "id": "UpL42dfZaRF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Metadata Analysis**\n",
        "- Define a function for metadata analysis"
      ],
      "metadata": {
        "id": "8WGV0gpibBij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metadata_analysis(metadata: Dict[str, Any]) -> DeepfakeAnalysisResult:\n",
        "    anomalies = []\n",
        "    scores = []\n",
        "\n",
        "    if metadata.get(\"fps\") < 10:\n",
        "        anomalies.append(\"Unusually low frame rate\")\n",
        "        scores.append(0.2)\n",
        "    if metadata.get(\"duration\") < 1:\n",
        "        anomalies.append(\"Unusually short duration\")\n",
        "        scores.append(0.2)\n",
        "    if metadata.get(\"file_size\") < 100000:\n",
        "        anomalies.append(\"Unusually small file size\")\n",
        "        scores.append(0.2)\n",
        "\n",
        "    final_score = np.mean(scores) if scores else 0.5\n",
        "    return DeepfakeAnalysisResult(\n",
        "        score=float(final_score),\n",
        "        label=\"REAL\" if final_score > 0.7 else \"FAKE\",\n",
        "        confidence=float(np.std(scores)) if scores else 0.0,\n",
        "        method=\"metadata_analysis\",\n",
        "        anomalies=anomalies\n",
        "    )"
      ],
      "metadata": {
        "id": "lr_VZJS_aRIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the Main Function**\n",
        "- Define the main function to run the deepfake detection system"
      ],
      "metadata": {
        "id": "iZRCoZgobKdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import asyncio\n",
        "from datetime import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "lwK0ZBvj6NxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_uploaded_file(uploaded_file):\n",
        "    \"\"\"\n",
        "    Saves the uploaded file to a local directory and returns its file path.\n",
        "    \"\"\"\n",
        "    file_name = uploaded_file['metadata']['name']\n",
        "    upload_dir = \"uploads\"\n",
        "    os.makedirs(upload_dir, exist_ok=True)\n",
        "    file_path = os.path.join(upload_dir, file_name)\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        f.write(uploaded_file['content'])\n",
        "    return file_path"
      ],
      "metadata": {
        "id": "gWC65JLB89k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def run_deepfake_detection(file_path: str, mode: str = \"all\") -> MultimodalAnalysisReport:\n",
        "    \"\"\"\n",
        "    Runs the deepfake detection pipeline asynchronously.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        state = {\n",
        "            \"input\": file_path,\n",
        "            \"mode\": mode,\n",
        "            \"models\": env[\"models\"],\n",
        "            \"device\": env[\"device\"]\n",
        "        }\n",
        "        workflow = create_detection_graph()\n",
        "        final_state = workflow.run(state)\n",
        "        return final_state[\"final_report\"]\n",
        "    except Exception as e:\n",
        "        print(f\"[{datetime.now()}] Error in deepfake detection: {str(e)}\")\n",
        "        raise RuntimeError(\"Deepfake detection failed. Check input and models.\") from e"
      ],
      "metadata": {
        "id": "yAEKfJjTyDVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Enhanced UI with ipywidgets\n",
        "# ---------------------------\n",
        "\n",
        "# File upload widget with custom style.\n",
        "file_upload = widgets.FileUpload(\n",
        "    accept='',\n",
        "    multiple=False,\n",
        "    description='Upload File',\n",
        "    style={'button_color': 'lightblue'},\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "# Dropdown to choose detection mode.\n",
        "mode_dropdown = widgets.Dropdown(\n",
        "    options=[('All', 'all'), ('Audio', 'audio'), ('Video', 'video'), ('Image', 'image')],\n",
        "    value='all',\n",
        "    description='Mode:',\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "# Start button with a clear label.\n",
        "start_button = widgets.Button(\n",
        "    description=\"Start Detection\",\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "# Progress bar for visual feedback.\n",
        "progress_bar = widgets.IntProgress(\n",
        "    value=0,\n",
        "    min=0,\n",
        "    max=10,\n",
        "    description='Progress:',\n",
        "    bar_style='info',\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "# Log output widget (scrollable for lengthy logs).\n",
        "log_output = widgets.Output(layout={'border': '1px solid black', 'height': '200px', 'overflow_y': 'auto'})\n",
        "\n",
        "# Global variable to store the uploaded file path.\n",
        "uploaded_file_path = None\n",
        "\n",
        "def on_file_upload_change(change):\n",
        "    global uploaded_file_path\n",
        "    if file_upload.value:\n",
        "        uploaded_file = list(file_upload.value.values())[0]\n",
        "        uploaded_file_path = save_uploaded_file(uploaded_file)\n",
        "        with log_output:\n",
        "            clear_output()\n",
        "            print(f\"[{datetime.now()}] File uploaded: {uploaded_file_path}\")\n",
        "        start_button.disabled = False\n",
        "\n",
        "async def process_detection(file_path, mode):\n",
        "    with log_output:\n",
        "        clear_output()\n",
        "        print(f\"[{datetime.now()}] Starting deepfake detection for file:\\n{file_path}\\nin mode: {mode}\\n\")\n",
        "    progress_bar.value = 0\n",
        "    # Simulate processing with periodic progress updates.\n",
        "    for i in range(10):\n",
        "        await asyncio.sleep(1)\n",
        "        progress_bar.value = i + 1\n",
        "    report = await run_deepfake_detection(file_path, mode)\n",
        "    with log_output:\n",
        "        print(\"\\nFinal Forensic Report:\")\n",
        "        print(json.dumps(report.dict(), indent=2, default=str))\n",
        "\n",
        "def on_start_button_click(b):\n",
        "    if uploaded_file_path:\n",
        "        asyncio.run(process_detection(uploaded_file_path, mode_dropdown.value))\n",
        "\n",
        "# Attach event handlers.\n",
        "file_upload.observe(on_file_upload_change, names='value')\n",
        "start_button.on_click(on_start_button_click)\n",
        "\n",
        "# Initially disable the start button until a file is uploaded.\n",
        "start_button.disabled = True\n",
        "\n",
        "# Layout: arrange widgets in a clean UI using containers.\n",
        "ui_left = widgets.VBox([file_upload, mode_dropdown, start_button, progress_bar])\n",
        "ui = widgets.HBox([ui_left, log_output])\n",
        "\n",
        "# Display the complete UI.\n",
        "display(ui)"
      ],
      "metadata": {
        "id": "f32-YNDWJlpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UEbvz2Uo8Muw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}