{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73bc880894c344e6a29314a9bb24e1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be2877339b734ba4a0004433c4630b3e",
              "IPY_MODEL_dd988348550e499b9ed2a3358c806aa2",
              "IPY_MODEL_ca208e1019c34766bebfb8cc83a1ff62"
            ],
            "layout": "IPY_MODEL_0a1736827f9d43858bd9fec650c62b4e"
          }
        },
        "be2877339b734ba4a0004433c4630b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d75db05f53d042e186f3c0b03155036e",
            "placeholder": "​",
            "style": "IPY_MODEL_ba9f95c9360e4c608fc41037cdb574d3",
            "value": "config.json: 100%"
          }
        },
        "dd988348550e499b9ed2a3358c806aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c56bd83eee2246628d62b27fa0fe2258",
            "max": 1414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30e1455765c848408d97cfc1e8682231",
            "value": 1414
          }
        },
        "ca208e1019c34766bebfb8cc83a1ff62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_681c0b4ffdc640ba84981b7be2594bf3",
            "placeholder": "​",
            "style": "IPY_MODEL_b4aaeb79c3b74f37ac8be827e1fbdd82",
            "value": " 1.41k/1.41k [00:00&lt;00:00, 140kB/s]"
          }
        },
        "0a1736827f9d43858bd9fec650c62b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d75db05f53d042e186f3c0b03155036e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba9f95c9360e4c608fc41037cdb574d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c56bd83eee2246628d62b27fa0fe2258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e1455765c848408d97cfc1e8682231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "681c0b4ffdc640ba84981b7be2594bf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4aaeb79c3b74f37ac8be827e1fbdd82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bae0fbecf1a444984e955305aac4590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_363126e377b3408aa94d1cff2f68e916",
              "IPY_MODEL_807fb97801ec47b58a9e618833bf7602",
              "IPY_MODEL_f6c7695bf3ac44aab0fdbe7613b79861"
            ],
            "layout": "IPY_MODEL_e0bda2770eda4bf2b5318fc310dd1d52"
          }
        },
        "363126e377b3408aa94d1cff2f68e916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97ba6011acc8442a8a4f6c8dd06721cd",
            "placeholder": "​",
            "style": "IPY_MODEL_4f145e30e93343ddae079fb9794bc539",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "807fb97801ec47b58a9e618833bf7602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7478f047813349caafe533145d1b180f",
            "max": 741,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16dfee8ebf1844588df046d6f5f30a96",
            "value": 741
          }
        },
        "f6c7695bf3ac44aab0fdbe7613b79861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1219ea0d0b9430196c5b565c65f6b1c",
            "placeholder": "​",
            "style": "IPY_MODEL_d319222c17824410827709e8ead8a0e5",
            "value": " 741/741 [00:00&lt;00:00, 80.1kB/s]"
          }
        },
        "e0bda2770eda4bf2b5318fc310dd1d52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97ba6011acc8442a8a4f6c8dd06721cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f145e30e93343ddae079fb9794bc539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7478f047813349caafe533145d1b180f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16dfee8ebf1844588df046d6f5f30a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1219ea0d0b9430196c5b565c65f6b1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d319222c17824410827709e8ead8a0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2764113b35454c64b1e60945715592d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8378cd37f2e54ebf95f3c53097a4c911",
              "IPY_MODEL_8942fd4792b149eca988d29a03220a0a",
              "IPY_MODEL_8e5e467bbb854af7aee00368f7b02afc"
            ],
            "layout": "IPY_MODEL_291fe7b719c149979540ee6faafed750"
          }
        },
        "8378cd37f2e54ebf95f3c53097a4c911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20aef92fc99746ed882c04b080ed9444",
            "placeholder": "​",
            "style": "IPY_MODEL_462d5e1720394c77b460f90e2f7bf8a2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8942fd4792b149eca988d29a03220a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7f9e9bdc86e4eb1ae067daff43d3b70",
            "max": 1505,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60a9aec016474e31962cdaed97873d17",
            "value": 1505
          }
        },
        "8e5e467bbb854af7aee00368f7b02afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3f4d9ce577d4346b2772792b5f8e554",
            "placeholder": "​",
            "style": "IPY_MODEL_9056603f864c43cb8aa1feca5a054beb",
            "value": " 1.50k/1.50k [00:00&lt;00:00, 143kB/s]"
          }
        },
        "291fe7b719c149979540ee6faafed750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20aef92fc99746ed882c04b080ed9444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "462d5e1720394c77b460f90e2f7bf8a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f9e9bdc86e4eb1ae067daff43d3b70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60a9aec016474e31962cdaed97873d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3f4d9ce577d4346b2772792b5f8e554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9056603f864c43cb8aa1feca5a054beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef5d273db62d495c827d888ce341b668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b6e6596cc9549e6a05c7e1bddf6baf4",
              "IPY_MODEL_8d1549821af5482e88577be363979be7",
              "IPY_MODEL_8a21d5760b7747049997ba2145978c2e"
            ],
            "layout": "IPY_MODEL_60435873ff914f2a807cba90ae44b423"
          }
        },
        "6b6e6596cc9549e6a05c7e1bddf6baf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4efe7a98fb114cd8b19af525a7d40e1a",
            "placeholder": "​",
            "style": "IPY_MODEL_92800dfeac394c7db11922f47e28c7bc",
            "value": "tokenizer.model: 100%"
          }
        },
        "8d1549821af5482e88577be363979be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c186d24731d4cf0bc382d7633884d45",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_339b113ba05c4b25a89965c5f0734ae2",
            "value": 499723
          }
        },
        "8a21d5760b7747049997ba2145978c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43885b045842462f93f1162da4f6d567",
            "placeholder": "​",
            "style": "IPY_MODEL_5e9b153252fd4ca696c21f307b7bfeec",
            "value": " 500k/500k [00:00&lt;00:00, 9.38MB/s]"
          }
        },
        "60435873ff914f2a807cba90ae44b423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4efe7a98fb114cd8b19af525a7d40e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92800dfeac394c7db11922f47e28c7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c186d24731d4cf0bc382d7633884d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "339b113ba05c4b25a89965c5f0734ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43885b045842462f93f1162da4f6d567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e9b153252fd4ca696c21f307b7bfeec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "441f0d8e537244e0a72dee1679ff8f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a040990c55d48788abd1dcc82b27b68",
              "IPY_MODEL_a1103056d2294bb3bc2a07d9afd93ec5",
              "IPY_MODEL_ca27c34cf57444749047ccb524c6fe4c"
            ],
            "layout": "IPY_MODEL_08093d403a064f6b9998fab703843942"
          }
        },
        "2a040990c55d48788abd1dcc82b27b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62fdbdaa0061423aa2c470e0ab17bbe5",
            "placeholder": "​",
            "style": "IPY_MODEL_80a1b162ebe74bc8adc1ed531f873087",
            "value": "tokenizer.json: 100%"
          }
        },
        "a1103056d2294bb3bc2a07d9afd93ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc11a550c74c45ec8db99539bf28b34d",
            "max": 1843172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78393cd9463b47d6ac5de716d6eff299",
            "value": 1843172
          }
        },
        "ca27c34cf57444749047ccb524c6fe4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f582047b984d399ebda08231a8f91f",
            "placeholder": "​",
            "style": "IPY_MODEL_e403e198c837419da3db17b4bbaa4783",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 7.58MB/s]"
          }
        },
        "08093d403a064f6b9998fab703843942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62fdbdaa0061423aa2c470e0ab17bbe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a1b162ebe74bc8adc1ed531f873087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc11a550c74c45ec8db99539bf28b34d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78393cd9463b47d6ac5de716d6eff299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6f582047b984d399ebda08231a8f91f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e403e198c837419da3db17b4bbaa4783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c9c2cc254cf430a996fa817d1da7715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11b72dfc66e1494f976b951b6ff32836",
              "IPY_MODEL_83c52844b8f8486cbc87a0db4e6ebc61",
              "IPY_MODEL_99aa4d7478a14fba947f493c3a8d5052"
            ],
            "layout": "IPY_MODEL_df3a3a45fab7402d8dd497d5e4d50fb5"
          }
        },
        "11b72dfc66e1494f976b951b6ff32836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9d651aec82c413391bd7e3d98b281dc",
            "placeholder": "​",
            "style": "IPY_MODEL_0fe890f0a6644ed2a9fc20168c0cefe2",
            "value": "added_tokens.json: 100%"
          }
        },
        "83c52844b8f8486cbc87a0db4e6ebc61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99243e4f01764324ab0cc028747839a8",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50493cbe2d844a9eb377cb9f968eb1e1",
            "value": 43
          }
        },
        "99aa4d7478a14fba947f493c3a8d5052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_634f774506ee42c887de6bbd6a24dbbf",
            "placeholder": "​",
            "style": "IPY_MODEL_df0cf436f6534c52ac838e0909f2824c",
            "value": " 43.0/43.0 [00:00&lt;00:00, 2.94kB/s]"
          }
        },
        "df3a3a45fab7402d8dd497d5e4d50fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9d651aec82c413391bd7e3d98b281dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe890f0a6644ed2a9fc20168c0cefe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99243e4f01764324ab0cc028747839a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50493cbe2d844a9eb377cb9f968eb1e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "634f774506ee42c887de6bbd6a24dbbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df0cf436f6534c52ac838e0909f2824c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7605828373f7450e966ada69bbb79020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_114e13d6e20d4fad9dcb38b505940e99",
              "IPY_MODEL_babdbf415a774af9bbbe80244c593c8a",
              "IPY_MODEL_1d5048b46b3348d4899499c6d40b8b56"
            ],
            "layout": "IPY_MODEL_3e2e248a855249e8b2b2695580fd1713"
          }
        },
        "114e13d6e20d4fad9dcb38b505940e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccab5745b88d4ad79eea45359b54e73b",
            "placeholder": "​",
            "style": "IPY_MODEL_40c39fad4a6f4b9b98d9430a8f0e00f1",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "babdbf415a774af9bbbe80244c593c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd56461747d74308a60d5e3fb4066c6e",
            "max": 552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2d88dd8eafa469b922ea99f057ffb82",
            "value": 552
          }
        },
        "1d5048b46b3348d4899499c6d40b8b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af1c59751ee3422e85fa07dbbffcbc28",
            "placeholder": "​",
            "style": "IPY_MODEL_8e2645ccd47340f0a63b7412d7ece641",
            "value": " 552/552 [00:00&lt;00:00, 31.9kB/s]"
          }
        },
        "3e2e248a855249e8b2b2695580fd1713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccab5745b88d4ad79eea45359b54e73b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40c39fad4a6f4b9b98d9430a8f0e00f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd56461747d74308a60d5e3fb4066c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d88dd8eafa469b922ea99f057ffb82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af1c59751ee3422e85fa07dbbffcbc28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e2645ccd47340f0a63b7412d7ece641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18aa8dde3c41466a89a7ef491de9f547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dd3e3ffc83b46078d9bff73a3c459cd",
              "IPY_MODEL_c884a6211381417195c6374c6bfdd6e1",
              "IPY_MODEL_266dc08a8e50415b890e93854bdb4d5a"
            ],
            "layout": "IPY_MODEL_8ca091a182874bb79bd3fb7a5c559960"
          }
        },
        "7dd3e3ffc83b46078d9bff73a3c459cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a8e2a1e076d4c8b8d982fbe04eb0fbc",
            "placeholder": "​",
            "style": "IPY_MODEL_9a538893223c4d68aa237692cfb83a42",
            "value": "generation_config.json: 100%"
          }
        },
        "c884a6211381417195c6374c6bfdd6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fe5db433af8421d81ae3e377de719b2",
            "max": 137,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4d2ddee856f443aaead94833d4f1e29",
            "value": 137
          }
        },
        "266dc08a8e50415b890e93854bdb4d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_905e3c1a49be40458dc332e98f11ab50",
            "placeholder": "​",
            "style": "IPY_MODEL_50e1745a69df43dfa5822ad00a7cc24c",
            "value": " 137/137 [00:00&lt;00:00, 12.1kB/s]"
          }
        },
        "8ca091a182874bb79bd3fb7a5c559960": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a8e2a1e076d4c8b8d982fbe04eb0fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a538893223c4d68aa237692cfb83a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fe5db433af8421d81ae3e377de719b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d2ddee856f443aaead94833d4f1e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "905e3c1a49be40458dc332e98f11ab50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50e1745a69df43dfa5822ad00a7cc24c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff5ed74c93084e0888cdb207e69a2170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c885bab8aa1c496e8c0c903961859a7e",
              "IPY_MODEL_5aa9ec5278ef44bab6fe0b8759b1bb91",
              "IPY_MODEL_f28a1a8c0ec043678b921bbeee6b7477"
            ],
            "layout": "IPY_MODEL_8427eb7e5cb2467c8766a52f81ac3dfe"
          }
        },
        "c885bab8aa1c496e8c0c903961859a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50756a618d884922bc060f64d2455b92",
            "placeholder": "​",
            "style": "IPY_MODEL_121db4cef18847ba9bcd9ef3dd727cc9",
            "value": "model-00001-of-00003.safetensors:  46%"
          }
        },
        "5aa9ec5278ef44bab6fe0b8759b1bb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c0cbc8a297a4493a5eb0975661df223",
            "max": 4992938952,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_035d1d9bc7584fbdb4124e3099657f18",
            "value": 2285895680
          }
        },
        "f28a1a8c0ec043678b921bbeee6b7477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc40f6b6b7db4d1c9e5aed447c5f69fb",
            "placeholder": "​",
            "style": "IPY_MODEL_397bda2a44e34653b932a4039014337a",
            "value": " 2.29G/4.99G [06:42&lt;12:49, 3.52MB/s]"
          }
        },
        "8427eb7e5cb2467c8766a52f81ac3dfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50756a618d884922bc060f64d2455b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "121db4cef18847ba9bcd9ef3dd727cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c0cbc8a297a4493a5eb0975661df223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "035d1d9bc7584fbdb4124e3099657f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc40f6b6b7db4d1c9e5aed447c5f69fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "397bda2a44e34653b932a4039014337a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e3e3109e92c4a3eb59c49a770f67707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_867db857707340ccb7ce5db91e25c3b6",
              "IPY_MODEL_512a0c0a2d824afdaa41e8a89b53545c",
              "IPY_MODEL_4abd3a08fe2c464f8081f36b5bcb30d5"
            ],
            "layout": "IPY_MODEL_88b825207ca74f52b0c152cf5701fbdb"
          }
        },
        "867db857707340ccb7ce5db91e25c3b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cab7685e32db40bea31154ffadc5ef3d",
            "placeholder": "​",
            "style": "IPY_MODEL_0d3e537e279a4805bb24d9b28d871060",
            "value": "model-00002-of-00003.safetensors:  47%"
          }
        },
        "512a0c0a2d824afdaa41e8a89b53545c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f9627c9dcfb4497b1763065267f06a2",
            "max": 4957878552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3fc141d2a824b178545bd532e682050",
            "value": 2317352960
          }
        },
        "4abd3a08fe2c464f8081f36b5bcb30d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a84d7ababd446deb2bb89c1514b38c7",
            "placeholder": "​",
            "style": "IPY_MODEL_362edb0a630947bc818d280195954e7a",
            "value": " 2.32G/4.96G [06:41&lt;08:44, 5.04MB/s]"
          }
        },
        "88b825207ca74f52b0c152cf5701fbdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cab7685e32db40bea31154ffadc5ef3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d3e537e279a4805bb24d9b28d871060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f9627c9dcfb4497b1763065267f06a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3fc141d2a824b178545bd532e682050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a84d7ababd446deb2bb89c1514b38c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "362edb0a630947bc818d280195954e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd2122a9d589488db3cb200754b3966d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0829cc0af73472992265ea560087dea",
              "IPY_MODEL_5563f321ceba47108d443a3fb8ad70a3",
              "IPY_MODEL_bcdad24e27fd4597918fc4e56b37b9e7"
            ],
            "layout": "IPY_MODEL_b00fb5fce9d04134badecd29dfcc8048"
          }
        },
        "c0829cc0af73472992265ea560087dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c73d0ebb7eaa48ca88809ada25452470",
            "placeholder": "​",
            "style": "IPY_MODEL_ec093cc413ca411abecf6f640a9811e2",
            "value": "model-00003-of-00003.safetensors:  54%"
          }
        },
        "5563f321ceba47108d443a3fb8ad70a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0abab42aa9e4c709e3c3db1a8bf6b86",
            "max": 4176137496,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ce6b5fcb2124d14af9f158ce9a8b4e9",
            "value": 2243952640
          }
        },
        "bcdad24e27fd4597918fc4e56b37b9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7cdeae682074ed8a96ac93105810443",
            "placeholder": "​",
            "style": "IPY_MODEL_de1e125adf12423ba3f7928a771ec658",
            "value": " 2.24G/4.18G [06:41&lt;06:23, 5.04MB/s]"
          }
        },
        "b00fb5fce9d04134badecd29dfcc8048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c73d0ebb7eaa48ca88809ada25452470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec093cc413ca411abecf6f640a9811e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0abab42aa9e4c709e3c3db1a8bf6b86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ce6b5fcb2124d14af9f158ce9a8b4e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7cdeae682074ed8a96ac93105810443": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1e125adf12423ba3f7928a771ec658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Deepfake_and_Manipulated_Media_Analysis_R%26D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Deepfake Detection and Manipulated Media Analysis using Multiagent System and Compound AI Approach**"
      ],
      "metadata": {
        "id": "TREWxWZdT5iE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TEMrzAzRW_w4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5692106-0dbb-4874-f798-5458ee657de1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.3/264.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.4/67.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.4/402.4 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.7/912.7 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.4/151.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.7/801.7 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for dlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install -q vllm transformers torch opencv-python librosa numpy face-recognition groq\n",
        "!pip install -qU dlib mediapipe scipy pillow tqdm pydantic moviepy langchain_community langgraph dtw-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import librosa\n",
        "import asyncio\n",
        "import json\n",
        "import base64\n",
        "import re\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import concurrent.futures\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional, Union\n",
        "from pydantic import BaseModel, Field\n",
        "from transformers import (\n",
        "    CLIPProcessor, Wav2Vec2Processor, VideoMAEFeatureExtractor,\n",
        "    EfficientNetForImageClassification, LlavaForConditionalGeneration,\n",
        ")\n",
        "from vllm import LLM, SamplingParams\n",
        "from groq import Groq  # Groq Python client\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.tools import BaseTool\n",
        "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent\n",
        "from langgraph.graph import Graph, StateGraph, END\n",
        "from moviepy import VideoFileClip\n",
        "import nest_asyncio\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from functools import lru_cache\n",
        "from skimage import exposure\n",
        "from scipy.signal import savgol_filter\n",
        "from dtw import dtw\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import time\n",
        "\n",
        "# Allow nested asyncio loops (useful in notebooks)\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "YvGEVqyrw7k3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456dc040-6843-43a5-97d4-1013a4268d76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-19 06:47:35 __init__.py:190] Automatically detected platform cuda.\n",
            "Importing the dtw module. When using in academic works please cite:\n",
            "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
            "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import VLLM and Groq clients (ensure these libraries are installed)\n",
        "from vllm import LLM\n",
        "from groq import Groq  # Ensure Groq client is installed\n",
        "\n",
        "# -------------------- Global Configuration and Model Initialization --------------------\n",
        "\n",
        "COMMON_PARAMS = {\n",
        "    \"task\": \"generate\",\n",
        "    \"max_model_len\": 2048,\n",
        "    \"dtype\": \"half\",\n",
        "    \"gpu_memory_utilization\": 0.7,\n",
        "    \"cpu_offload_gb\": 6,\n",
        "    \"enforce_eager\": True\n",
        "}\n",
        "\n",
        "def init_vllm_model(name: str, model_id: str, **overrides) -> LLM:\n",
        "    \"\"\"Initialize a VLLM model with a common configuration.\"\"\"\n",
        "    model = LLM(model=model_id, **{**COMMON_PARAMS, **overrides})\n",
        "    print(f\"[VLLM] {name} loaded: {model_id}\")\n",
        "    return model\n",
        "\n",
        "def init_groq_model(name: str, model_id: str):\n",
        "    \"\"\"Initialize a Groq model for accelerated inference.\"\"\"\n",
        "    groq_client = Groq(api_key=\"YOUR_GROQ_API_KEY\")\n",
        "    model = groq_client.load_model(model_id)\n",
        "    print(f\"[Groq] {name} loaded: {model_id}\")\n",
        "    return model\n",
        "\n",
        "# -------------------- Model Initializations --------------------\n",
        "# Video Analysis Models (VLLM)\n",
        "llava_next_video = init_vllm_model(\"llava_next_video\", \"llava-hf/LLaVA-NeXT-Video-7B-hf\")\n",
        "xclip = init_vllm_model(\"xclip\", \"xclip-model\")\n",
        "videomae = init_vllm_model(\"videomae\", \"videomae-model\")\n",
        "\n",
        "# Audio Analysis Models\n",
        "wav2vec2 = init_vllm_model(\"wav2vec2\", \"facebook/wav2vec2-large-960h\")\n",
        "llava_audio = init_vllm_model(\"llava_next_video\", \"llava-hf/LLaVA-NeXT-Video-7B-hf\")\n",
        "groq_audio_model = init_groq_model(\"groq_audio_model\", \"whisper-large-v3-turbo\")\n",
        "\n",
        "# Image Analysis Models\n",
        "llava_image = init_vllm_model(\"llava_onevision\", \"llava-hf/llava-onevision-qwen2-7b-ov-hf\")\n",
        "clip = init_vllm_model(\"clip\", \"openai/clip-vit-large-patch14\")\n",
        "groq_vision_model = init_groq_model(\"groq_vision_model\", \"llama-3.2-90b-vision-preview\")\n",
        "\n",
        "# Text Analysis / Report Generation Model\n",
        "groq_text_model = init_groq_model(\"groq_text_model\", \"llama-3.3-70b-versatile\")\n",
        "\n",
        "# Clear unused GPU memory\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\nModels loaded successfully:\")\n",
        "print(\"Video Analysis: llava_next_video, xclip, videomae\")\n",
        "print(\"Audio Analysis: wav2vec2, llava_audio, groq_audio_model\")\n",
        "print(\"Image Analysis: llava_image, clip, groq_vision_model\")\n",
        "print(\"Text Analysis/Report Generation: groq_text_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667,
          "referenced_widgets": [
            "73bc880894c344e6a29314a9bb24e1d9",
            "be2877339b734ba4a0004433c4630b3e",
            "dd988348550e499b9ed2a3358c806aa2",
            "ca208e1019c34766bebfb8cc83a1ff62",
            "0a1736827f9d43858bd9fec650c62b4e",
            "d75db05f53d042e186f3c0b03155036e",
            "ba9f95c9360e4c608fc41037cdb574d3",
            "c56bd83eee2246628d62b27fa0fe2258",
            "30e1455765c848408d97cfc1e8682231",
            "681c0b4ffdc640ba84981b7be2594bf3",
            "b4aaeb79c3b74f37ac8be827e1fbdd82",
            "5bae0fbecf1a444984e955305aac4590",
            "363126e377b3408aa94d1cff2f68e916",
            "807fb97801ec47b58a9e618833bf7602",
            "f6c7695bf3ac44aab0fdbe7613b79861",
            "e0bda2770eda4bf2b5318fc310dd1d52",
            "97ba6011acc8442a8a4f6c8dd06721cd",
            "4f145e30e93343ddae079fb9794bc539",
            "7478f047813349caafe533145d1b180f",
            "16dfee8ebf1844588df046d6f5f30a96",
            "d1219ea0d0b9430196c5b565c65f6b1c",
            "d319222c17824410827709e8ead8a0e5",
            "2764113b35454c64b1e60945715592d1",
            "8378cd37f2e54ebf95f3c53097a4c911",
            "8942fd4792b149eca988d29a03220a0a",
            "8e5e467bbb854af7aee00368f7b02afc",
            "291fe7b719c149979540ee6faafed750",
            "20aef92fc99746ed882c04b080ed9444",
            "462d5e1720394c77b460f90e2f7bf8a2",
            "d7f9e9bdc86e4eb1ae067daff43d3b70",
            "60a9aec016474e31962cdaed97873d17",
            "d3f4d9ce577d4346b2772792b5f8e554",
            "9056603f864c43cb8aa1feca5a054beb",
            "ef5d273db62d495c827d888ce341b668",
            "6b6e6596cc9549e6a05c7e1bddf6baf4",
            "8d1549821af5482e88577be363979be7",
            "8a21d5760b7747049997ba2145978c2e",
            "60435873ff914f2a807cba90ae44b423",
            "4efe7a98fb114cd8b19af525a7d40e1a",
            "92800dfeac394c7db11922f47e28c7bc",
            "4c186d24731d4cf0bc382d7633884d45",
            "339b113ba05c4b25a89965c5f0734ae2",
            "43885b045842462f93f1162da4f6d567",
            "5e9b153252fd4ca696c21f307b7bfeec",
            "441f0d8e537244e0a72dee1679ff8f21",
            "2a040990c55d48788abd1dcc82b27b68",
            "a1103056d2294bb3bc2a07d9afd93ec5",
            "ca27c34cf57444749047ccb524c6fe4c",
            "08093d403a064f6b9998fab703843942",
            "62fdbdaa0061423aa2c470e0ab17bbe5",
            "80a1b162ebe74bc8adc1ed531f873087",
            "fc11a550c74c45ec8db99539bf28b34d",
            "78393cd9463b47d6ac5de716d6eff299",
            "b6f582047b984d399ebda08231a8f91f",
            "e403e198c837419da3db17b4bbaa4783",
            "9c9c2cc254cf430a996fa817d1da7715",
            "11b72dfc66e1494f976b951b6ff32836",
            "83c52844b8f8486cbc87a0db4e6ebc61",
            "99aa4d7478a14fba947f493c3a8d5052",
            "df3a3a45fab7402d8dd497d5e4d50fb5",
            "c9d651aec82c413391bd7e3d98b281dc",
            "0fe890f0a6644ed2a9fc20168c0cefe2",
            "99243e4f01764324ab0cc028747839a8",
            "50493cbe2d844a9eb377cb9f968eb1e1",
            "634f774506ee42c887de6bbd6a24dbbf",
            "df0cf436f6534c52ac838e0909f2824c",
            "7605828373f7450e966ada69bbb79020",
            "114e13d6e20d4fad9dcb38b505940e99",
            "babdbf415a774af9bbbe80244c593c8a",
            "1d5048b46b3348d4899499c6d40b8b56",
            "3e2e248a855249e8b2b2695580fd1713",
            "ccab5745b88d4ad79eea45359b54e73b",
            "40c39fad4a6f4b9b98d9430a8f0e00f1",
            "bd56461747d74308a60d5e3fb4066c6e",
            "e2d88dd8eafa469b922ea99f057ffb82",
            "af1c59751ee3422e85fa07dbbffcbc28",
            "8e2645ccd47340f0a63b7412d7ece641",
            "18aa8dde3c41466a89a7ef491de9f547",
            "7dd3e3ffc83b46078d9bff73a3c459cd",
            "c884a6211381417195c6374c6bfdd6e1",
            "266dc08a8e50415b890e93854bdb4d5a",
            "8ca091a182874bb79bd3fb7a5c559960",
            "8a8e2a1e076d4c8b8d982fbe04eb0fbc",
            "9a538893223c4d68aa237692cfb83a42",
            "4fe5db433af8421d81ae3e377de719b2",
            "d4d2ddee856f443aaead94833d4f1e29",
            "905e3c1a49be40458dc332e98f11ab50",
            "50e1745a69df43dfa5822ad00a7cc24c",
            "ff5ed74c93084e0888cdb207e69a2170",
            "c885bab8aa1c496e8c0c903961859a7e",
            "5aa9ec5278ef44bab6fe0b8759b1bb91",
            "f28a1a8c0ec043678b921bbeee6b7477",
            "8427eb7e5cb2467c8766a52f81ac3dfe",
            "50756a618d884922bc060f64d2455b92",
            "121db4cef18847ba9bcd9ef3dd727cc9",
            "7c0cbc8a297a4493a5eb0975661df223",
            "035d1d9bc7584fbdb4124e3099657f18",
            "fc40f6b6b7db4d1c9e5aed447c5f69fb",
            "397bda2a44e34653b932a4039014337a",
            "2e3e3109e92c4a3eb59c49a770f67707",
            "867db857707340ccb7ce5db91e25c3b6",
            "512a0c0a2d824afdaa41e8a89b53545c",
            "4abd3a08fe2c464f8081f36b5bcb30d5",
            "88b825207ca74f52b0c152cf5701fbdb",
            "cab7685e32db40bea31154ffadc5ef3d",
            "0d3e537e279a4805bb24d9b28d871060",
            "8f9627c9dcfb4497b1763065267f06a2",
            "b3fc141d2a824b178545bd532e682050",
            "8a84d7ababd446deb2bb89c1514b38c7",
            "362edb0a630947bc818d280195954e7a",
            "dd2122a9d589488db3cb200754b3966d",
            "c0829cc0af73472992265ea560087dea",
            "5563f321ceba47108d443a3fb8ad70a3",
            "bcdad24e27fd4597918fc4e56b37b9e7",
            "b00fb5fce9d04134badecd29dfcc8048",
            "c73d0ebb7eaa48ca88809ada25452470",
            "ec093cc413ca411abecf6f640a9811e2",
            "d0abab42aa9e4c709e3c3db1a8bf6b86",
            "6ce6b5fcb2124d14af9f158ce9a8b4e9",
            "b7cdeae682074ed8a96ac93105810443",
            "de1e125adf12423ba3f7928a771ec658"
          ]
        },
        "id": "-xNU8D9MAXpo",
        "outputId": "45912c36-b776-48a3-efca-e383c900944d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73bc880894c344e6a29314a9bb24e1d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/741 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bae0fbecf1a444984e955305aac4590"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING 02-19 06:55:01 cuda.py:95] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
            "WARNING 02-19 06:55:01 config.py:678] Async output processing is not supported on the current platform type cuda.\n",
            "INFO 02-19 06:55:01 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='llava-hf/LLaVA-NeXT-Video-7B-hf', speculative_config=None, tokenizer='llava-hf/LLaVA-NeXT-Video-7B-hf', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=llava-hf/LLaVA-NeXT-Video-7B-hf, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[],\"max_capture_size\":0}, use_cached_outputs=False, \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2764113b35454c64b1e60945715592d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef5d273db62d495c827d888ce341b668"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "441f0d8e537244e0a72dee1679ff8f21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c9c2cc254cf430a996fa817d1da7715"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7605828373f7450e966ada69bbb79020"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18aa8dde3c41466a89a7ef491de9f547"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-19 06:55:05 cuda.py:179] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 02-19 06:55:05 cuda.py:227] Using XFormers backend.\n",
            "INFO 02-19 06:55:06 model_runner.py:1110] Starting to load model llava-hf/LLaVA-NeXT-Video-7B-hf...\n",
            "INFO 02-19 06:55:06 cuda.py:179] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 02-19 06:55:06 cuda.py:227] Using XFormers backend.\n",
            "INFO 02-19 06:55:06 config.py:2992] cudagraph sizes specified by model runner [] is overridden by config []\n",
            "INFO 02-19 06:55:13 weight_utils.py:252] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff5ed74c93084e0888cdb207e69a2170"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e3e3109e92c4a3eb59c49a770f67707"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.18G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd2122a9d589488db3cb200754b3966d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Up the Groq Client and More Models for Text, Audio and Vedio Analysis**"
      ],
      "metadata": {
        "id": "-ytDSCQDUAje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Data Models**\n",
        "- Define the data models for storing analysis results and reports:\n"
      ],
      "metadata": {
        "id": "X8RzT9-AWZCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepfakeAnalysisResult(BaseModel):\n",
        "    score: float = Field(..., description=\"Confidence score (0-1)\")\n",
        "    label: str = Field(..., description=\"Classification label\")\n",
        "    anomalies: List[str] = Field(default_factory=list)\n",
        "    artifacts: List[str] = Field(default_factory=list)\n",
        "    confidence: float = Field(..., description=\"Model confidence\")\n",
        "    method: str = Field(..., description=\"Detection method used\")\n",
        "    timestamp: datetime = Field(default_factory=datetime.now)\n",
        "\n",
        "class MultimodalAnalysisReport(BaseModel):\n",
        "    case_id: str\n",
        "    file_info: Dict[str, Any]\n",
        "    video_analysis: Optional[DeepfakeAnalysisResult]\n",
        "    audio_analysis: Optional[DeepfakeAnalysisResult]\n",
        "    image_analysis: Optional[DeepfakeAnalysisResult]\n",
        "    text_analysis: Optional[DeepfakeAnalysisResult]\n",
        "    multimodal_score: float\n",
        "    verdict: str\n",
        "    evidence: List[Dict[str, Any]]\n",
        "    metadata: Dict[str, Any]"
      ],
      "metadata": {
        "id": "MyJ0N4mSWZio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frame Stabilization**\n"
      ],
      "metadata": {
        "id": "vZdtcqEPytTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stabilize_frames(frames: List[np.ndarray]) -> List[np.ndarray]:\n",
        "    stabilized_frames = []\n",
        "    prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)\n",
        "    transforms = []\n",
        "\n",
        "    for i in range(1, len(frames)):\n",
        "        curr_gray = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
        "        transform = cv2.estimateRigidTransform(prev_gray, curr_gray, False)\n",
        "        transforms.append(transform)\n",
        "        prev_gray = curr_gray\n",
        "\n",
        "    for i, frame in enumerate(frames):\n",
        "        if i == 0:\n",
        "            stabilized_frames.append(frame)\n",
        "        else:\n",
        "            stabilized_frame = cv2.warpAffine(frame, transforms[i-1], (frame.shape[1], frame.shape[0]))\n",
        "            stabilized_frames.append(stabilized_frame)\n",
        "\n",
        "    return stabilized_frames\n",
        "\n",
        "def adaptive_noise_reduction(audio_data: np.ndarray) -> np.ndarray:\n",
        "    noise_profile = np.mean(audio_data[:1000])\n",
        "    reduced_noise_audio = audio_data - noise_profile\n",
        "    return reduced_noise_audio"
      ],
      "metadata": {
        "id": "kNzO5fgyy0sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Functions for Preprocessing**\n",
        "- Define helper functions for preprocessing audio, image, and video data:"
      ],
      "metadata": {
        "id": "0ktikzemXOd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_image_resolution(image_path: str) -> np.ndarray:\n",
        "    image = cv2.imread(image_path)\n",
        "    image_upscaled = cv2.resize(image, (image.shape[1] * 2, image.shape[0] * 2), interpolation=cv2.INTER_CUBIC)\n",
        "    return image_upscaled\n",
        "\n",
        "def adaptive_histogram_equalization(image: np.ndarray) -> np.ndarray:\n",
        "    return exposure.equalize_adapthist(image, clip_limit=0.03)\n",
        "\n",
        "def spectral_noise_reduction(audio_data: np.ndarray, sample_rate: int) -> np.ndarray:\n",
        "    reduced_noise_audio = savgol_filter(audio_data, window_length=51, polyorder=3)\n",
        "    return reduced_noise_audio\n",
        "\n",
        "def temporal_alignment_dtw(frames: List[np.ndarray]) -> List[np.ndarray]:\n",
        "    aligned_frames = []\n",
        "    for i in range(1, len(frames)):\n",
        "        alignment = dtw(frames[i-1], frames[i])\n",
        "        aligned_frames.append(alignment.index2)\n",
        "    return aligned_frames\n",
        "\n",
        "def deblur_image(image: np.ndarray) -> np.ndarray:\n",
        "    gaussian_blur = cv2.GaussianBlur(image, (0, 0), 3)\n",
        "    unsharp_image = cv2.addWeighted(image, 1.5, gaussian_blur, -0.5, 0)\n",
        "    return unsharp_image\n",
        "\n",
        "def extract_audio_features(audio_data: np.ndarray, sample_rate: int) -> Dict[str, Any]:\n",
        "    mfcc = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n",
        "    chroma = librosa.feature.chroma_stft(y=audio_data, sr=sample_rate)\n",
        "    mel = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
        "    return {\n",
        "        \"mfcc\": mfcc,\n",
        "        \"chroma\": chroma,\n",
        "        \"mel\": mel\n",
        "    }\n",
        "\n",
        "def extract_image_features(image: np.ndarray) -> Dict[str, Any]:\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    sift = cv2.SIFT_create()\n",
        "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
        "    return {\n",
        "        \"keypoints\": keypoints,\n",
        "        \"descriptors\": descriptors\n",
        "    }\n",
        "\n",
        "def calculate_dense_optical_flow(prev_frame: np.ndarray, curr_frame: np.ndarray) -> np.ndarray:\n",
        "    gray_prev = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "    gray_curr = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
        "    flow = cv2.calcOpticalFlowFarneback(gray_prev, gray_curr, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    return flow\n",
        "\n",
        "def extract_temporal_features(optical_flow: np.ndarray) -> Dict[str, Any]:\n",
        "    mag, ang = cv2.cartToPolar(optical_flow[..., 0], optical_flow[..., 1])\n",
        "    return {\n",
        "        \"magnitude\": mag,\n",
        "        \"angle\": ang\n",
        "    }\n",
        "\n",
        "def estimate_noise(frame: np.ndarray) -> float:\n",
        "    return np.mean(cv2.Laplacian(frame, cv2.CV_64F).var())\n",
        "\n",
        "def calculate_contrast(frame: np.ndarray) -> float:\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    return gray.std()\n",
        "\n",
        "def detect_compression_artifacts(frame: np.ndarray) -> float:\n",
        "    dct = cv2.dct(np.float32(frame) / 255.0)\n",
        "    return np.mean(np.abs(dct))"
      ],
      "metadata": {
        "id": "9A9KPnzU36TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Preprocessing Functions**\n",
        "- Define functions for preprocessing audio, image, and video data"
      ],
      "metadata": {
        "id": "13iwCPIrX-Vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def enhanced_preprocessing(file_path: str) -> Dict[str, Any]:\n",
        "    file_extension = os.path.splitext(file_path)[1].lower()\n",
        "    if file_extension in [\".mp3\", \".wav\", \".flac\"]:\n",
        "        return await enhanced_audio_preprocessing(file_path)\n",
        "    elif file_extension in [\".jpg\", \".jpeg\", \".png\", \".bmp\"]:\n",
        "        return await enhanced_image_preprocessing(file_path)\n",
        "    elif file_extension in [\".mp4\", \".avi\", \".mov\", \".mkv\"]:\n",
        "        return await enhanced_video_preprocessing(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format\")\n",
        "\n",
        "async def enhanced_audio_preprocessing(audio_path: str) -> Dict[str, Any]:\n",
        "    audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
        "    audio_data = spectral_noise_reduction(audio_data, sample_rate)\n",
        "    audio_features = extract_audio_features(audio_data, sample_rate)\n",
        "    return {\"audio\": audio_data, \"sample_rate\": sample_rate, \"audio_features\": audio_features}\n",
        "\n",
        "async def enhanced_image_preprocessing(image_path: str) -> Dict[str, Any]:\n",
        "    image = cv2.imread(image_path)\n",
        "    image = enhance_image_resolution(image)\n",
        "    image = adaptive_histogram_equalization(image)\n",
        "    image = deblur_image(image)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image_features = extract_image_features(image_rgb)\n",
        "    return {\"image\": image_rgb, \"image_features\": image_features}\n",
        "\n",
        "async def enhanced_video_preprocessing(video_path: str) -> Dict[str, Any]:\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    audio_data = None\n",
        "    metadata = {\n",
        "        \"fps\": cap.get(cv2.CAP_PROP_FPS),\n",
        "        \"frame_count\": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
        "        \"width\": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "        \"height\": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
        "        \"duration\": float(cap.get(cv2.CAP_PROP_FRAME_COUNT)) / float(cap.get(cv2.CAP_PROP_FPS)),\n",
        "        \"codec\": int(cap.get(cv2.CAP_PROP_FOURCC)).to_bytes(4, byteorder='little').decode(),\n",
        "        \"file_size\": os.path.getsize(video_path)\n",
        "    }\n",
        "    frame_quality_metrics = []\n",
        "    optical_flow_data = []\n",
        "    prev_frame = None\n",
        "    temporal_features = []\n",
        "\n",
        "    loop = asyncio.get_event_loop()\n",
        "    executor = ThreadPoolExecutor(max_workers=4)\n",
        "\n",
        "    async def process_frame(frame):\n",
        "        return await loop.run_in_executor(executor, enhance_image_resolution, frame)\n",
        "\n",
        "    async def process_quality_metrics(frame):\n",
        "        return await loop.run_in_executor(executor, lambda: {\n",
        "            \"blur\": cv2.Laplacian(frame, cv2.CV_64F).var(),\n",
        "            \"noise\": estimate_noise(frame),\n",
        "            \"brightness\": np.mean(frame),\n",
        "            \"contrast\": calculate_contrast(frame),\n",
        "            \"compression_artifacts\": detect_compression_artifacts(frame)\n",
        "        })\n",
        "\n",
        "    async def process_optical_flow(prev_frame, frame):\n",
        "        return await loop.run_in_executor(executor, calculate_dense_optical_flow, prev_frame, frame)\n",
        "\n",
        "    async def process_temporal_features(flow):\n",
        "        return await loop.run_in_executor(executor, extract_temporal_features, flow)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame, quality_metrics = await asyncio.gather(\n",
        "            process_frame(frame),\n",
        "            process_quality_metrics(frame)\n",
        "        )\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frames.append(rgb_frame)\n",
        "        frame_quality_metrics.append(quality_metrics)\n",
        "        if prev_frame is not None:\n",
        "            flow, temp_features = await asyncio.gather(\n",
        "                process_optical_flow(prev_frame, frame),\n",
        "                process_temporal_features(flow)\n",
        "            )\n",
        "            optical_flow_data.append(flow)\n",
        "            temporal_features.append(temp_features)\n",
        "        prev_frame = frame.copy()\n",
        "    cap.release()\n",
        "\n",
        "    try:\n",
        "        video = VideoFileClip(video_path)\n",
        "        audio = video.audio\n",
        "        if audio is not None:\n",
        "            audio_array = audio.to_soundarray()\n",
        "            audio_data = extract_audio_features(audio_array, audio.fps)\n",
        "        video.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Audio extraction error: {e}\")\n",
        "        audio_data = None\n",
        "\n",
        "    return {\n",
        "        \"frames\": frames,\n",
        "        \"audio\": audio_data,\n",
        "        \"metadata\": metadata,\n",
        "        \"quality_metrics\": frame_quality_metrics,\n",
        "        \"optical_flow\": optical_flow_data,\n",
        "        \"temporal_features\": temporal_features\n",
        "    }"
      ],
      "metadata": {
        "id": "ltWcOSlP36Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Analysis Functions**\n",
        "- functions for analyzing transcription, vision response, and other features"
      ],
      "metadata": {
        "id": "GExLYgMaYVBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_transcription(transcription: str) -> List[str]:\n",
        "    anomalies = []\n",
        "    if \"repeated phrase\" in transcription.lower():\n",
        "        anomalies.append(\"Repetitive phrases detected\")\n",
        "    if \"inconsistent timestamp\" in transcription.lower():\n",
        "        anomalies.append(\"Inconsistent timestamps detected\")\n",
        "    return anomalies\n",
        "\n",
        "def analyze_vision_response(response: str) -> List[str]:\n",
        "    anomalies = []\n",
        "    if \"blurry region\" in response.lower():\n",
        "        anomalies.append(\"Blurry regions detected\")\n",
        "    if \"unnatural shadow\" in response.lower():\n",
        "        anomalies.append(\"Unnatural shadows detected\")\n",
        "    return anomalies\n",
        "\n",
        "def analyze_av_sync(frames: List[np.ndarray], audio: np.ndarray) -> float:\n",
        "    sync_score = 0.9\n",
        "    return sync_score\n",
        "\n",
        "def analyze_temporal_features(temporal_features: List[Dict[str, Any]]) -> List[str]:\n",
        "    anomalies = []\n",
        "    for feature in temporal_features:\n",
        "        if feature[\"magnitude\"].max() > 1.0:\n",
        "            anomalies.append(\"Abrupt changes in motion detected\")\n",
        "    return anomalies\n",
        "\n",
        "def analyze_optical_flow(optical_flow: List[np.ndarray]) -> List[str]:\n",
        "    anomalies = []\n",
        "    for flow in optical_flow:\n",
        "        if flow.max() > 1.0:\n",
        "            anomalies.append(\"Inconsistent flow patterns detected\")\n",
        "    return anomalies\n",
        "\n",
        "def analyze_biometric_consistency(frames: List[np.ndarray], models: Dict[str, Any]) -> float:\n",
        "    consistency_score = 0.9\n",
        "    return consistency_score\n",
        "\n",
        "def analyze_llava_response(response: str) -> float:\n",
        "    score_match = re.search(r\"Score: (0\\.\\d+|1\\.0)\", response)\n",
        "    return float(score_match.group(1)) if score_match else 0.5\n",
        "\n",
        "\n",
        "def parse_model_output(response: str) -> Tuple[float, List[str]]:\n",
        "    \"\"\"\n",
        "    Parse the model's output string.\n",
        "    Expected format (exact format can be adjusted as needed):\n",
        "\n",
        "      Score: <score_value>\n",
        "      Anomalies: [ \"anomaly1\", \"anomaly2\", ... ]\n",
        "\n",
        "    Returns:\n",
        "        A tuple (score, anomalies) where score is a float and anomalies is a list of strings.\n",
        "    \"\"\"\n",
        "    score_pattern = r\"Score:\\s*([\\d\\.]+)\"\n",
        "    anomalies_pattern = r\"Anomalies:\\s*\\[([^\\]]+)\\]\"\n",
        "\n",
        "    score_match = re.search(score_pattern, response)\n",
        "    if score_match:\n",
        "        score = float(score_match.group(1))\n",
        "    else:\n",
        "        score = 0.5  # default value if no score found\n",
        "\n",
        "    anomalies = []\n",
        "    anomalies_match = re.search(anomalies_pattern, response)\n",
        "    if anomalies_match:\n",
        "        # Split by comma and strip quotes and whitespace.\n",
        "        anomalies_raw = anomalies_match.group(1)\n",
        "        anomalies = [a.strip().strip('\"\\'' ) for a in anomalies_raw.split(\",\") if a.strip()]\n",
        "    return score, anomalies\n",
        "\n",
        "def analyze_transcription_details(transcription: str) -> Tuple[float, List[str]]:\n",
        "    \"\"\"\n",
        "    Analyze the transcription text for indicators of deepfake manipulation.\n",
        "    This function scans for keywords that may suggest manipulation.\n",
        "\n",
        "    Returns:\n",
        "        A tuple (score, anomalies), where a higher score indicates higher likelihood of manipulation.\n",
        "    \"\"\"\n",
        "    keywords = [\"fake\", \"inconsistent\", \"manipulated\", \"error\"]\n",
        "    found = [word for word in keywords if word in transcription.lower()]\n",
        "    # If any keyword is found, assume higher likelihood; otherwise, lower.\n",
        "    score = 0.8 if found else 0.4\n",
        "    return score, found"
      ],
      "metadata": {
        "id": "YkN1p_l2u-KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Analysis Functions**\n",
        "- Define functions for analyzing audio, image, and video data using Groq models"
      ],
      "metadata": {
        "id": "05aBMDMgY5CI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advanced Audio Analysis**"
      ],
      "metadata": {
        "id": "_KKDSAFn1uLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def advanced_audio_analysis(audio_data: Dict[str, Any], device: torch.device) -> DeepfakeAnalysisResult:\n",
        "    \"\"\"\n",
        "    Detailed audio analysis using two VLLM models and one Groq model.\n",
        "    1. wav2vec2 extracts detailed speech features.\n",
        "    2. llava_audio evaluates the audio for subtle manipulations.\n",
        "    3. groq_audio_model performs transcription analysis.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    anomalies = []\n",
        "\n",
        "    # Model 1: wav2vec2 – speech feature extraction\n",
        "    model = wav2vec2.to(device)\n",
        "    prompt1 = (\n",
        "        \"Analyze the audio waveform for speech features including tone, pitch, and rhythm. \"\n",
        "        \"Identify anomalies indicative of deepfake manipulation. Output format:\\n\"\n",
        "        \"Score: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    inputs1 = {\"audio\": audio_data.get(\"waveform\"), \"text\": prompt1}\n",
        "    with torch.no_grad():\n",
        "        output1 = model.generate(**inputs1)\n",
        "    score1, anomalies1 = parse_model_output(output1)\n",
        "    scores.append(score1)\n",
        "    anomalies.extend(anomalies1)\n",
        "\n",
        "    # Model 2: llava_audio – multimodal audio analysis\n",
        "    model = llava_audio.to(device)\n",
        "    prompt2 = (\n",
        "        \"Examine the audio clip for subtle signs of manipulation such as irregular speech tempo and lip-sync issues. \"\n",
        "        \"Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    inputs2 = {\"audio\": audio_data.get(\"waveform\"), \"text\": prompt2}\n",
        "    with torch.no_grad():\n",
        "        output2 = model.generate(**inputs2)\n",
        "    score2, anomalies2 = parse_model_output(output2)\n",
        "    scores.append(score2)\n",
        "    anomalies.extend(anomalies2)\n",
        "\n",
        "    # Model 3: Groq audio model – transcription analysis\n",
        "    response = groq_audio_model.transcriptions.create(\n",
        "        file=audio_data.get(\"waveform\"),\n",
        "        model=\"whisper-large-v3-turbo\"\n",
        "    )\n",
        "    transcription = response.text  # Actual transcription from the Groq model\n",
        "    score3, anomalies3 = analyze_transcription_details(transcription)\n",
        "    scores.append(score3)\n",
        "    anomalies.extend(anomalies3)\n",
        "\n",
        "    final_score = float(np.mean(scores))\n",
        "    return DeepfakeAnalysisResult(\n",
        "        score=final_score,\n",
        "        label=\"REAL\" if final_score > 0.7 else \"FAKE\",\n",
        "        confidence=float(np.std(scores)),\n",
        "        method=\"audio_analysis\",\n",
        "        anomalies=anomalies\n",
        "    )"
      ],
      "metadata": {
        "id": "GDaz8dMlu-No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advanced Image Analysis**"
      ],
      "metadata": {
        "id": "bWICXYdq1y2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def advanced_image_analysis(image: np.ndarray, device: torch.device) -> DeepfakeAnalysisResult:\n",
        "    \"\"\"\n",
        "    Detailed image analysis using two VLLM models and one Groq model.\n",
        "    1. llava_image inspects for digital artifacts.\n",
        "    2. clip evaluates image–text consistency.\n",
        "    3. groq_vision_model provides rapid visual anomaly detection.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    anomalies = []\n",
        "\n",
        "    # Model 1: llava_image – artifact detection\n",
        "    model = llava_image.to(device)\n",
        "    prompt1 = (\n",
        "        \"Inspect this image for signs of digital manipulation including lighting inconsistencies, edge artifacts, \"\n",
        "        \"and color mismatches. Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    inputs1 = {\"image\": image, \"text\": prompt1}\n",
        "    with torch.no_grad():\n",
        "        output1 = model.generate(**inputs1)\n",
        "    score1, anomalies1 = parse_model_output(output1)\n",
        "    scores.append(score1)\n",
        "    anomalies.extend(anomalies1)\n",
        "\n",
        "    # Model 2: clip – cross-modal evaluation\n",
        "    model = clip.to(device)\n",
        "    prompt2 = (\n",
        "        \"Evaluate the image against expected textual cues and detect any inconsistencies or signs of tampering. \"\n",
        "        \"Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    inputs2 = {\"image\": image, \"text\": prompt2}\n",
        "    with torch.no_grad():\n",
        "        output2 = model.generate(**inputs2)\n",
        "    score2, anomalies2 = parse_model_output(output2)\n",
        "    scores.append(score2)\n",
        "    anomalies.extend(anomalies2)\n",
        "\n",
        "    # Model 3: groq_vision_model – rapid anomaly detection\n",
        "    _, buffer = cv2.imencode('.png', image)\n",
        "    image_b64 = base64.b64encode(buffer).decode()\n",
        "    response = groq_vision_model.chat_completions.create(\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": (\n",
        "                \"Perform a detailed analysis of the image for digital tampering, focusing on lighting discrepancies, \"\n",
        "                \"color shifts, and edge artifacts. Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "            ),\n",
        "            \"image_url\": \"data:image/png;base64,\" + image_b64\n",
        "        }],\n",
        "        model=\"llama-3.2-90b-vision-preview\"\n",
        "    )\n",
        "    output3 = response.choices[0].message.content\n",
        "    score3, anomalies3 = parse_model_output(output3)\n",
        "    scores.append(score3)\n",
        "    anomalies.extend(anomalies3)\n",
        "\n",
        "    final_score = float(np.mean(scores))\n",
        "    return DeepfakeAnalysisResult(\n",
        "        score=final_score,\n",
        "        label=\"REAL\" if final_score > 0.7 else \"FAKE\",\n",
        "        confidence=float(np.std(scores)),\n",
        "        method=\"image_analysis\",\n",
        "        anomalies=anomalies\n",
        "    )"
      ],
      "metadata": {
        "id": "fVZT1Ci_13nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dlib\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "\n",
        "def analyze_eye_movements(frames: List[np.ndarray], models: Dict[str, Any]) -> List[str]:\n",
        "    anomalies = []\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "    blink_threshold = 0.2\n",
        "    blink_count = 0\n",
        "    for frame in frames:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = detector(gray)\n",
        "\n",
        "        for face in faces:\n",
        "            landmarks = predictor(gray, face)\n",
        "            left_eye_ratio = get_eye_aspect_ratio(landmarks, [36, 37, 38, 39, 40, 41])\n",
        "            right_eye_ratio = get_eye_aspect_ratio(landmarks, [42, 43, 44, 45, 46, 47])\n",
        "            if left_eye_ratio < blink_threshold or right_eye_ratio < blink_threshold:\n",
        "                blink_count += 1\n",
        "\n",
        "    if blink_count > len(frames) * 0.2:  # Example threshold for abnormal blink rate\n",
        "        anomalies.append(\"Abnormal blink rate detected\")\n",
        "\n",
        "    return anomalies\n",
        "\n",
        "def get_eye_aspect_ratio(landmarks, eye_points):\n",
        "    A = np.linalg.norm(np.array([landmarks.part(eye_points[1]).x, landmarks.part(eye_points[1]).y]) -\n",
        "                       np.array([landmarks.part(eye_points[5]).x, landmarks.part(eye_points[5]).y]))\n",
        "    B = np.linalg.norm(np.array([landmarks.part(eye_points[2]).x, landmarks.part(eye_points[2]).y]) -\n",
        "                       np.array([landmarks.part(eye_points[4]).x, landmarks.part(eye_points[4]).y]))\n",
        "    C = np.linalg.norm(np.array([landmarks.part(eye_points[0]).x, landmarks.part(eye_points[0]).y]) -\n",
        "                       np.array([landmarks.part(eye_points[3]).x, landmarks.part(eye_points[3]).y]))\n",
        "    ear = (A + B) / (2.0 * C)\n",
        "    return ear\n",
        "\n",
        "def analyze_facial_blood_flow(frames: List[np.ndarray], models: Dict[str, Any]) -> List[str]:\n",
        "    anomalies = []\n",
        "    mp_face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
        "\n",
        "    for frame in frames:\n",
        "        results = mp_face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        if results.multi_face_landmarks:\n",
        "            for face_landmarks in results.multi_face_landmarks:\n",
        "                if detect_blood_flow_anomaly(frame, face_landmarks):\n",
        "                    anomalies.append(\"Inconsistent blood flow patterns detected\")\n",
        "\n",
        "    return anomalies\n",
        "\n",
        "def detect_blood_flow_anomaly(frame, face_landmarks):\n",
        "    # Example logic to detect blood flow anomalies using color consistency\n",
        "    mean_color = np.mean(frame, axis=(0, 1))\n",
        "    if np.std(mean_color) > 10:  # Example threshold for color inconsistency\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def analyze_physics_based_patterns(frames: List[np.ndarray], models: Dict[str, Any]) -> List[str]:\n",
        "    anomalies = []\n",
        "    for frame in frames:\n",
        "        if detect_physics_anomaly(frame):\n",
        "            anomalies.append(\"Physics-based inconsistencies detected\")\n",
        "    return anomalies\n",
        "\n",
        "def detect_physics_anomaly(frame):\n",
        "    # Example logic for detecting hair movement and shadow consistency\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    if np.mean(edges) > 50:  # Example threshold for detecting sharp edges\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def detect_neural_rendering_artifacts(frames: List[np.ndarray], models: Dict[str, Any]) -> List[str]:\n",
        "    anomalies = []\n",
        "    gan_artifact_model = models[\"gan_artifact_model\"]\n",
        "\n",
        "    for frame in frames:\n",
        "        if detect_gan_artifacts(frame, gan_artifact_model):\n",
        "            anomalies.append(\"Neural rendering artifacts detected\")\n",
        "\n",
        "    return anomalies\n",
        "\n",
        "def detect_gan_artifacts(frame, model):\n",
        "    # Example logic for detecting GAN artifacts using a neural network\n",
        "    resized_frame = cv2.resize(frame, (224, 224))\n",
        "    frame_tensor = torch.tensor(resized_frame).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
        "    with torch.no_grad():\n",
        "        output = model(frame_tensor.to(device))\n",
        "    if output.argmax() == 1:  # Assuming the model outputs 1 for GAN artifacts\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "HB7oFZEZy05y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advanced Video Analysis**"
      ],
      "metadata": {
        "id": "MlQVINuo1_2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def advanced_video_analysis(video_data: Dict[str, Any], device: torch.device) -> DeepfakeAnalysisResult:\n",
        "    \"\"\"\n",
        "    Detailed video analysis using three VLLM models.\n",
        "    1. llava_next_video analyzes motion irregularities.\n",
        "    2. xclip evaluates the consistency of a representative frame.\n",
        "    3. videomae extracts spatiotemporal features.\n",
        "    Each model is prompted to return output in a standard format.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    anomalies = []\n",
        "\n",
        "    # Model 1: llava_next_video – motion and facial expression analysis\n",
        "    model = llava_next_video.to(device)\n",
        "    prompt1 = (\n",
        "        \"Analyze the following video frames for subtle motion irregularities, unnatural blinking, \"\n",
        "        \"and inconsistent facial expressions. Provide output in the format:\\n\"\n",
        "        \"Score: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    inputs1 = {\"video\": video_data.get(\"frames\"), \"text\": prompt1}\n",
        "    with torch.no_grad():\n",
        "        output1 = model.generate(**inputs1)  # Assume output1 is a text string\n",
        "    score1, anomalies1 = parse_model_output(output1)\n",
        "    scores.append(score1)\n",
        "    anomalies.extend(anomalies1)\n",
        "\n",
        "    # Model 2: xclip – cross-modal embedding consistency check\n",
        "    model = xclip.to(device)\n",
        "    prompt2 = (\n",
        "        \"Evaluate the consistency of the given video frame with its contextual description. \"\n",
        "        \"Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    rep_frame = video_data.get(\"frames\")[0]\n",
        "    inputs2 = {\"image\": rep_frame, \"text\": prompt2}\n",
        "    with torch.no_grad():\n",
        "        output2 = model.generate(**inputs2)\n",
        "    score2, anomalies2 = parse_model_output(output2)\n",
        "    scores.append(score2)\n",
        "    anomalies.extend(anomalies2)\n",
        "\n",
        "    # Model 3: videomae – spatiotemporal feature extraction\n",
        "    model = videomae.to(device)\n",
        "    prompt3 = (\n",
        "        \"Extract spatiotemporal features from the provided video frames to detect any signs of digital tampering. \"\n",
        "        \"Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "    )\n",
        "    inputs3 = {\"video\": video_data.get(\"frames\"), \"text\": prompt3}\n",
        "    with torch.no_grad():\n",
        "        output3 = model.generate(**inputs3)\n",
        "    score3, anomalies3 = parse_model_output(output3)\n",
        "    scores.append(score3)\n",
        "    anomalies.extend(anomalies3)\n",
        "\n",
        "    final_score = float(np.mean(scores))\n",
        "    return DeepfakeAnalysisResult(\n",
        "        score=final_score,\n",
        "        label=\"REAL\" if final_score > 0.7 else \"FAKE\",\n",
        "        confidence=float(np.std(scores)),\n",
        "        method=\"video_analysis\",\n",
        "        anomalies=anomalies\n",
        "    )"
      ],
      "metadata": {
        "id": "jRAPWt8u2IsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, XCLIPModel\n",
        "from vllm import LLM, SamplingParams\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def lip_sync_detection(frames: List[Any], audio_text: str, threshold: float = 0.7) -> DeepfakeAnalysisResult:\n",
        "    \"\"\"\n",
        "    Detect lip synchronization by comparing features extracted from video frames and audio text.\n",
        "    Uses ensemble extraction from both VLLM and Groq text models.\n",
        "    \"\"\"\n",
        "    # Process video frames using XCLIP to obtain video features.\n",
        "    video_inputs = xclip_processor(videos=list(frames), return_tensors=\"pt\")\n",
        "    video_features = xclip_model.get_video_features(**video_inputs).mean(dim=1)\n",
        "\n",
        "    # Extract text features using VLLM text model with a detailed prompt.\n",
        "    sampling_params = SamplingParams(temperature=0, max_tokens=64)\n",
        "    prompt_vllm = f\"Extract detailed semantic features from the following audio description for lip sync analysis: {audio_text}\"\n",
        "    vllm_text_output = vllm_text_model.generate(inputs=[prompt_vllm], sampling_params=sampling_params)\n",
        "    vllm_text_features = vllm_text_output[0].mean(dim=1)\n",
        "\n",
        "    # Extract text features using Groq text model with an equally detailed prompt.\n",
        "    groq_prompt = f\"Provide semantic feature extraction for lip sync detection from the audio: {audio_text}\"\n",
        "    groq_response = groq_text_model.chat_completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": groq_prompt}],\n",
        "        model=\"llama-3.3-70b-versatile\"\n",
        "    )\n",
        "    groq_text_str = groq_response.choices[0].message.content\n",
        "    # Extract numeric features from the response (in production, use proper embedding extraction)\n",
        "    nums = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", groq_text_str)\n",
        "    groq_text_features = torch.tensor([float(x) for x in nums]).unsqueeze(0)\n",
        "\n",
        "    # Combine features from both text models\n",
        "    combined_text_features = (vllm_text_features + groq_text_features) / 2.0\n",
        "\n",
        "    # Normalize features and compute cosine similarity\n",
        "    video_norm = video_features / video_features.norm(dim=1, keepdim=True)\n",
        "    text_norm = combined_text_features / combined_text_features.norm(dim=1, keepdim=True)\n",
        "    sync_scores = torch.nn.functional.cosine_similarity(video_norm, text_norm)\n",
        "    final_score = torch.mean(sync_scores).item()\n",
        "    confidence = torch.std(sync_scores).item()\n",
        "\n",
        "    anomalies = [\"Lip-sync inconsistency detected\"] if final_score < threshold else []\n",
        "    result_label = \"REAL\" if final_score > threshold else \"FAKE\"\n",
        "    return DeepfakeAnalysisResult(score=final_score, label=result_label, confidence=confidence,\n",
        "                                  method=\"lip_sync_detection\", anomalies=anomalies)"
      ],
      "metadata": {
        "id": "49tH6GarH7Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_consistency_analysis(results: Dict[str, DeepfakeAnalysisResult], llms: Dict[str, Any]) -> float:\n",
        "    \"\"\"\n",
        "    Analyze the semantic consistency between modalities using an advanced prompt.\n",
        "    The prompt asks the LLM to consider narrative coherence, temporal alignment, and emotional consistency.\n",
        "    \"\"\"\n",
        "    prompt_template = (\n",
        "        \"Analyze the following modality analyses for overall semantic consistency:\\n\\n\"\n",
        "        \"Video Analysis: {video_analysis}\\n\"\n",
        "        \"Audio Analysis: {audio_analysis}\\n\"\n",
        "        \"Image Analysis: {image_analysis}\\n\"\n",
        "        \"Text Analysis: {text_analysis}\\n\\n\"\n",
        "        \"Evaluate narrative coherence, logical contradictions, and emotional alignment. \"\n",
        "        \"Provide a score between 0 and 1 (where 1 is perfectly consistent) along with detailed reasoning.\\n\"\n",
        "        \"Output format:\\nScore: <score>\\nReasoning: <explanation>\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "    chain = LLMChain(llm=llms[\"llava\"], prompt=prompt)\n",
        "    response = chain.run({\n",
        "        \"video_analysis\": results[\"video\"].__dict__,\n",
        "        \"audio_analysis\": results[\"audio\"].__dict__,\n",
        "        \"image_analysis\": results[\"image\"].__dict__,\n",
        "        \"text_analysis\": results[\"text\"].__dict__\n",
        "    })\n",
        "    score_match = re.search(r\"Score:\\s*([0-9]*\\.?[0-9]+)\", response)\n",
        "    if score_match:\n",
        "        return float(score_match.group(1))\n",
        "    return 0.5"
      ],
      "metadata": {
        "id": "8K7h2pSWEbO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def face_forgery_detection(video_data: Dict[str, Any], device: torch.device, threshold: float = 0.0) -> DeepfakeAnalysisResult:\n",
        "    \"\"\"\n",
        "    Improved face forgery detection using an ensemble of two models:\n",
        "\n",
        "    1. VLLM Component (CLIP/xclip):\n",
        "       - Processes all face images (cropped from video frames) to extract image features.\n",
        "       - Computes text features for the prompts \"a real face\" and \"a manipulated face\".\n",
        "       - Calculates cosine similarity difference (similarity_real - similarity_fake) as score_vllm.\n",
        "\n",
        "    2. Groq Component:\n",
        "       - Uses a detailed prompt with the Groq vision model via its chat-completions API.\n",
        "       - The input face image (first frame) is encoded and sent; the response is parsed to yield score_groq and anomalies.\n",
        "\n",
        "    The final score is the average of score_vllm and score_groq. A positive combined score indicates REAL, while a negative one indicates FAKE.\n",
        "\n",
        "    Returns:\n",
        "        DeepfakeAnalysisResult with final score, label, confidence, method, and anomalies.\n",
        "    \"\"\"\n",
        "    # -- VLLM Component using CLIP --\n",
        "    try:\n",
        "        processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "        clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n",
        "    except Exception as e:\n",
        "        print(\"Error loading CLIP model:\", e)\n",
        "        return DeepfakeAnalysisResult(0, \"ERROR\", 0, \"face_forgery_detection\", [\"CLIP load error\"])\n",
        "\n",
        "    frames = video_data.get(\"frames\", [])\n",
        "    if not frames:\n",
        "        return DeepfakeAnalysisResult(0, \"ERROR\", 0, \"face_forgery_detection\", [\"No frames provided\"])\n",
        "\n",
        "    inputs = processor(images=frames, return_tensors=\"pt\", padding=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        image_features = clip_model.get_image_features(**inputs)\n",
        "    # Average features across frames\n",
        "    image_features = image_features.mean(dim=0, keepdim=True)\n",
        "\n",
        "    # Prepare text prompts and compute text embeddings.\n",
        "    text_prompts = [\"a real face\", \"a manipulated face\"]\n",
        "    text_inputs = processor(text=text_prompts, return_tensors=\"pt\", padding=True)\n",
        "    text_inputs = {k: v.to(device) for k, v in text_inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        text_features = clip_model.get_text_features(**text_inputs)\n",
        "\n",
        "    # Normalize and compute cosine similarities.\n",
        "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "    similarities = torch.matmul(image_features, text_features.T)  # shape (1, 2)\n",
        "    similarity_real = similarities[0, 0].item()\n",
        "    similarity_fake = similarities[0, 1].item()\n",
        "    score_vllm = similarity_real - similarity_fake\n",
        "    anomalies_vllm = []  # Optionally flag low score here.\n",
        "    if score_vllm < threshold:\n",
        "        anomalies_vllm.append(\"CLIP indicates potential forgery\")\n",
        "\n",
        "    # -- Groq Component --\n",
        "    # Assume groq_vision_model is already initialized in your environment.\n",
        "    try:\n",
        "        # Convert the first face image to base64-encoded PNG.\n",
        "        first_frame = frames[0]\n",
        "        _, buffer = cv2.imencode('.png', first_frame)\n",
        "        image_b64 = base64.b64encode(buffer).decode()\n",
        "        groq_prompt = (\n",
        "            \"Perform a detailed analysis of the face image for signs of digital manipulation. \"\n",
        "            \"Return the result in the following format:\\n\"\n",
        "            \"Score: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "        )\n",
        "        groq_response = groq_vision_model.chat_completions.create(\n",
        "            messages=[{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": groq_prompt,\n",
        "                \"image_url\": \"data:image/png;base64,\" + image_b64\n",
        "            }],\n",
        "            model=\"llama-3.2-90b-vision-preview\"\n",
        "        )\n",
        "        response_text = groq_response.choices[0].message.content\n",
        "        score_groq, anomalies_groq = robust_parse_output(response_text)\n",
        "    except Exception as e:\n",
        "        print(\"Error in Groq analysis:\", e)\n",
        "        score_groq = 0.0\n",
        "        anomalies_groq = [\"Groq analysis error\"]\n",
        "\n",
        "    # -- Fusion of VLLM and Groq Outputs --\n",
        "    combined_score = (score_vllm + score_groq) / 2.0\n",
        "    combined_anomalies = anomalies_vllm + anomalies_groq\n",
        "    # Confidence can be defined as the absolute difference between the two model scores.\n",
        "    confidence = abs(score_vllm - score_groq)\n",
        "    label = \"REAL\" if combined_score > threshold else \"FAKE\"\n",
        "\n",
        "    return DeepfakeAnalysisResult(\n",
        "        score=combined_score,\n",
        "        label=label,\n",
        "        confidence=confidence,\n",
        "        method=\"face_forgery_detection\",\n",
        "        anomalies=combined_anomalies\n",
        "    )"
      ],
      "metadata": {
        "id": "q61-4f7OEeJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def background_consistency_analysis(video_data: Dict[str, Any], models: Dict[str, Any], device: torch.device) -> DeepfakeAnalysisResult:\n",
        "    \"\"\"\n",
        "    Analyze background consistency using an ensemble approach.\n",
        "    Uses a VLLM-based Vision Transformer (ViT) and a Groq vision model.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    anomalies = []\n",
        "    # Model 1: VLLM-based background analysis using ViT.\n",
        "    model = models[\"vision\"].to(device)\n",
        "    vit_processor = AutoProcessor.from_pretrained(Config.MODEL_PATHS[\"clip_processor\"])\n",
        "    inputs = vit_processor(images=video_data[\"frames\"], return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        output_text = model.generate(**inputs)\n",
        "    score1, anomalies1 = parse_model_output(output_text)\n",
        "    scores.append(score1)\n",
        "    anomalies.extend(anomalies1)\n",
        "\n",
        "    # Model 2: Groq vision model for rapid background analysis.\n",
        "    _, buffer = cv2.imencode('.png', video_data[\"frames\"][0])\n",
        "    image_b64 = base64.b64encode(buffer).decode()\n",
        "    response = models[\"groq_vision\"].chat_completions.create(\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": (\n",
        "                \"Perform a detailed background analysis of the provided video frame to detect digital tampering. \"\n",
        "                \"Output format:\\nScore: <score>\\nAnomalies: [\\\"anomaly1\\\", \\\"anomaly2\\\", ...]\"\n",
        "            ),\n",
        "            \"image_url\": \"data:image/png;base64,\" + image_b64\n",
        "        }],\n",
        "        model=\"llama-3.2-90b-vision-preview\"\n",
        "    )\n",
        "    output_text_groq = response.choices[0].message.content\n",
        "    score2, anomalies2 = parse_model_output(output_text_groq)\n",
        "    scores.append(score2)\n",
        "    anomalies.extend(anomalies2)\n",
        "\n",
        "    final_score = float(np.mean(scores))\n",
        "    return DeepfakeAnalysisResult(score=final_score, label=\"REAL\" if final_score > 0.7 else \"FAKE\",\n",
        "                                  confidence=float(np.std(scores)), method=\"background_consistency_analysis\", anomalies=anomalies)"
      ],
      "metadata": {
        "id": "r_JDhnaAEkUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_temporal_coherence(temporal_features: List[Dict[str, Any]]) -> float:\n",
        "    anomalies = []\n",
        "    for feature in temporal_features:\n",
        "        if feature[\"magnitude\"].max() > 1.0:\n",
        "            anomalies.append(\"Abrupt changes in motion detected\")\n",
        "    return 1.0 - (len(anomalies) / len(temporal_features))"
      ],
      "metadata": {
        "id": "fnLHMoz0Epy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Tool Creation Functions**\n",
        "- Define functions for creating deepfake detection tools and agents"
      ],
      "metadata": {
        "id": "HoftOwSUZPye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_deepfake_detection_tools(models: Dict[str, Any], device: torch.device) -> List[Tool]:\n",
        "    tools = [\n",
        "        Tool(\n",
        "            name=\"analyze_video\",\n",
        "            func=lambda x: advanced_video_analysis(x, models, device),\n",
        "            description=\"Analyzes video content for signs of manipulation\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"analyze_audio\",\n",
        "            func=lambda x: advanced_audio_analysis(x, models, device),\n",
        "            description=\"Analyzes audio content for signs of manipulation\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"analyze_image\",\n",
        "            func=lambda x: advanced_image_analysis(x, models, device),\n",
        "            description=\"Analyzes image content for signs of manipulation\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"semantic_analysis\",\n",
        "            func=lambda x: semantic_consistency_analysis(x, models[\"llms\"]),\n",
        "            description=\"Analyzes semantic consistency across modalities\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"face_forgery_detection\",\n",
        "            func=lambda x: face_forgery_detection(x, models, device),\n",
        "            description=\"Detects face forgeries in video content\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"lip_sync_detection\",\n",
        "            func=lambda x: lip_sync_detection(x, models, device),\n",
        "            description=\"Analyzes lip-sync consistency between audio and video\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"background_consistency\",\n",
        "            func=lambda x: background_consistency_analysis(x, models, device),\n",
        "            description=\"Analyzes background consistency across frames\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"real_time_streaming_analysis\",\n",
        "            func=lambda x: real_time_streaming_analysis(x, models, device),\n",
        "            description=\"Analyzes live video streams for signs of manipulation\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"text_analysis\",\n",
        "            func=lambda x: text_analysis(x, models[\"llms\"]),\n",
        "            description=\"Analyzes text content for signs of manipulation\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"metadata_analysis\",\n",
        "            func=lambda x: metadata_analysis(x),\n",
        "            description=\"Analyzes metadata for signs of manipulation\"\n",
        "        )\n",
        "    ]\n",
        "    return tools"
      ],
      "metadata": {
        "id": "PEWzNSs3ZGK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Detection Agent**\n",
        "- Define the detection graph for processing the input data"
      ],
      "metadata": {
        "id": "IgsLH-Xp2eW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
        "from langchain.schema import AgentAction, AgentFinish\n",
        "from langchain.tools import Tool\n",
        "\n",
        "def create_detection_agent(tools: List[Tool], llm: ChatOpenAI) -> AgentExecutor:\n",
        "    class DeepfakeDetectionOutputParser:\n",
        "        def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
        "            try:\n",
        "                if \"Final Answer:\" in llm_output:\n",
        "                    return AgentFinish(\n",
        "                        return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
        "                        log=llm_output,\n",
        "                    )\n",
        "                action_match = re.search(r\"Action: (.*?)\\nAction Input: (.*)\", llm_output, re.DOTALL)\n",
        "                if not action_match:\n",
        "                    raise ValueError(\"Could not parse LLM output: \" + llm_output)\n",
        "                action = action_match.group(1).strip()\n",
        "                action_input = action_match.group(2).strip()\n",
        "                return AgentAction(tool=action, tool_input=action_input, log=llm_output)\n",
        "            except Exception as e:\n",
        "                raise ValueError(f\"Could not parse LLM output: {llm_output}\") from e\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        SystemMessagePromptTemplate.from_template(\"\"\"\n",
        "            You are an expert forensic deepfake detection analyst.\n",
        "            You have received detailed outputs from various specialized modality tools:\n",
        "            - Video (spatiotemporal analysis)\n",
        "            - Audio (transcription and acoustic anomaly analysis)\n",
        "            - Image (ensemble analysis using multiple vision models)\n",
        "            - Text (extraction and reasoning)\n",
        "            - Face forgery and background consistency analysis\n",
        "            Your task is to review these outputs and provide a comprehensive, step-by-step explanation of the findings.\n",
        "            For each modality:\n",
        "              1. Summarize the key evidence.\n",
        "              2. Explain any detected anomalies or inconsistencies.\n",
        "            Finally, provide an overall verdict on the authenticity of the media and justify your decision.\n",
        "            Format your response as:\n",
        "            Action: [Tool Name]\n",
        "            Action Input: [Summary of results]\n",
        "            Observation: [Detailed step-by-step reasoning]\n",
        "            Final Answer: [Overall verdict with supporting details]\n",
        "            Available tools: {tools}\n",
        "        \"\"\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{input}\")\n",
        "    ])\n",
        "\n",
        "    return AgentExecutor.from_agent_and_tools(\n",
        "        agent=LLMSingleActionAgent(\n",
        "            llm_chain=LLMChain(llm=llm, prompt=prompt),\n",
        "            output_parser=DeepfakeDetectionOutputParser(),\n",
        "            stop=[\"Observation:\", \"Final Answer:\"],\n",
        "            allowed_tools=[tool.name for tool in tools]\n",
        "        ),\n",
        "        tools=tools,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "def create_detection_graph() -> StateGraph:\n",
        "    def preprocess(state):\n",
        "        input_data = state[\"input\"]\n",
        "        processed_data = asyncio.run(enhanced_preprocessing(input_data))\n",
        "        return {**state, \"processed_data\": processed_data}\n",
        "\n",
        "    def analyze_modalities(state):\n",
        "        processed_data = state[\"processed_data\"]\n",
        "        models = state[\"models\"]\n",
        "        device = state[\"device\"]\n",
        "        results = {\n",
        "            \"video\": asyncio.run(advanced_video_analysis(processed_data, models, device)) if \"frames\" in processed_data else None,\n",
        "            \"audio\": asyncio.run(advanced_audio_analysis(processed_data.get(\"audio\"), models, device)) if \"audio\" in processed_data else None,\n",
        "            \"image\": asyncio.run(advanced_image_analysis(processed_data[\"image\"], models, device)) if \"image\" in processed_data else None,\n",
        "            \"text\": asyncio.run(text_analysis(processed_data.get(\"text\"), models[\"llms\"])) if \"text\" in processed_data else None,\n",
        "            \"face_forgery\": face_forgery_detection(processed_data, models, device) if \"frames\" in processed_data else None,\n",
        "            \"background\": background_consistency_analysis(processed_data, models, device) if \"frames\" in processed_data else None\n",
        "        }\n",
        "        return {**state, \"modality_results\": results}\n",
        "\n",
        "    def cross_modal_analysis(state):\n",
        "        results = state[\"modality_results\"]\n",
        "        processed_data = state[\"processed_data\"]\n",
        "        models = state[\"models\"]\n",
        "        cross_modal_score = analyze_cross_modal_consistency(results, processed_data, models)\n",
        "        return {**state, \"cross_modal_score\": cross_modal_score}\n",
        "\n",
        "    def generate_report(state):\n",
        "        results = state[\"modality_results\"]\n",
        "        cross_modal_score = state[\"cross_modal_score\"]\n",
        "        processed_data = state[\"processed_data\"]\n",
        "        report = generate_comprehensive_report(results, cross_modal_score, processed_data)\n",
        "        return {**state, \"final_report\": report}\n",
        "\n",
        "    workflow = StateGraph(nodes=[\n",
        "        (\"preprocess\", preprocess),\n",
        "        (\"analyze_modalities\", analyze_modalities),\n",
        "        (\"cross_modal_analysis\", cross_modal_analysis),\n",
        "        (\"generate_report\", generate_report)\n",
        "    ])\n",
        "    workflow.add_edge(\"preprocess\", \"analyze_modalities\")\n",
        "    workflow.add_edge(\"analyze_modalities\", \"cross_modal_analysis\")\n",
        "    workflow.add_edge(\"cross_modal_analysis\", \"generate_report\")\n",
        "    workflow.add_edge(\"generate_report\", END)\n",
        "    return workflow"
      ],
      "metadata": {
        "id": "epoIrEie2nx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Functions for Analyzing Cross-Modal Consistency and Generating Reports**"
      ],
      "metadata": {
        "id": "EF3CZ3zAaAPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_cross_modal_consistency(\n",
        "    results: Dict[str, DeepfakeAnalysisResult],\n",
        "    processed_data: Dict[str, Any],\n",
        "    models: Dict[str, Any]\n",
        ") -> float:\n",
        "    scores = []\n",
        "    if results[\"audio\"] and results[\"video\"]:\n",
        "        sync_score = analyze_av_sync(processed_data[\"frames\"], processed_data[\"audio\"])\n",
        "        scores.append(sync_score)\n",
        "    semantic_score = analyze_semantic_consistency(results, processed_data, models[\"llms\"])\n",
        "    scores.append(semantic_score)\n",
        "    temporal_score = analyze_temporal_coherence(processed_data[\"temporal_features\"])\n",
        "    scores.append(temporal_score)\n",
        "    bio_score = analyze_biometric_consistency(processed_data[\"frames\"], models)\n",
        "    scores.append(bio_score)\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "def analyze_semantic_consistency(\n",
        "    results: Dict[str, DeepfakeAnalysisResult],\n",
        "    processed_data: Dict[str, Any],\n",
        "    llms: Dict[str, ChatOpenAI]\n",
        ") -> float:\n",
        "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "        Analyze the consistency between different modalities in the content:\n",
        "\n",
        "        Video Analysis: {video_analysis}\n",
        "        Audio Analysis: {audio_analysis}\n",
        "        Image Analysis: {image_analysis}\n",
        "        Text Analysis: {text_analysis}\n",
        "\n",
        "        Consider:\n",
        "        1. Do the modalities tell a coherent story?\n",
        "        2. Are there logical contradictions?\n",
        "        3. Do temporal patterns align?\n",
        "        4. Is the emotional content consistent?\n",
        "\n",
        "        Rate the consistency from 0 to 1, where 1 is perfectly consistent.\n",
        "        Provide detailed reasoning for your rating.\n",
        "\n",
        "        Output format:\n",
        "        Score: [0-1]\n",
        "        Reasoning: [detailed explanation]\n",
        "    \"\"\")\n",
        "    chain = LLMChain(llm=llms[\"gpt4\"], prompt=prompt)\n",
        "    response = chain.run({\n",
        "        \"video_analysis\": results[\"video\"].dict() if results[\"video\"] else \"N/A\",\n",
        "        \"audio_analysis\": results[\"audio\"].dict() if results[\"audio\"] else \"N/A\",\n",
        "        \"image_analysis\": results[\"image\"].dict() if results[\"image\"] else \"N/A\",\n",
        "        \"text_analysis\": results[\"text\"].dict() if results[\"text\"] else \"N/A\"\n",
        "    })\n",
        "    score_match = re.search(r\"Score: (0\\.\\d+|1\\.0)\", response)\n",
        "    if score_match:\n",
        "        return float(score_match.group(1))\n",
        "    return 0.5\n",
        "\n",
        "def generate_comprehensive_report(\n",
        "    results: Dict[str, DeepfakeAnalysisResult],\n",
        "    cross_modal_score: float,\n",
        "    processed_data: Dict[str, Any]\n",
        ") -> MultimodalAnalysisReport:\n",
        "    scores = [\n",
        "        results[\"video\"].score if results[\"video\"] else 0.5,\n",
        "        results[\"audio\"].score if results[\"audio\"] else 0.5,\n",
        "        results[\"image\"].score if results[\"image\"] else 0.5,\n",
        "        results[\"text\"].score if results[\"text\"] else 0.5,\n",
        "        cross_modal_score\n",
        "    ]\n",
        "    weights = [0.3, 0.2, 0.2, 0.2, 0.1]\n",
        "    final_score = sum(s * w for s, w in zip(scores, weights))\n",
        "    evidence = []\n",
        "    for modality, result in results.items():\n",
        "        if result:\n",
        "            evidence.extend([\n",
        "                {\n",
        "                    \"type\": modality,\n",
        "                    \"description\": anomaly,\n",
        "                    \"confidence\": result.confidence,\n",
        "                    \"method\": result.method\n",
        "                }\n",
        "                for anomaly in result.anomalies\n",
        "            ])\n",
        "    return MultimodalAnalysisReport(\n",
        "        case_id=f\"DFD-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
        "        file_info=processed_data[\"metadata\"] if \"metadata\" in processed_data else {},\n",
        "        video_analysis=results[\"video\"],\n",
        "        audio_analysis=results[\"audio\"],\n",
        "        image_analysis=results[\"image\"],\n",
        "        text_analysis=results[\"text\"],\n",
        "        multimodal_score=float(final_score),\n",
        "        verdict=\"AUTHENTIC\" if final_score > 0.7 else \"MANIPULATED\",\n",
        "        evidence=evidence,\n",
        "        metadata={\n",
        "            \"processing_time\": datetime.now().isoformat(),\n",
        "            \"models_used\": list(results.keys()),\n",
        "            \"cross_modal_score\": cross_modal_score,\n",
        "            \"confidence_distribution\": {\n",
        "                modality: result.confidence\n",
        "                for modality, result in results.items() if result\n",
        "            }\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "id": "H0mTuH2hZ5de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Real-Time Streaming Analysis**\n",
        "- Define a function for real-time streaming analysis"
      ],
      "metadata": {
        "id": "Ov48BT01aOO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def real_time_streaming_analysis(video_stream: Any, models: Dict[str, Any], device: torch.device) -> DeepfakeAnalysisResult:\n",
        "    frames = []\n",
        "    audio_data = None\n",
        "    metadata = {\n",
        "        \"fps\": 30,\n",
        "        \"frame_count\": 0,\n",
        "        \"width\": 0,\n",
        "        \"height\": 0,\n",
        "        \"duration\": 0,\n",
        "        \"codec\": \"N/A\",\n",
        "        \"file_size\": 0\n",
        "    }\n",
        "    frame_quality_metrics = []\n",
        "    optical_flow_data = []\n",
        "    prev_frame = None\n",
        "    temporal_features = []\n",
        "\n",
        "    loop = asyncio.get_event_loop()\n",
        "    executor = ThreadPoolExecutor(max_workers=4)\n",
        "\n",
        "    async def process_frame(frame):\n",
        "        return await loop.run_in_executor(executor, enhance_image_resolution, frame)\n",
        "\n",
        "    async def process_quality_metrics(frame):\n",
        "        return await loop.run_in_executor(executor, lambda: {\n",
        "            \"blur\": cv2.Laplacian(frame, cv2.CV_64F).var(),\n",
        "            \"noise\": estimate_noise(frame),\n",
        "            \"brightness\": np.mean(frame),\n",
        "            \"contrast\": calculate_contrast(frame),\n",
        "            \"compression_artifacts\": detect_compression_artifacts(frame)\n",
        "        })\n",
        "\n",
        "    async def process_optical_flow(prev_frame, frame):\n",
        "        return await loop.run_in_executor(executor, calculate_dense_optical_flow, prev_frame, frame)\n",
        "\n",
        "    async def process_temporal_features(flow):\n",
        "        return await loop.run_in_executor(executor, extract_temporal_features, flow)\n",
        "\n",
        "    while True:\n",
        "        frame = await video_stream.read()\n",
        "        if frame is None:\n",
        "            break\n",
        "        frame, quality_metrics = await asyncio.gather(\n",
        "            process_frame(frame),\n",
        "            process_quality_metrics(frame)\n",
        "        )\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frames.append(rgb_frame)\n",
        "        frame_quality_metrics.append(quality_metrics)\n",
        "        if prev_frame is not None:\n",
        "            flow, temp_features = await asyncio.gather(\n",
        "                process_optical_flow(prev_frame, frame),\n",
        "                process_temporal_features(flow)\n",
        "            )\n",
        "            optical_flow_data.append(flow)\n",
        "            temporal_features.append(temp_features)\n",
        "        prev_frame = frame.copy()\n",
        "\n",
        "    video_data = {\n",
        "        \"frames\": frames,\n",
        "        \"audio\": audio_data,\n",
        "        \"metadata\": metadata,\n",
        "        \"quality_metrics\": frame_quality_metrics,\n",
        "        \"optical_flow\": optical_flow_data,\n",
        "        \"temporal_features\": temporal_features\n",
        "    }\n",
        "\n",
        "    return await advanced_video_analysis(video_data, models, device)"
      ],
      "metadata": {
        "id": "e6-q4yeeaKEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Text Analysis**\n",
        "- Define a function for text analysis using Groq models:"
      ],
      "metadata": {
        "id": "hHpkFFGDaqtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def text_analysis(text: str, llms: Dict[str, ChatOpenAI]) -> DeepfakeAnalysisResult:\n",
        "    response = groq_client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Analyze the following text for signs of manipulation or inconsistencies:\\n\\n{text}\"\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "    )\n",
        "    content = response.choices[0].message.content\n",
        "    score_match = re.search(r\"Score: (0\\.\\d+|1\\.0)\", content)\n",
        "    if score_match:\n",
        "        score = float(score_match.group(1))\n",
        "    else:\n",
        "        score = 0.5\n",
        "    anomalies = [line.strip() for line in content.split(\"Reasoning:\")[-1].strip().split(\"\\n\") if line.strip()]\n",
        "    return DeepfakeAnalysisResult(\n",
        "        score=score,\n",
        "        label=\"REAL\" if score > 0.7 else \"FAKE\",\n",
        "        confidence=0.0,\n",
        "        method=\"text_analysis\",\n",
        "        anomalies=anomalies\n",
        "    )"
      ],
      "metadata": {
        "id": "UpL42dfZaRF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Metadata Analysis**\n",
        "- Define a function for metadata analysis"
      ],
      "metadata": {
        "id": "8WGV0gpibBij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metadata_analysis(metadata: Dict[str, Any]) -> DeepfakeAnalysisResult:\n",
        "    anomalies = []\n",
        "    scores = []\n",
        "\n",
        "    if metadata.get(\"fps\") < 10:\n",
        "        anomalies.append(\"Unusually low frame rate\")\n",
        "        scores.append(0.2)\n",
        "    if metadata.get(\"duration\") < 1:\n",
        "        anomalies.append(\"Unusually short duration\")\n",
        "        scores.append(0.2)\n",
        "    if metadata.get(\"file_size\") < 100000:\n",
        "        anomalies.append(\"Unusually small file size\")\n",
        "        scores.append(0.2)\n",
        "\n",
        "    final_score = np.mean(scores) if scores else 0.5\n",
        "    return DeepfakeAnalysisResult(\n",
        "        score=float(final_score),\n",
        "        label=\"REAL\" if final_score > 0.7 else \"FAKE\",\n",
        "        confidence=float(np.std(scores)) if scores else 0.0,\n",
        "        method=\"metadata_analysis\",\n",
        "        anomalies=anomalies\n",
        "    )"
      ],
      "metadata": {
        "id": "lr_VZJS_aRIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the Main Function**\n",
        "- Define the main function to run the deepfake detection system"
      ],
      "metadata": {
        "id": "iZRCoZgobKdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import asyncio\n",
        "from datetime import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "lwK0ZBvj6NxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_uploaded_file(uploaded_file):\n",
        "    \"\"\"\n",
        "    Saves the uploaded file to a local directory and returns its file path.\n",
        "    \"\"\"\n",
        "    file_name = uploaded_file['metadata']['name']\n",
        "    upload_dir = \"uploads\"\n",
        "    os.makedirs(upload_dir, exist_ok=True)\n",
        "    file_path = os.path.join(upload_dir, file_name)\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        f.write(uploaded_file['content'])\n",
        "    return file_path"
      ],
      "metadata": {
        "id": "gWC65JLB89k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def run_deepfake_detection(file_path: str, mode: str = \"all\") -> MultimodalAnalysisReport:\n",
        "    \"\"\"\n",
        "    Runs the deepfake detection pipeline asynchronously.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        state = {\n",
        "            \"input\": file_path,\n",
        "            \"mode\": mode,\n",
        "            \"models\": env[\"models\"],\n",
        "            \"device\": env[\"device\"]\n",
        "        }\n",
        "        workflow = create_detection_graph()\n",
        "        final_state = workflow.run(state)\n",
        "        return final_state[\"final_report\"]\n",
        "    except Exception as e:\n",
        "        print(f\"[{datetime.now()}] Error in deepfake detection: {str(e)}\")\n",
        "        raise RuntimeError(\"Deepfake detection failed. Check input and models.\") from e"
      ],
      "metadata": {
        "id": "yAEKfJjTyDVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Enhanced UI with ipywidgets\n",
        "# ---------------------------\n",
        "\n",
        "# File upload widget with custom style.\n",
        "file_upload = widgets.FileUpload(\n",
        "    accept='',\n",
        "    multiple=False,\n",
        "    description='Upload File',\n",
        "    style={'button_color': 'lightblue'},\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "# Dropdown to choose detection mode.\n",
        "mode_dropdown = widgets.Dropdown(\n",
        "    options=[('All', 'all'), ('Audio', 'audio'), ('Video', 'video'), ('Image', 'image')],\n",
        "    value='all',\n",
        "    description='Mode:',\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "# Start button with a clear label.\n",
        "start_button = widgets.Button(\n",
        "    description=\"Start Detection\",\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "# Progress bar for visual feedback.\n",
        "progress_bar = widgets.IntProgress(\n",
        "    value=0,\n",
        "    min=0,\n",
        "    max=10,\n",
        "    description='Progress:',\n",
        "    bar_style='info',\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "# Log output widget (scrollable for lengthy logs).\n",
        "log_output = widgets.Output(layout={'border': '1px solid black', 'height': '200px', 'overflow_y': 'auto'})\n",
        "\n",
        "# Global variable to store the uploaded file path.\n",
        "uploaded_file_path = None\n",
        "\n",
        "def on_file_upload_change(change):\n",
        "    global uploaded_file_path\n",
        "    if file_upload.value:\n",
        "        uploaded_file = list(file_upload.value.values())[0]\n",
        "        uploaded_file_path = save_uploaded_file(uploaded_file)\n",
        "        with log_output:\n",
        "            clear_output()\n",
        "            print(f\"[{datetime.now()}] File uploaded: {uploaded_file_path}\")\n",
        "        start_button.disabled = False\n",
        "\n",
        "async def process_detection(file_path, mode):\n",
        "    with log_output:\n",
        "        clear_output()\n",
        "        print(f\"[{datetime.now()}] Starting deepfake detection for file:\\n{file_path}\\nin mode: {mode}\\n\")\n",
        "    progress_bar.value = 0\n",
        "    # Simulate processing with periodic progress updates.\n",
        "    for i in range(10):\n",
        "        await asyncio.sleep(1)\n",
        "        progress_bar.value = i + 1\n",
        "    report = await run_deepfake_detection(file_path, mode)\n",
        "    with log_output:\n",
        "        print(\"\\nFinal Forensic Report:\")\n",
        "        print(json.dumps(report.dict(), indent=2, default=str))\n",
        "\n",
        "def on_start_button_click(b):\n",
        "    if uploaded_file_path:\n",
        "        asyncio.run(process_detection(uploaded_file_path, mode_dropdown.value))\n",
        "\n",
        "# Attach event handlers.\n",
        "file_upload.observe(on_file_upload_change, names='value')\n",
        "start_button.on_click(on_start_button_click)\n",
        "\n",
        "# Initially disable the start button until a file is uploaded.\n",
        "start_button.disabled = True\n",
        "\n",
        "# Layout: arrange widgets in a clean UI using containers.\n",
        "ui_left = widgets.VBox([file_upload, mode_dropdown, start_button, progress_bar])\n",
        "ui = widgets.HBox([ui_left, log_output])\n",
        "\n",
        "# Display the complete UI.\n",
        "display(ui)"
      ],
      "metadata": {
        "id": "f32-YNDWJlpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UEbvz2Uo8Muw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}