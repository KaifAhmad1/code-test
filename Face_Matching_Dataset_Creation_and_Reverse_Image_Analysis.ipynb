{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgg37SToR3f2K9O351iiIz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Face_Matching_Dataset_Creation_and_Reverse_Image_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0jJucOQMBR67"
      },
      "outputs": [],
      "source": [
        "%pip install -q pandas opencv-python tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from zipfile import ZipFile\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "1AqzbBRfCk_t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_face_test_dataset(output_dir=\"forensic_face_test\", num_images=20, seed=42):\n",
        "    \"\"\"\n",
        "    Create a test dataset for face forensic analysis using VGGFace2 dataset.\n",
        "\n",
        "    Args:\n",
        "        output_dir: Output directory for the test dataset\n",
        "        num_images: Number of images to include (default: 20)\n",
        "        seed: Random seed for reproducibility\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Create directory structure\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, \"images\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, \"metadata\"), exist_ok=True)\n",
        "\n",
        "    print(f\"Creating face test dataset with {num_images} images...\")\n",
        "\n",
        "    # VGGFace2 test set (smaller portion of VGGFace2)\n",
        "    # Note: In a real setting, you would need to apply for access to this dataset\n",
        "    # We're providing the code assuming access has been granted\n",
        "    # URL: https://www.robots.ox.ac.uk/~vgg/data/vgg_face2/\n",
        "\n",
        "    vggface_dir = os.path.join(output_dir, \"vggface2_test\")\n",
        "\n",
        "    # For this example, let's assume the dataset has been downloaded and extracted\n",
        "    # If you have the dataset downloaded, replace the following comment with actual path\n",
        "    if not os.path.exists(vggface_dir):\n",
        "        print(\"Please download the VGGFace2 test dataset from:\")\n",
        "        print(\"https://www.robots.ox.ac.uk/~vgg/data/vgg_face2/\")\n",
        "        print(f\"Extract it to {vggface_dir}\")\n",
        "        print(\"The dataset requires application for access.\")\n",
        "\n",
        "        # As an alternative, we can use a small sample from FFHQ dataset\n",
        "        print(\"Using Flickr-Faces-HQ (FFHQ) sample as an alternative...\")\n",
        "        ffhq_sample_url = \"https://github.com/NVlabs/ffhq-dataset/raw/master/thumbnails128x128/00000.png\"\n",
        "\n",
        "        # Create temporary directory\n",
        "        temp_dir = os.path.join(output_dir, \"temp\")\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "        # Download a few sample images from FFHQ thumbnails\n",
        "        sample_images = []\n",
        "        for i in range(30):  # Download 30 to have enough to choose from\n",
        "            img_id = str(i).zfill(5)\n",
        "            img_url = f\"https://github.com/NVlabs/ffhq-dataset/raw/master/thumbnails128x128/{img_id}.png\"\n",
        "            img_path = os.path.join(temp_dir, f\"{img_id}.png\")\n",
        "\n",
        "            try:\n",
        "                response = requests.get(img_url, stream=True)\n",
        "                if response.status_code == 200:\n",
        "                    with open(img_path, 'wb') as f:\n",
        "                        for chunk in response:\n",
        "                            f.write(chunk)\n",
        "                    sample_images.append((img_path, f\"person_{len(sample_images) // 2}\", len(sample_images) % 2))\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading {img_url}: {e}\")\n",
        "\n",
        "        # Process these images\n",
        "        selected_images = sample_images[:num_images-1]  # Save one slot for a manipulated image\n",
        "    else:\n",
        "        # If VGGFace2 is available, use it\n",
        "        person_dirs = [d for d in os.listdir(vggface_dir) if os.path.isdir(os.path.join(vggface_dir, d))]\n",
        "\n",
        "        # Select people with multiple images for identity clustering\n",
        "        selected_people = random.sample(person_dirs, min(num_images // 2, len(person_dirs)))\n",
        "\n",
        "        selected_images = []\n",
        "        for person in selected_people:\n",
        "            person_dir = os.path.join(vggface_dir, person)\n",
        "            person_images = os.listdir(person_dir)\n",
        "\n",
        "            # Take 2 images for each person\n",
        "            if len(person_images) >= 2:\n",
        "                selected = random.sample(person_images, 2)\n",
        "                for img in selected:\n",
        "                    selected_images.append((os.path.join(person_dir, img), person, selected.index(img)))\n",
        "\n",
        "    # Process the images\n",
        "    metadata = []\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    for i, (img_path, person_id, img_index) in enumerate(tqdm(selected_images, desc=\"Processing images\")):\n",
        "        if i >= num_images - 1:  # Save one slot for manipulated image\n",
        "            break\n",
        "\n",
        "        # New file name\n",
        "        new_filename = f\"{i+1:02d}_{person_id}_{Path(img_path).name}\"\n",
        "        dst_path = os.path.join(output_dir, \"images\", new_filename)\n",
        "\n",
        "        # Copy the image\n",
        "        shutil.copy2(img_path, dst_path)\n",
        "\n",
        "        # Detect faces\n",
        "        try:\n",
        "            image = cv2.imread(img_path)\n",
        "            if image is None:\n",
        "                print(f\"Failed to read image: {img_path}\")\n",
        "                continue\n",
        "\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "            if len(faces) > 0:\n",
        "                x, y, w, h = faces[0]\n",
        "                face_coords = {\"x\": int(x), \"y\": int(y), \"width\": int(w), \"height\": int(h)}\n",
        "            else:\n",
        "                face_coords = {\"x\": 0, \"y\": 0, \"width\": image.shape[1], \"height\": image.shape[0]}\n",
        "\n",
        "            # Add to metadata\n",
        "            metadata.append({\n",
        "                \"filename\": new_filename,\n",
        "                \"person_id\": person_id,\n",
        "                \"image_index\": img_index,\n",
        "                \"source\": \"vggface2\" if os.path.exists(vggface_dir) else \"ffhq\",\n",
        "                \"face_detected\": len(faces) > 0,\n",
        "                \"face_x\": face_coords[\"x\"],\n",
        "                \"face_y\": face_coords[\"y\"],\n",
        "                \"face_width\": face_coords[\"width\"],\n",
        "                \"face_height\": face_coords[\"height\"],\n",
        "                \"image_width\": image.shape[1],\n",
        "                \"image_height\": image.shape[0],\n",
        "                \"has_duplicate\": any(m[\"person_id\"] == person_id for m in metadata)\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {e}\")\n",
        "\n",
        "    # Create a manipulated version of one image\n",
        "    if metadata:\n",
        "        # Pick a random image to manipulate\n",
        "        original_idx = random.randint(0, len(metadata)-1)\n",
        "        original_file = os.path.join(output_dir, \"images\", metadata[original_idx][\"filename\"])\n",
        "\n",
        "        # Create a manipulated version\n",
        "        manipulated_filename = f\"manipulated_{metadata[original_idx]['filename']}\"\n",
        "        manipulated_file = os.path.join(output_dir, \"images\", manipulated_filename)\n",
        "\n",
        "        # Load the image\n",
        "        img = cv2.imread(original_file)\n",
        "        if img is not None:\n",
        "            # Apply a simple manipulation (face swap or morphing)\n",
        "            if len(metadata) > 1:\n",
        "                # Try to find another image of a different person\n",
        "                other_persons = [i for i, m in enumerate(metadata)\n",
        "                                if m[\"person_id\"] != metadata[original_idx][\"person_id\"]]\n",
        "\n",
        "                if other_persons:\n",
        "                    # Face swap (simplified version)\n",
        "                    donor_idx = random.choice(other_persons)\n",
        "                    donor_file = os.path.join(output_dir, \"images\", metadata[donor_idx][\"filename\"])\n",
        "                    donor_img = cv2.imread(donor_file)\n",
        "\n",
        "                    if donor_img is not None and metadata[original_idx][\"face_detected\"] and metadata[donor_idx][\"face_detected\"]:\n",
        "                        # Get face regions\n",
        "                        x1, y1, w1, h1 = (metadata[original_idx][\"face_x\"], metadata[original_idx][\"face_y\"],\n",
        "                                          metadata[original_idx][\"face_width\"], metadata[original_idx][\"face_height\"])\n",
        "\n",
        "                        x2, y2, w2, h2 = (metadata[donor_idx][\"face_x\"], metadata[donor_idx][\"face_y\"],\n",
        "                                          metadata[donor_idx][\"face_width\"], metadata[donor_idx][\"face_height\"])\n",
        "\n",
        "                        # Resize donor face to match original face size\n",
        "                        donor_face = donor_img[y2:y2+h2, x2:x2+w2]\n",
        "                        donor_face_resized = cv2.resize(donor_face, (w1, h1))\n",
        "\n",
        "                        # Create a copy of the original image\n",
        "                        manipulated_img = img.copy()\n",
        "\n",
        "                        # Apply face swap with simple blending\n",
        "                        manipulated_img[y1:y1+h1, x1:x1+w1] = donor_face_resized\n",
        "\n",
        "                        # Save manipulated image\n",
        "                        cv2.imwrite(manipulated_file, manipulated_img)\n",
        "                        manipulation_type = \"face_swap\"\n",
        "                    else:\n",
        "                        # Apply blur as fallback\n",
        "                        manipulated_img = img.copy()\n",
        "                        h, w = manipulated_img.shape[:2]\n",
        "                        face_region = manipulated_img[y1:y1+h1, x1:x1+w1]\n",
        "                        blurred_face = cv2.GaussianBlur(face_region, (25, 25), 0)\n",
        "                        manipulated_img[y1:y1+h1, x1:x1+w1] = blurred_face\n",
        "                        cv2.imwrite(manipulated_file, manipulated_img)\n",
        "                        manipulation_type = \"face_blur\"\n",
        "                else:\n",
        "                    # Apply blur to face\n",
        "                    x, y, w, h = (metadata[original_idx][\"face_x\"], metadata[original_idx][\"face_y\"],\n",
        "                                 metadata[original_idx][\"face_width\"], metadata[original_idx][\"face_height\"])\n",
        "                    face_region = img[y:y+h, x:x+w]\n",
        "                    blurred_face = cv2.GaussianBlur(face_region, (25, 25), 0)\n",
        "                    img[y:y+h, x:x+w] = blurred_face\n",
        "                    cv2.imwrite(manipulated_file, img)\n",
        "                    manipulation_type = \"face_blur\"\n",
        "\n",
        "                # Add to metadata\n",
        "                metadata.append({\n",
        "                    \"filename\": manipulated_filename,\n",
        "                    \"original_filename\": metadata[original_idx][\"filename\"],\n",
        "                    \"person_id\": f\"MANIPULATED_{metadata[original_idx]['person_id']}\",\n",
        "                    \"source\": \"MANIPULATED\",\n",
        "                    \"face_detected\": metadata[original_idx][\"face_detected\"],\n",
        "                    \"face_x\": metadata[original_idx][\"face_x\"],\n",
        "                    \"face_y\": metadata[original_idx][\"face_y\"],\n",
        "                    \"face_width\": metadata[original_idx][\"face_width\"],\n",
        "                    \"face_height\": metadata[original_idx][\"face_height\"],\n",
        "                    \"image_width\": metadata[original_idx][\"image_width\"],\n",
        "                    \"image_height\": metadata[original_idx][\"image_height\"],\n",
        "                    \"has_duplicate\": True,\n",
        "                    \"manipulation_type\": manipulation_type,\n",
        "                    \"original_image\": metadata[original_idx][\"filename\"]\n",
        "                })\n",
        "\n",
        "    # Save metadata to CSV\n",
        "    df = pd.DataFrame(metadata)\n",
        "    df.to_csv(os.path.join(output_dir, \"metadata\", \"face_images_metadata.csv\"), index=False)\n",
        "\n",
        "    # Create a README file\n",
        "    with open(os.path.join(output_dir, \"README.md\"), \"w\") as f:\n",
        "        f.write(\"# Forensic Face Analysis Test Dataset\\n\\n\")\n",
        "        f.write(f\"This dataset contains {len(df)} images for testing face detection, clustering, and forensic analysis.\\n\\n\")\n",
        "        f.write(\"## Dataset Statistics\\n\\n\")\n",
        "        f.write(f\"- Total images: {len(df)}\\n\")\n",
        "        f.write(f\"- Unique individuals: {len(df['person_id'].unique())}\\n\")\n",
        "        f.write(f\"- Images with detected faces: {df['face_detected'].sum()}\\n\")\n",
        "        f.write(f\"- Manipulated images: {len(df[df['source'] == 'MANIPULATED'])}\\n\\n\")\n",
        "        f.write(\"## Usage Instructions\\n\\n\")\n",
        "        f.write(\"This dataset is designed to test face detection, clustering, and manipulation detection capabilities.\\n\")\n",
        "        f.write(\"The metadata CSV contains ground truth information for validation purposes.\\n\")\n",
        "\n",
        "    print(f\"Dataset created successfully at: {output_dir}\")\n",
        "    print(f\"Total images created: {len(df)}\")\n",
        "\n",
        "    # Cleanup temporary files if they exist\n",
        "    if os.path.exists(os.path.join(output_dir, \"temp\")):\n",
        "        shutil.rmtree(os.path.join(output_dir, \"temp\"))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_face_test_dataset(num_images=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "NVWL9lGtCwsd",
        "outputId": "542afb69-c544-4a35-fcda-02fb92371d4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating face test dataset with 20 images...\n",
            "Please download the VGGFace2 test dataset from:\n",
            "https://www.robots.ox.ac.uk/~vgg/data/vgg_face2/\n",
            "Extract it to forensic_face_test/vggface2_test\n",
            "The dataset requires application for access.\n",
            "Using Flickr-Faces-HQ (FFHQ) sample as an alternative...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'person_id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-69f4054b3918>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mcreate_face_test_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-69f4054b3918>\u001b[0m in \u001b[0;36mcreate_face_test_dataset\u001b[0;34m(output_dir, num_images, seed)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"## Dataset Statistics\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"- Total images: {len(df)}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"- Unique individuals: {len(df['person_id'].unique())}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"- Images with detected faces: {df['face_detected'].sum()}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"- Manipulated images: {len(df[df['source'] == 'MANIPULATED'])}\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'person_id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GxoUDrwtC329"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}