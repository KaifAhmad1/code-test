{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Langgraph_Agentic_RAG_Cyber_AI_Copilot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cyber AI Copilot for Security and Intelligence Domain**"
      ],
      "metadata": {
        "id": "M0rt8qzmxyyR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Wzih_tgLwXK6",
        "outputId": "dd6cc5a8-46f8-4784-948d-daee375f0128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "crawl4ai 0.3.72 requires playwright==1.47.0, but you have playwright 1.48.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mPlaywright Host validation warning: \n",
            "╔══════════════════════════════════════════════════════╗\n",
            "║ Host system is missing dependencies to run browsers. ║\n",
            "║ Missing libraries:                                   ║\n",
            "║     libwoff2dec.so.1.0.2                             ║\n",
            "║     libgstgl-1.0.so.0                                ║\n",
            "║     libgstcodecparsers-1.0.so.0                      ║\n",
            "║     libharfbuzz-icu.so.0                             ║\n",
            "║     libenchant-2.so.2                                ║\n",
            "║     libsecret-1.so.0                                 ║\n",
            "║     libhyphen.so.0                                   ║\n",
            "║     libmanette-0.2.so.0                              ║\n",
            "╚══════════════════════════════════════════════════════╝\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:216:9)\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\u001b[39m\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:707:43)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:805:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:794:43)\n",
            "    at async t.<anonymous> (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/cli/program.js:119:7)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "%pip install --upgrade --quiet sentence-transformers langchain langchain-groq langchain-pinecone langchain-core asknews langgraph\n",
        "%pip install --quiet -U \"langchain-community>=0.2.16\" langchain-exa langchain-google-community goose3 crawl4ai[all] langchain-openai\n",
        "%pip install --upgrade --quiet playwright lxml\n",
        "!playwright install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List, Dict, Any, Optional, TypedDict\n",
        "from pydantic import BaseModel\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "from exa_py import Exa\n",
        "from langchain_community.tools import JinaSearch\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.tools import tool\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from IPython.display import Image, display\n",
        "import getpass\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_community.agent_toolkits import PlayWrightBrowserToolkit\n",
        "from langchain_community.tools.playwright.utils import create_async_playwright_browser\n",
        "import nest_asyncio\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# API Keys (hidden for security purposes)\n",
        "GROQ_API_KEY = getpass.getpass(\"Enter your Groq API key: \")\n",
        "PINECONE_API_KEY = \"8e15b925-3b96-497d-b20a-08d308782b83\"\n",
        "PINECONE_ENVIRONMENT = \"us-east-1\"\n",
        "ASKNEWS_CLIENT_ID = \"a0de4609-b760-4c83-9609-5c04d7743b84\"\n",
        "ASKNEWS_CLIENT_SECRET = \"D5Mlhkztk4TcW24diUgcW0FA2w\"\n",
        "SERPER_API_KEY = \"d8e815ef6caa94dbef7b977a0ea7d505b43a5a06\"\n",
        "EXA_API_KEY = \"953b5801-11be-4b37-a313-f8df8f37027c\"\n",
        "GOOGLE_API_KEY=\"AIzaSyBIQo9X6acoBazBfte9jF9Pl0QEZ9oe8pk\"\n",
        "GOOGLE_CSE_ID=\"63053004a7e2445c3\"\n",
        "Tavily_API_KEY=\"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\"\n",
        "FIRECRAWL_API_KEY = \"fc-9c7bf92d1db44ae1a34f9dc56a6031e6\"\n",
        "\n",
        "# Set environment variables for Search Tools\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "os.environ[\"ASKNEWS_CLIENT_ID\"] = ASKNEWS_CLIENT_ID\n",
        "os.environ[\"ASKNEWS_CLIENT_SECRET\"] = ASKNEWS_CLIENT_SECRET\n",
        "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY\n",
        "os.environ[\"EXA_API_KEY\"] = EXA_API_KEY\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = GOOGLE_CSE_ID\n",
        "os.environ[\"TAVILY_API_KEY\"] = Tavily_API_KEY"
      ],
      "metadata": {
        "id": "FY2ZeXgvxMxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96bc863d-9701-4055-e6eb-d20ecbce8ff3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Groq model\n",
        "llm = ChatGroq(\n",
        "    model=\"mixtral-8x7b-32768\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")\n",
        "\n",
        "# Initialize the embeddings\n",
        "embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=\"BAAI/bge-small-en\",\n",
        "    model_kwargs={\"device\": \"cpu\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True}\n",
        ")\n",
        "\n",
        "# Initialize Pinecone and vector store\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
        "pinecone_index = pc.Index(\"new-cyber-search\")\n",
        "vector_store = PineconeVectorStore(index=pinecone_index, embedding=embeddings)\n",
        "\n",
        "# Initialize search tools\n",
        "google_serper = GoogleSerperAPIWrapper()\n",
        "tavily_search = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    search_depth=\"advanced\",\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    include_images=True,\n",
        ")\n",
        "google_search = GoogleSearchAPIWrapper()\n",
        "exa = Exa(api_key=EXA_API_KEY)\n",
        "jina_tool = JinaSearch()\n",
        "\n",
        "# Initialize Playwright tools\n",
        "nest_asyncio.apply()\n",
        "async_browser = create_async_playwright_browser()\n",
        "toolkit = PlayWrightBrowserToolkit.from_browser(async_browser=async_browser)\n",
        "tools = toolkit.get_tools()\n",
        "\n",
        "tools_by_name = {tool.name: tool for tool in tools}\n",
        "navigate_tool = tools_by_name[\"navigate_browser\"]\n",
        "get_elements_tool = tools_by_name[\"get_elements\"]\n",
        "extract_hyperlinks_tool = tools_by_name[\"extract_hyperlinks\"]"
      ],
      "metadata": {
        "id": "XxTld11_xT0d"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: List[Dict[str, str]]\n",
        "    memory: Optional[Dict[str, Any]]\n",
        "\n",
        "class SearchResult(BaseModel):\n",
        "    source: str\n",
        "    title: str\n",
        "    snippet: str\n",
        "    url: str\n",
        "    date: Optional[str]\n",
        "    media: Optional[List[str]] = []\n",
        "    media_content: Optional[List[Dict[str, str]]] = []\n",
        "    links: Optional[List[str]] = []\n",
        "\n",
        "def parse_date(date_str: Optional[str]) -> Optional[datetime]:\n",
        "    if not date_str:\n",
        "        return None\n",
        "    try:\n",
        "        return datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
        "    except ValueError:\n",
        "        try:\n",
        "            return datetime.strptime(date_str, \"%Y-%m-%d\")\n",
        "        except ValueError:\n",
        "            return None\n",
        "\n",
        "def vector_search(query: str) -> List[SearchResult]:\n",
        "    results = vector_store.similarity_search(query, k=5)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Vector Search\",\n",
        "            title=f\"Result {i+1}\",\n",
        "            snippet=doc.page_content,\n",
        "            url=doc.metadata.get(\"source\", \"No URL\"),\n",
        "            date=doc.metadata.get(\"date\")\n",
        "        ) for i, doc in enumerate(results)\n",
        "    ]\n",
        "\n",
        "def google_serper_search(query: str) -> List[SearchResult]:\n",
        "    results = google_serper.results(query)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Google Serper\",\n",
        "            title=result.get(\"title\", \"No title\"),\n",
        "            snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "            url=result.get(\"link\", \"No link\"),\n",
        "            date=result.get(\"date\")\n",
        "        ) for result in results.get(\"organic\", [])\n",
        "    ]\n",
        "\n",
        "def jina_search(query: str) -> List[SearchResult]:\n",
        "    result = jina_tool.run(query)\n",
        "    print(f\"DEBUG: Jina Search results: {result}\")\n",
        "    return [SearchResult(\n",
        "        source=\"Jina Search\",\n",
        "        title=\"Jina Search Result\",\n",
        "        snippet=result,\n",
        "        url=\"\",\n",
        "        date=None\n",
        "    )]\n",
        "\n",
        "# Exa search function\n",
        "@tool\n",
        "def search_and_contents(query: str):\n",
        "    \"\"\"Search for webpages based on the query and retrieve their contents.\"\"\"\n",
        "    return exa.search_and_contents(\n",
        "        query, use_autoprompt=True, num_results=5, text=True, highlights=True\n",
        "    )\n",
        "\n",
        "def exa_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        print(f\"DEBUG: Starting Exa Search with query: {query}\")\n",
        "        response = search_and_contents(query)\n",
        "        print(f\"DEBUG: Raw results from Exa Search: {response}\")\n",
        "\n",
        "        if not isinstance(response, exa_py.api.SearchResponse):\n",
        "            print(f\"DEBUG: Exa Search results are not a SearchResponse. Type: {type(response)}\")\n",
        "            return []\n",
        "\n",
        "        results = response.results  # Extract the list of results from the SearchResponse object\n",
        "\n",
        "        search_results = [\n",
        "            SearchResult(\n",
        "                source=\"Exa Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "                url=result.get(\"link\", \"No link\"),\n",
        "                date=result.get(\"date\")\n",
        "            ) for result in results\n",
        "        ]\n",
        "\n",
        "        print(f\"DEBUG: Processed Exa Search results: {search_results}\")\n",
        "        return search_results\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Exa Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Tavily search tool\n",
        "tavily_tool = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    search_depth=\"advanced\",\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    include_images=True,\n",
        ")\n",
        "\n",
        "def tavily_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        results = tavily_tool.invoke({\"query\": query})\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Tavily Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"content\", \"No snippet\"),\n",
        "                url=result.get(\"url\", \"No link\"),\n",
        "                date=result.get(\"date\")\n",
        "            ) for result in results\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Tavily Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# New Google Programmable Search function\n",
        "def google_programmable_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        results = google_search.results(query, num_results=5)\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Google Programmable Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "                url=result.get(\"link\", \"No link\"),\n",
        "                date=result.get(\"date\")\n",
        "            ) for result in results\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Google Programmable Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Google Serper Image Search\n",
        "def google_serper_image_search(query: str) -> List[SearchResult]:\n",
        "    search_images = GoogleSerperAPIWrapper(type=\"images\")\n",
        "    results_images = search_images.results(query)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Google Serper Image Search\",\n",
        "            title=result.get(\"title\", \"No title\"),\n",
        "            snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "            url=result.get(\"imageUrl\", \"No link\"),\n",
        "            date=None,\n",
        "            media=[result.get(\"imageUrl\", \"No link\")]\n",
        "        ) for result in results_images.get(\"images\", [])\n",
        "    ]\n",
        "\n",
        "# Google Programmable Image Search\n",
        "def google_programmable_image_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        results = google_search.results(query + \" image\", num_results=5)\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Google Programmable Image Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "                url=result.get(\"link\", \"No link\"),\n",
        "                date=None,\n",
        "                media=[result.get(\"link\", \"No link\")]\n",
        "            ) for result in results\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Google Programmable Image Search: {str(e)}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "rnQiDPU8xddo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_searches(state: AgentState) -> AgentState:\n",
        "    query = state[\"messages\"][-1][\"content\"]\n",
        "    searches = [\n",
        "        (\"Vector Search\", vector_search),\n",
        "        (\"Google Serper Search\", google_serper_search),\n",
        "        (\"Exa Search\", exa_search),\n",
        "        (\"Tavily Search\", tavily_search),\n",
        "        (\"Jina Search\", jina_search),\n",
        "        (\"Google Programmable Search\", google_programmable_search),\n",
        "        (\"Google Serper Image Search\", google_serper_image_search),\n",
        "        (\"Google Programmable Image Search\", google_programmable_image_search)\n",
        "    ]\n",
        "\n",
        "    all_results = []\n",
        "    for name, func in searches:\n",
        "        try:\n",
        "            results = func(query)\n",
        "            all_results.extend(results)\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR in {name}: {str(e)}\")\n",
        "            state[\"messages\"].append({\"role\": \"tool\", \"content\": f\"{name} Error: {str(e)}\"})\n",
        "\n",
        "    # Sort results by date (if available) and relevance\n",
        "    def sort_key(x):\n",
        "        parsed_date = parse_date(x.date)\n",
        "        return (parsed_date is not None, parsed_date or datetime.min, x.title)\n",
        "\n",
        "    all_results.sort(key=sort_key, reverse=True)\n",
        "\n",
        "    # Select top 10 most relevant and recent results\n",
        "    top_results = all_results[:10]\n",
        "\n",
        "    state[\"messages\"].append({\"role\": \"tool\", \"content\": \"Search Results\", \"results\": top_results})\n",
        "    return state"
      ],
      "metadata": {
        "id": "YKgGbgXaW0UL"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "def generate_response(state: AgentState) -> AgentState:\n",
        "    memory = state.get(\"memory\", {})\n",
        "    chat_history = memory.get(\"chat_history\", \"\")\n",
        "\n",
        "    search_results = next((m[\"results\"] for m in reversed(state[\"messages\"])\n",
        "                         if m[\"role\"] == \"tool\" and \"results\" in m), [])\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([(\n",
        "        \"system\", \"\"\"You are an advanced AI copilot specializing in cybersecurity and intelligence analysis. Your primary function is to synthesize and analyze information from multiple search engines and data sources to provide comprehensive, query-specific responses.\n",
        "\n",
        "SEARCH RESULTS ANALYSIS PROTOCOL:\n",
        "1. Primary Source Evaluation:\n",
        "   - Assess credibility of each source domain\n",
        "   - Verify publication dates for temporal relevance\n",
        "   - Cross-reference information across multiple sources\n",
        "   - Identify and flag potential misinformation or conflicting data\n",
        "\n",
        "2. Content Processing Guidelines:\n",
        "   - Extract and normalize key data points\n",
        "   - Identify patterns and correlations across sources\n",
        "   - Prioritize information based on:\n",
        "     * Temporal relevance (newest to oldest)\n",
        "     * Source reliability\n",
        "     * Direct query relevance\n",
        "     * Technical depth\n",
        "     * Actionable insights\n",
        "\n",
        "3. Media Content Analysis:\n",
        "   - Evaluate included images, diagrams, or screenshots\n",
        "   - Extract relevant technical indicators from visual data\n",
        "   - Correlate visual evidence with textual information\n",
        "   - Note any visual proof of concepts or attack demonstrations\n",
        "\n",
        "RESPONSE STRUCTURE:\n",
        "1. Executive Summary (2-3 sentences)\n",
        "   - Core findings\n",
        "   - Critical alerts or time-sensitive information\n",
        "   - Confidence level in findings\n",
        "\n",
        "2. Detailed Analysis:\n",
        "   a) Key Findings\n",
        "      - Bullet points of critical discoveries\n",
        "      - Emerging threats or developments\n",
        "      - Statistical data or metrics\n",
        "\n",
        "   b) Technical Details\n",
        "      - Specific vulnerabilities or exploits\n",
        "      - Attack vectors and techniques\n",
        "      - System impacts and affected components\n",
        "\n",
        "   c) Contextual Analysis\n",
        "      - Industry impact\n",
        "      - Threat actor attribution (if applicable)\n",
        "      - Historical context or similar incidents\n",
        "\n",
        "3. Evidence and Citations:\n",
        "   - Link every major claim to source material\n",
        "   - Include relevant quote snippets\n",
        "   - Provide context for technical indicators\n",
        "   - Reference related media content\n",
        "\n",
        "4. Actionable Intelligence:\n",
        "   - Immediate response recommendations\n",
        "   - Mitigation strategies\n",
        "   - Detection methods\n",
        "   - Prevention measures\n",
        "\n",
        "5. Future Implications:\n",
        "   - Projected developments\n",
        "   - Potential cascade effects\n",
        "   - Areas requiring monitoring\n",
        "\n",
        "SPECIALIZED PROCESSING INSTRUCTIONS:\n",
        "1. For Threat Intelligence:\n",
        "   - Extract and validate IOCs\n",
        "   - Identify TTPs and map to MITRE ATT&CK\n",
        "   - Analyze malware behaviors\n",
        "   - Document C2 infrastructure\n",
        "\n",
        "2. For Vulnerability Analysis:\n",
        "   - Verify CVE details\n",
        "   - Document exploit requirements\n",
        "   - Assess patch availability\n",
        "   - Evaluate real-world exploitation\n",
        "\n",
        "3. For Incident Response:\n",
        "   - Timeline reconstruction\n",
        "   - Attack path analysis\n",
        "   - Impact assessment\n",
        "   - Recovery recommendations\n",
        "\n",
        "4. For Trend Analysis:\n",
        "   - Identify pattern changes\n",
        "   - Map threat evolution\n",
        "   - Project future developments\n",
        "   - Compare against historical data\n",
        "\n",
        "Previous conversation context: {chat_history}\n",
        "Current query: {input}\n",
        "Available search results: {search_results}\n",
        "Current timestamp: {current_date}\n",
        "\n",
        "RESPONSE REQUIREMENTS:\n",
        "1. Maintain clinical precision and technical accuracy\n",
        "2. Prioritize actionable intelligence over general information\n",
        "3. Include explicit confidence levels for all assessments\n",
        "4. Cite ALL sources using [Source Name](URL) format\n",
        "5. Highlight time-sensitive information\n",
        "6. Address any information gaps or uncertainties\n",
        "7. Format output for maximum readability\n",
        "8. Include relevant media references\n",
        "9. Provide specific, implementable recommendations\n",
        "10. Maintain proper technical context throughout\n",
        "\n",
        "Generate a comprehensive response that directly addresses the query while synthesizing all available intelligence from the search results:\"\"\"\n",
        "    )])\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    current_date = datetime.now(pytz.utc).strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
        "\n",
        "    # Enhanced search results formatting\n",
        "    formatted_results = []\n",
        "    for result in search_results:\n",
        "        # Process media content\n",
        "        media_info = []\n",
        "        if result.media_content:\n",
        "            for media in result.media_content:\n",
        "                media_info.append({\n",
        "                    \"type\": media.get(\"type\", \"unknown\"),\n",
        "                    \"url\": media.get(\"url\", \"no url\"),\n",
        "                    \"description\": media.get(\"description\", \"\"),\n",
        "                    \"timestamp\": media.get(\"timestamp\", \"\")\n",
        "                })\n",
        "\n",
        "        # Create detailed result entry\n",
        "        result_str = (\n",
        "            f\"SOURCE ENTRY:\\n\"\n",
        "            f\"Title: {result.title}\\n\"\n",
        "            f\"Source: {result.source}\\n\"\n",
        "            f\"URL: {result.url}\\n\"\n",
        "            f\"Date: {result.date or 'Not specified'}\\n\"\n",
        "            f\"Content: {result.snippet}\\n\"\n",
        "        )\n",
        "\n",
        "        # Add media information if available\n",
        "        if media_info:\n",
        "            result_str += \"Media Content:\\n\"\n",
        "            for media in media_info:\n",
        "                result_str += (\n",
        "                    f\"- Type: {media['type']}\\n\"\n",
        "                    f\"  URL: {media['url']}\\n\"\n",
        "                    f\"  Description: {media['description']}\\n\"\n",
        "                    f\"  Timestamp: {media['timestamp']}\\n\"\n",
        "                )\n",
        "\n",
        "        # Add linked resources if available\n",
        "        if result.links:\n",
        "            result_str += \"Related Links:\\n\"\n",
        "            for link in result.links:\n",
        "                result_str += f\"- {link}\\n\"\n",
        "\n",
        "        result_str += \"-\" * 50 + \"\\n\"\n",
        "        formatted_results.append(result_str)\n",
        "\n",
        "    # Generate response\n",
        "    response = chain.invoke({\n",
        "        \"input\": state[\"messages\"][-1][\"content\"],\n",
        "        \"search_results\": \"\\n\".join(formatted_results),\n",
        "        \"chat_history\": chat_history,\n",
        "        \"current_date\": current_date\n",
        "    })\n",
        "\n",
        "    # Process response and ensure citations\n",
        "    processed_response = ensure_citations(response.content, search_results)\n",
        "\n",
        "    # Display media content\n",
        "    for result in search_results:\n",
        "        if result.media_content:\n",
        "            for media in result.media_content:\n",
        "                if media.get(\"type\") == \"image\":\n",
        "                    display(Image(url=media.get(\"url\"), width=400))\n",
        "\n",
        "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": processed_response})\n",
        "    state[\"memory\"] = {\n",
        "        \"chat_history\": chat_history + f\"\\nHuman: {state['messages'][-2]['content']}\\nAI: {processed_response}\"\n",
        "    }\n",
        "    return state\n",
        "\n",
        "def ensure_citations(text: str, search_results: List[SearchResult]) -> str:\n",
        "    paragraphs = text.split('\\n\\n')\n",
        "    cited_paragraphs = []\n",
        "\n",
        "    for paragraph in paragraphs:\n",
        "        if not any(result.url in paragraph for result in search_results) and not paragraph.startswith('**'):\n",
        "            most_relevant_source = max(search_results, key=lambda x: len(set(paragraph.lower().split()) & set(x.snippet.lower().split())))\n",
        "            paragraph += f' {format_source_link(most_relevant_source.source, most_relevant_source.url)}'\n",
        "        cited_paragraphs.append(paragraph)\n",
        "\n",
        "    if not any(p.startswith('**Sources**') for p in cited_paragraphs):\n",
        "        sources = set(f\"- {format_source_link(result.source, result.url)}\" for result in search_results)\n",
        "        cited_paragraphs.append(\"**Sources**\\n\" + \"\\n\".join(sources))\n",
        "\n",
        "    return '\\n\\n'.join(cited_paragraphs)\n",
        "\n",
        "def format_source_link(source: str, url: str) -> str:\n",
        "    return f\"[{source}]({url})\"\n",
        "\n",
        "# Workflow definition\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"execute_searches\", execute_searches)\n",
        "workflow.add_node(\"generate_response\", generate_response)\n",
        "workflow.add_edge(\"execute_searches\", \"generate_response\")\n",
        "workflow.add_edge(\"generate_response\", END)\n",
        "workflow.set_entry_point(\"execute_searches\")\n",
        "graph = workflow.compile()\n",
        "\n",
        "def run_agent(query: str, memory: Optional[Dict[str, Any]] = None) -> AgentState:\n",
        "    state = AgentState(messages=[{\"role\": \"human\", \"content\": query}], memory=memory or {})\n",
        "    result = graph.invoke(state)\n",
        "    return result"
      ],
      "metadata": {
        "id": "v9JUEkwqZS80"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    query = \"Share some details on currently active Infostealer malware and give me their TTPs and IOCs\"\n",
        "    result = run_agent(query)\n",
        "    for message in result[\"messages\"]:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            print(\"Processing Query and Generating Response from Cyber AI Copilot Please Wait...:\")\n",
        "            print(message[\"content\"])"
      ],
      "metadata": {
        "id": "3uJzx5fiZXey",
        "outputId": "047eba5d-b2d0-418e-f5e9-da1ad7343c4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Starting Exa Search with query: Share some details on currently active Infostealer malware and give me their TTPs and IOCs\n",
            "DEBUG: Raw results from Exa Search: Title: SECURITY AFFAIRS MALWARE NEWSLETTER – ROUND 18\n",
            "URL: https://securityaffairs.com/170532/malware/security-affairs-malware-newsletter-round-18.html\n",
            "ID: https://securityaffairs.com/170532/malware/security-affairs-malware-newsletter-round-18.html\n",
            "Score: 0.11539284139871597\n",
            "Published Date: 2024-11-03T00:00:00.000Z\n",
            "Author: Pierluigi Paganini\n",
            "Image: None\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: \n",
            "Highlights: ['']\n",
            "Highlight Scores: [0.09097861498594284]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: Security Affairs newsletter Round 496 by Pierluigi Paganini – INTERNATIONAL EDITION\n",
            "URL: https://securityaffairs.com/170525/breaking-news/security-affairs-newsletter-round-496-by-pierluigi-paganini-international-edition.html\n",
            "ID: https://securityaffairs.com/170525/breaking-news/security-affairs-newsletter-round-496-by-pierluigi-paganini-international-edition.html\n",
            "Score: 0.1051483303308487\n",
            "Published Date: 2024-11-03T00:00:00.000Z\n",
            "Author: Pierluigi Paganini\n",
            "Image: None\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: \n",
            "Highlights: ['']\n",
            "Highlight Scores: [0.09097861498594284]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: \n",
            "URL: https://twitter.com/SCMagazine/status/1853005195321471472\n",
            "ID: https://twitter.com/SCMagazine/status/1853005195321471472\n",
            "Score: 0.10484641045331955\n",
            "Published Date: 2024-11-03T09:24:00.000Z\n",
            "Author: SCMagazine\n",
            "Image: None\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: The Russian nation-state threat actor tracked as Midnight Blizzard has been running spear-phishing campaigns to thousands of targets at more than 100 organizations, primarily in the United States and Europe. #cybersecurity #infosec #ITsecurity https://t.co/RJUtguBcg1| created_at: Sun Nov 03 09:24:00 +0000 2024 | favorite_count: 1 | quote_count: 0 | reply_count: 0 | retweet_count: 2 | is_quote_status: False | retweeted: False | lang: en\n",
            "Highlights: ['The Russian nation-state threat actor tracked as Midnight Blizzard has been running spear-phishing campaigns to thousands of targets at more than 100 organizations, primarily in the United States and Europe. #cybersecurity #infosec #ITsecurity https://t.co/RJUtguBcg1| created_at: Sun Nov 03 09:24:00 +0000 2024 | favorite_count: 1 | quote_count: 0 | reply_count: 0 | retweet_count: 2 | is_quote_status: False | retweeted: False | lang: en']\n",
            "Highlight Scores: [0.20313143730163574]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: ZachXBT's report on Chainabuse: Hack - Other\n",
            "URL: https://www.chainabuse.com/report/094193aa-aba7-4af8-b7e6-84f0a6b608db\n",
            "ID: https://www.chainabuse.com/report/094193aa-aba7-4af8-b7e6-84f0a6b608db\n",
            "Score: 0.09287841618061066\n",
            "Published Date: 2024-11-03T00:00:00.000Z\n",
            "Author: \n",
            "Image: None\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: Hack - Other    Metawin $4M Exploit Nov 2024       GSL3YLYdytmvpzkSeU4DKq5dQoQq7dRQan1NUddHy82F       GgwJRf8f5fDEEGqkDuXqMEekryiPnCoG6EAMUUqzrt4X       Fi82oqjE3CP4RnZCVb5Rri4jeFFfu5sWiGDrTC8i3Tqf       ENMVwm2rewcyaAYUfm4jQPwECqDGubhYuzgXfDTnGDpR       CMBLvR8oyYm2t7qp6v3s5GXUp4Adm1FsL4sTf5L7pvQ3       C42SXF1GXeCcfEYVdpgmzeVMSwNDf7Ssar4E378GSxhd       AQaLzdUYPZBctEE4RNdFkhMBZMUVU3QCqfS1yRNxa1oj       Ab6hwj4YoDoqhhuCxE5Vvva9PLgqq46CjiyAfxPzCWJ1       9YCK7FfNnefUvbbNFyuvTsrpwW3CH2gbSkFRfJAPNgGt       9U6gvUvBqtG359MzJoGvkVTxihfWeShrezpcBprk6tT       9BowSvPyQ77e4PJpX8wjdfzWB4hwL51LMQy4iKUotEqN       8wEviLFsm6vf57UUcB63TcvmYrCCWbMuFVWuXfEBLZ8B       8T4deegvVM4Qi7MKuTecbUCZPwNd8pup7ib8ZPsiU9HZ       7ifShgytg8cDsMfCSg9QR1fcoBFgY62U2tvXkDJyhTD8       5D6HWEMzyfeZuaPS1YQjJZVoeRHkF6J4y4XCPB3wixsi       4tT52eMJSzBzgwf7rzdKzd1MjjYV2i687ijCpWDfqPoy       4rDpUgXx7XAsecJj91bBS3S8UL3RVDsCmRnnvE5qxTsh       3GNrJGYGt9TaSDh7icqV82GZEHXEt1Vy48n8fDgKRL4e       3b4wcCC1PCCJnm2mi9ziYgA2aj8XHhAwo7NfjscJPmyY       2uEag56aPEhHSM83sFmgDHZvN7sXb4TkSeni3eLyjVz9       2SZtpQvmxA7Be9zSghz6iKnmqu6oVnrmVQtxowdYN2kE       0xf4d520149541f948f6da99eaec6ef6d699690ba3       0xf18a752afa2bda79b0625c58af317f164cd4bd07       0xec38cdaa045f4c5062d7c389778202a48e46924a       0xea7e088c38d587f7bc223088b64aa0b528e45dd1       0xea361defb28805eda5070557233b3eb5f346294c       0xe9726858219c1f7e89f3aba15828925cfbc13373       0xe678b48fe9dc7b6598e26cee8b4656d7d653ee36       0xe5f796767fa117c2e1994fbd1ddef03c0c3ba51c       0xe519aced284778597c13a85eacd641f274e428e5       0xe1b189cb1f896e6eb0193391314f70607711fc51       0xe06a63c18bcaf97bdfdb39fb937c4e5d12145fea       0xe01433d3ba3fb35e7f282876cb0b14412f6ed6ae       0xde2684f15f5357d00e15046ffbbfc883f0ae01da       0xddef10a4d636f795d11da527f08b770d2d3254f6       0xdce037d32245b5a23326a63b7f123930970c74b9       0xdb495ba000abb53c89f671373431877bf6c03416       0xd2bd9c63ed559887f0c47db0acbade780b62504a       0xcbd66563001f1176d895a419f93d231785cca295       0xcb4df15b08fe94aedfdaceaf8c95e37450b8d4f7       0xca2c763568262a51e76063256f7c6fc96bba4490       0xc8a3b54689e2c759dc23c50ff881bb847d0cf952       0xc852154c387573c8c47b3fa669cd822a02bc9ce7       0xc2bafd430e401ec3e9e9e493f0992d862b98c303       0xc16bf6783e8d529eb5aabaa31609fbdb15b6dadb       0xc12a65b56df5e9e27a6443ab058ab75820a6fd4d       0xbf7f7e76826ad024b817c8769a2184558f0cf563       0xbd96509a41888b7c21881b294523b5d08b08139c       0xbc065efd59e2cc579ec6c781378edbf8bb7387f8       0xbbd1289583d9969816bae6740c9080ac267524b7       0xbab5954c7510b5bb07f8f9cc1ae554febae74c8f       0xb9b829ad21943095bd546dfc44b874782a7897e1       0xb66987d6a899d751a3ef3aa4f13eba5c5c879b96       0xb40d39fc3a379847e4e9ea0fc2817d9ffee96e18       0xb0ac8756061399c3e93275d934f796d5524c02ae       0xb05092d560dc788ba396a9676eedcc565895c19b       0xaf915ba837038a11c19faffd4bf711f655dfd962       0xaf14c4846346abaee1846109692cdf8648123de6       0xaabffec0e94e3e31ff94abebf5404773c25f2f60       0xaabfd90faf95165d546ab597291f7a85c3c2603f       0xaa469ab3b4d6e84eb8d1e1f2a2ac9c940ec10a45       0xa6be998b9f18d34af90e2ed7fa8be79f3037e8d1       0xa0a6cf42e3206590701bb0b13781d63636e35053       0x9f069c7d4e28a8c70a08bee848f933cad433ffbd       0x9e35436948689973146e19ab57af738d3075dc04       0x9bea33bb85c22181fab2f78e0d737058ea58298c       0x9bae4a7d4da14617b1e3fe18354112e6b691e62f       0x8ea9ca8ca2ae1f49d96a37e32cb85521a0d02711       0x8dccf203e31d4aecce06df1779e382389d31d8cb       0x8b871566938cd0fa3b30ec9d417257856c75ba0d       0x8adbf7ba25c86a908d52a2586340acba8a11eec3       0x8abadee35bb88f0e967c518d84fb7943530898ac       0x88d5b6e37d1107657d6a5c4e8eeff99378d91a3e       0x83d1cb59b7d1c717477e2797648fc9cc2e16c263       0x818c54960ba798b8a8abc7628cc17f074f845e42       0x7a427c53022382001ffb30a4675b86314b375cd9       0x7939135f7129ef6d89533f9670909e3f6785ace1       0x7826271c31a7b44c140f981c49aae4d8ae6ebe98       0x74712fc7d3614f459e629547d70ddb738644e915       0x745a70cd3e12321706bdc108e62ba5712e0a9b62       0x72e211dc03993b601fb60e0945406bd2bc0d7e51       0x723043b51ca012d02a853270b3005edc7ea3a508       0x6cb3e6a5c816c72456d6ff9f6334c8aa870e57bb       0x6be36d5ed0565ce8f65a009f61f9db9e8b516f61       0x67bffd570a13c0927e62d23d1b8850b811f35b2e       0x668971de352022585cbe744786a9743f475033d7       0x658ee51e89254c1139cace67fe0a92e1624efe10       0x5cb34fa777479f58d5a86ea86cffd6dfcedc3635       0x5b33c0c1ce565112d3e725de650ca2eab23a369b       0x58df61896190cb7f706bcedf56145d93a7895437       0x583f94b3e019fb84c359dfbce569551a52dc1eb4       0x5538aca7037772cb9c96df93e127277033779e55       0x551a6027d119c10fc7b9e16f22058c046b40a184       0x51e79fb64fb0899ba3c66d537445317e5d1f7217       0x4e00477c5d40e2915341c477169c9b287c3628ac       0x4ce8b0cc99127d3479bdbc2fcbd6a149bcb259c7       0x4a5b310cf9a6c1456e2bbd89c298828c7b9a5eeb       0x49d89d98b12ed3ccddcbb112e741b95f2228730c       0x4933edb5f558bebf1bb90ad98c9a4a1119acb651       0x482b118c5b09313560f2a9d50d55f25c6829ef2c       0x44d3f8a59132fa5203703831fdb92c6bad122be7       0x3d47c71f1aa0e1373f8b83352ecd930deea3ec5c       0x3cab7a60c644f93af1f1256d81573265e1d5a415       0x3104c19d4f25416be13a5a4fd4b05307458b89eb       0x2f960f2c8f29808adbf9432c126be3b5dea0cda6       0x210e2f1d574c35deedffd8be225f9aaec7ad834f       0x19f6c28646102553ee4592362d9cf380bb8d2f27       0x18fa3093716d5ff7b795c8b40a44bfce1d5db159       0x166251613faa7577b92de2cc53a6aad732462ce5       0x15cb0e29433ffd19d03b7ef797f1c74cdfcd9229       0x0dab0023da34290832098436d553339d8d4f6a94       0x0999bf4bf1b033c5b64c7252497254d015774d6b       0x08a0be0bcd25b6b60b4aadb5e6b78ea541762632       0x084b2326cc95ff05bbd455f5648585732c8df5c1       0x032b449bd8bac13980fadb6d5cff4fdbe130f195\n",
            "Highlights: ['Hack - Other    Metawin $4M Exploit Nov 2024       GSL3YLYdytmvpzkSeU4DKq5dQoQq7dRQan1NUddHy82F       GgwJRf8f5fDEEGqkDuXqMEekryiPnCoG6EAMUUqzrt4X       Fi82oqjE3CP4RnZCVb5Rri4jeFFfu5sWiGDrTC8i3Tqf       ENMVwm2rewcyaAYUfm4jQPwECqDGubhYuzgXfDTnGDpR       CMBLvR8oyYm2t7qp6v3s5GXUp4Adm1FsL4sTf5L7pvQ3       C42SXF1GXeCcfEYVdpgmzeVMSwNDf7Ssar4E378GSxhd       AQaLzdUYPZBctEE4RNdFkhMBZMUVU3QCqfS1yRNxa1oj       Ab6hwj4YoDoqhhuCxE5Vvva9PLgqq46CjiyAfxPzCWJ1       9YCK7FfNnefUvbbNFyuvTsrpwW3CH2gbSkFRfJAPNgGt       9U6gvUvBqtG359MzJoGvkVTxihfWeShrezpcBprk6tT       9BowSvPyQ77e4PJpX8wjdfzWB4hwL51LMQy4iKUotEqN       8wEviLFsm6vf57UUcB63TcvmYrCCWbMuFVWuXfEBLZ8B       8T4deegvVM4Qi7MKuTecbUCZPwNd8pup7ib8ZPsiU9HZ       7ifShgytg8cDsMfCSg9QR1fcoBFgY62U2tvXkDJyhTD8       5D6HWEMzyfeZuaPS1YQjJZVoeRHkF6J4y4XCPB3wixsi       4tT52eMJSzBzgwf7rzdKzd1MjjYV2i687ijCpWDfqPoy       4rDpUgXx7XAsecJj91bBS3S8UL3RVDsCmRnnvE5qxTsh       3GNrJGYGt9TaSDh7icqV82GZEHXEt1Vy48n8fDgKRL4e       3b4wcCC1PCCJnm2mi9ziYgA2aj8XHhAwo7NfjscJPmyY       2uEag56aPEhHSM83sFmgDHZvN7sXb4TkSeni3eLyjVz9       2SZtpQvmxA7Be9zSghz6iKnmqu6oVnrmVQtxowdYN2kE       0xf4d520149541f948f6da99eaec6ef6d699690ba3       0xf18a752afa2bda79b0625c58af317f164cd4bd07       0xec38cdaa045f4c5062d7c389778202a48e46924a       0xea7e088c38d587f7bc223088b64aa0b528e45dd1       0xea361defb28805eda5070557233b3eb5f346294c       0xe9726858219c1f7e89f3aba15828925cfbc13373       0xe678b48fe9dc7b6598e26cee8b4656d7d653ee36       0xe5f796767fa117c2e1994fbd1ddef03c0c3ba51c       0xe519aced284778597c13a85eacd641f274e428e5       0xe1b189cb1f896e6eb0193391314f70607711fc51       0xe06a63c18bcaf97bdfdb39fb937c4e5d12145fea       0xe01433d3ba3fb35e7f282876cb0b14412f6ed6ae       0xde2684f15f5357d00e15046ffbbfc883f0ae01da       0xddef10a4d636f795d11da527f08b770d2d3254f6       0xdce037d32245b5a23326a63b7f123930970c74b9       0xdb495ba000abb53c89f671373431877bf6c03416       0xd2bd9c63ed559887f0c47db0acbade780b62504a       0xcbd66563001f1176d895a419f93d231785cca295       0xcb4df15b08fe94aedfdaceaf8c95e37450b8d4f7       0xca2c763568262a51e76063256f7c6fc96bba4490       0xc8a3b54689e2c759dc23c50ff881bb847d0cf952       0xc852154c387573c8c47b3fa669cd822a02bc9ce7       0xc2bafd430e401ec3e9e9e493f0992d862b98c303       0xc16bf6783e8d529eb5aabaa31609fbdb15b6dadb       0xc12a65b56df5e9e27a6443ab058ab75820a6fd4d       0xbf7f7e76826ad024b817c8769a2184558f0cf563       0xbd96509a41888b7c21881b294523b5d08b08139c       0xbc065efd59e2cc579ec6c781378edbf8bb7387f8       0xbbd1289583d9969816bae6740c9080ac267524b7       0xbab5954c7510b5bb07f8f9cc1ae554febae74c8f       0xb9b829ad21943095bd546dfc44b874782a7897e1       0xb66987d6a899d751a3ef3aa4f13eba5c5c879b96       0xb40d39fc3a379847e4e9ea0fc2817d9ffee96e18       0xb0ac8756061399c3e93275d934f796d5524c02ae       0xb05092d560dc788ba396a9676eedcc565895c19b       0xaf915ba837038a11c19faffd4bf711f655dfd962       0xaf14c4846346abaee1846109692cdf8648123de6       0xaabffec0e94e3e31ff94abebf5404773c25f2f60       0xaabfd90faf95165d546ab597291f7a85c3c2603f       0xaa469ab3b4d6e84eb8d1e1f2a2ac9c940ec10a45       0xa6be998b9f18d34af90e2ed7fa8be79f3037e8d1       0xa0a6cf42e3206590701bb0b13781d63636e35053       0x9f069c7d4e28a8c70a08bee848f933cad433ffbd       0x9e35436948689973146e19ab57af738d3075dc04       0x9bea33bb85c22181fab2f78e0d737058ea58298c       0x9bae4a7d4da14617b1e3fe18354112e6b691e62f       0x8ea9ca8ca2ae1f49d96a37e32cb85521a0d02711       0x8dccf203e31d4aecce06df1779e382389d31d8cb       0x8b871566938cd0fa3b30ec9d417257856c75ba0d       0x8adbf7ba25c86a908d52a2586340acba8a11eec3       0x8abadee35bb88f0e967c518d84fb7943530898ac       0x88d5b6e37d1107657d6a5c4e8eeff99378d91a3e       0x83d1cb59b7d1c717477e2797648fc9cc2e16c263       0x818c54960ba798b8a8abc7628cc17f074f845e42       0x7a427c53022382001ffb30a4675b86314b375cd9       0x7939135f7129ef6d89533f9670909e3f6785ace1       0x7826271c31a7b44c140f981c49aae4d8ae6ebe98       0x74712fc7d3614f459e629547d70ddb738644e915       0x745a70cd3e12321706bdc108e62ba5712e0a9b62       0x72e211dc03993b601fb60e0945406bd2bc0d7e51       0x723043b51ca012d02a853270b3005edc7ea3a508       0x6cb3e6a5c816c72456d6ff9f6334c8aa870e57bb       0x6be36d5ed0565ce8f65a009f61f9db9e8b516f61       0x67bffd570a13c0927e62d23d1b8850b811f35b2e       0x668971de352022585cbe744786a9743f475033d7       0x658ee51e89254c1139cace67fe0a92e1624efe10       0x5cb34fa777479f58d5a86ea86cffd6dfcedc3635       0x5b33c0c1ce565112d3e725de650ca2eab23a369b       0x58df61896190cb7f706bcedf56145d93a7895437       0x583f94b3e019fb84c359dfbce569551a52dc1eb4       0x5538aca7037772cb9c96df93e127277033779e55       0x551a6027d119c10fc7b9e16f22058c046b40a184       0x51e79fb64fb0899ba3c66d537445317e5d1f7217       0x4e00477c5d40e2915341c477169c9b287c3628ac       0x4ce8b0cc99127d3479bdbc2fcbd6a149bcb259c7       0x4a5b310cf9a6c1456e2bbd89c298828c7b9a5eeb       0x49d89d98b12ed3ccddcbb112e741b95f2228730c       0x4933edb5f558bebf1bb90ad98c9a4a1119acb651       0x482b118c5b09313560f2a9d50d55f25c6829ef2c       0x44d3f8a59132fa5203703831fdb92c6bad122be7       0x3d47c71f1aa0e1373f8b83352ecd930deea3ec5c       0x3cab7a60c644f93af1f1256d81573265e1d5a415       0x3104c19d4f25416be13a5a4fd4b05307458b89eb       0x2f960f2c8f29808adbf9432c126be3b5dea0cda6       0x210e2f1d574c35deedffd8be225f9aaec7ad834f       0x19f6c28646102553ee4592362d9cf380bb8d2f27       0x18fa3093716d5ff7b795c8b40a44bfce1d5db159       0x166251613faa7577b92de2cc53a6aad732462ce5       0x15cb0e29433ffd19d03b7ef797f1c74cdfcd9229       0x0dab0023da34290832098436d553339d8d4f6a94       0x0999bf4bf1b033c5b64c7252497254d015774d6b       0x08a0be0bcd25b6b60b4aadb5e6b78ea541762632       0x084b2326cc95ff05bbd455f5648585732c8df5c1       0x032b449bd8bac13980fadb6d5cff4fdbe130f195']\n",
            "Highlight Scores: [0.07017918676137924]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: \n",
            "URL: https://twitter.com/SCMagazine/status/1853073898595655977\n",
            "ID: https://twitter.com/SCMagazine/status/1853073898595655977\n",
            "Score: 0.08938160538673401\n",
            "Published Date: 2024-11-03T13:57:00.000Z\n",
            "Author: SCMagazine\n",
            "Image: None\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: A group lead by the Dutch National Police said it dismantled the infrastructure behind the Redline and META info-stealing malware networks. #cybersecurity #infosec #ITsecurity https://t.co/c2W9Eveie5| created_at: Sun Nov 03 13:57:00 +0000 2024 | favorite_count: 2 | quote_count: 0 | reply_count: 0 | retweet_count: 1 | is_quote_status: False | retweeted: False | lang: en\n",
            "Highlights: ['A group lead by the Dutch National Police said it dismantled the infrastructure behind the Redline and META info-stealing malware networks. #cybersecurity #infosec #ITsecurity https://t.co/c2W9Eveie5| created_at: Sun Nov 03 13:57:00 +0000 2024 | favorite_count: 2 | quote_count: 0 | reply_count: 0 | retweet_count: 1 | is_quote_status: False | retweeted: False | lang: en']\n",
            "Highlight Scores: [0.0800100713968277]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Autoprompt String: Here are some details on currently active Infostealer malware, including their TTPs and IOCs:\n",
            "Resolved Search Type: 2024-11-03T07:40:03.131Z\n",
            "ERROR in Exa Search: name 'exa_py' is not defined\n",
            "ERROR in Jina Search: HTTP error 401\n",
            "Processing Query and Generating Response from Cyber AI Copilot Please Wait...:\n",
            "Executive Summary:\n",
            "- UNC3944 uses SMS phishing for SIM swapping, ransomware, and extortion [Google Programmable Image Search](https://cloud.google.com/blog/topics/threat-intelligence/unc3944-sms-phishing-sim-swapping-ransomware/)\n",
            "- InfoStealer malware is a significant threat, often targeting sensitive information [Google Serper](https://www.packetlabs.net/posts/what-is-infostealer-malware-and-how-does-it-work/), including logs and third-party software-as-a-service applications [Google Serper](https://flashpoint.io/blog/protecting-against-infostealer-malware/)\n",
            "- Lumma Info-Stealer is a new Malware-as-a-Service (MaaS) information stealer [Google Programmable Search](https://darktrace.com/blog/the-rise-of-the-lumma-info-stealer), posing an emerging threat\n",
            "- Confidence: High\n",
            "\n",
            "Detailed Analysis: [Google Programmable Image Search](https://cloud.google.com/blog/topics/threat-intelligence/unc3944-sms-phishing-sim-swapping-ransomware/)\n",
            "\n",
            "Key Findings:\n",
            "- UNC3944's SMS phishing campaigns are a notable threat, employing SIM swapping, ransomware, and extortion tactics\n",
            "- InfoStealer malware is a prevalent and serious issue, focusing on extracting sensitive data from infected systems\n",
            "- Lumma Info-Stealer, a new MaaS offering, has emerged as a potential threat [Google Programmable Image Search](https://cloud.google.com/blog/topics/threat-intelligence/unc3944-sms-phishing-sim-swapping-ransomware/)\n",
            "\n",
            "Technical Details:\n",
            "- InfoStealer malware variants extract sensitive information from infected systems [Google Serper](https://www.packetlabs.net/posts/what-is-infostealer-malware-and-how-does-it-work/)\n",
            "- Lumma Info-Stealer is a MaaS information stealer, potentially enabling less experienced threat actors to carry out attacks [Google Programmable Search](https://darktrace.com/blog/the-rise-of-the-lumma-info-stealer)\n",
            "\n",
            "Contextual Analysis:\n",
            "- The rise of InfoStealer malware and MaaS offerings like Lumma Stealer indicate a growing trend in cybercrime, focusing on information theft\n",
            "- Threat actors are increasingly targeting sensitive data, including logs and third-party software-as-a-service application credentials [Google Serper](https://flashpoint.io/blog/protecting-against-infostealer-malware/)\n",
            "\n",
            "Evidence and Citations:\n",
            "- [Google Programmable Image Search](https://cloud.google.com/blog/topics/threat-intelligence/unc3944-sms-phishing-sim-swapping-ransomware/): UNC3944's SMS phishing campaigns\n",
            "- [Google Serper](https://www.packetlabs.net/posts/what-is-infostealer-malware-and-how-does-it-work/): InfoStealer malware overview\n",
            "- [Google Serper](https://flashpoint.io/blog/protecting-against-infostealer-malware/): InfoStealer malware targeting logs and third-party software-as-a-service applications\n",
            "- [Google Programmable Search](https://darktrace.com/blog/the-rise-of-the-lumma-info-stealer): Lumma Info-Stealer emergence\n",
            "\n",
            "Actionable Intelligence:\n",
            "- Implement robust SMS phishing detection and prevention measures\n",
            "- Monitor networks for signs of InfoStealer malware infection\n",
            "- Stay updated on new MaaS offerings like Lumma Stealer and adjust defense strategies accordingly\n",
            "- Regularly review and secure sensitive data storage and access practices [Google Programmable Image Search](https://cloud.google.com/blog/topics/threat-intelligence/unc3944-sms-phishing-sim-swapping-ransomware/)\n",
            "\n",
            "Future Implications:\n",
            "- The trend of information theft is likely to continue, with new malware variants and MaaS offerings emerging\n",
            "- Organizations should prioritize threat intelligence and proactive defense measures to stay ahead of these threats [Google Serper](https://www.packetlabs.net/posts/what-is-infostealer-malware-and-how-does-it-work/)\n",
            "\n",
            "**Sources**\n",
            "- [Google Programmable Search](https://darktrace.com/blog/the-rise-of-the-lumma-info-stealer)\n",
            "- [Google Serper](https://darktrace.com/blog/the-rise-of-the-lumma-info-stealer)\n",
            "- [Google Serper Image Search](https://www.magnetforensics.com/wp-content/uploads/2023/04/image-15.png)\n",
            "- [Google Serper Image Search](https://cdn.prod.website-files.com/626ff19cdd07d1258d49238d/64d3b3c501dad065b00001fe_SOC-Threat%20Research.webp)\n",
            "- [Google Programmable Image Search](https://cloud.google.com/blog/topics/threat-intelligence/unc3944-sms-phishing-sim-swapping-ransomware/)\n",
            "- [Google Programmable Image Search](https://darktrace.com/blog/the-rise-of-the-lumma-info-stealer)\n",
            "- [Google Serper](https://flashpoint.io/blog/protecting-against-infostealer-malware/)\n",
            "- [Google Serper Image Search](https://www.cisecurity.org/-/media/project/cisecurity/cisecurity/data/media/img/insights_images/blog_post_img/2024/05/top-10-malware-(4).png?rev=be940dd893ba43b09b3a8652bffef9da&hash=E36AC24CE1686D27B219D15DBB0FAA9E)\n",
            "- [Google Serper](https://www.packetlabs.net/posts/what-is-infostealer-malware-and-how-does-it-work/)\n",
            "- [Google Serper Image Search](https://blogs.blackberry.com/content/dam/blogs-blackberry-com/images/blogs/2024/06/risepro-fig01c.png)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijnYw-YF4isE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}