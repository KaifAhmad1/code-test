{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Langgraph_Agentic_RAG_Cyber_AI_Copilot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cyber AI Copilot for Security and Intelligence Domain**"
      ],
      "metadata": {
        "id": "M0rt8qzmxyyR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wzih_tgLwXK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1379c4a2-2b2e-4bd3-cccb-891bd85ac4a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.4/404.4 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.7/108.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.0/378.0 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet sentence-transformers langchain langchain-groq langchain-pinecone langchain-core asknews langgraph\n",
        "%pip install --quiet -U \"langchain-community>=0.2.16\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List, Dict, Any, Optional, TypedDict\n",
        "from pydantic import BaseModel\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_community.tools.asknews import AskNewsSearch\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "from langchain_community.tools import JinaSearch\n",
        "from dotenv import load_dotenv\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# API Keys (hidden for security purposes)\n",
        "GROQ_API_KEY = \"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\"\n",
        "PINECONE_API_KEY = \"8e15b925-3b96-497d-b20a-08d308782b83\"\n",
        "PINECONE_ENVIRONMENT = \"us-east-1\"\n",
        "ASKNEWS_CLIENT_ID = \"a0de4609-b760-4c83-9609-5c04d7743b84\"\n",
        "ASKNEWS_CLIENT_SECRET = \"D5Mlhkztk4TcW24diUgcW0FA2w\"\n",
        "SERPER_API_KEY = \"d8e815ef6caa94dbef7b977a0ea7d505b43a5a06\"\n",
        "\n",
        "# Set environment variables for AskNews\n",
        "os.environ[\"ASKNEWS_CLIENT_ID\"] = ASKNEWS_CLIENT_ID\n",
        "os.environ[\"ASKNEWS_CLIENT_SECRET\"] = ASKNEWS_CLIENT_SECRET\n",
        "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY"
      ],
      "metadata": {
        "id": "FY2ZeXgvxMxp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the LLM and embeddings\n",
        "llm = ChatGroq(temperature=0, model=\"llama-3.1-8b-instant\", api_key=GROQ_API_KEY)\n",
        "embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=\"BAAI/bge-small-en\",\n",
        "    model_kwargs={\"device\": \"cpu\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True}\n",
        ")\n",
        "\n",
        "# Initialize Pinecone and vector store\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
        "pinecone_index = pc.Index(\"new-cyber-search\")\n",
        "vector_store = PineconeVectorStore(index=pinecone_index, embedding=embeddings)\n",
        "\n",
        "# Initialize search tool\n",
        "asknews_tool = AskNewsSearch(max_results=5)\n",
        "google_serper = GoogleSerperAPIWrapper()\n",
        "jina_search = JinaSearch()"
      ],
      "metadata": {
        "id": "XxTld11_xT0d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: List[Dict[str, str]]\n",
        "    memory: Optional[Dict[str, Any]]\n",
        "\n",
        "def vector_search(query: str) -> str:\n",
        "    results = vector_store.similarity_search(query, k=5)\n",
        "    return \"\\n\".join([f\"Source {i+1}: {doc.page_content}\" for i, doc in enumerate(results)])\n",
        "\n",
        "def search_wrapper(search_func, query: str) -> str:\n",
        "    results = search_func({\"query\": query})\n",
        "    formatted_results = []\n",
        "    for i, result in enumerate(results, 1):\n",
        "        formatted_results.append(f\"Result {i}:\\nTitle: {result.get('title', 'No title')}\\nSnippet: {result.get('snippet', 'No snippet')}\\nURL: {result.get('link', 'No link')}\")\n",
        "    return \"\\n\\n\".join(formatted_results)\n",
        "\n",
        "def execute_searches(state: AgentState) -> AgentState:\n",
        "    query = state[\"messages\"][-1][\"content\"]\n",
        "    searches = [\n",
        "        (\"Vector Search\", vector_search),\n",
        "        (\"AskNews Search\", lambda q: asknews_tool.invoke({\"query\": q})),\n",
        "        (\"Google Serper Search\", lambda q: search_wrapper(google_serper.run, q)),\n",
        "        (\"Jina Search\", lambda q: search_wrapper(jina_search.invoke, q))\n",
        "    ]\n",
        "\n",
        "    for name, func in searches:\n",
        "        try:\n",
        "            result = func(query)\n",
        "            state[\"messages\"].append({\"role\": \"tool\", \"content\": f\"{name} Result: {result}\"})\n",
        "        except Exception as e:\n",
        "            state[\"messages\"].append({\"role\": \"tool\", \"content\": f\"{name} Error: {str(e)}\"})\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "rnQiDPU8xddo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(state: AgentState) -> AgentState:\n",
        "    memory = state.get(\"memory\", {})\n",
        "    chat_history = memory.get(\"chat_history\", \"\")\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([(\n",
        "        \"system\", \"\"\"You are an advanced AI specializing in cybersecurity and intelligence analysis. Your task is to provide highly relevant and actionable insights based on the latest incidents. Follow these guidelines:\n",
        "\n",
        "1. Analyze all search results thoroughly, focusing on the most recent and relevant information.\n",
        "2. Prioritize information from reputable sources and official reports.\n",
        "3. Identify patterns, trends, and potential implications of the latest cyber incidents.\n",
        "4. Provide a structured response with the following sections:\n",
        "   a. Summary of Latest Incidents\n",
        "   b. Key Findings and Trends\n",
        "   c. Potential Impact and Risks\n",
        "   d. Recommended Actions\n",
        "5. Include clear citations for all information, linking to specific search results.\n",
        "6. If critical information is missing, identify gaps and suggest additional areas for investigation.\n",
        "7. Maintain a concise yet comprehensive format, ensuring all key points are covered.\n",
        "\n",
        "Previous conversation: {chat_history}\n",
        "Human query: {input}\n",
        "Vector Search Result: {vector_result}\n",
        "AskNews Search Result: {asknews_result}\n",
        "Google Serper Search Result: {google_serper_result}\n",
        "Jina Search Result: {jina_result}\n",
        "\n",
        "Provide a structured, actionable response based on the latest findings:\n",
        "\"\"\"\n",
        "    )])\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    response = chain.invoke({\n",
        "        \"input\": state[\"messages\"][-1][\"content\"],\n",
        "        \"vector_result\": next((m[\"content\"] for m in reversed(state[\"messages\"]) if m[\"role\"] == \"tool\" and \"Vector Search\" in m[\"content\"]), \"No vector search results.\"),\n",
        "        \"asknews_result\": next((m[\"content\"] for m in reversed(state[\"messages\"]) if m[\"role\"] == \"tool\" and \"AskNews\" in m[\"content\"]), \"No AskNews results.\"),\n",
        "        \"google_serper_result\": next((m[\"content\"] for m in reversed(state[\"messages\"]) if m[\"role\"] == \"tool\" and \"Google Serper\" in m[\"content\"]), \"No Google Serper results.\"),\n",
        "        \"jina_result\": next((m[\"content\"] for m in reversed(state[\"messages\"]) if m[\"role\"] == \"tool\" and \"Jina Search\" in m[\"content\"]), \"No Jina results.\"),\n",
        "        \"chat_history\": chat_history\n",
        "    })\n",
        "\n",
        "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": response.content})\n",
        "    state[\"memory\"] = {\"chat_history\": chat_history + f\"\\nHuman: {state['messages'][-2]['content']}\\nAI: {response.content}\"}\n",
        "    return state\n",
        "\n",
        "# Workflow definition\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"execute_searches\", execute_searches)\n",
        "workflow.add_node(\"generate_response\", generate_response)\n",
        "workflow.add_edge(\"execute_searches\", \"generate_response\")\n",
        "workflow.add_edge(\"generate_response\", END)\n",
        "workflow.set_entry_point(\"execute_searches\")\n",
        "graph = workflow.compile()\n",
        "\n",
        "def run_agent(query: str, memory: Optional[Dict[str, Any]] = None) -> AgentState:\n",
        "    state = AgentState(messages=[{\"role\": \"human\", \"content\": query}], memory=memory or {})\n",
        "    return graph.invoke(state)"
      ],
      "metadata": {
        "id": "EGkMBAYB2V9U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    query = \"Latest Cyber Incidents from Blackbasta Ransomware?\"\n",
        "    result = run_agent(query)\n",
        "    for message in result[\"messages\"]:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            print(\"AI Copilot Analysis:\")\n",
        "            print(message[\"content\"])"
      ],
      "metadata": {
        "id": "oWVMX_Ue2bTO",
        "outputId": "b808c18e-e431-4048-8a28-2bd20dccc1ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Copilot Analysis:\n",
            "**Summary of Latest Incidents**\n",
            "\n",
            "Recent cybersecurity incidents highlight the evolving threat landscape, with ransomware attacks on the rise. Key findings include:\n",
            "\n",
            "* A 14% increase in ransomware attacks in August 2024, with 450 attacks reported (Source: itbrew.com).\n",
            "* RansomHub, a threat actor, was responsible for 16% of attacks in August and saw a 67% increase in attacks from July to August (Source: itbrew.com).\n",
            "* A hacking group, GoldenJackal, has developed custom USB-focused malware to attack air-gapped computers, highlighting the vulnerability of even isolated systems (Source: PCMag UK).\n",
            "* A massive data breach targeting Dr.Web, a prominent Russian cybersecurity company, resulted in the exfiltration of 10 terabytes of sensitive data (Source: cybersecuritynews.com).\n",
            "* The number of ransomware double-extortion groups posting to leak sites reached an all-time high in May 2024, with 40 groups actively listing victims (Source: cybersecuritydive.com).\n",
            "\n",
            "**Key Findings and Trends**\n",
            "\n",
            "* Ransomware attacks continue to rise, with a 14% increase in August 2024.\n",
            "* RansomHub's increased presence is partly due to law enforcement crackdowns on other criminal groups, leaving a vacuum.\n",
            "* Generative AI is being used to spearhead phishing attacks and other social engineering threats, making the ransomware and threat picture more complicated and dangerous.\n",
            "* Air-gapped computers are not impervious to hacking, as demonstrated by GoldenJackal's custom USB-focused malware.\n",
            "* Ransomware double-extortion groups are becoming more prevalent, with 40 groups actively listing victims in May 2024.\n",
            "* Vulnerabilities and credentials remain key initial access targets, with unpatched vulnerabilities being the top initial access vector for ransomware groups.\n",
            "\n",
            "**Potential Impact and Risks**\n",
            "\n",
            "* The rise in ransomware attacks poses a significant threat to organizations, particularly those in the professional, scientific, and technical services (PSTS) sector, which includes software companies.\n",
            "* The use of generative AI in phishing attacks and other social engineering threats increases the risk of successful attacks.\n",
            "* The vulnerability of air-gapped computers highlights the need for robust security measures and continuous vigilance.\n",
            "* The prevalence of ransomware double-extortion groups increases the risk of data breaches and financial losses.\n",
            "\n",
            "**Recommended Actions**\n",
            "\n",
            "1. **Implement robust security measures**: Organizations should prioritize patching vulnerabilities, implementing robust security protocols, and conducting regular security audits.\n",
            "2. **Monitor for phishing attacks**: Organizations should be vigilant in monitoring for phishing attacks, particularly those using generative AI.\n",
            "3. **Protect air-gapped computers**: Organizations should ensure that air-gapped computers are properly secured and isolated from potential threats.\n",
            "4. **Stay informed**: Organizations should stay informed about the latest threat landscape and adjust their security measures accordingly.\n",
            "5. **Invest in threat intelligence**: Organizations should invest in threat intelligence to stay ahead of emerging threats and potential vulnerabilities.\n",
            "\n",
            "**Gaps and Areas for Investigation**\n",
            "\n",
            "* Further investigation is needed to understand the motivations and tactics of GoldenJackal and other hacking groups.\n",
            "* The use of generative AI in phishing attacks and other social engineering threats requires further research to understand its impact and potential mitigation strategies.\n",
            "* The prevalence of ransomware double-extortion groups highlights the need for further research into their tactics, techniques, and procedures (TTPs).\n",
            "\n",
            "**Sources**\n",
            "\n",
            "* itbrew.com: \"Ransomware attacks up in August, study shows\"\n",
            "* PCMag UK: \"Hacking Group Targets Air-Gapped Computers With USB Malware\"\n",
            "* cybersecuritynews.com: \"DumpForums Claims to Have Stolen 10TB Data from Cybersecurity Firm Dr.Web\"\n",
            "* cybersecuritydive.com: \"Ransomware double-extortion group listings peaked in 2024, report finds\"\n",
            "* homelandsecuritynewswire.com: \"Homeland Security Blocked 500-Plus Ransomware Attacks Since 2021\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y4IwTdv2euND"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}