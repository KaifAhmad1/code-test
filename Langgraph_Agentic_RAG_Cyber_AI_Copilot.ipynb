{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Langgraph_Agentic_RAG_Cyber_AI_Copilot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cyber AI Copilot for Security and Intelligence Domain**"
      ],
      "metadata": {
        "id": "M0rt8qzmxyyR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Wzih_tgLwXK6"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet sentence-transformers langchain langchain-groq langchain-pinecone langchain-core asknews langgraph\n",
        "%pip install --quiet -U \"langchain-community>=0.2.16\" langchain-exa langchain-google-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List, Dict, Any, Optional, TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_community.tools.asknews import AskNewsSearch\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "from dotenv import load_dotenv\n",
        "from datetime import datetime, timedelta\n",
        "from exa_py import Exa\n",
        "from langchain_core.tools import tool\n",
        "import re\n",
        "from typing import List, Union\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# API Keys (hidden for security purposes)\n",
        "GROQ_API_KEY = \"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\"\n",
        "PINECONE_API_KEY = \"8e15b925-3b96-497d-b20a-08d308782b83\"\n",
        "PINECONE_ENVIRONMENT = \"us-east-1\"\n",
        "ASKNEWS_CLIENT_ID = \"a0de4609-b760-4c83-9609-5c04d7743b84\"\n",
        "ASKNEWS_CLIENT_SECRET = \"D5Mlhkztk4TcW24diUgcW0FA2w\"\n",
        "SERPER_API_KEY = \"d8e815ef6caa94dbef7b977a0ea7d505b43a5a06\"\n",
        "EXA_API_KEY = \"953b5801-11be-4b37-a313-f8df8f37027c\"\n",
        "GOOGLE_API_KEY=\"AIzaSyBIQo9X6acoBazBfte9jF9Pl0QEZ9oe8pk\"\n",
        "GOOGLE_CSE_ID=\"63053004a7e2445c3\"\n",
        "Tavily_API_KEY=\"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\"\n",
        "\n",
        "\n",
        "# Set environment variables for Search Tools\n",
        "os.environ[\"ASKNEWS_CLIENT_ID\"] = ASKNEWS_CLIENT_ID\n",
        "os.environ[\"ASKNEWS_CLIENT_SECRET\"] = ASKNEWS_CLIENT_SECRET\n",
        "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY\n",
        "os.environ[\"EXA_API_KEY\"] = EXA_API_KEY\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = GOOGLE_CSE_ID\n",
        "os.environ[\"TAVILY_API_KEY\"] = Tavily_API_KEY"
      ],
      "metadata": {
        "id": "FY2ZeXgvxMxp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the LLM and embeddings\n",
        "llm = ChatGroq(temperature=0, model=\"llama-3.1-8b-instant\", api_key=GROQ_API_KEY)\n",
        "embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=\"BAAI/bge-small-en\",\n",
        "    model_kwargs={\"device\": \"cpu\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True}\n",
        ")\n",
        "\n",
        "# Initialize Pinecone and vector store\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
        "pinecone_index = pc.Index(\"new-cyber-search\")\n",
        "vector_store = PineconeVectorStore(index=pinecone_index, embedding=embeddings)\n",
        "\n",
        "# Initialize search tools\n",
        "asknews_tool = AskNewsSearch(max_results=5)\n",
        "google_serper = GoogleSerperAPIWrapper()\n",
        "tavily_search = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    search_depth=\"advanced\",\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    include_images=True\n",
        ")\n",
        "google_search = GoogleSearchAPIWrapper(k=5)\n",
        "\n",
        "# Initialize Exa search tools\n",
        "exa = Exa(api_key=EXA_API_KEY)\n",
        "\n",
        "@tool\n",
        "def search_and_contents(query: str, **kwargs):\n",
        "    \"\"\"\n",
        "    Search for webpages based on the query and retrieve their contents.\n",
        "    \"\"\"\n",
        "    return exa.search_and_contents(\n",
        "        query,\n",
        "        use_autoprompt=True,\n",
        "        num_results=5,\n",
        "        text=True,\n",
        "        highlights=True,\n",
        "        **kwargs\n",
        "    )\n",
        "\n",
        "@tool\n",
        "def find_similar_and_contents(url: str, **kwargs):\n",
        "    \"\"\"\n",
        "    Search for webpages similar to a given URL and retrieve their contents.\n",
        "    \"\"\"\n",
        "    return exa.find_similar_and_contents(\n",
        "        url,\n",
        "        num_results=5,\n",
        "        text=True,\n",
        "        highlights={\"num_sentences\": 1, \"highlights_per_url\": 1},\n",
        "        **kwargs\n",
        "    )\n",
        "\n",
        "tools = [search_and_contents, find_similar_and_contents]"
      ],
      "metadata": {
        "id": "XxTld11_xT0d"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: List[Dict[str, str]]\n",
        "    memory: Optional[Dict[str, Any]]\n",
        "\n",
        "class SearchResult(BaseModel):\n",
        "    source: str\n",
        "    title: str\n",
        "    snippet: str\n",
        "    url: str\n",
        "    date: Optional[str]\n",
        "    media: Optional[List[Dict[str, str]]]\n",
        "    images: Optional[List[str]]\n",
        "\n",
        "def vector_search(query: str) -> List[SearchResult]:\n",
        "    results = vector_store.similarity_search(query, k=5)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Vector Search\",\n",
        "            title=f\"Result {i+1}\",\n",
        "            snippet=doc.page_content,\n",
        "            url=doc.metadata.get(\"source\", \"No URL\"),\n",
        "            date=doc.metadata.get(\"date\")\n",
        "        ) for i, doc in enumerate(results)\n",
        "    ]\n",
        "\n",
        "def asknews_search(query: str) -> List[SearchResult]:\n",
        "    results = asknews_tool.run({\"query\": query})\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"AskNews\",\n",
        "            title=result.get(\"title\", \"No title\"),\n",
        "            snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "            url=result.get(\"link\", \"No link\"),\n",
        "            date=result.get(\"date\")\n",
        "        ) for result in results\n",
        "    ]\n",
        "\n",
        "def google_serper_search(query: str) -> List[SearchResult]:\n",
        "    results = google_serper.results(query)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Google Serper\",\n",
        "            title=result.get(\"title\", \"No title\"),\n",
        "            snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "            url=result.get(\"link\", \"No link\"),\n",
        "            date=result.get(\"date\")\n",
        "        ) for result in results.get(\"organic\", [])\n",
        "    ]\n",
        "\n",
        "def exa_search(query: str) -> List[SearchResult]:\n",
        "    results = search_and_contents(query)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Exa Search\",\n",
        "            title=result.get(\"title\", \"No title\"),\n",
        "            snippet=result.get(\"text\", \"No text\")[:500],\n",
        "            url=result.get(\"url\", \"No URL\"),\n",
        "            date=result.get(\"published_date\"),\n",
        "            images=result.get(\"image_urls\", [])\n",
        "        ) for result in results\n",
        "    ]\n",
        "\n",
        "def tavily_search(query: str) -> List[SearchResult]:\n",
        "    results = tavily_search.invoke({\"query\": query})\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Tavily Search\",\n",
        "            title=result.get(\"title\", \"No title\"),\n",
        "            snippet=result.get(\"content\", \"No content\"),\n",
        "            url=result.get(\"url\", \"No URL\"),\n",
        "            date=result.get(\"published_date\"),\n",
        "            images=result.get(\"image_url\", []) if result.get(\"image_url\") else []\n",
        "        ) for result in results\n",
        "    ]\n",
        "\n",
        "def google_programmable_search(query: str) -> List[SearchResult]:\n",
        "    results = google_search.results(query)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Google Programmable Search\",\n",
        "            title=result.get(\"title\", \"No title\"),\n",
        "            snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "            url=result.get(\"link\", \"No link\"),\n",
        "            date=result.get(\"date\")\n",
        "        ) for result in results\n",
        "    ]"
      ],
      "metadata": {
        "id": "rnQiDPU8xddo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_searches(state: AgentState) -> AgentState:\n",
        "    query = state[\"messages\"][-1][\"content\"]\n",
        "    searches = [\n",
        "        (\"Vector Search\", vector_search),\n",
        "        (\"AskNews Search\", asknews_search),\n",
        "        (\"Google Serper Search\", google_serper_search),\n",
        "        (\"Exa Search\", exa_search),\n",
        "        (\"Tavily Search\", tavily_search),\n",
        "        (\"Google Programmable Search\", google_programmable_search)\n",
        "    ]\n",
        "\n",
        "    all_results = []\n",
        "    for name, func in searches:\n",
        "        try:\n",
        "            results = func(query)\n",
        "            all_results.extend(results)\n",
        "        except Exception as e:\n",
        "            state[\"messages\"].append({\"role\": \"tool\", \"content\": f\"{name} Error: {str(e)}\"})\n",
        "\n",
        "    # Sort results by date (if available) and relevance\n",
        "    def sort_key(x):\n",
        "        return (x.date is not None, x.date or \"\", x.title)\n",
        "\n",
        "    all_results.sort(key=sort_key, reverse=True)\n",
        "\n",
        "    # Select top 10 most relevant results\n",
        "    top_results = all_results[:10]\n",
        "\n",
        "    state[\"messages\"].append({\"role\": \"tool\", \"content\": \"Search Results\", \"results\": top_results})\n",
        "    return state"
      ],
      "metadata": {
        "id": "EGkMBAYB2V9U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(state: AgentState) -> AgentState:\n",
        "    memory = state.get(\"memory\", {})\n",
        "    chat_history = memory.get(\"chat_history\", \"\")\n",
        "\n",
        "    search_results = next((m[\"results\"] for m in reversed(state[\"messages\"]) if m[\"role\"] == \"tool\" and \"results\" in m), [])\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([(\n",
        "        \"system\", \"\"\"You are an advanced AI copilot specializing in cybersecurity and intelligence. Your task is to provide highly relevant, actionable, and up-to-date information based on the user's query. Follow these guidelines:\n",
        "\n",
        "1. Analyze the user's query to understand their specific needs and context.\n",
        "2. Thoroughly examine all search results, prioritizing the most recent and relevant information from reputable sources.\n",
        "3. Identify emerging patterns, trends, and potential implications related to the user's query.\n",
        "4. Provide a structured response tailored to the user's query, including:\n",
        "   a. Key Findings (bullet points of the most critical and relevant information)\n",
        "   b. Detailed Analysis (in-depth examination of the key points, focusing on what's most relevant to the user's query)\n",
        "   c. Implications & Recommendations (numbered list of important implications and actionable recommendations)\n",
        "\n",
        "5. Include clear citations for ALL information using the format [Source Name](URL).\n",
        "6. Prioritize information from the last 30 days. If using older sources, explain why the information is still relevant.\n",
        "7. If search results contain conflicting information, acknowledge the discrepancies and provide a balanced view.\n",
        "8. For each recommendation, explain the rationale and potential impact.\n",
        "9. Adjust the length and depth of your response based on the complexity of the query and the available information.\n",
        "10. If the query is related to a specific cybersecurity threat or technology, include technical details when appropriate.\n",
        "\n",
        "Previous conversation: {chat_history}\n",
        "Human query: {input}\n",
        "Search Results: {search_results}\n",
        "\n",
        "Current date: {current_date}\n",
        "\n",
        "Provide a structured, actionable response based on the user query and latest findings, ensuring every piece of information is properly cited:\n",
        "\"\"\"\n",
        "    )])\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    response = chain.invoke({\n",
        "        \"input\": state[\"messages\"][-1][\"content\"],\n",
        "        \"search_results\": \"\\n\".join([f\"{result.title}\\n{result.snippet}\\n{format_source_link(result.source, result.url)}\\nDate: {result.date or 'Not specified'}\\n\" for result in search_results]),\n",
        "        \"chat_history\": chat_history,\n",
        "        \"current_date\": current_date\n",
        "    })\n",
        "\n",
        "    processed_response = add_highlights(response.content)\n",
        "    processed_response = ensure_citations(processed_response, search_results)\n",
        "\n",
        "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": processed_response})\n",
        "    state[\"memory\"] = {\"chat_history\": chat_history + f\"\\nHuman: {state['messages'][-2]['content']}\\nAI: {processed_response}\"}\n",
        "    return state\n",
        "\n",
        "def add_highlights(text: str) -> str:\n",
        "    highlight_phrases = [\n",
        "        \"Critical vulnerability\",\n",
        "        \"Zero-day exploit\",\n",
        "        \"Ransomware attack\",\n",
        "        \"Data breach\",\n",
        "        \"Advanced Persistent Threat\",\n",
        "        \"Supply chain attack\",\n",
        "        \"Phishing campaign\",\n",
        "        \"Malware outbreak\",\n",
        "        \"Cybersecurity best practice\",\n",
        "        \"Emerging threat\"\n",
        "    ]\n",
        "\n",
        "    for phrase in highlight_phrases:\n",
        "        text = re.sub(f\"({phrase})\", r\"**\\1**\", text, flags=re.IGNORECASE)\n",
        "\n",
        "    return text\n",
        "\n",
        "def ensure_citations(text: str, search_results: List[SearchResult]) -> str:\n",
        "    paragraphs = text.split('\\n\\n')\n",
        "    cited_paragraphs = []\n",
        "\n",
        "    for paragraph in paragraphs:\n",
        "        if not re.search(r'\\[.*?\\]\\(.*?\\)', paragraph) and not paragraph.startswith('**'):\n",
        "            paragraph += ' [Source needed]()'\n",
        "        cited_paragraphs.append(paragraph)\n",
        "\n",
        "    if not any(p.startswith('**Sources**') for p in cited_paragraphs):\n",
        "        sources = set(f\"- {format_source_link(result.source, result.url)}\" for result in search_results)\n",
        "        cited_paragraphs.append(\"**Sources**\\n\" + \"\\n\".join(sources))\n",
        "\n",
        "    return '\\n\\n'.join(cited_paragraphs)\n",
        "\n",
        "def format_source_link(source: str, url: str) -> str:\n",
        "    return f\"[{source}]({url})\"\n",
        "\n",
        "# Workflow definition\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"execute_searches\", execute_searches)\n",
        "workflow.add_node(\"generate_response\", generate_response)\n",
        "workflow.add_edge(\"execute_searches\", \"generate_response\")\n",
        "workflow.add_edge(\"generate_response\", END)\n",
        "workflow.set_entry_point(\"execute_searches\")\n",
        "graph = workflow.compile()\n",
        "\n",
        "def run_agent(query: str, memory: Optional[Dict[str, Any]] = None) -> AgentState:\n",
        "    state = AgentState(messages=[{\"role\": \"human\", \"content\": query}], memory=memory or {})\n",
        "    return graph.invoke(state)"
      ],
      "metadata": {
        "id": "oWVMX_Ue2bTO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    query = \"Latest Incidents and attacks by Blackbasta Ransomware Gang?\"\n",
        "    result = run_agent(query)\n",
        "    for message in result[\"messages\"]:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            print(\"AI Copilot Analysis:\")\n",
        "            print(message[\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcMBx1wiW1oG",
        "outputId": "1cf4bfea-69f9-48cd-fec0-e99c48d9cb9f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Copilot Analysis:\n",
            "Based on your query \"Search Results,\" I'll provide a structured response tailored to your needs. However, I need more context to provide a more accurate and relevant answer. Please provide more information about what you're looking for in search results, such as: [Source needed]()\n",
            "\n",
            "- A specific topic or industry (e.g., cybersecurity, AI, healthcare)?\n",
            "- A particular type of search result (e.g., academic papers, news articles, social media posts)?\n",
            "- A desired format or structure for the search results (e.g., list, table, graph)? [Source needed]()\n",
            "\n",
            "Assuming you're looking for general information on search results, I'll provide a response based on the latest findings. [Source needed]()\n",
            "\n",
            "**Key Findings:**\n",
            "\n",
            "* Google's search algorithm is constantly evolving, with the latest update (October 2024) focusing on improving search results for long-tail queries [1].\n",
            "* Bing's search engine has introduced a new feature, \"Bing Spotlight,\" which provides users with a curated list of relevant search results [2].\n",
            "* A recent study found that 70% of users trust search results from the first page of Google, highlighting the importance of search engine optimization (SEO) [3].\n",
            "* The rise of voice search has led to an increase in conversational search queries, with 50% of users using voice assistants to search online [4]. [Source needed]()\n",
            "\n",
            "**Detailed Analysis:**\n",
            "\n",
            "Google's search algorithm update aims to provide more accurate and relevant results for long-tail queries, which are phrases with low search volume but high commercial intent. This update is expected to benefit businesses and websites that have optimized their content for long-tail keywords [1]. [Source needed]()\n",
            "\n",
            "Bing's \"Bing Spotlight\" feature is designed to provide users with a more personalized search experience by highlighting relevant results from trusted sources. This feature is expected to improve user engagement and increase the visibility of high-quality content [2]. [Source needed]()\n",
            "\n",
            "The study on user trust in search results highlights the importance of SEO in improving website visibility and credibility. By optimizing their content for search engines, businesses can increase their chances of appearing on the first page of search results and attracting more users [3]. [Source needed]()\n",
            "\n",
            "The rise of voice search has led to an increase in conversational search queries, which are expected to continue growing in the future. Businesses that have optimized their content for voice search are likely to see an increase in traffic and engagement [4]. [Source needed]()\n",
            "\n",
            "**Implications & Recommendations:**\n",
            "\n",
            "1. **Optimize your content for long-tail keywords**: With Google's latest algorithm update, it's essential to optimize your content for long-tail keywords to improve your website's visibility and credibility.\n",
            "2. **Use Bing's \"Bing Spotlight\" feature**: If you're using Bing as your search engine, consider optimizing your content to appear in Bing's \"Bing Spotlight\" feature, which can increase your website's visibility and credibility.\n",
            "3. **Invest in SEO**: With 70% of users trusting search results from the first page of Google, investing in SEO is crucial to improve your website's visibility and credibility.\n",
            "4. **Optimize your content for voice search**: With the rise of voice search, it's essential to optimize your content for conversational search queries to attract more users and increase engagement. [Source needed]()\n",
            "\n",
            "References: [Source needed]()\n",
            "\n",
            "[1] Google (2024). \"Google's latest algorithm update: Improving search results for long-tail queries.\" [https://blog.google/products/search/](https://blog.google/products/search/)\n",
            "\n",
            "[2] Bing (2024). \"Introducing Bing Spotlight: A new feature to help you find what you're looking for.\" [https://www.bing.com/en-us/](https://www.bing.com/en-us/)\n",
            "\n",
            "[3] Search Engine Journal (2024). \"70% of Users Trust Search Results from the First Page of Google.\" [https://www.searchenginejournal.com/](https://www.searchenginejournal.com/)\n",
            "\n",
            "[4] Voicebot (2024). \"50% of Users Use Voice Assistants to Search Online.\" [https://voicebot.ai/](https://voicebot.ai/)\n",
            "\n",
            "**Sources**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hXAS79VuXAlg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}