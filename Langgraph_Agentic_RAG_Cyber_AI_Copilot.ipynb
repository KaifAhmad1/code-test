{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Langgraph_Agentic_RAG_Cyber_AI_Copilot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cyber AI Copilot for Security and Intelligence Domain**"
      ],
      "metadata": {
        "id": "M0rt8qzmxyyR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wzih_tgLwXK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52516533-8b48-433e-aad7-363dc90946cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.4/404.4 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.0/378.0 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet sentence-transformers langchain langchain-groq langchain-pinecone langchain-core asknews langgraph\n",
        "%pip install --quiet -U \"langchain-community>=0.2.16\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List, Dict, Any, Optional, TypedDict\n",
        "from pydantic import BaseModel\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_community.tools.asknews import AskNewsSearch\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "from langchain_community.tools import JinaSearch\n",
        "from dotenv import load_dotenv\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# API Keys (hidden for security purposes)\n",
        "GROQ_API_KEY = \"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\"\n",
        "PINECONE_API_KEY = \"8e15b925-3b96-497d-b20a-08d308782b83\"\n",
        "PINECONE_ENVIRONMENT = \"us-east-1\"\n",
        "ASKNEWS_CLIENT_ID = \"a0de4609-b760-4c83-9609-5c04d7743b84\"\n",
        "ASKNEWS_CLIENT_SECRET = \"D5Mlhkztk4TcW24diUgcW0FA2w\"\n",
        "SERPER_API_KEY = \"d8e815ef6caa94dbef7b977a0ea7d505b43a5a06\"\n",
        "\n",
        "# Set environment variables for AskNews\n",
        "os.environ[\"ASKNEWS_CLIENT_ID\"] = ASKNEWS_CLIENT_ID\n",
        "os.environ[\"ASKNEWS_CLIENT_SECRET\"] = ASKNEWS_CLIENT_SECRET\n",
        "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY"
      ],
      "metadata": {
        "id": "FY2ZeXgvxMxp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the LLM and embeddings\n",
        "llm = ChatGroq(temperature=0, model=\"llama3-8b-8192\", api_key=GROQ_API_KEY)\n",
        "embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=\"BAAI/bge-small-en\",\n",
        "    model_kwargs={\"device\": \"cpu\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True}\n",
        ")\n",
        "\n",
        "# Initialize Pinecone and vector store\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
        "pinecone_index = pc.Index(\"new-cyber-search\")\n",
        "vector_store = PineconeVectorStore(index=pinecone_index, embedding=embeddings)\n",
        "\n",
        "# Initialize search tool\n",
        "asknews_tool = AskNewsSearch(max_results=5)\n",
        "google_serper = GoogleSerperAPIWrapper()\n",
        "jina_search = JinaSearch()"
      ],
      "metadata": {
        "id": "XxTld11_xT0d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: List[Dict[str, str]]\n",
        "    memory: Optional[Dict[str, Any]]\n",
        "\n",
        "def vector_search(query: str) -> str:\n",
        "    results = vector_store.similarity_search(query, k=5)\n",
        "    return \"\\n\".join([f\"Source {i+1}: {doc.page_content}\" for i, doc in enumerate(results)])\n",
        "\n",
        "def search_wrapper(search_func, query: str) -> str:\n",
        "    results = search_func({\"query\": query})\n",
        "    formatted_results = []\n",
        "    for i, result in enumerate(results, 1):\n",
        "        formatted_results.append(f\"Result {i}:\\nTitle: {result.get('title', 'No title')}\\nSnippet: {result.get('snippet', 'No snippet')}\\nURL: {result.get('link', 'No link')}\")\n",
        "    return \"\\n\\n\".join(formatted_results)\n",
        "\n",
        "def execute_searches(state: AgentState) -> AgentState:\n",
        "    query = state[\"messages\"][-1][\"content\"]\n",
        "    searches = [\n",
        "        (\"Vector Search\", vector_search),\n",
        "        (\"AskNews Search\", lambda q: asknews_tool.invoke({\"query\": q})),\n",
        "        (\"Google Serper Search\", lambda q: search_wrapper(google_serper.run, q)),\n",
        "        (\"Jina Search\", lambda q: search_wrapper(jina_search.invoke, q))\n",
        "    ]\n",
        "\n",
        "    for name, func in searches:\n",
        "        try:\n",
        "            result = func(query)\n",
        "            state[\"messages\"].append({\"role\": \"tool\", \"content\": f\"{name} Result: {result}\"})\n",
        "        except Exception as e:\n",
        "            state[\"messages\"].append({\"role\": \"tool\", \"content\": f\"{name} Error: {str(e)}\"})\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "rnQiDPU8xddo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(state: AgentState) -> AgentState:\n",
        "    memory = state.get(\"memory\", {})\n",
        "    chat_history = memory.get(\"chat_history\", \"\")\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are an advanced AI copilot specializing in cybersecurity and intelligence. Provide accurate, up-to-date information on cyber threats, vulnerabilities, and intelligence matters. Guidelines:\n",
        "\n",
        "1. Directly address the query with precision and relevance.\n",
        "2. Be concise and clear, using bullet points or lists when appropriate.\n",
        "3. Cite sources as [Source: Name] for each piece of information.\n",
        "4. Only include information from provided search results. Do not add any information from your training data.\n",
        "5. If the search results don't contain relevant information to answer the query, state that you don't have enough information to provide a confident answer.\n",
        "6. Specify the timeframe of information and highlight significant trends if available.\n",
        "7. Maintain a neutral, professional tone and focus on defense and mitigation strategies.\n",
        "\n",
        "Previous conversation:\n",
        "{chat_history}\n",
        "\n",
        "New human question: {input}\n",
        "Vector Search Result: {vector_result}\n",
        "AskNews Search Result: {asknews_result}\n",
        "Google Serper Search Result: {google_serper_result}\n",
        "Jina Search Result: {jina_result}\n",
        "\n",
        "Response:\"\"\"),\n",
        "    ])\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    response = chain.invoke({\n",
        "        \"input\": state[\"messages\"][-1][\"content\"],\n",
        "        \"vector_result\": next((m[\"content\"] for m in reversed(state[\"messages\"]) if m[\"role\"] == \"tool\" and \"Vector Search\" in m[\"content\"]), \"No vector search results.\"),\n",
        "        \"asknews_result\": next((m[\"content\"] for m in reversed(state[\"messages\"]) if m[\"role\"] == \"tool\" and \"AskNews\" in m[\"content\"]), \"No AskNews results.\"),\n",
        "        \"google_serper_result\": next((m[\"content\"] for m in reversed(state[\"messages\"]) if m[\"role\"] == \"tool\" and \"Google Serper\" in m[\"content\"]), \"No Google Serper search results.\"),\n",
        "        \"jina_result\": next((m[\"content\"] for m in reversed(state[\"messages\"]) if m[\"role\"] == \"tool\" and \"Jina Search\" in m[\"content\"]), \"No Jina search results.\"),\n",
        "        \"chat_history\": chat_history\n",
        "    })\n",
        "\n",
        "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": response.content})\n",
        "    state[\"memory\"] = {\"chat_history\": chat_history + f\"\\nHuman: {state['messages'][-2]['content']}\\nAI: {response.content}\"}\n",
        "    return state\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"execute_searches\", execute_searches)\n",
        "workflow.add_node(\"generate_response\", generate_response)\n",
        "workflow.add_edge(\"execute_searches\", \"generate_response\")\n",
        "workflow.add_edge(\"generate_response\", END)\n",
        "workflow.set_entry_point(\"execute_searches\")\n",
        "graph = workflow.compile()\n",
        "\n",
        "def run_agent(query: str, memory: Optional[Dict[str, Any]] = None) -> AgentState:\n",
        "    state = AgentState(messages=[{\"role\": \"human\", \"content\": query}], memory=memory or {})\n",
        "    return graph.invoke(state)"
      ],
      "metadata": {
        "id": "EGkMBAYB2V9U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    query = \"Latest Cyber Incidents happened by Blackbasta Ransomeware Gang?\"\n",
        "    result = run_agent(query)\n",
        "    for message in result[\"messages\"]:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            print(\"AI Copilot:\", message[\"content\"])"
      ],
      "metadata": {
        "id": "oWVMX_Ue2bTO",
        "outputId": "ad281303-2466-4569-eac9-e431a6bb8d0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Copilot: I've analyzed the provided search results and identified the following key points related to cyber threats and vulnerabilities:\n",
            "\n",
            "1. **Ransomware attacks**: The search results highlight the increasing threat of ransomware attacks, with 67% of healthcare organizations affected in the past year. LockBit, Black Basta, and Play are among the most prolific ransomware gangs.\n",
            "2. **Microsoft warning**: Microsoft has issued a warning to millions of Windows users, advising them to switch to Microsoft Edge to stop new attacks. The attacks use defense evasion tactics and rely on fraudulent websites to harvest user credentials.\n",
            "3. **Ransomware in healthcare**: Sophos Limited reported a 67% increase in ransomware attacks on global healthcare organizations in 2024, with 95% of affected organizations saying the cybercriminals attempted to compromise their backups.\n",
            "4. **Ransomware gangs**: ESET research shed light on CosmicBeetle, a small-time ransomware gang targeting small and midsize businesses (SMBs) with custom ransomware. The gang has been known to impersonate more intimidating gangs like LockBit.\n",
            "5. **Ransomware ecosystem**: Secureworks observed a 30% year-on-year rise in active ransomware groups, with 31 new groups joining the ecosystem in the last 12 months. LockBit, PLAY, and RansomHub are among the top three most active ransomware groups.\n",
            "\n",
            "To mitigate these threats, I recommend the following:\n",
            "\n",
            "1. **Implement robust security measures**: Ensure that your organization has a robust security posture, including regular software updates, strong passwords, and multi-factor authentication.\n",
            "2. **Use reputable antivirus software**: Install and regularly update reputable antivirus software to detect and prevent ransomware attacks.\n",
            "3. **Back up critical data**: Regularly back up critical data to a secure location, such as an external hard drive or cloud storage service.\n",
            "4. **Monitor for suspicious activity**: Monitor your systems and networks for suspicious activity, such as unusual login attempts or file modifications.\n",
            "5. **Stay informed**: Stay informed about the latest ransomware threats and trends, and adjust your security measures accordingly.\n",
            "\n",
            "Please note that the search results do not provide a comprehensive overview of all cyber threats and vulnerabilities. It is essential to stay informed and adapt to the evolving threat landscape to ensure the security of your organization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y4IwTdv2euND"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}