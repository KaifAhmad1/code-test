{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Langgraph_Agentic_RAG_Cyber_AI_Copilot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cyber AI Copilot for Security and Intelligence Domain**"
      ],
      "metadata": {
        "id": "M0rt8qzmxyyR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Wzih_tgLwXK6",
        "outputId": "2abed28a-df1f-4f02-cfc1-a9b4882e9a21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/255.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.8/255.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet sentence-transformers langchain langchain-groq langchain-pinecone langchain-core asknews langgraph\n",
        "%pip install --quiet -U \"langchain-community>=0.2.16\" langchain-exa langchain-google-community goose3 crawl4ai[all] langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List, Dict, Any, Optional, TypedDict\n",
        "from pydantic import BaseModel\n",
        "from langchain_openai import OpenAI as ChatOpenAI\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "from exa_py import Exa\n",
        "from langchain_community.document_loaders.firecrawl import FireCrawlLoader\n",
        "from langchain_community.tools import JinaSearch\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.tools import tool\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import asyncio\n",
        "from crawl4ai import AsyncWebCrawler, WebCrawler\n",
        "from crawl4ai.extraction_strategy import LLMExtractionStrategy, JsonCssExtractionStrategy\n",
        "from crawl4ai.chunking_strategy import RegexChunking\n",
        "from pydantic import BaseModel, Field\n",
        "import json\n",
        "import base64\n",
        "import getpass\n",
        "\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# API Keys (hidden for security purposes)\n",
        "OPENAI_API_KEY = getpass.getpass(\"Please enter your OpenAI API key: \")\n",
        "PINECONE_API_KEY = \"8e15b925-3b96-497d-b20a-08d308782b83\"\n",
        "PINECONE_ENVIRONMENT = \"us-east-1\"\n",
        "ASKNEWS_CLIENT_ID = \"a0de4609-b760-4c83-9609-5c04d7743b84\"\n",
        "ASKNEWS_CLIENT_SECRET = \"D5Mlhkztk4TcW24diUgcW0FA2w\"\n",
        "SERPER_API_KEY = \"d8e815ef6caa94dbef7b977a0ea7d505b43a5a06\"\n",
        "EXA_API_KEY = \"953b5801-11be-4b37-a313-f8df8f37027c\"\n",
        "GOOGLE_API_KEY=\"AIzaSyBIQo9X6acoBazBfte9jF9Pl0QEZ9oe8pk\"\n",
        "GOOGLE_CSE_ID=\"63053004a7e2445c3\"\n",
        "Tavily_API_KEY=\"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\"\n",
        "FIRECRAWL_API_KEY = \"fc-9c7bf92d1db44ae1a34f9dc56a6031e6\"\n",
        "\n",
        "# Set environment variables for Search Tools\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "os.environ[\"ASKNEWS_CLIENT_ID\"] = ASKNEWS_CLIENT_ID\n",
        "os.environ[\"ASKNEWS_CLIENT_SECRET\"] = ASKNEWS_CLIENT_SECRET\n",
        "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY\n",
        "os.environ[\"EXA_API_KEY\"] = EXA_API_KEY\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = GOOGLE_CSE_ID\n",
        "os.environ[\"TAVILY_API_KEY\"] = Tavily_API_KEY"
      ],
      "metadata": {
        "id": "FY2ZeXgvxMxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a4584d-dffd-498e-c877-7f42dbb5b107"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the OpenAI model\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-4\",\n",
        "    temperature=0.2,\n",
        "    api_key=OPENAI_API_KEY\n",
        ")\n",
        "\n",
        "# Initialize the embeddings\n",
        "embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=\"BAAI/bge-small-en\",\n",
        "    model_kwargs={\"device\": \"cpu\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True}\n",
        ")\n",
        "\n",
        "# Initialize Pinecone and vector store\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
        "pinecone_index = pc.Index(\"new-cyber-search\")\n",
        "vector_store = PineconeVectorStore(index=pinecone_index, embedding=embeddings)\n",
        "\n",
        "# Initialize search tools\n",
        "google_serper = GoogleSerperAPIWrapper()\n",
        "tavily_search = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    search_depth=\"advanced\",\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    include_images=True,\n",
        ")\n",
        "google_search = GoogleSearchAPIWrapper()\n",
        "exa = Exa(api_key=EXA_API_KEY)\n",
        "jina_tool = JinaSearch()"
      ],
      "metadata": {
        "id": "XxTld11_xT0d"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: List[Dict[str, str]]\n",
        "    memory: Optional[Dict[str, Any]]\n",
        "\n",
        "class SearchResult(BaseModel):\n",
        "    source: str\n",
        "    title: str\n",
        "    snippet: str\n",
        "    url: str\n",
        "    date: Optional[str]\n",
        "    media: Optional[List[str]] = []\n",
        "    links: Optional[List[str]] = []\n",
        "    image_url: Optional[str] = Field(None, description=\"URL of the image associated with the search result\")\n",
        "\n",
        "def parse_date(date_str: Optional[str]) -> Optional[datetime]:\n",
        "    if not date_str:\n",
        "        return None\n",
        "    try:\n",
        "        return datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
        "    except ValueError:\n",
        "        try:\n",
        "            return datetime.strptime(date_str, \"%Y-%m-%d\")\n",
        "        except ValueError:\n",
        "            return None\n",
        "\n",
        "def vector_search(query: str) -> List[SearchResult]:\n",
        "    results = vector_store.similarity_search(query, k=5)\n",
        "    return [\n",
        "        SearchResult(\n",
        "            source=\"Vector Search\",\n",
        "            title=f\"Result {i+1}\",\n",
        "            snippet=doc.page_content,\n",
        "            url=doc.metadata.get(\"source\", \"No URL\"),\n",
        "            date=doc.metadata.get(\"date\")\n",
        "        ) for i, doc in enumerate(results)\n",
        "    ]\n",
        "\n",
        "def google_serper_search(query: str) -> List[SearchResult]:\n",
        "    serper = GoogleSerperAPIWrapper()\n",
        "    results = serper.results(query)\n",
        "    search_results = []\n",
        "\n",
        "    for result in results.get(\"organic\", []):\n",
        "        search_result = SearchResult(\n",
        "            source=\"Google Serper\",\n",
        "            title=result.get(\"title\", \"No title\"),\n",
        "            snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "            url=result.get(\"link\", \"No link\"),\n",
        "            date=result.get(\"date\"),\n",
        "            image_url=result.get(\"imageUrl\")\n",
        "        )\n",
        "        search_results.append(search_result)\n",
        "\n",
        "    # Add image results\n",
        "    for image in results.get(\"images\", []):\n",
        "        search_result = SearchResult(\n",
        "            source=\"Google Serper Images\",\n",
        "            title=image.get(\"title\", \"No title\"),\n",
        "            snippet=image.get(\"snippet\", \"No snippet\"),\n",
        "            url=image.get(\"link\", \"No link\"),\n",
        "            image_url=image.get(\"imageUrl\")\n",
        "        )\n",
        "        search_results.append(search_result)\n",
        "\n",
        "    return search_results\n",
        "\n",
        "def jina_search(query: str) -> List[SearchResult]:\n",
        "    result = jina_tool.run(query)\n",
        "    print(f\"DEBUG: Jina Search results: {result}\")\n",
        "    return [SearchResult(\n",
        "        source=\"Jina Search\",\n",
        "        title=\"Jina Search Result\",\n",
        "        snippet=result,\n",
        "        url=\"\",\n",
        "        date=None\n",
        "    )]\n",
        "\n",
        "# Exa search function\n",
        "@tool\n",
        "def search_and_contents(query: str):\n",
        "    \"\"\"Search for webpages based on the query and retrieve their contents.\"\"\"\n",
        "    return exa.search_and_contents(\n",
        "        query, use_autoprompt=True, num_results=5, text=True, highlights=True\n",
        "    )\n",
        "\n",
        "def exa_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        print(f\"DEBUG: Starting Exa Search with query: {query}\")\n",
        "        response = search_and_contents(query)\n",
        "        print(f\"DEBUG: Raw results from Exa Search: {response}\")\n",
        "\n",
        "        if not isinstance(response, exa_py.api.SearchResponse):\n",
        "            print(f\"DEBUG: Exa Search results are not a SearchResponse. Type: {type(response)}\")\n",
        "            return []\n",
        "\n",
        "        results = response.results  # Extract the list of results from the SearchResponse object\n",
        "\n",
        "        search_results = [\n",
        "            SearchResult(\n",
        "                source=\"Exa Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "                url=result.get(\"link\", \"No link\"),\n",
        "                date=result.get(\"date\")\n",
        "            ) for result in results\n",
        "        ]\n",
        "\n",
        "        print(f\"DEBUG: Processed Exa Search results: {search_results}\")\n",
        "        return search_results\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Exa Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Tavily search tool\n",
        "tavily_tool = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    search_depth=\"advanced\",\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    include_images=True,\n",
        ")\n",
        "\n",
        "def tavily_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        results = tavily_tool.invoke({\"query\": query})\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Tavily Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"content\", \"No snippet\"),\n",
        "                url=result.get(\"url\", \"No link\"),\n",
        "                date=result.get(\"date\")\n",
        "            ) for result in results\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Tavily Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# New Google Programmable Search function\n",
        "def google_programmable_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        google_search = GoogleSearchAPIWrapper()\n",
        "        results = google_search.results(query, num_results=5)\n",
        "        search_results = []\n",
        "\n",
        "        for result in results:\n",
        "            search_result = SearchResult(\n",
        "                source=\"Google Programmable Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "                url=result.get(\"link\", \"No link\"),\n",
        "                date=result.get(\"date\"),\n",
        "                image_url=result.get(\"image\")\n",
        "            )\n",
        "            search_results.append(search_result)\n",
        "\n",
        "        # Add image search results\n",
        "        image_results = google_search.results(query + \" image\", num_results=5)\n",
        "        for image in image_results:\n",
        "            search_result = SearchResult(\n",
        "                source=\"Google Programmable Search Images\",\n",
        "                title=image.get(\"title\", \"No title\"),\n",
        "                snippet=image.get(\"snippet\", \"No snippet\"),\n",
        "                url=image.get(\"link\", \"No link\"),\n",
        "                image_url=image.get(\"image\")\n",
        "            )\n",
        "            search_results.append(search_result)\n",
        "\n",
        "        return search_results\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Google Programmable Search: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "class PageSummary(BaseModel):\n",
        "    title: str = Field(..., description=\"Title of the page.\")\n",
        "    summary: str = Field(..., description=\"Summary of the page.\")\n",
        "    brief_summary: str = Field(..., description=\"Brief summary of the page.\")\n",
        "    keywords: list = Field(..., description=\"Keywords assigned to the page.\")\n",
        "\n",
        "async def crawl_and_summarize(url):\n",
        "    extraction_strategy = LLMExtractionStrategy(\n",
        "        provider=\"openai/gpt-4o\",\n",
        "        api_token=os.getenv('OPENAI_API_KEY'),\n",
        "        schema=PageSummary.model_json_schema(),\n",
        "        extraction_type=\"schema\",\n",
        "        apply_chunking=False,\n",
        "        instruction=(\n",
        "            \"From the crawled content, extract the following details: \"\n",
        "            \"1. Title of the page \"\n",
        "            \"2. Summary of the page, which is a detailed summary \"\n",
        "            \"3. Brief summary of the page, which is a paragraph text \"\n",
        "            \"4. Keywords assigned to the page, which is a list of keywords. \"\n",
        "            'The extracted JSON format should look like this: '\n",
        "            '{ \"title\": \"Page Title\", \"summary\": \"Detailed summary of the page.\", '\n",
        "            '\"brief_summary\": \"Brief summary in a paragraph.\", \"keywords\": [\"keyword1\", \"keyword2\", \"keyword3\"] }'\n",
        "        )\n",
        "    )\n",
        "\n",
        "    async with AsyncWebCrawler(verbose=True) as crawler:\n",
        "        try:\n",
        "            result = await crawler.arun(\n",
        "                url=url,\n",
        "                word_count_threshold=1,\n",
        "                extraction_strategy=extraction_strategy,\n",
        "                chunking_strategy=RegexChunking(),\n",
        "                bypass_cache=True,\n",
        "                screenshot=True,\n",
        "                extract_media=True,\n",
        "                extract_links=True\n",
        "            )\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR in crawling {url}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "async def crawl_multiple_urls(urls):\n",
        "    async with AsyncWebCrawler(verbose=True) as crawler:\n",
        "        tasks = [crawler.arun(\n",
        "            url=url,\n",
        "            word_count_threshold=1,\n",
        "            extraction_strategy=LLMExtractionStrategy(\n",
        "                provider=\"openai/gpt-4o\",\n",
        "                api_token=os.getenv('OPENAI_API_KEY'),\n",
        "                schema=PageSummary.model_json_schema(),\n",
        "                extraction_type=\"schema\",\n",
        "                apply_chunking=False,\n",
        "                instruction=(\n",
        "                    \"From the crawled content, extract the following details: \"\n",
        "                    \"1. Title of the page \"\n",
        "                    \"2. Summary of the page, which is a detailed summary \"\n",
        "                    \"3. Brief summary of the page, which is a paragraph text \"\n",
        "                    \"4. Keywords assigned to the page, which is a list of keywords. \"\n",
        "                    'The extracted JSON format should look like this: '\n",
        "                    '{ \"title\": \"Page Title\", \"summary\": \"Detailed summary of the page.\", '\n",
        "                    '\"brief_summary\": \"Brief summary in a paragraph.\", \"keywords\": [\"keyword1\", \"keyword2\", \"keyword3\"] }'\n",
        "                )\n",
        "            ),\n",
        "            chunking_strategy=RegexChunking(),\n",
        "            bypass_cache=True,\n",
        "            screenshot=True,\n",
        "            extract_media=True,\n",
        "            extract_links=True\n",
        "        ) for url in urls]\n",
        "        results = await asyncio.gather(*tasks)\n",
        "    return results\n",
        "\n",
        "def crawl4ai_search(query: str) -> List[SearchResult]:\n",
        "    try:\n",
        "        # Use a search engine to get relevant URLs\n",
        "        search_results = google_serper_search(query)\n",
        "        urls = [result.url for result in search_results]\n",
        "\n",
        "        # Crawl and summarize each URL\n",
        "        summaries = asyncio.run(crawl_multiple_urls(urls))\n",
        "\n",
        "        search_results = []\n",
        "        for i, summary in enumerate(summaries):\n",
        "            if summary.success:\n",
        "                page_summary = json.loads(summary.extracted_content)\n",
        "                search_results.append(\n",
        "                    SearchResult(\n",
        "                        source=\"Crawl4AI\",\n",
        "                        title=page_summary.get(\"title\", \"No title\"),\n",
        "                        snippet=page_summary.get(\"brief_summary\", \"No snippet\"),\n",
        "                        url=urls[i],\n",
        "                        date=None,\n",
        "                        media=summary.media,\n",
        "                        links=summary.links\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        return search_results\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in Crawl4AI Search: {str(e)}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "rnQiDPU8xddo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_searches(state: AgentState) -> AgentState:\n",
        "    query = state[\"messages\"][-1][\"content\"]\n",
        "    searches = [\n",
        "        (\"Vector Search\", vector_search),\n",
        "        (\"Google Serper Search\", google_serper_search),\n",
        "        (\"Exa Search\", exa_search),\n",
        "        (\"Tavily Search\", tavily_search),\n",
        "        (\"Jina Search\", jina_search),\n",
        "        (\"Google Programmable Search\", google_programmable_search),\n",
        "        (\"Crawl4AI Search\", crawl4ai_search)\n",
        "    ]\n",
        "\n",
        "    all_results = []\n",
        "    for name, func in searches:\n",
        "        try:\n",
        "            results = func(query)\n",
        "            all_results.extend(results)\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR in {name}: {str(e)}\")\n",
        "            state[\"messages\"].append({\"role\": \"tool\", \"content\": f\"{name} Error: {str(e)}\"})\n",
        "\n",
        "    # Sort results by date (if available) and relevance\n",
        "    def sort_key(x):\n",
        "        parsed_date = parse_date(x.date)\n",
        "        return (parsed_date is not None, parsed_date or datetime.min, x.title)\n",
        "\n",
        "    all_results.sort(key=sort_key, reverse=True)\n",
        "\n",
        "    # Select top 10 most relevant and recent results\n",
        "    top_results = all_results[:10]\n",
        "\n",
        "    state[\"messages\"].append({\"role\": \"tool\", \"content\": \"Search Results\", \"results\": top_results})\n",
        "    return state"
      ],
      "metadata": {
        "id": "YKgGbgXaW0UL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(state: AgentState) -> AgentState:\n",
        "    memory = state.get(\"memory\", {})\n",
        "    chat_history = memory.get(\"chat_history\", \"\")\n",
        "\n",
        "    search_results = next((m[\"results\"] for m in reversed(state[\"messages\"]) if m[\"role\"] == \"tool\" and \"results\" in m), [])\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([(\n",
        "        \"system\", \"\"\"You are an advanced AI copilot specializing in cybersecurity and intelligence. Your task is to provide highly relevant, actionable, and up-to-date information based on the user's query. Follow these guidelines:\n",
        "\n",
        "1. Analyze the user's query: {input}\n",
        "2. Examine the search results, prioritizing the most recent and relevant information from reputable sources.\n",
        "3. Identify emerging patterns, trends, and potential implications related to the query, focusing on real-time cybersecurity threats and developments.\n",
        "4. Provide a concise, structured response tailored to the query, including:\n",
        "   a. Key Findings (3-4 bullet points of the most critical and recent information)\n",
        "   b. Detailed Analysis (focused examination of the key points, directly addressing the query and emphasizing recent developments)\n",
        "   c. Actionable Recommendations (2-3 specific, timely actions with rationale)\n",
        "   d. Potential Implications (brief overview of how these findings might impact the cybersecurity landscape)\n",
        "\n",
        "5. Include clear citations for ALL information using the format [Source Name](URL).\n",
        "6. If search results contain images or videos, mention their content and relevance, especially for recent visual data.\n",
        "7. Adjust the response length based on the query complexity and available information, prioritizing depth for critical, time-sensitive issues.\n",
        "8. Include technical details when appropriate, such as specific vulnerabilities, exploit techniques, or mitigation strategies, focusing on the most recent discoveries.\n",
        "9. Highlight any time-sensitive information or emerging threats that require immediate attention.\n",
        "10. If there are conflicting reports or uncertainties in the recent data, acknowledge them and provide a balanced view.\n",
        "\n",
        "Previous conversation: {chat_history}\n",
        "Human query: {input}\n",
        "Search Results: {search_results}\n",
        "\n",
        "Current date: {current_date}\n",
        "\n",
        "Provide a comprehensive, actionable response based on the query and latest findings, ensuring every piece of information is properly cited and emphasizing the most recent and critical cybersecurity insights:\n",
        "\"\"\"\n",
        "    )])\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    current_date = datetime.now(pytz.utc).strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
        "\n",
        "    response = chain.invoke({\n",
        "        \"input\": state[\"messages\"][-1][\"content\"],\n",
        "        \"search_results\": \"\\n\".join([f\"{result.title}\\n{result.snippet}\\n{format_source_link(result.source, result.url)}\\nDate: {result.date or 'Not specified'}\\nMedia: {', '.join(result.media)}\\nLinks: {', '.join(result.links)}\\n\" for result in search_results]),\n",
        "        \"chat_history\": chat_history,\n",
        "        \"current_date\": current_date\n",
        "    })\n",
        "\n",
        "    processed_response = ensure_citations(response.content, search_results)\n",
        "\n",
        "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": processed_response})\n",
        "    state[\"memory\"] = {\"chat_history\": chat_history + f\"\\nHuman: {state['messages'][-2]['content']}\\nAI: {processed_response}\"}\n",
        "    return state\n",
        "\n",
        "def ensure_citations(text: str, search_results: List[SearchResult]) -> str:\n",
        "    paragraphs = text.split('\\n\\n')\n",
        "    cited_paragraphs = []\n",
        "\n",
        "    for paragraph in paragraphs:\n",
        "        if not any(result.url in paragraph for result in search_results) and not paragraph.startswith('**'):\n",
        "            most_relevant_source = max(search_results, key=lambda x: len(set(paragraph.lower().split()) & set(x.snippet.lower().split())))\n",
        "            paragraph += f' {format_source_link(most_relevant_source.source, most_relevant_source.url)}'\n",
        "        cited_paragraphs.append(paragraph)\n",
        "\n",
        "    if not any(p.startswith('**Sources**') for p in cited_paragraphs):\n",
        "        sources = set(f\"- {format_source_link(result.source, result.url)}\" for result in search_results)\n",
        "        cited_paragraphs.append(\"**Sources**\\n\" + \"\\n\".join(sources))\n",
        "\n",
        "    return '\\n\\n'.join(cited_paragraphs)\n",
        "\n",
        "def format_source_link(source: str, url: str) -> str:\n",
        "    return f\"[{source}]({url})\"\n",
        "\n",
        "# Workflow definition\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"execute_searches\", execute_searches)\n",
        "workflow.add_node(\"generate_response\", generate_response)\n",
        "workflow.add_edge(\"execute_searches\", \"generate_response\")\n",
        "workflow.add_edge(\"generate_response\", END)\n",
        "workflow.set_entry_point(\"execute_searches\")\n",
        "graph = workflow.compile()\n",
        "\n",
        "def run_agent(query: str, memory: Optional[Dict[str, Any]] = None) -> AgentState:\n",
        "    state = AgentState(messages=[{\"role\": \"human\", \"content\": query}], memory=memory or {})\n",
        "    result = graph.invoke(state)\n",
        "    return result"
      ],
      "metadata": {
        "id": "v9JUEkwqZS80"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    query = \"Share some details on currently active Infostealer malware and give me their TTPs and IOCs\"\n",
        "    result = run_agent(query)\n",
        "    for message in result[\"messages\"]:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            print(\"Processing Query and Generating Response from Cyber AI Copilot Please Wait...:\")\n",
        "            print(message[\"content\"])"
      ],
      "metadata": {
        "id": "3uJzx5fiZXey",
        "outputId": "9c003712-00c9-40f3-cd3e-26e9d4a0230f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Starting Exa Search with query: Share some details on currently active Infostealer malware and give me their TTPs and IOCs\n",
            "DEBUG: Raw results from Exa Search: Title: Sly Malware Found in Fake Google Chrome and MS Teams Installers\n",
            "URL: https://www.forescout.com/blog/sly-malware-found-in-fake-google-chrome-and-ms-teams-installers/\n",
            "ID: https://www.forescout.com/blog/sly-malware-found-in-fake-google-chrome-and-ms-teams-installers/\n",
            "Score: 0.1304047405719757\n",
            "Published Date: 2024-09-26T00:00:00.000Z\n",
            "Author: Sai Molige\n",
            "Image: None\n",
            "Text: Forescout’s Security Operations Center (SOC) recently investigated a malware incident on a customer’s network involving malware disguised as Google Chrome. During the investigation, we discovered the domain hosting the malware had been involved in similar attacks using fake Microsoft Teams and fake Microsoft Edge installers prompting a deeper look into the incidents. As a result, we identified several new malware samples, domains and IP addresses, including Tactics, Techniques and Procedures (TTP), threat-hunting opportunities and detection strategies. The Indicators of Compromise (IoC) are also available on Forescout Vedere Labs’ threat feed. The malware’s primary purpose is reconnaissance to gather user and network information for detailed profiles of potential targets. This information could serve as a foundation for more targeted future attacks ranging from deploying customized ransomware to installing remote access tools on individual systems. The threat actor may have dual objectives:  Immediate monetization through the sale of harvested data and access Preparation for larger-scale cyberattacks (either to directly exploit high-value targets or sell access)  We are tracking this as a distinct cluster referred to as Chaya_002. The name ‘Chaya’ follows our naming convention for unknown threat clusters (it means ‘shadow’ in Sanskrit). By tracking this threat as Chaya_002, we can focus on its unique attributes and ongoing evolution. We are closely watching for new tactics or tools used by the threat actors to distinguish it from previously known malware clusters. For example, we have already identified changes in the threat actor’s delivery mechanisms — specifically in the malware’s file characteristics and storage.  Malware Activity Cluster: ‘Chaya_002’ Details and Characteristics   Unique Payload Characteristics  Chaya_002 has distinct payload and post-infection tactics worth investigating. The delivery, download and staging mechanisms resemble:   Scarlet Goldfinch   FakeSG   ClearFake   FakeUpdateRU   SocGholish   Evolving Functionality As of September 23, the malware exhibited new behaviors, including:  Executes PowerShell commands from within MSIX bundles Uses AutoIt scripts Uses WMIC to gather domain information  Distinct Tool Usage Unlike previous versions, this malware can download additional tools other than NetSupport RMM which showcases developing capabilities. Progression in File Naming Conventions Previously, files were named with patterns like: Update_[date_components].js, Update_[random_numeric_string].[msix|exe] or [legitimate_software_name]_[random_numeric_string].exe. Now, we observe a shift to names like upd_[random_numeric_string].[exe|msix] Transition in File Types The malware payload has shifted from JavaScript files (.js) to executable formats (.msix, .exe) showing ongoing refinement in deployment and increasing its potential impact. Diversification of File Path The threat actor rotates through various WordPress directory structures to store malware:  wp-includes/[css|promo|uploads] wp-admin/images wp-includes/images/ wp-content/upgrades  Similar Malware Incidents Trigger Our Investigation On September 20, the Canadian Centre for Cyber Security issued a TLP:AMBER cyber flash, “CF24-005 – Tactics, techniques and procedures associated with malware masquerading as an MS Teams installer”, in response to an incident that occurred on September 9. The attack leveraged users’ tendency to search for Microsoft Teams via their Windows Start Menu. Instead of reaching the official Microsoft page, the user landed on an SEO poisoned page that prompted them to download what appeared to be MS Teams installer. Upon further investigation, the Cyber Centre discovered several TTPs associated with this attack, including password dumping, Kerberoasting, persistence through run keys, collection of user-specific information, and exfiltration via C2 Beacon.  The Cyber Centre’s investigation noted that the domain responsible for distributing this fake Teams installer was apple-online[.]shop. A day earlier, on September 19, Forescout Security Operations Center (SOC) had blocked an access attempt to a suspicious domain, hxxps://tayakay[.]com/analytics.js. This domain was injecting a malicious JavaScript file into legitimate websites, in this case www[.]powerlineblog[.]com. The script then redirected users to a /js.php endpoint on the same domain, which initiated the download of a malicious file, upd_6259478.exe, from a compromised WordPress site (hxxps://airbluefootgear[.]com/wp-includes/images/xits.php).   The upd_6259478.exe executable runs the PowerShell command shown below, which downloads and runs another file, named ChromeSetup.exe, from a temporary folder. The source of this download was apple-online[.]shop – the same domain seen in the Canadian incident – which resolved to two IP addresses: 172.67.178[.]253 and 104.21.67[.]172.   Upon execution, upd_6259478.exe initiates network communication with the remote IP 217.148.142[.]19, a recurring element in this malware cluster. Multiple samples have been observed connecting to this IP, which was previously identified nearly three years ago as a Cobalt Strike command and control (C2) server. In earlier versions of similar malware samples, we also observed the use of a PowerShell command to establish persistence by creating a .lnk file in the Windows Startup folder. This .lnk file pointed to the upd_* executable, ensuring it ran automatically at system startup. Additionally, all samples were observed querying system information about the infected machine, likely for reconnaissance purposes.   Most of the other TTPs observed in this customer incident were consistent with those identified by the Canadian Cyber Centre, with the exception of Kerberoasting. This discrepancy could be due to the fact that the executable was likely run in a sandbox environment that wasn’t domain-joined, which may have prevented Kerberoasting from being triggered. However, there was no explicit event to verify this.   Uncovering Further Malicious Activity in Fake Google Chrome and Fake MS ‘Setup’ Executables Since both incidents originated from apple-online[.]shop, we pivoted off this domain to investigate the activity cluster behind them. One notable observation was the submission of the URL apple-online[.]shop/MicrosoftEdgeSetup.exe (file hash: 7531341da720162541747b3142722f9c52d9d5fe57678d8aeefa62532014f672) to VirusTotal. This file, with a creation time of 2024-07-24 17:53:31 UTC carries a legitimate Microsoft signature. We hypothesize that the threat actors might be testing the file delivery mechanism.   Further VirusTotal analysis revealed several additional files uploaded between September 10 and September 21, 2024, all directly linked to this domain.   Nearly all files are digitally signed by of “Foshan Yongqiheng Trading Co., Ltd.” The metadata for each file—including copyright, product, description, internal name, and comments—reflects the name under which it was downloaded. Notably, the signing date aligns with the download date.    Other samples are signed by “Langfang Alkem Material Technology Co., Ltd.”, including those with the following hashes:   42c1550b035353ae529e98304f89bf6065647833e582d08f0228185b493d0022 8d911ef72bdb4ec5b99b7548c0c89ffc8639068834a5e2b684c9d78504550927 92d2488e401d24a4bfc1598d813bc53af5c225769efedf0c7e5e4083623f4486 941fa9119eb1413fdd4f05333e285c49935280cc85f167fb31627012ef71a6b3 aa25a7c2520da54ba2045a21de252632c93f8eae06e031091ab908dca4eadf45    The only file lacking a digital signature in the list shown above is 941fa9119eb1413fdd4f05333e285c49935280cc85f167fb31627012ef71a6b3 Regarding the tayakay[.]com domain, when a user visits the site that is embedded with tayakay[.]com JS script, it constructs a query parameter containing victim information – such as device name, IP address and others – to send to the js.php endpoint.   By constructing a query in URLScan based on the observed characteristics, we identified additional pivot points exhibiting similar behavior. This investigation revealed an additional extension, “/adcount.js”, along with a mechanism that redirects users based on the returned content. According to URLScan results, approximately 87 domains currently have analytics.js embedded in their sites.   From previous samples, it is likely that these sites are using a Traffic Distribution System (TDS) which redirects users to another page—often another compromised WordPress site—that delivers fake executables embedded with malicious code. By analyzing the file naming patterns, we uncovered several compromised WordPress pages, as well as second stage malware that was downloaded via PowerShell.   The threat actor employs multi-vector approach, with objectives of network infiltration and data acquisition. The end goal appears to be facilitating large-scale cyberattacks where feasible, through one or more of three phases:   Initial Reconnaissance: Harvesting user-specif\n",
            "Highlights: ['During the investigation, we discovered the domain hosting the malware had been involved in similar attacks using fake Microsoft Teams and fake Microsoft Edge installers prompting a deeper look into the incidents. As a result, we identified several new malware samples, domains and IP addresses, including Tactics, Techniques and Procedures (TTP), threat-hunting opportunities and detection strategies. The Indicators of Compromise (IoC) are also available on Forescout Vedere Labs’ threat feed. The malware’s primary purpose is reconnaissance to gather user and network information for detailed profiles of potential targets. This information could serve as a foundation for more targeted future attacks ranging from deploying customized ransomware to installing remote access tools on individual systems.']\n",
            "Highlight Scores: [0.1744595170021057]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: Fake Human Verification Prompt Delivers Infostealers\n",
            "URL: https://www.secureworks.com/blog/fake-human-verification-prompt-delivers-infostealers\n",
            "ID: https://www.secureworks.com/blog/fake-human-verification-prompt-delivers-infostealers\n",
            "Score: 0.12606173753738403\n",
            "Published Date: 2024-09-23T00:00:00.000Z\n",
            "Author: \n",
            "Image: None\n",
            "Text: In two September 2024 engagements, Secureworks® incident responders identified users being directed to malicious websites after searching Google for video streaming services. One victim browsed for websites to watch sports, and the other searched for a movie. In both incidents, the victim was redirected to a malicious URL that prompted them to verify they were human by completing the actions shown in Figure 1. Pressing the Windows button + R opens the Run menu, CTRL + V pastes an encoded PowerShell command generated when the victim opens the malicious URL, and Enter runs the command.\n",
            " \n",
            "Figure 1. Fraudulent human verification steps. (Source: Secureworks) \n",
            "The PowerShell execution (see Figure 2) delivers malware via a ZIP archive file that is extracted to \\AppData\\Local\\Temp\\file\\Setup.exe on the victim's system. This executable is run on the host, followed by tools such as a renamed BitTorrent tool (StrCmp.exe) and a Windows utility (Search Indexer). Secureworks Counter Threat Unit™ (CTU) researchers identified additional incidents that deployed infostealers such as Vidar and StealC.\n",
            " \n",
            "Figure 2. Encoded PowerShell command execution. (Source: Secureworks) \n",
            "This novel attack vector poses significant risk, as it circumvents browser security controls by opening a command prompt. The victim is then directed to execute unauthorized code directly on their host.\n",
            "Following this analysis, CTU™ researchers identified instances where controls mitigated similar attacks in the Middle East and Australia, highlighting the global nature of this campaign. Multiple third-party reports describe similar activity. Orange Cyberdefense encountered campaigns in France in May and June 2024. In September, GitHub-themed phishing messages reportedly directed victims to a site that used the fake verification to deploy the LummaC2 infostealer.\n",
            "In 2023, CTU researchers warned about the growing threat from infostealers. Threat actors regularly use infostealers to obtain credentials for a wide range of online services and corporate networks. The criminals then sell this access in  underground marketplaces or use the access to conduct attacks such as phishing hotel customers. CTU analysis of underground activity related to the September 2024 incident response engagements revealed that credentials collected from victims of the fake human verification prompt were published to Russian Market within days of collection.\n",
            "CTU researchers recommend that organizations implement policies restricting employees from using corporate systems to browse for streaming services or risky content. Organizations should also conduct regular social engineering training that incorporates up-to-date threat intelligence on the latest techniques. Using web proxies to limit access to potentially malicious web pages could mitigate this threat.\n",
            "To mitigate exposure to this malware, CTU researchers recommend that customers use available controls to review and restrict access using the indicators listed in Table 1. The URLs may contain malicious content, so consider the risks before opening them in a browser.\n",
            "Indicator\n",
            "Type\n",
            "Context\n",
            "https://pcheck9.b-cdn.net/prop9.html\n",
            "URL\n",
            "Hosting fraudulent human verification web page\n",
            "https://secure-bot15.b-cdn.net/tera32.html\n",
            "URL\n",
            "Hosting fraudulent human verification web page\n",
            "https://report1.b-cdn.net/tra17\n",
            "URL\n",
            "Delivers malware in campaign using fraudulent human verification\n",
            "https://newvideozones.click/veri.html\n",
            "URL\n",
            "Redirects to fraudulent human verification web page\n",
            "https://yip.su/25yX94\n",
            "URL\n",
            "Delivers malware in campaign using fraudulent human verification\n",
            "https://pub-9c4ec7f3f95c448b85e464d2b533aac1.r2.dev/peltgon.zip\n",
            "URL\n",
            "Delivers malware in campaign using fraudulent human verification\n",
            " Table 1. Indicators for this threat. \n",
            "Read more about infostealers and other threats in the 2023 State of the Threat report. If you need urgent assistance with an incident, contact the Secureworks Incident Response team.\n",
            "Highlights: ['Read more about infostealers and other threats in the 2023 State of the Threat report. If you need urgent assistance with an incident, contact the Secureworks Incident Response team.']\n",
            "Highlight Scores: [0.17177104949951172]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: Inside SnipBot: The Latest RomCom Malware Variant\n",
            "URL: https://unit42.paloaltonetworks.com/snipbot-romcom-malware-variant/\n",
            "ID: https://unit42.paloaltonetworks.com/snipbot-romcom-malware-variant/\n",
            "Score: 0.12360869348049164\n",
            "Published Date: 2024-09-23T00:00:00.000Z\n",
            "Author: Yaron Samuel; Dominik Reichel\n",
            "Image: None\n",
            "Text: Executive Summary\n",
            "We recently discovered a novel version of the RomCom malware family called SnipBot and, for the first time, show post-infection activity from the attacker on a victim system. This new strain makes use of new tricks and unique code obfuscation methods in addition to those seen in previous versions of RomCom 3.0 and PEAPOD (RomCom 4.0).\n",
            "In early April, our sandbox Advanced WildFire discovered an unusual DLL module that turned out to be part of a broader tool set called SnipBot. By examining the malware sample and using Cortex XDR telemetry data, we were able to reconstruct the infection chain and the attacker's subsequent actions.\n",
            "We also discovered more related malware strains dating back to December 2023. Although the aim of the attacker is unknown, the behavior we observed indicates an attempt to pivot through the victim's network and exfiltrate certain files.\n",
            "SnipBot gives the attacker the ability to execute commands and download additional modules onto a victim's system. It is a new version of the RomCom malware that is mainly based on RomCom 3.0. However, it also contains techniques seen in its offshoot PEAPOD called RomCom 4.0 by Trend Micro. Therefore, we’ve assigned it version 5.0.\n",
            "This threat operates in several stages, with the initial downloader always being an executable, followed by further EXEs or DLLs. The downloader we observed was consistently signed with a valid code signing certificate that the threat actor likely obtained either through certificate theft or fraud to purchase a new certificate, while subsequent modules were unsigned.\n",
            "In collaboration with Sophos, which initially found this new RomCom version in February during an incident, we investigated the malware's capabilities and gathered some knowledge about the attackers' activity on a victim’s system.\n",
            "Palo Alto Networks customers are better protected from the SnipBot malware through products like Cortex and Advanced WildFire, with its different memory analysis features. Advanced WildFire classifies the SnipBot malware samples in this article as malicious. Advanced URL Filtering and Advanced DNS Security classify known URLs and domains associated with this activity as malicious.\n",
            "If you think you might have been compromised or have an urgent matter, contact the Unit 42 Incident Response team.\n",
            " Related Unit 42 Topics \n",
            "  Backdoors ,  RomCom  \n",
            "  Malware Background\n",
            " RomCom RAT is a malware family that has evolved over the years to include different features and attack methods. The threat actor using RomCom has been active since at least 2022. They engage in ransomware, extortion and targeted credential gathering, likely to support intelligence-gathering operations. RomCom has made multiple advancements, leading to its newest iteration called SnipBot, which employs new commands and evasion techniques.\n",
            "The SnipBot variant of RomCom leverages a basic set of features that allows the attacker to run commands on a victim's system and download additional modules. The initial payload is always either an executable downloader masked as a PDF file or an actual PDF file sent to the victim in an email that leads to an executable.\n",
            "The earliest initial sample of SnipBot we found was a PDF file that shows distorted text that states a font is missing that’s needed to show it correctly. If the victim clicks on the contained link that’s purported to download and install the font package, they will instead download the SnipBot downloader.\n",
            "SnipBot consists of several stages where the initial downloader is always an executable file and the remaining payloads are either EXEs or DLLs. The downloader is always signed with a legitimate and valid code signing certificate. We don’t know how the threat actors obtain these certificates, but it’s likely they steal them or gain them by fraud. Subsequent modules were not signed.\n",
            "  Email Infection Vector\n",
            "By reviewing Cortex XDR telemetry data and reverse engineering the initial sample, we were able to recreate the whole infection chain. The initial infection vector in our case was an email that contained a link that redirects twice to the SnipBot downloader.\n",
            "Figure 1 shows the chain of URLs from the initial one contained in the email to the final SnipBot downloader file link. The attacker registered the domains and . The website is a legitimate file sharing service with a set hosting period of three days.\n",
            " Figure 1. URL chain from the email to the downloader (icon sources). \n",
            "We discovered another chain of links that was likely used by the same attacker to deliver a similar SnipBot downloader variant. The distinct initial domain and the similar downloader file name imply this was part of a campaign targeting multiple victims.\n",
            "Figure 2 shows another chain of URLs used in another attack. The attacker created the domain ; it is not a legitimate file sharing service.\n",
            " Figure 2. Different URL chain from the email to the downloader (icon sources). \n",
            "  SnipBot Malware\n",
            "Figure 3 shows the infection chain of the different SnipBot stages. The initial downloader is a 64-bit Windows executable (SHA256: ) disguised as a PDF file. It is signed with a presumably stolen or spoofed certificate from , which is a company located in Denmark.\n",
            " Figure 3. SnipBot execution flow from the initial EXE downloader to the main bot file (icon sources). \n",
            "This downloader uses two simple yet effective anti-sandbox tricks. The first one checks for the original file name by comparing the hashed process name against a hard-coded value. The second one checks whether there are at least 100 entries in the registry key, which is usually the case on a regular user’s system but less likely to be the case in a sandbox system.\n",
            " \n",
            "Figure 4 shows the registry key of a typical Windows system with more than 100 values present.\n",
            " Figure 4. registry key of a typical Windows system. \n",
            "The downloader is also obfuscated with a window message-based control-flow obfuscation algorithm. The malware code is split up into multiple unordered blocks that are triggered by custom window messages.\n",
            "To accomplish this, a window is created that has a callback message that contains these code blocks. The window message queue is used to call each block in its original order.\n",
            "The first message block is triggered by sending the initial message and then each block sends the next message when it’s done. Additionally, each block can also send nested messages, which makes it even more challenging to follow the execution flow.\n",
            " \n",
            "Most of the strings, such as the command and control (C2) domain name and all the names of dynamically resolved API functions, are encrypted. The threat actor likely did this to prevent easy static detection, thus making malware analysis more time-consuming.\n",
            "Upon execution, the downloader contacts the first C2 domain and tries to get a PDF file and the first payload. We couldn’t recover the original downloaded first payload, but for an unknown reason, the attacker later downloaded the same payload with different configuration data and started it manually. We were able to obtain this file and could continue our analysis.\n",
            "The threat downloads the PDF to the local user’s temporary folder with a random name before opening it. The first payload is a DLL file (internally named ) that the threat executes in memory. It has an exported function named that contains its malicious code.\n",
            "This DLL file’s purpose is to download the next stage COM DLL named from the second C2 and inject it into Explorer. For this, it uses COM hijacking to register the file as the thumbnail cache library in the registry hive of the current user.\n",
            "When restarting , the DLL gets loaded into its address space and executed. While this is a reliable method of loading a payload into Explorer, forcing it to terminate can result in a crash, as it did on the victim's machine.\n",
            " \n",
            "Figure 5 illustrates how the registered COM DLL loads into after restarting.\n",
            " Figure 5. Explorer Injection via COM hijacking as shown with\n",
            "Highlights: ['The website is a legitimate file sharing service with a set hosting period of three days.  Figure 1. URL chain from the email to the downloader (icon sources).  We discovered another chain of links that was likely used by the same attacker to deliver a similar SnipBot downloader variant. The distinct initial domain and the similar downloader file name imply this was part of a campaign targeting multiple victims.']\n",
            "Highlight Scores: [0.18665342032909393]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: Stonefly: Extortion Attacks Continue Against U.S. Targets\n",
            "URL: https://symantec-enterprise-blogs.security.com/threat-intelligence/stonefly-north-korea-extortion\n",
            "ID: https://symantec-enterprise-blogs.security.com/threat-intelligence/stonefly-north-korea-extortion\n",
            "Score: 0.12255967408418655\n",
            "Published Date: 2024-10-02T00:00:00.000Z\n",
            "Author: Threat Hunter Team Symantec\n",
            "Image: None\n",
            "Text: \n",
            "Highlights: ['']\n",
            "Highlight Scores: [-0.029671212658286095]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Title: Infostealer malware bypasses Chrome’s new cookie-theft defenses\n",
            "URL: https://www.bleepingcomputer.com/news/security/infostealer-malware-bypasses-chromes-new-cookie-theft-defenses/\n",
            "ID: https://www.bleepingcomputer.com/news/security/infostealer-malware-bypasses-chromes-new-cookie-theft-defenses/\n",
            "Score: 0.1213291808962822\n",
            "Published Date: 2024-09-24T00:00:00.000Z\n",
            "Author: Bill Toulas\n",
            "Image: None\n",
            "Text: Infostealer malware developers released updates claiming to bypass Google Chrome’s recently introduced feature App-Bound Encryption to protect sensitive data such as cookies.\n",
            "App-Bound Encryption was introduced in Chrome 127 and is designed to encrypt cookies and stored passwords using a Windows service that runs with system privileges.\n",
            "This model does not allow infostealer malware, which runs with the permissions of the logged user, to steal secrets stored in Chrome browser.\n",
            "To bypass this protection, the malware would need system privileges or to inject code into Chrome, both noisy actions that are likely to trigger warnings from security tools, said Will Harris of the Chrome security team. \n",
            "However, security researchers g0njxa and also RussianPanda9xx obseerved multiple infostealer developers boasting that they have implemented a working bypass for their tools (MeduzaStealer, Whitesnake, Lumma Stealer, Lumar (PovertyStealer), Vidar Stealer, StealC).\n",
            "  Whitesnake stealer grabbing cookies from Chrome 128  Source: @g0njxa   \n",
            "It appears that at least some of the claims are real, as g0njxa confirmed for BleepingComputer that the latest variant of Lumma Stealer can bypass the encryption feature in Chrome 129, the currently the most recent version of the browser.\n",
            "  Extracted cookies from Chrome 129, using latest Lumma  Source: @g0njxa   \n",
            "The researcher tested the malware on a Windows 10 Pro system in a sandbox environment.\n",
            "In terms of timing, Meduza, and WhiteSnake implemented their bypassing mechanisms over two weeks ago, Lumma last week, and Vidar and StealC this week.\n",
            "Lumar initially responded to App-Bound Encryption by implementing a temporary solution that required launching the malware with admin rights, but followed with a bypass mechanism that works with the privileges of the logged-in user.\n",
            "The developers of Lumma Stealer assured its customer that they don't need to execute the malware with admin privileges for the cookie theft to work.\n",
            "“Added a new method of collecting Chrome cookies. The new method does not require admin rights and/or restart, which simplifies the crypt build and reduces the chances of detection, and thus increase the knock rate.” – developers of Lumma Stealer\n",
            "How exactly the bypass of App-Bound Encryption is achieved remains undisclosed, but the authors of Rhadamanthys malware commented that it took them 10 minutes to reverse the encryption.\n",
            "BleepingComputer contacted the tech giant for a comment about the malware developer's response to App-Bound Encryption in Chrome but we are still waiting for a reply.\n",
            " Update 1 - 9/25: Researcher RussianPanda9xx also confirmed to BleepingComputer that Vidar and Lumma are capable of retrieving cookies from the latest Chrome, as she validated through testing.\n",
            " Update 2 - 9/25: A Google spokesperson has sent BleepingComputer the following comment regarding the developments in the infostealer malware space.\n",
            "We are aware of the disruption that this new defense has caused to the infostealer landscape and, as we stated in the blog, we expect this protection to cause a shift in attacker behavior to more observables technique such as injection or memory scraping. This matches the new behavior we have seen.\n",
            "We continue to work with OS and AV vendors to try and more reliably detect these new types of attacks, as well as continuing to iterate on hardening defenses to improve protection against infostealers for our users. - A Google spokesperson\n",
            "Highlights: [' Update 2 - 9/25: A Google spokesperson has sent BleepingComputer the following comment regarding the developments in the infostealer malware space. We are aware of the disruption that this new defense has caused to the infostealer landscape and, as we stated in the blog, we expect this protection to cause a shift in attacker behavior to more observables technique such as injection or memory scraping. This matches the new behavior we have seen. We continue to work with OS and AV vendors to try and more reliably detect these new types of attacks, as well as continuing to iterate on hardening defenses to improve protection against infostealers for our users. - A Google spokesperson']\n",
            "Highlight Scores: [0.23152025043964386]\n",
            "Summary: None\n",
            "\n",
            "\n",
            "Autoprompt String: Here is a link to information about currently active Infostealer malware and their TTPs and IOCs:\n",
            "Resolved Search Type: 2024-09-21T15:11:06.478Z\n",
            "ERROR in Exa Search: name 'exa_py' is not defined\n",
            "DEBUG: Jina Search results: [{\"title\": \"What is InfoStealer Malware and How Does It Work?\", \"link\": \"https://www.packetlabs.net/posts/what-is-infostealer-malware-and-how-does-it-work/\", \"snippet\": \"<strong>InfoStealer</strong> <strong>malware</strong> plays a key role in many cyber attacks, enabling extortion and lateral movement via stolen credentials. Learn the fundamentals about <strong>InfoStealers</strong> in this article.\", \"content\": \"Cyberattacks are not random but rather follow a set of methodical and somewhat tactics and techniques. [The Cyber Kill Chain](https://www.lockheedmartin.com/en-us/capabilities/cyber/cyber-kill-chain.html), developed by Lockheed Martin, details the sequential phases of a cyber attack: reconnaissance, weaponization, delivery, exploitation, installation, command and control (C2), and actions on objectives. Attacker tactics and techniques can be mapped using models such as the [MITRE ATT&CK](https://attack.mitre.org/) framework.\\n\\nFollowing these known strategies, after gaining unauthorized initial access, the installation phase allows the attacker to establish a foothold, and through command and control (C2), they maintain ongoing access to the compromised environment.\\n\\nDuring these middle stages InfoStealer malware often comes into play. InfoStealer malware is a type of malicious software specifically designed to extract sensitive information from an infected system. The stolen information can be leveraged to extort victims, threatening to release the data unless a ransom is paid, or sold on the blackmarket to other organized criminal organizations.\\u00a0 Furthermore, if the stolen information contains the victim's credentials such as username, passwords, or private keys, the attacker can use them to compromise other systems, furthering their attack.\\n\\nIn this article we will provide a comprehensive review of InfoStealer malware, what information it targets, how it operates, and list the most prolific InfoStealer malware strains. By understanding the role of InfoStealer malware organizations can better prepare and respond to the intricate landscape of cyber threats they face today.\\n\\nWhat is InfoStealer Malware?\\n----------------------------\\n\\nInfoStealer malware, as its name suggests, is a type of malicious software designed specifically to gather sensitive information from infected systems. This category of malware targets personal, financial, and business data, which can include passwords, [credit card numbers](https://www.packetlabs.net/posts/pci-penetration-test/), browsing history, and other valuable information. The ultimate goal of InfoStealers is to transmit this stolen data to cybercriminals who can use it for financial gain, identity theft, or further malicious activities.\\n\\nInfoStealers often enter systems through phishing emails, malicious attachments, or [compromised websites](https://www.packetlabs.net/posts/heres-how-you-can-defend-against-drive-by-compromise-attacks/). Once installed, they can operate quietly in the background, making them particularly hard to detect. They may also employ various techniques to avoid detection, maintain persistence, find other valuable targets on a network, and allow attackers to issue commands remotely. The most sophisticated InfoStealers are modular; they can import specific payloads after scanning the environment for potential sources of valuable information.\\n\\nHow Do InfoStealers Work?\\n-------------------------\\n\\nInfoStealer malware employs a variety of techniques to target and extract specific types of data from infected systems. Each strain of malware that is classified as a InfoStealer has different capabilities ranging from simple scripts to sophisticated modular malware. It's also important to remember that data can be stolen from a system using native built-in OS tooling known as a [Living Off The Land (LOTL)](https://www.packetlabs.net/posts/what-are-living-off-the-land-attacks/) attack.\\n\\nEach method discussed below targets specific types of data or input-output peripherals. Each method also leverages unique vulnerabilities associated with how that data is used, stored, and transmitted. The diversity of these techniques underscores the necessity for comprehensive security measures that protect not just against one type of threat but a broad array of infiltration strategies.\\n\\nHere are some ways that InfoStealer malware operates:\\n\\n*   **Keylogging**: One of the most common tactics, keylogging involves recording keystrokes made by a user. By capturing everything typed, attackers can later filter out passwords, credit card details, and other sensitive personal information\\n    \\n*   **Form Grabbing**: This technique is used to intercept data submitted in forms on web pages before it is encrypted by the browser. It's particularly effective for stealing login credentials, payment information, and other data entered on websites\\n    \\n*   **Clipboard Hijacking**: InfoStealers can monitor and modify the clipboard content on an infected device. When a user copies data such as account numbers or passwords, the malware replaces or steals this information. This attack technique can even steal usernames and passwords as they are auto-filled by a [password manager](https://www.packetlabs.net/posts/password-manager-breach/)\\n    \\n*   **Screen Capturing**: By taking screenshots of the user\\u2019s screen at critical moments\\u2014such as while entering credentials or viewing personal information\\u2014this method can bypass text-based data extraction limitations, capturing data displayed on the screen in any form\\n    \\n*   **Browser Session Hijacking**: This method involves stealing cookies and session tokens from a browser's cached memory which can allow cybercriminals to impersonate the victim's online session, gaining unauthorized access to online accounts without needing a username and password\\n    \\n*   **Credential Dumping**: This method extracts data from user accounts stored on the system, such as login credentials saved in web browsers or other client software. If they are stored in encrypted format, attackers will attempt to crack them offline using specialized hardware and software tools\\n    \\n*   **Man-in-the-Browser Attacks**: These are more sophisticated attacks where the malware injects malicious code [into the web browser itself](https://www.packetlabs.net/posts/how-safe-are-your-browsers/). This allows the attacker to intercept and manipulate information in real-time as it is entered on secure websites\\n    \\n*   **Email Harvesting**: The malware searches through files and emails stored on the computer to collect email addresses and other contact information, which can be used for spamming or further phishing attacks\\n    \\n*   **Crypto-Wallet Harvesting:** Some InfoStealer malware can search known installation paths for common crypto-wallet software and attempt to steal private keys. Once in the attacker's possession these keys can be used to transfer the victim's cryptocurrency to attacker controlled accounts\\n    \\n\\nThe Most Prolific Strains of InfoStealer Malware\\n------------------------------------------------\\n\\nEstimating the exact number of InfoStealer malware strains is challenging due to the constantly evolving nature of malware and the frequent emergence of new variants. However, cybersecurity experts and researchers generally agree that there are hundreds, if not thousands, of different strains of InfoStealer malware in existence. This vast range includes everything from well-documented and widely recognized strains to more obscure or specialized ones that target specific geographic regions or sectors.\\n\\n*   [**Zeus (Zbot)**](https://www.cynet.com/malware/zeus-malware-variants-methods-and-history/)**:** Perhaps the most infamous InfoStealer, Zeus primarily targets financial information. First identified in 2007, it has been responsible for numerous cybercrimes, including banking fraud and the formation of botnets. Zeus is known for its ability to elude detection by using stealth techniques and its capability to replicate and distribute itself\\n    \\n*   [**Ursnif (Gozi)**](https://attack.mitre.org/software/S0386/)**:** Ursnif is another banking Trojan that has been active for over a decade. Ursnif is known for its sophisticated evasion techniques, modular design, and its ability to steal a wide variety of data types, including banking credentials and personal identifiable information (PII). Ursnif is typically spread through exploit kits and phishing emails\\n    \\n*   [**Agent Tesla**](https://attack.mitre.org/software/S0331/)**:** Agent Tesla is a sophisticated spyware that functions primarily as a keylogger and a remote access trojan (RAT). First identified around 2014, it is capable of monitoring and collecting the victim's keyboard inputs, system clipboard, taking screenshots, and exfiltrating credentials from a variety of software installed on the victim\\u2019s machine. Agent Tesla is often distributed via malicious email attachments, disguised as legitimate files or links that execute the malware upon opening\\n    \\n*   [**LokiBot**](https://attack.mitre.org/software/S0447/)**:** LokiBot, first detected in 2015, is an information stealer that targets multiple platforms to steal a variety of credentials such as passwords, cryptocurrency wallets, and other data. It also has modular functionalities to download and execute additional malicious payloads giving the attacker remote access. LokiBot is typically distributed through phishing emails, malicious software installers, and compromised websites\\n    \\n*   [**TrickBot**](https://attack.mitre.org/software/S0266/)**:** Originally identified in 2016, TrickBot has evolved from a banking trojan into a sophisticated multi-purpose malware capable of launching ransomware attacks and providing attackers with remote access to infected systems. TrickBot spreads through malspam campaigns and exploits vulnerabilities in network infrastructure. TrickBot is often considered one of the most sophisticated strains of malware with diverse capabilities\\n    \\n*   [**Raccoon Stealer**](https://www.blackberry.com/us/en/solutions/endpoint-security/ransomware-protection/raccoon-infostealer)**:** Raccoon Stealer is an information-stealing malware that emerged in 2019, known for its ease of use for low-skilled attackers, and its ability to extract a wide range of personal data. This malware steals credentials, web session cookies, and credit card data from browser caches, and searches for cryptocurrency wallets to extract private keys. Raccoon Stealer spreads via malicious email campaigns and exploit kits, leveraging its simplicity and effectiveness to appeal to a wide range of cybercriminals, including those with limited technical expertise\\n    \\n*   [**Redline Stealer**](https://blogs.blackberry.com/en/2021/07/threat-thursday-redline-infostealer)**:** Redline Stealer, first observed in 2020, is a relatively new but rapidly popular malware designed to steal passwords, credit card information, and other sensitive data stored in web browsers. It can also collect details about the infected system\\u2019s environment in order to facilitate secondary attacks such as privilege escalation and maintaining persistence. Redline Stealer is typically distributed through phishing campaigns, malicious advertisements, and bundled with cracked software, highlighting the risks of downloading unverified software from the internet\\n    \\n\\nConclusion\\n----------\\n\\nInfoStealers represents a distinct type of malware, adept at extracting sensitive information from compromised systems, and plays a crucial role during the middle stages of a cyber attack\\u2014post-initial access. It targets a wide range of data, from personal and financial information to credentials that facilitate lateral movements within networks or enable extortion schemes.\\u00a0 Understanding the nature and function of InfoStealer malware is essential for organizations seeking to enhance their defensive strategies against an increasingly sophisticated array of cyber threats.\\n\\nLooking for more deep-dives on topics related to InfoStealer malware and other cybersecurity news? Sign up for our informational zero-spam newsletter.\"}, {\"title\": \"Understanding and Protecting Against Infostealer Malware: A Comprehensive Guide | Flashpoint\", \"link\": \"https://flashpoint.io/blog/protecting-against-infostealer-malware/\", \"snippet\": \"One of the most effective ways to protect against infostealers is to <strong>ensure that specific, targeted security measures are in place</strong>. This is even more important as organizations increasingly rely on third-party services and platforms.\", \"content\": \"\"}, {\"title\": \"The Growing Threat from Infostealers | Secureworks\", \"link\": \"https://www.secureworks.com/research/the-growing-threat-from-infostealers\", \"snippet\": \"<strong>Bots are computers that were infected with infostealer malware to steal information and the browser fingerprint from a victim&#x27;s web browser</strong>. The browser fingerprint can be used to impersonate the victim and access the victim&#x27;s bank accounts, take over accounts, and make fraudulent purchases.\", \"content\": \"\"}, {\"title\": \"Infostealer Malware: Top 5 Stealers in 2024 \\u2013 Gridinsoft Blog\", \"link\": \"https://gridinsoft.com/blogs/infostealer-malware-top/\", \"snippet\": \"<strong>Infostealer</strong> <strong>malware</strong> may be as dangerous as ransomware and other threats. See which stealers dominate the market\", \"content\": \"\"}, {\"title\": \"The Enduring Legacy Of Infostealer Malware\\u2014What You Can Do \\u2013 Innovate Cybersecurity | Threat Advisory, News, and Events\", \"link\": \"https://innovatecybersecurity.com/news/the-enduring-legacy-of-infostealer-malware-what-you-can-do/\", \"snippet\": \"Infostealer malware, short for information-stealer, is <strong>a type of malware that primarily aims to collect and exfiltrate sensitive information</strong>. It typically targets login information, bank details, cryptocurrency wallets, and personally identifiable information such as SSNs and dates of birth.\", \"content\": \"\"}]\n",
            "ERROR in Google Programmable Search: 1 validation error for SearchResult\n",
            "date\n",
            "  Field required [type=missing, input_value={'source': 'Google Progra...75a', 'image_url': None}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
            "ERROR in Crawl4AI Search: asyncio.run() cannot be called from a running event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-777c3d9ca3e3>:275: RuntimeWarning: coroutine 'crawl_multiple_urls' was never awaited\n",
            "  return []\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Error code: 404 - {'error': {'message': 'This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-cdb100e399d2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Share some details on currently active Infostealer malware and give me their TTPs and IOCs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-8d562ea76970>\u001b[0m in \u001b[0;36mrun_agent\u001b[0;34m(query, memory)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAgentState\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgentState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"human\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1586\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   1587\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                     \u001b[0mmanager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 ):\n\u001b[0;32m-> 1315\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   1316\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mrun_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;31m# if successful, end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-8d562ea76970>\u001b[0m in \u001b[0;36mgenerate_response\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mcurrent_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d %H:%M:%S UTC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     response = chain.invoke({\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;34m\"search_results\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{result.title}\\n{result.snippet}\\n{format_source_link(result.source, result.url)}\\nDate: {result.date or 'Not specified'}\\nMedia: {', '.join(result.media)}\\nLinks: {', '.join(result.links)}\\n\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msearch_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         return (\n\u001b[0;32m--> 390\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    391\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    754\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m                 )\n\u001b[1;32m    949\u001b[0m             ]\n\u001b[0;32m--> 950\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    951\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             output = (\n\u001b[0;32m--> 779\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    780\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/llms/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 )\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_prompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                     \u001b[0;31m# V1 client returns the response in an PyDantic object instead of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     ) -> Completion | Stream[Completion]:\n\u001b[0;32m--> 539\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0;34m\"/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m         )\n\u001b[0;32m-> 1277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    955\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': 'This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ob3VmIABZalr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}