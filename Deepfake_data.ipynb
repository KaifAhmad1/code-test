{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRmaUie5LjZ0SVyoib/ri7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Deepfake_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Deepfake and Manipulated Media Analysis Data Download**"
      ],
      "metadata": {
        "id": "V5er949VRqvP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3adQdF8KJWyE",
        "outputId": "158b7187-792f-479e-c1b2-1fbba0ebd702",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU kaggle pandas requests tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "E5SKXUPiJobX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, dest_path):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, stream=True, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Handle dynamic filenames for certain sources\n",
        "        if \"thispersondoesnotexist\" in url:\n",
        "            filename = f\"generated_face_{hash(url)}.jpg\"\n",
        "            dest_path = dest_path.parent / filename\n",
        "\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "        dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        with open(dest_path, 'wb') as f, tqdm(\n",
        "            desc=f\"Downloading {dest_path.name}\",\n",
        "            total=total_size,\n",
        "            unit='iB',\n",
        "            unit_scale=True,\n",
        "        ) as pbar:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                    pbar.update(len(chunk))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {url}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def download_multimodal_subset():\n",
        "    base_dir = Path(\"./multimodal_deepfake_data\")\n",
        "\n",
        "    # Updated with verified working URLs\n",
        "    datasets = {\n",
        "        \"images\": {\n",
        "            \"real\": [\n",
        "                # From Wikimedia Commons (CC0 licensed)\n",
        "                \"https://upload.wikimedia.org/wikipedia/commons/6/6e/Thomas_Edison_1880.jpg\",\n",
        "                \"https://upload.wikimedia.org/wikipedia/commons/b/b4/Steve_Jobs_1976_crop.jpg\",\n",
        "            ],\n",
        "            \"fake\": [\n",
        "                # ThisPersonDoesNotExist with proper headers\n",
        "                \"https://thispersondoesnotexist.com\" for _ in range(5)\n",
        "            ]\n",
        "        },\n",
        "        \"videos\": {\n",
        "            \"real\": [\n",
        "                # From Wikimedia Commons sample videos\n",
        "                \"https://upload.wikimedia.org/wikipedia/commons/transcoded/c/c0/Big_Buck_Bunny_4K.webm/Big_Buck_Bunny_4K.webm.360p.vp9.webm\",\n",
        "            ],\n",
        "            \"fake\": [\n",
        "                # DFDC sample videos from official source\n",
        "                \"https://github.com/microsoft/DFD/raw/master/resources/release_samples/dfdc_fake_00.mp4\",\n",
        "                \"https://github.com/microsoft/DFD/raw/master/resources/release_samples/dfdc_fake_01.mp4\",\n",
        "            ]\n",
        "        },\n",
        "        \"audio\": {\n",
        "            \"real\": [\n",
        "                # From Common Voice dataset\n",
        "                \"https://mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com/cv-corpus-15.0-2024-02-05/en/clips/common_voice_en_38308318.mp3\",\n",
        "            ],\n",
        "            \"fake\": [\n",
        "                # Synthetic audio samples from ESPNet\n",
        "                \"https://github.com/espnet/espnet/raw/master/egs2/ljspeech/tts1/audio.wav\",\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    results = {\"images\": 0, \"videos\": 0, \"audio\": 0}\n",
        "\n",
        "    for modality, categories in datasets.items():\n",
        "        print(f\"\\n{'='*40}\\nDownloading {modality.upper()} samples\\n{'='*40}\")\n",
        "        for category, urls in categories.items():\n",
        "            print(f\"\\n{category.capitalize()} samples:\")\n",
        "            modality_dir = base_dir / modality / category\n",
        "\n",
        "            for url in urls:\n",
        "                filename = url.split(\"/\")[-1].split(\"?\")[0]  # Clean URL parameters\n",
        "                dest_path = modality_dir / filename\n",
        "                if download_file(url, dest_path):\n",
        "                    results[modality] += 1\n",
        "\n",
        "    print(\"\\nFinal Report:\")\n",
        "    print(f\"Images downloaded: {results['images']}\")\n",
        "    print(f\"Videos downloaded: {results['videos']}\")\n",
        "    print(f\"Audio downloaded: {results['audio']}\")\n",
        "    print(f\"Total dataset size: {sum(results.values())} files\")\n",
        "    print(f\"Data location: {base_dir.absolute()}\")"
      ],
      "metadata": {
        "id": "pxb5lV48LQyB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    download_multimodal_subset()"
      ],
      "metadata": {
        "id": "v8dnHHHBYRQo",
        "outputId": "5f85845d-311c-4b57-9114-8a44a264d420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Downloading IMAGES samples\n",
            "========================================\n",
            "\n",
            "Real samples:\n",
            "Error downloading https://upload.wikimedia.org/wikipedia/commons/6/6e/Thomas_Edison_1880.jpg: 404 Client Error: Not Found for url: https://upload.wikimedia.org/wikipedia/commons/6/6e/Thomas_Edison_1880.jpg\n",
            "Error downloading https://upload.wikimedia.org/wikipedia/commons/b/b4/Steve_Jobs_1976_crop.jpg: 404 Client Error: Not Found for url: https://upload.wikimedia.org/wikipedia/commons/b/b4/Steve_Jobs_1976_crop.jpg\n",
            "\n",
            "Fake samples:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading generated_face_-5473839726246319828.jpg: 100%|██████████| 523k/523k [00:00<00:00, 1.02MiB/s]\n",
            "Downloading generated_face_-5473839726246319828.jpg: 100%|██████████| 518k/518k [00:00<00:00, 978kiB/s] \n",
            "Downloading generated_face_-5473839726246319828.jpg: 100%|██████████| 512k/512k [00:00<00:00, 940kiB/s] \n",
            "Downloading generated_face_-5473839726246319828.jpg: 100%|██████████| 635k/635k [00:00<00:00, 1.12MiB/s]\n",
            "Downloading generated_face_-5473839726246319828.jpg: 100%|██████████| 552k/552k [00:00<00:00, 1.04MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Downloading VIDEOS samples\n",
            "========================================\n",
            "\n",
            "Real samples:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Big_Buck_Bunny_4K.webm.360p.vp9.webm: 100%|██████████| 57.0M/57.0M [00:02<00:00, 27.3MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fake samples:\n",
            "Error downloading https://github.com/microsoft/DFD/raw/master/resources/release_samples/dfdc_fake_00.mp4: 404 Client Error: Not Found for url: https://github.com/microsoft/DFD/raw/master/resources/release_samples/dfdc_fake_00.mp4\n",
            "Error downloading https://github.com/microsoft/DFD/raw/master/resources/release_samples/dfdc_fake_01.mp4: 404 Client Error: Not Found for url: https://github.com/microsoft/DFD/raw/master/resources/release_samples/dfdc_fake_01.mp4\n",
            "\n",
            "========================================\n",
            "Downloading AUDIO samples\n",
            "========================================\n",
            "\n",
            "Real samples:\n",
            "Error downloading https://mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com/cv-corpus-15.0-2024-02-05/en/clips/common_voice_en_38308318.mp3: 403 Client Error: Forbidden for url: https://mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com/cv-corpus-15.0-2024-02-05/en/clips/common_voice_en_38308318.mp3\n",
            "\n",
            "Fake samples:\n",
            "Error downloading https://github.com/espnet/espnet/raw/master/egs2/ljspeech/tts1/audio.wav: 404 Client Error: Not Found for url: https://github.com/espnet/espnet/raw/master/egs2/ljspeech/tts1/audio.wav\n",
            "\n",
            "Final Report:\n",
            "Images downloaded: 5\n",
            "Videos downloaded: 1\n",
            "Audio downloaded: 0\n",
            "Total dataset size: 6 files\n",
            "Data location: /content/multimodal_deepfake_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o-JlIK1KUdP0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}