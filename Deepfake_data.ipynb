{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYJhJWTgigJWC4Qcfav7aa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Deepfake_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Deepfake and Manipulated Media Analysis Data Download**"
      ],
      "metadata": {
        "id": "V5er949VRqvP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3adQdF8KJWyE",
        "outputId": "158b7187-792f-479e-c1b2-1fbba0ebd702",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU kaggle pandas requests tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import time"
      ],
      "metadata": {
        "id": "E5SKXUPiJobX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, dest_path):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, stream=True, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Generate unique filenames for dynamic content\n",
        "        if \"thispersondoesnotexist\" in url:\n",
        "            filename = f\"generated_face_{int(time.time())}.jpg\"\n",
        "            dest_path = dest_path.parent / filename\n",
        "\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "        dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        with open(dest_path, 'wb') as f, tqdm(\n",
        "            desc=f\"Downloading {dest_path.name}\",\n",
        "            total=total_size,\n",
        "            unit='iB',\n",
        "            unit_scale=True,\n",
        "        ) as pbar:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                    pbar.update(len(chunk))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {url}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def download_multimodal_subset():\n",
        "    base_dir = Path(\"./multimodal_deepfake_data\")\n",
        "\n",
        "    # Updated with verified working URLs\n",
        "    datasets = {\n",
        "        \"images\": {\n",
        "            \"real\": [\n",
        "                # Verified Wikimedia URLs\n",
        "                \"https://upload.wikimedia.org/wikipedia/commons/1/18/Thomas_Edison2.jpg\",\n",
        "                \"https://upload.wikimedia.org/wikipedia/commons/d/dc/Steve_Jobs_Headshot_2010-CROP.jpg\",\n",
        "            ],\n",
        "            \"fake\": [\n",
        "                \"https://thispersondoesnotexist.com\" for _ in range(5)\n",
        "            ]\n",
        "        },\n",
        "        \"videos\": {\n",
        "            \"real\": [\n",
        "                # Shorter test video from Wikimedia\n",
        "                \"https://upload.wikimedia.org/wikipedia/commons/transcoded/c/c0/Big_Buck_Bunny_4K.webm/Big_Buck_Bunny_4K.webm.240p.vp9.webm\",\n",
        "            ],\n",
        "            \"fake\": [\n",
        "                # DFDC samples from Kaggle\n",
        "                \"https://storage.googleapis.com/kaggle-datasets/25814/33244/dfdc_train_part_0.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1725580486&Signature=...\",\n",
        "            ]\n",
        "        },\n",
        "        \"audio\": {\n",
        "            \"real\": [\n",
        "                # Common Voice sample from official mirror\n",
        "                \"https://cdn.commonvoice.mozilla.org/training-datasets/cv-corpus-15.0-2024-02-05/en/clips/common_voice_en_38308318.mp3\",\n",
        "            ],\n",
        "            \"fake\": [\n",
        "                # Updated ESPNet sample\n",
        "                \"https://github.com/espnet/espnet/raw/master/egs2/TEMPLATE/tts1/audio.wav\",\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    results = {\"images\": 0, \"videos\": 0, \"audio\": 0}\n",
        "\n",
        "    for modality, categories in datasets.items():\n",
        "        print(f\"\\n{'='*40}\\nDownloading {modality.upper()} samples\\n{'='*40}\")\n",
        "        for category, urls in categories.items():\n",
        "            print(f\"\\n{category.capitalize()} samples:\")\n",
        "            modality_dir = base_dir / modality / category\n",
        "\n",
        "            for url in urls:\n",
        "                filename = url.split(\"/\")[-1].split(\"?\")[0]\n",
        "                dest_path = modality_dir / filename\n",
        "                if not dest_path.exists():  # Skip existing files\n",
        "                    if download_file(url, dest_path):\n",
        "                        results[modality] += 1\n",
        "                else:\n",
        "                    print(f\"Skipping existing file: {dest_path.name}\")\n",
        "                    results[modality] += 1\n",
        "\n",
        "    print(\"\\nFinal Report:\")\n",
        "    print(f\"Images downloaded: {results['images']}\")\n",
        "    print(f\"Videos downloaded: {results['videos']}\")\n",
        "    print(f\"Audio downloaded: {results['audio']}\")\n",
        "    print(f\"Total dataset size: {sum(results.values())} files\")\n",
        "    print(f\"Data location: {base_dir.absolute()}\")"
      ],
      "metadata": {
        "id": "pxb5lV48LQyB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    download_multimodal_subset()"
      ],
      "metadata": {
        "id": "v8dnHHHBYRQo",
        "outputId": "b297df48-ce59-4c74-c3c7-c8c8d6084c53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Downloading IMAGES samples\n",
            "========================================\n",
            "\n",
            "Real samples:\n",
            "Error downloading https://upload.wikimedia.org/wikipedia/commons/1/18/Thomas_Edison2.jpg: 404 Client Error: Not Found for url: https://upload.wikimedia.org/wikipedia/commons/1/18/Thomas_Edison2.jpg\n",
            "Error downloading https://upload.wikimedia.org/wikipedia/commons/d/dc/Steve_Jobs_Headshot_2010-CROP.jpg: 404 Client Error: Not Found for url: https://upload.wikimedia.org/wikipedia/commons/d/dc/Steve_Jobs_Headshot_2010-CROP.jpg\n",
            "\n",
            "Fake samples:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading generated_face_1738219268.jpg: 100%|██████████| 568k/568k [00:00<00:00, 1.02MiB/s]\n",
            "Downloading generated_face_1738219269.jpg: 100%|██████████| 568k/568k [00:00<00:00, 1.01MiB/s]\n",
            "Downloading generated_face_1738219270.jpg: 100%|██████████| 567k/567k [00:00<00:00, 976kiB/s]\n",
            "Downloading generated_face_1738219271.jpg: 100%|██████████| 515k/515k [00:00<00:00, 938kiB/s] \n",
            "Downloading generated_face_1738219272.jpg: 100%|██████████| 544k/544k [00:00<00:00, 978kiB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Downloading VIDEOS samples\n",
            "========================================\n",
            "\n",
            "Real samples:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Big_Buck_Bunny_4K.webm.240p.vp9.webm: 100%|██████████| 30.4M/30.4M [00:01<00:00, 25.2MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fake samples:\n",
            "Error downloading https://storage.googleapis.com/kaggle-datasets/25814/33244/dfdc_train_part_0.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1725580486&Signature=...: 400 Client Error: Bad Request for url: https://storage.googleapis.com/kaggle-datasets/25814/33244/dfdc_train_part_0.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1725580486&Signature=...\n",
            "\n",
            "========================================\n",
            "Downloading AUDIO samples\n",
            "========================================\n",
            "\n",
            "Real samples:\n",
            "Error downloading https://cdn.commonvoice.mozilla.org/training-datasets/cv-corpus-15.0-2024-02-05/en/clips/common_voice_en_38308318.mp3: HTTPSConnectionPool(host='cdn.commonvoice.mozilla.org', port=443): Max retries exceeded with url: /training-datasets/cv-corpus-15.0-2024-02-05/en/clips/common_voice_en_38308318.mp3 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7d6746083d50>: Failed to resolve 'cdn.commonvoice.mozilla.org' ([Errno -2] Name or service not known)\"))\n",
            "\n",
            "Fake samples:\n",
            "Error downloading https://github.com/espnet/espnet/raw/master/egs2/TEMPLATE/tts1/audio.wav: 404 Client Error: Not Found for url: https://github.com/espnet/espnet/raw/master/egs2/TEMPLATE/tts1/audio.wav\n",
            "\n",
            "Final Report:\n",
            "Images downloaded: 5\n",
            "Videos downloaded: 1\n",
            "Audio downloaded: 0\n",
            "Total dataset size: 6 files\n",
            "Data location: /content/multimodal_deepfake_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o-JlIK1KUdP0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}