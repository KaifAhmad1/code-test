{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOA/01YaeRkTD5p6o2BXyS4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Deepfake_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Deepfake and Manipulated Media Analysis Data Download**"
      ],
      "metadata": {
        "id": "V5er949VRqvP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3adQdF8KJWyE",
        "outputId": "c0288022-ade1-470d-e189-78e39d24a05d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU kaggle pandas tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import tarfile\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "import json\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "E5SKXUPiJobX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_robust_session():\n",
        "    session = requests.Session()\n",
        "    retries = Retry(\n",
        "        total=3,\n",
        "        backoff_factor=0.5,\n",
        "        status_forcelist=[429, 500, 502, 503, 504],\n",
        "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
        "    )\n",
        "    session.mount('http://', HTTPAdapter(max_retries=retries))\n",
        "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
        "    return session"
      ],
      "metadata": {
        "id": "pxb5lV48LQyB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_url_availability(session, url):\n",
        "    try:\n",
        "        response = session.head(url, timeout=10)\n",
        "        return response.status_code == 200\n",
        "    except Exception as e:\n",
        "        print(f\"URL check failed for {url}: {str(e)}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "8f0_v4lTMwAe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(session, url, dest_path, desc=\"\"):\n",
        "    try:\n",
        "        if not check_url_availability(session, url):\n",
        "            print(f\"URL not accessible: {url}\")\n",
        "            return False\n",
        "\n",
        "        response = session.get(url, stream=True, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "        os.makedirs(dest_path.parent, exist_ok=True)\n",
        "        temp_path = dest_path.with_suffix('.temp')\n",
        "\n",
        "        with open(temp_path, 'wb') as f, tqdm(\n",
        "            desc=desc,\n",
        "            total=total_size,\n",
        "            unit='iB',\n",
        "            unit_scale=True,\n",
        "            unit_divisor=1024,\n",
        "        ) as pbar:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                size = f.write(chunk)\n",
        "                pbar.update(size)\n",
        "\n",
        "        temp_path.rename(dest_path)\n",
        "\n",
        "        if dest_path.suffix in ['.zip', '.tar', '.gz']:\n",
        "            extract_archive(dest_path)\n",
        "\n",
        "        print(f\"Successfully downloaded: {dest_path}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {url}: {str(e)}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "ZjQa9UMpRfxj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_archive(archive_path):\n",
        "    try:\n",
        "        print(f\"Extracting {archive_path}\")\n",
        "        extract_path = archive_path.parent / archive_path.stem\n",
        "\n",
        "        if archive_path.suffix == '.zip':\n",
        "            with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_path)\n",
        "        elif archive_path.suffix in ['.tar', '.gz']:\n",
        "            with tarfile.open(archive_path, 'r:*') as tar_ref:\n",
        "                tar_ref.extractall(extract_path)\n",
        "\n",
        "        archive_path.unlink()\n",
        "        print(f\"Successfully extracted to {extract_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting {archive_path}: {str(e)}\")"
      ],
      "metadata": {
        "id": "_MPNNEvbUNSV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_all(base_dir):\n",
        "    session = create_robust_session()\n",
        "    sources = {\n",
        "        'images': {\n",
        "            'Deepfake Detection Challenge Sample': {\n",
        "                'url': 'https://github.com/selimsef/dfdc_deepfake_challenge/releases/download/0.0.1/example_videos.zip'\n",
        "            },\n",
        "            'FaceForensics++ Sample': {\n",
        "                'url': 'https://github.com/ondyari/FaceForensics/blob/master/dataset/sample_videos.zip?raw=true'\n",
        "            }\n",
        "        },\n",
        "        'videos': {\n",
        "            'Celeb-DF Sample': {\n",
        "                'url': 'https://github.com/yuezunli/celeb-deepfakeforensics/blob/master/sample_videos.zip?raw=true'\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    summary = {media_type: {'success': 0, 'failed': 0} for media_type in sources.keys()}\n",
        "\n",
        "    for media_type, datasets in sources.items():\n",
        "        for dataset_name, info in datasets.items():\n",
        "            dest_path = Path(base_dir) / media_type / f\"{dataset_name}.zip\"\n",
        "            success = download_file(session, info['url'], dest_path, f\"Downloading {dataset_name}\")\n",
        "            if success:\n",
        "                summary[media_type]['success'] += 1\n",
        "            else:\n",
        "                summary[media_type]['failed'] += 1\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "ZnBUKkDYUTRL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_report(summary, base_dir):\n",
        "    report = \"Public DeepFake Test Data Download Summary\\n\"\n",
        "    report += \"=\" * 40 + \"\\n\\n\"\n",
        "\n",
        "    total_success = sum(v['success'] for v in summary.values())\n",
        "    total_failed = sum(v['failed'] for v in summary.values())\n",
        "\n",
        "    for media_type, counts in summary.items():\n",
        "        report += f\"{media_type.title()}:\\n\"\n",
        "        report += f\"  - Successfully downloaded: {counts['success']}\\n\"\n",
        "        report += f\"  - Failed downloads: {counts['failed']}\\n\\n\"\n",
        "\n",
        "    report += f\"Overall Statistics:\\n\"\n",
        "    report += f\"  - Total successful downloads: {total_success}\\n\"\n",
        "    report += f\"  - Total failed downloads: {total_failed}\\n\\n\"\n",
        "    report += f\"Storage location: {base_dir}\\n\"\n",
        "    return report"
      ],
      "metadata": {
        "id": "ms0GdSgLUW8B"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    base_dir = \"./deepfake_test_data\"\n",
        "    print(\"Starting deepfake test data download...\")\n",
        "    summary = download_all(base_dir)\n",
        "    print(generate_report(summary, base_dir))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "yk8udOcpUaVx",
        "outputId": "be297ebf-92ac-4bc8-e08b-f8680374c804",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting deepfake test data download...\n",
            "URL not accessible: https://github.com/selimsef/dfdc_deepfake_challenge/releases/download/0.0.1/example_videos.zip\n",
            "URL not accessible: https://github.com/ondyari/FaceForensics/blob/master/dataset/sample_videos.zip?raw=true\n",
            "URL not accessible: https://github.com/yuezunli/celeb-deepfakeforensics/blob/master/sample_videos.zip?raw=true\n",
            "Public DeepFake Test Data Download Summary\n",
            "========================================\n",
            "\n",
            "Images:\n",
            "  - Successfully downloaded: 0\n",
            "  - Failed downloads: 2\n",
            "\n",
            "Videos:\n",
            "  - Successfully downloaded: 0\n",
            "  - Failed downloads: 1\n",
            "\n",
            "Overall Statistics:\n",
            "  - Total successful downloads: 0\n",
            "  - Total failed downloads: 3\n",
            "\n",
            "Storage location: ./deepfake_test_data\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o-JlIK1KUdP0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}