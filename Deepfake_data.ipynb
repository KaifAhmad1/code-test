{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaJOON2XEQZp9ABNd2p3jj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Deepfake_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3adQdF8KJWyE",
        "outputId": "c0288022-ade1-470d-e189-78e39d24a05d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU kaggle pandas tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "import hashlib\n",
        "import zipfile\n",
        "import tarfile\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry"
      ],
      "metadata": {
        "id": "E5SKXUPiJobX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepFakeDownloader:\n",
        "    def __init__(self, base_dir=\"./deepfake_test_data\"):\n",
        "        self.base_dir = Path(base_dir)\n",
        "\n",
        "        # Configure session with retry strategy\n",
        "        self.session = requests.Session()\n",
        "        retries = Retry(\n",
        "            total=3,\n",
        "            backoff_factor=0.5,\n",
        "            status_forcelist=[500, 502, 503, 504]\n",
        "        )\n",
        "        self.session.mount('http://', HTTPAdapter(max_retries=retries))\n",
        "        self.session.mount('https://', HTTPAdapter(max_retries=retries))\n",
        "\n",
        "        # Focus only on manipulated media test sets\n",
        "        self.sources = {\n",
        "            'images': {\n",
        "                # FaceForensics++ test set samples\n",
        "                'https://github.com/ondyari/FaceForensics/raw/master/dataset/test_set.zip',\n",
        "                # CelebDF-v2 test set\n",
        "                'https://github.com/yuezunli/celeb-deepfakeforensics/raw/master/test_release.zip',\n",
        "                # DFDC Preview Test Set\n",
        "                'https://dfdc-preview-test.s3.amazonaws.com/dfdc_test_set.zip'\n",
        "            },\n",
        "            'videos': {\n",
        "                # DeepFake Detection Challenge test samples\n",
        "                'https://dfdc.ai/api/get/test_sample.zip',\n",
        "                # FakeAVCeleb test set\n",
        "                'https://fakeavceleb.com/download/test_set.zip',\n",
        "                # DeeperForensics-1.0 test set\n",
        "                'https://github.com/EndlessSora/DeeperForensics-1.0/raw/master/test.zip'\n",
        "            },\n",
        "            'audio': {\n",
        "                # ASVspoof 2021 LA evaluation set\n",
        "                'https://datashare.ed.ac.uk/bitstream/handle/10283/3336/LA_test.zip',\n",
        "                # FakeVoice test set\n",
        "                'https://github.com/fakevoice/dataset/raw/main/test_set.zip'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Dataset access credentials (to be filled by user)\n",
        "        self.credentials = {\n",
        "            'dfdc': {'api_key': ''},\n",
        "            'asvspoof': {'username': '', 'password': ''},\n",
        "            'celeb_df': {'access_token': ''}\n",
        "        }\n",
        "\n",
        "    def download_file(self, url, dest_path, desc=\"\", chunk_size=8192):\n",
        "        \"\"\"Download a file with progress tracking\"\"\"\n",
        "        try:\n",
        "            # Handle authentication if needed\n",
        "            headers = {}\n",
        "            if 'dfdc.ai' in url and self.credentials['dfdc']['api_key']:\n",
        "                headers['Authorization'] = f\"Bearer {self.credentials['dfdc']['api_key']}\"\n",
        "            elif 'datashare.ed.ac.uk' in url:\n",
        "                auth = (self.credentials['asvspoof']['username'],\n",
        "                       self.credentials['asvspoof']['password'])\n",
        "            else:\n",
        "                auth = None\n",
        "\n",
        "            response = self.session.get(url,\n",
        "                                      stream=True,\n",
        "                                      timeout=30,\n",
        "                                      headers=headers,\n",
        "                                      auth=auth)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            total_size = int(response.headers.get('content-length', 0))\n",
        "            dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            with open(dest_path, 'wb') as f, tqdm(\n",
        "                desc=desc,\n",
        "                total=total_size,\n",
        "                unit='iB',\n",
        "                unit_scale=True,\n",
        "                unit_divisor=1024,\n",
        "            ) as pbar:\n",
        "                for chunk in response.iter_content(chunk_size=chunk_size):\n",
        "                    size = f.write(chunk)\n",
        "                    pbar.update(size)\n",
        "\n",
        "            # Extract if it's a compressed file\n",
        "            if dest_path.suffix in ['.zip', '.tar', '.gz']:\n",
        "                self.extract_archive(dest_path)\n",
        "            return True\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error downloading {url}: {str(e)}\")\n",
        "            if hasattr(e.response, 'status_code') and e.response.status_code == 403:\n",
        "                print(\"Authentication required. Please check credentials.\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def extract_archive(self, archive_path):\n",
        "        \"\"\"Extract downloaded archives\"\"\"\n",
        "        try:\n",
        "            print(f\"Extracting {archive_path}\")\n",
        "            extract_path = archive_path.parent / archive_path.stem\n",
        "\n",
        "            if archive_path.suffix == '.zip':\n",
        "                with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(extract_path)\n",
        "            elif archive_path.suffix in ['.tar', '.gz']:\n",
        "                with tarfile.open(archive_path, 'r:*') as tar_ref:\n",
        "                    tar_ref.extractall(extract_path)\n",
        "\n",
        "            archive_path.unlink()\n",
        "            print(f\"Successfully extracted to {extract_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting {archive_path}: {str(e)}\")\n",
        "\n",
        "    def download_all(self, skip_existing=True):\n",
        "        \"\"\"Download all test datasets\"\"\"\n",
        "        summary = {media_type: 0 for media_type in self.sources.keys()}\n",
        "\n",
        "        for media_type, urls in self.sources.items():\n",
        "            print(f\"\\nDownloading {media_type} test sets...\")\n",
        "            media_dir = self.base_dir / media_type\n",
        "\n",
        "            for i, url in enumerate(urls):\n",
        "                filename = f\"test_set_{i}{Path(url).suffix}\"\n",
        "                dest_path = media_dir / filename\n",
        "\n",
        "                if skip_existing and dest_path.exists():\n",
        "                    print(f\"Skipping existing file: {filename}\")\n",
        "                    summary[media_type] += 1\n",
        "                    continue\n",
        "\n",
        "                if self.download_file(url, dest_path, f\"{media_type}/{filename}\"):\n",
        "                    summary[media_type] += 1\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def generate_report(self, summary):\n",
        "        \"\"\"Generate download summary\"\"\"\n",
        "        report = \"DeepFake Test Data Download Summary\\n\"\n",
        "        report += \"=\" * 35 + \"\\n\\n\"\n",
        "\n",
        "        total_files = 0\n",
        "        for media_type, count in summary.items():\n",
        "            report += f\"{media_type.title()}: {count} test sets\\n\"\n",
        "            total_files += count\n",
        "\n",
        "        report += f\"\\nTotal test sets downloaded: {total_files}\"\n",
        "        report += f\"\\nStorage location: {self.base_dir}\"\n",
        "        return report"
      ],
      "metadata": {
        "id": "pxb5lV48LQyB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    downloader = DeepFakeDownloader()\n",
        "    print(\"Starting deepfake test data download...\")\n",
        "    summary = downloader.download_all()\n",
        "    print(\"\\n\" + downloader.generate_report(summary))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "8f0_v4lTMwAe",
        "outputId": "75e14e4e-4545-4ef7-a881-a5084bf7a4ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting deepfake test data download...\n",
            "\n",
            "Downloading images test sets...\n",
            "Error downloading https://github.com/yuezunli/celeb-deepfakeforensics/raw/master/test_release.zip: 404 Client Error: Not Found for url: https://github.com/yuezunli/celeb-deepfakeforensics/raw/master/test_release.zip\n",
            "Error downloading https://dfdc-preview-test.s3.amazonaws.com/dfdc_test_set.zip: 404 Client Error: Not Found for url: https://dfdc-preview-test.s3.amazonaws.com/dfdc_test_set.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)'))': /api/get/test_sample.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading https://github.com/ondyari/FaceForensics/raw/master/dataset/test_set.zip: 404 Client Error: Not Found for url: https://github.com/ondyari/FaceForensics/raw/master/dataset/test_set.zip\n",
            "\n",
            "Downloading videos test sets...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)'))': /api/get/test_sample.zip\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)'))': /api/get/test_sample.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading https://dfdc.ai/api/get/test_sample.zip: HTTPSConnectionPool(host='dfdc.ai', port=443): Max retries exceeded with url: /api/get/test_sample.zip (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)')))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7e4d315061d0>: Failed to resolve 'fakeavceleb.com' ([Errno -2] Name or service not known)\")': /download/test_set.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading https://github.com/EndlessSora/DeeperForensics-1.0/raw/master/test.zip: 404 Client Error: Not Found for url: https://github.com/EndlessSora/DeeperForensics-1.0/raw/master/test.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7e4d31507b90>: Failed to resolve 'fakeavceleb.com' ([Errno -2] Name or service not known)\")': /download/test_set.zip\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7e4d31519550>: Failed to resolve 'fakeavceleb.com' ([Errno -2] Name or service not known)\")': /download/test_set.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading https://fakeavceleb.com/download/test_set.zip: HTTPSConnectionPool(host='fakeavceleb.com', port=443): Max retries exceeded with url: /download/test_set.zip (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7e4d31507710>: Failed to resolve 'fakeavceleb.com' ([Errno -2] Name or service not known)\"))\n",
            "\n",
            "Downloading audio test sets...\n",
            "Error downloading https://datashare.ed.ac.uk/bitstream/handle/10283/3336/LA_test.zip: 404 Client Error: 404 for url: https://datashare.ed.ac.uk/bitstream/handle/10283/3336/LA_test.zip\n",
            "Error downloading https://github.com/fakevoice/dataset/raw/main/test_set.zip: 404 Client Error: Not Found for url: https://github.com/fakevoice/dataset/raw/main/test_set.zip\n",
            "\n",
            "DeepFake Test Data Download Summary\n",
            "===================================\n",
            "\n",
            "Images: 0 test sets\n",
            "Videos: 0 test sets\n",
            "Audio: 0 test sets\n",
            "\n",
            "Total test sets downloaded: 0\n",
            "Storage location: deepfake_test_data\n"
          ]
        }
      ]
    }
  ]
}