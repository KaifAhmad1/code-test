{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Deepfake_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Deepfake and Manipulated Media Analysis Data Download**"
      ],
      "metadata": {
        "id": "V5er949VRqvP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3adQdF8KJWyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dbe1e83-2f6a-476b-9eb1-8b7d677f52dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.1/464.1 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "langchain 0.3.16 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.2 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.2 which is incompatible.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.2.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.2 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install required dependencies\n",
        "%pip install -qU soundfile numpy datasets pandas pillow tqdm huggingface_hub decord"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import decord\n",
        "from decord import VideoReader\n",
        "import hashlib\n",
        "import requests\n",
        "from PIL import Image\n",
        "import warnings\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import gdown\n",
        "import json"
      ],
      "metadata": {
        "id": "E5SKXUPiJobX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "pxb5lV48LQyB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepfakeMediaCollector:\n",
        "    def __init__(self, base_dir: str = \"./deepfake_dataset\", max_samples: int = 20):\n",
        "        self.base_dir = Path(base_dir)\n",
        "        self.max_samples = max_samples\n",
        "        self.metadata = []\n",
        "        self.temp_dir = self.base_dir / \"temp\"\n",
        "        self.base_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.temp_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def download_from_gdrive(self, file_id: str, output_path: Path) -> bool:\n",
        "        \"\"\"Download file from Google Drive\"\"\"\n",
        "        try:\n",
        "            url = f'https://drive.google.com/uc?id={file_id}'\n",
        "            return gdown.download(url, str(output_path), quiet=False)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to download from Google Drive: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def download_from_url(self, url: str, output_path: Path) -> bool:\n",
        "        \"\"\"Download file from direct URL\"\"\"\n",
        "        try:\n",
        "            response = requests.get(url, stream=True)\n",
        "            response.raise_for_status()\n",
        "            total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "            with open(output_path, 'wb') as f, tqdm(\n",
        "                desc=output_path.name,\n",
        "                total=total_size,\n",
        "                unit='iB',\n",
        "                unit_scale=True\n",
        "            ) as pbar:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    size = f.write(chunk)\n",
        "                    pbar.update(size)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to download from URL: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def download_dfdc_sample(self):\n",
        "        \"\"\"Download sample from DeepFake Detection Challenge dataset\"\"\"\n",
        "        logger.info(\"Downloading DFDC sample videos...\")\n",
        "\n",
        "        # Sample videos from DFDC preview set\n",
        "        samples = {\n",
        "            'real': 'https://github.com/ondyari/FaceForensics/raw/master/example_videos/original.mp4',\n",
        "            'fake': 'https://github.com/ondyari/FaceForensics/raw/master/example_videos/manipulated.mp4'\n",
        "        }\n",
        "\n",
        "        for category, url in samples.items():\n",
        "            save_dir = self.base_dir / 'video' / category\n",
        "            save_dir.mkdir(parents=True, exist_ok=True)\n",
        "            output_path = save_dir / f'dfdc_{category}_sample.mp4'\n",
        "\n",
        "            if self.download_from_url(url, output_path):\n",
        "                if self.validate_media_file(output_path, 'video'):\n",
        "                    self.metadata.append({\n",
        "                        'modality': 'video',\n",
        "                        'category': category,\n",
        "                        'filename': output_path.name,\n",
        "                        'file_path': str(output_path),\n",
        "                        'source': 'DFDC',\n",
        "                        'manipulation': 'None' if category == 'real' else 'face_swap'\n",
        "                    })\n",
        "\n",
        "    def download_celeba_sample(self):\n",
        "        \"\"\"Download sample from CelebA dataset\"\"\"\n",
        "        logger.info(\"Downloading CelebA sample images...\")\n",
        "\n",
        "        # Sample images from CelebA\n",
        "        base_url = \"https://mmlab.ie.cuhk.edu.hk/projects/CelebA/images\"\n",
        "        samples = {\n",
        "            'real': [f\"{base_url}/000001.jpg\", f\"{base_url}/000002.jpg\"],\n",
        "            'fake': []  # We'll generate manipulated versions\n",
        "        }\n",
        "\n",
        "        for category, urls in samples.items():\n",
        "            save_dir = self.base_dir / 'image' / category\n",
        "            save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            for idx, url in enumerate(urls):\n",
        "                output_path = save_dir / f'celeba_{category}_{idx:03d}.jpg'\n",
        "\n",
        "                if self.download_from_url(url, output_path):\n",
        "                    if self.validate_media_file(output_path, 'image'):\n",
        "                        self.metadata.append({\n",
        "                            'modality': 'image',\n",
        "                            'category': category,\n",
        "                            'filename': output_path.name,\n",
        "                            'file_path': str(output_path),\n",
        "                            'source': 'CelebA',\n",
        "                            'manipulation': 'None'\n",
        "                        })\n",
        "\n",
        "    def download_audio_deepfake_sample(self):\n",
        "        \"\"\"Download sample from Audio Deepfake Dataset\"\"\"\n",
        "        logger.info(\"Downloading Audio Deepfake samples...\")\n",
        "\n",
        "        # Sample audio files (using Mozilla Common Voice samples for real)\n",
        "        samples = {\n",
        "            'real': 'https://github.com/mozilla/DeepSpeech/raw/master/data/smoke_test/smoke_test.wav',\n",
        "            'fake': 'https://github.com/mozilla/DeepSpeech/raw/master/data/smoke_test/smoke_test_filtered.wav'\n",
        "        }\n",
        "\n",
        "        for category, url in samples.items():\n",
        "            save_dir = self.base_dir / 'audio' / category\n",
        "            save_dir.mkdir(parents=True, exist_ok=True)\n",
        "            output_path = save_dir / f'audio_{category}_sample.wav'\n",
        "\n",
        "            if self.download_from_url(url, output_path):\n",
        "                if self.validate_media_file(output_path, 'audio'):\n",
        "                    self.metadata.append({\n",
        "                        'modality': 'audio',\n",
        "                        'category': category,\n",
        "                        'filename': output_path.name,\n",
        "                        'file_path': str(output_path),\n",
        "                        'source': 'AudioDeepfake',\n",
        "                        'manipulation': 'None' if category == 'real' else 'voice_conversion'\n",
        "                    })\n",
        "\n",
        "    def validate_media_file(self, file_path: Path, media_type: str) -> bool:\n",
        "        try:\n",
        "            if not file_path.exists():\n",
        "                return False\n",
        "\n",
        "            if media_type == 'video':\n",
        "                try:\n",
        "                    with VideoReader(str(file_path)) as vr:\n",
        "                        return vr[0] is not None\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Video validation failed: {str(e)}\")\n",
        "                    return False\n",
        "\n",
        "            elif media_type == 'image':\n",
        "                try:\n",
        "                    with Image.open(file_path) as img:\n",
        "                        img.verify()\n",
        "                    return True\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Image validation failed: {str(e)}\")\n",
        "                    return False\n",
        "\n",
        "            elif media_type == 'audio':\n",
        "                try:\n",
        "                    data, samplerate = sf.read(file_path)\n",
        "                    return len(data) > 0 and samplerate > 0\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Audio validation failed: {str(e)}\")\n",
        "                    return False\n",
        "\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Validation failed for {file_path}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def save_metadata(self) -> None:\n",
        "        if self.metadata:\n",
        "            metadata_path = self.base_dir / \"metadata.csv\"\n",
        "            pd.DataFrame(self.metadata).to_csv(metadata_path, index=False)\n",
        "            logger.info(f\"Metadata saved to {metadata_path}\")\n",
        "\n",
        "            # Save a summary\n",
        "            summary = pd.DataFrame(self.metadata).groupby(['modality', 'category']).size()\n",
        "            summary_path = self.base_dir / \"summary.txt\"\n",
        "            with open(summary_path, 'w') as f:\n",
        "                f.write(\"Dataset Summary:\\n\\n\")\n",
        "                f.write(str(summary))\n",
        "        else:\n",
        "            logger.warning(\"No metadata to save\")\n",
        "\n",
        "    def cleanup(self):\n",
        "        \"\"\"Clean up temporary files\"\"\"\n",
        "        if self.temp_dir.exists():\n",
        "            shutil.rmtree(self.temp_dir)\n",
        "            logger.info(\"Cleaned up temporary files\")\n",
        "\n",
        "def main():\n",
        "    # Initialize collector\n",
        "    collector = DeepfakeMediaCollector(\n",
        "        base_dir=\"./deepfake_dataset\",\n",
        "        max_samples=20\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Download samples from different sources\n",
        "        collector.download_dfdc_sample()\n",
        "        collector.download_celeba_sample()\n",
        "        collector.download_audio_deepfake_sample()\n",
        "\n",
        "        # Save metadata and summary\n",
        "        collector.save_metadata()\n",
        "\n",
        "    finally:\n",
        "        # Clean up temporary files\n",
        "        collector.cleanup()"
      ],
      "metadata": {
        "id": "v8dnHHHBYRQo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "o-JlIK1KUdP0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "c66dfdeb-4f0d-4876-947b-81d16b6d6b7b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Failed to download from URL: 404 Client Error: Not Found for url: https://github.com/ondyari/FaceForensics/raw/master/example_videos/original.mp4\n",
            "ERROR:__main__:Failed to download from URL: 404 Client Error: Not Found for url: https://github.com/ondyari/FaceForensics/raw/master/example_videos/manipulated.mp4\n",
            "ERROR:__main__:Failed to download from URL: 404 Client Error: Not Found for url: https://mmlab.ie.cuhk.edu.hk/projects/CelebA/images/000001.jpg\n",
            "ERROR:__main__:Failed to download from URL: 404 Client Error: Not Found for url: https://mmlab.ie.cuhk.edu.hk/projects/CelebA/images/000002.jpg\n",
            "ERROR:__main__:Failed to download from URL: 404 Client Error: Not Found for url: https://github.com/mozilla/DeepSpeech/raw/master/data/smoke_test/smoke_test.wav\n",
            "ERROR:__main__:Failed to download from URL: 404 Client Error: Not Found for url: https://github.com/mozilla/DeepSpeech/raw/master/data/smoke_test/smoke_test_filtered.wav\n",
            "WARNING:__main__:No metadata to save\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'shutil' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-972361fa1b80>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-2ad97575ec6e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# Clean up temporary files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mcollector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-2ad97575ec6e>\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;34m\"\"\"Clean up temporary files\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cleaned up temporary files\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shutil' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iw1aBSV6NLMo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}