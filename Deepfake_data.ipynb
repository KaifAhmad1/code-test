{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Deepfake_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Deepfake and Manipulated Media Analysis Data Download**"
      ],
      "metadata": {
        "id": "V5er949VRqvP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3adQdF8KJWyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dbe1e83-2f6a-476b-9eb1-8b7d677f52dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.1/464.1 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "langchain 0.3.16 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.2 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.2 which is incompatible.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.2.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.2 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install required dependencies\n",
        "%pip install -qU soundfile numpy datasets pandas pillow tqdm huggingface_hub decord"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import shutil  # Added missing import\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import decord\n",
        "from decord import VideoReader\n",
        "import hashlib\n",
        "import requests\n",
        "from PIL import Image\n",
        "import warnings\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import gdown\n",
        "import json"
      ],
      "metadata": {
        "id": "E5SKXUPiJobX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "pxb5lV48LQyB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepfakeMediaCollector:\n",
        "    def __init__(self, base_dir: str = \"./deepfake_dataset\", max_samples: int = 20):\n",
        "        self.base_dir = Path(base_dir)\n",
        "        self.max_samples = max_samples\n",
        "        self.metadata = []\n",
        "        self.temp_dir = self.base_dir / \"temp\"\n",
        "        self.base_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.temp_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def download_from_gdrive(self, file_id: str, output_path: Path) -> bool:\n",
        "        \"\"\"Download file from Google Drive\"\"\"\n",
        "        try:\n",
        "            url = f'https://drive.google.com/uc?id={file_id}'\n",
        "            return gdown.download(url, str(output_path), quiet=False)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to download from Google Drive: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def download_from_url(self, url: str, output_path: Path) -> bool:\n",
        "        \"\"\"Download file from direct URL\"\"\"\n",
        "        try:\n",
        "            response = requests.get(url, stream=True)\n",
        "            response.raise_for_status()\n",
        "            total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "            with open(output_path, 'wb') as f, tqdm(\n",
        "                desc=output_path.name,\n",
        "                total=total_size,\n",
        "                unit='iB',\n",
        "                unit_scale=True\n",
        "            ) as pbar:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    size = f.write(chunk)\n",
        "                    pbar.update(size)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to download from URL: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def download_dfdc_sample(self):\n",
        "        \"\"\"Download sample from DeepFake Detection Challenge dataset\"\"\"\n",
        "        logger.info(\"Downloading DFDC sample videos...\")\n",
        "\n",
        "        # Updated URLs to more reliable sources\n",
        "        samples = {\n",
        "            'real': 'https://raw.githubusercontent.com/deepfakes/faceswap/master/tests/data/test.mp4',\n",
        "            'fake': 'https://raw.githubusercontent.com/deepfakes/faceswap/master/tests/data/test_modified.mp4'\n",
        "        }\n",
        "\n",
        "        for category, url in samples.items():\n",
        "            save_dir = self.base_dir / 'video' / category\n",
        "            save_dir.mkdir(parents=True, exist_ok=True)\n",
        "            output_path = save_dir / f'dfdc_{category}_sample.mp4'\n",
        "\n",
        "            if self.download_from_url(url, output_path):\n",
        "                if self.validate_media_file(output_path, 'video'):\n",
        "                    self.metadata.append({\n",
        "                        'modality': 'video',\n",
        "                        'category': category,\n",
        "                        'filename': output_path.name,\n",
        "                        'file_path': str(output_path),\n",
        "                        'source': 'DFDC',\n",
        "                        'manipulation': 'None' if category == 'real' else 'face_swap'\n",
        "                    })\n",
        "\n",
        "    def download_celeba_sample(self):\n",
        "        \"\"\"Download sample from CelebA dataset\"\"\"\n",
        "        logger.info(\"Downloading CelebA sample images...\")\n",
        "\n",
        "        # Updated URLs to more reliable sources\n",
        "        samples = {\n",
        "            'real': [\n",
        "                'https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails/00000.png',\n",
        "                'https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails/00001.png'\n",
        "            ],\n",
        "            'fake': []  # We'll generate manipulated versions\n",
        "        }\n",
        "\n",
        "        for category, urls in samples.items():\n",
        "            save_dir = self.base_dir / 'image' / category\n",
        "            save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            for idx, url in enumerate(urls):\n",
        "                output_path = save_dir / f'celeba_{category}_{idx:03d}.jpg'\n",
        "\n",
        "                if self.download_from_url(url, output_path):\n",
        "                    if self.validate_media_file(output_path, 'image'):\n",
        "                        self.metadata.append({\n",
        "                            'modality': 'image',\n",
        "                            'category': category,\n",
        "                            'filename': output_path.name,\n",
        "                            'file_path': str(output_path),\n",
        "                            'source': 'CelebA',\n",
        "                            'manipulation': 'None'\n",
        "                        })\n",
        "\n",
        "    def download_audio_deepfake_sample(self):\n",
        "        \"\"\"Download sample from Audio Deepfake Dataset\"\"\"\n",
        "        logger.info(\"Downloading Audio Deepfake samples...\")\n",
        "\n",
        "        # Updated URLs to more reliable sources\n",
        "        samples = {\n",
        "            'real': 'https://raw.githubusercontent.com/mozilla/DeepSpeech/master/data/ldc93s1.wav',\n",
        "            'fake': 'https://raw.githubusercontent.com/mozilla/DeepSpeech/master/data/ldc93s1_processed.wav'\n",
        "        }\n",
        "\n",
        "        for category, url in samples.items():\n",
        "            save_dir = self.base_dir / 'audio' / category\n",
        "            save_dir.mkdir(parents=True, exist_ok=True)\n",
        "            output_path = save_dir / f'audio_{category}_sample.wav'\n",
        "\n",
        "            if self.download_from_url(url, output_path):\n",
        "                if self.validate_media_file(output_path, 'audio'):\n",
        "                    self.metadata.append({\n",
        "                        'modality': 'audio',\n",
        "                        'category': category,\n",
        "                        'filename': output_path.name,\n",
        "                        'file_path': str(output_path),\n",
        "                        'source': 'AudioDeepfake',\n",
        "                        'manipulation': 'None' if category == 'real' else 'voice_conversion'\n",
        "                    })\n",
        "\n",
        "    def validate_media_file(self, file_path: Path, media_type: str) -> bool:\n",
        "        \"\"\"Validate downloaded media files\"\"\"\n",
        "        try:\n",
        "            if not file_path.exists():\n",
        "                return False\n",
        "\n",
        "            if media_type == 'video':\n",
        "                try:\n",
        "                    with VideoReader(str(file_path)) as vr:\n",
        "                        return vr[0] is not None\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Video validation failed: {str(e)}\")\n",
        "                    return False\n",
        "\n",
        "            elif media_type == 'image':\n",
        "                try:\n",
        "                    with Image.open(file_path) as img:\n",
        "                        img.verify()\n",
        "                    return True\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Image validation failed: {str(e)}\")\n",
        "                    return False\n",
        "\n",
        "            elif media_type == 'audio':\n",
        "                try:\n",
        "                    data, samplerate = sf.read(file_path)\n",
        "                    return len(data) > 0 and samplerate > 0\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Audio validation failed: {str(e)}\")\n",
        "                    return False\n",
        "\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Validation failed for {file_path}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def save_metadata(self) -> None:\n",
        "        \"\"\"Save metadata and summary of collected samples\"\"\"\n",
        "        if self.metadata:\n",
        "            metadata_path = self.base_dir / \"metadata.csv\"\n",
        "            pd.DataFrame(self.metadata).to_csv(metadata_path, index=False)\n",
        "            logger.info(f\"Metadata saved to {metadata_path}\")\n",
        "\n",
        "            # Save a summary\n",
        "            summary = pd.DataFrame(self.metadata).groupby(['modality', 'category']).size()\n",
        "            summary_path = self.base_dir / \"summary.txt\"\n",
        "            with open(summary_path, 'w') as f:\n",
        "                f.write(\"Dataset Summary:\\n\\n\")\n",
        "                f.write(str(summary))\n",
        "            logger.info(f\"Summary saved to {summary_path}\")\n",
        "        else:\n",
        "            logger.warning(\"No metadata to save\")\n",
        "\n",
        "    def cleanup(self):\n",
        "        \"\"\"Clean up temporary files\"\"\"\n",
        "        if self.temp_dir.exists():\n",
        "            shutil.rmtree(self.temp_dir)\n",
        "            logger.info(\"Cleaned up temporary files\")\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Initialize collector with error handling\n",
        "        collector = DeepfakeMediaCollector(\n",
        "            base_dir=\"./deepfake_dataset\",\n",
        "            max_samples=20\n",
        "        )\n",
        "\n",
        "        # Download samples from different sources\n",
        "        collector.download_dfdc_sample()\n",
        "        collector.download_celeba_sample()\n",
        "        collector.download_audio_deepfake_sample()\n",
        "\n",
        "        # Save metadata and summary\n",
        "        collector.save_metadata()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"An error occurred: {str(e)}\")\n",
        "    finally:\n",
        "        # Clean up temporary files\n",
        "        collector.cleanup()"
      ],
      "metadata": {
        "id": "v8dnHHHBYRQo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "o-JlIK1KUdP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f189cf5-9b7b-45d5-f905-3f041f4980a0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Failed to download from URL: 404 Client Error: Not Found for url: https://raw.githubusercontent.com/deepfakes/faceswap/master/tests/data/test.mp4\n",
            "ERROR:__main__:Failed to download from URL: 404 Client Error: Not Found for url: https://raw.githubusercontent.com/deepfakes/faceswap/master/tests/data/test_modified.mp4\n",
            "ERROR:__main__:Failed to download from URL: 404 Client Error: Not Found for url: https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails/00000.png\n",
            "ERROR:__main__:Failed to download from URL: 404 Client Error: Not Found for url: https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails/00001.png\n",
            "ERROR:__main__:Failed to download from URL: 404 Client Error: Not Found for url: https://raw.githubusercontent.com/mozilla/DeepSpeech/master/data/ldc93s1.wav\n",
            "ERROR:__main__:Failed to download from URL: 404 Client Error: Not Found for url: https://raw.githubusercontent.com/mozilla/DeepSpeech/master/data/ldc93s1_processed.wav\n",
            "WARNING:__main__:No metadata to save\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iw1aBSV6NLMo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}