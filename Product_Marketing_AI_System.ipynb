{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPRFu7lCICx/1EEZ9qg5p7i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Product_Marketing_AI_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Product Marketing AI System\n",
        "\n",
        "\n",
        "## Overview\n",
        "This system helps create high-quality marketing images automatically. It takes in photos and optional audio or video, then processes, refines, and enhances them to produce beautiful marketing visuals for many different industries.\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- **Easy Input:** Upload main and supplementary images, plus optional multimedia for extra context.\n",
        "- **Smart Processing:** The system automatically cuts out key parts, improves image details, and boosts overall clarity.\n",
        "- **Creative Prompts:** Custom prompts are generated to guide the image creation process, making it tailored to your needs.\n",
        "- **Fast Generation:** Uses multiple AI models working together to generate and improve images quickly.\n",
        "- **Quality Check:** Compares final images to the originals and provides simple quality feedback.\n",
        "- **Simple Reports:** Automatically produces a brief report with the final prompt and quality scores.\n",
        "\n",
        "## Benefits\n",
        "- Saves time by automating the creation of professional marketing images.\n",
        "- Provides consistent and attractive visuals optimized for your business.\n",
        "- Easy to use with straightforward input and clear feedback.\n",
        "\n",
        "Enjoy a seamless experience in making your marketing visuals stand out!"
      ],
      "metadata": {
        "id": "Y8kVOa8p2KCW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UNuaT-u16cA",
        "outputId": "2e377ca9-d43e-4a8e-ad8c-5429b6ed86d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement base64 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for base64\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -q torch transformers diffusers opencv-python langchain langchain-huggingface tenacity numpy matplotlib base64 scikit-image\n",
        "!pip install -qU langchain-google-genai groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export GROQ_API_KEY=\"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\"\n",
        "!export GOOGLE_API_KEY=\"AIzaSyBtxgbJXvlkl6Xz5AWwlVIj0UuWcraXZ5M\""
      ],
      "metadata": {
        "id": "XmI8Vvove-ni"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import base64\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
        "from groq import Groq\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from google.ai.generativelanguage_v1beta.types import Tool as GenAITool\n",
        "import io\n",
        "import sys\n",
        "\n",
        "# Detect environment\n",
        "try:\n",
        "    from google.colab import files\n",
        "    ENV = \"colab\"\n",
        "except ImportError:\n",
        "    try:\n",
        "        from IPython.display import FileUpload\n",
        "        ENV = \"jupyter\"\n",
        "    except ImportError:\n",
        "        import tkinter as tk\n",
        "        from tkinter import filedialog\n",
        "        ENV = \"standalone\"\n",
        "\n",
        "# Setup environment\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "os.makedirs(\"uploads\", exist_ok=True)\n",
        "OUTPUT_DIR = \"outputs\"\n",
        "UPLOAD_DIR = \"uploads\"\n",
        "\n",
        "# Check CUDA availability\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize Stable Diffusion with ControlNet\n",
        "try:\n",
        "    controlnet = ControlNetModel.from_pretrained(\n",
        "        \"lllyasviel/control_v11p_sd15_seg\",\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True\n",
        "    ).to(device)\n",
        "    sd_pipeline = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        controlnet=controlnet,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True\n",
        "    ).to(device)\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing Stable Diffusion pipeline: {e}\")\n",
        "    sd_pipeline = None\n",
        "\n",
        "# Initialize Groq client\n",
        "groq_client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\", \"your_groq_api_key\"))\n",
        "\n",
        "# Initialize Google Gemini for image generation and context analysis\n",
        "try:\n",
        "    gemini_llm = ChatGoogleGenerativeAI(\n",
        "        model=\"models/gemini-2.0-flash-exp-image-generation\",\n",
        "        temperature=0.7,\n",
        "        max_retries=2\n",
        "    )\n",
        "    gemini_context = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        temperature=0\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing Gemini models: {e}\")\n",
        "    gemini_llm = None\n",
        "    gemini_context = None"
      ],
      "metadata": {
        "id": "GunSNk1M5HG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define structured output for prompt\n",
        "class MarketingPrompt(BaseModel):\n",
        "    \"\"\"Structured marketing prompt.\"\"\"\n",
        "    product: str = Field(description=\"The product to feature\")\n",
        "    setting: str = Field(description=\"The background or scene\")\n",
        "    style: str = Field(description=\"The aesthetic style\")\n",
        "    lighting: str = Field(description=\"The lighting condition\")\n",
        "    caption: str = Field(description=\"A catchy caption\")"
      ],
      "metadata": {
        "id": "N-5zwJuI7CvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Input Collection with File Upload\n",
        "def collect_inputs():\n",
        "    try:\n",
        "        # Image upload\n",
        "        def upload_image(prompt):\n",
        "            print(prompt)\n",
        "            if ENV == \"colab\":\n",
        "                uploaded = files.upload()\n",
        "                if not uploaded:\n",
        "                    raise ValueError(\"No file uploaded\")\n",
        "                filename = list(uploaded.keys())[0]\n",
        "                file_path = os.path.join(UPLOAD_DIR, filename)\n",
        "                with open(file_path, \"wb\") as f:\n",
        "                    f.write(uploaded[filename])\n",
        "                return file_path\n",
        "            elif ENV == \"jupyter\":\n",
        "                from IPython.display import display\n",
        "                uploader = FileUpload(accept=\".jpg,.png,.jpeg\", multiple=False)\n",
        "                display(uploader)\n",
        "                input(\"Press Enter after uploading the file...\")\n",
        "                if not uploader.value:\n",
        "                    raise ValueError(\"No file uploaded\")\n",
        "                filename = list(uploader.value.keys())[0]\n",
        "                file_path = os.path.join(UPLOAD_DIR, filename)\n",
        "                with open(file_path, \"wb\") as f:\n",
        "                    f.write(uploader.value[filename][\"content\"])\n",
        "                return file_path\n",
        "            else:  # standalone\n",
        "                root = tk.Tk()\n",
        "                root.withdraw()\n",
        "                file_path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg *.png *.jpeg\")])\n",
        "                if not file_path:\n",
        "                    raise ValueError(\"No file selected\")\n",
        "                dest_path = os.path.join(UPLOAD_DIR, os.path.basename(file_path))\n",
        "                with open(file_path, \"rb\") as src, open(dest_path, \"wb\") as dst:\n",
        "                    dst.write(src.read())\n",
        "                return dest_path\n",
        "\n",
        "        base_image_path = upload_image(\"Upload base image (e.g., background.jpg):\")\n",
        "        base_image = cv2.imread(base_image_path)\n",
        "        if base_image is None:\n",
        "            raise ValueError(\"Failed to load base image\")\n",
        "        base_image_rgb = cv2.cvtColor(base_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        secondary_image_path = upload_image(\"Upload secondary image (e.g., product.jpg):\")\n",
        "        secondary_image = cv2.imread(secondary_image_path)\n",
        "        if secondary_image is None:\n",
        "            raise ValueError(\"Failed to load secondary image\")\n",
        "        secondary_image_rgb = cv2.cvtColor(secondary_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Prompt upload\n",
        "        domain = None\n",
        "        initial_prompt = None\n",
        "        print(\"Upload a prompt file (prompt.txt) or press Enter to input manually:\")\n",
        "        if ENV == \"colab\":\n",
        "            uploaded = files.upload()\n",
        "            if uploaded:\n",
        "                filename = list(uploaded.keys())[0]\n",
        "                file_path = os.path.join(UPLOAD_DIR, filename)\n",
        "                with open(file_path, \"wb\") as f:\n",
        "                    f.write(uploaded[filename])\n",
        "                with open(file_path, \"r\") as f:\n",
        "                    lines = f.readlines()\n",
        "                    for line in lines:\n",
        "                        if line.startswith(\"domain:\"):\n",
        "                            domain = line.split(\":\")[1].strip().lower()\n",
        "                        elif line.startswith(\"prompt:\"):\n",
        "                            initial_prompt = line.split(\":\")[1].strip()\n",
        "        elif ENV == \"jupyter\":\n",
        "            uploader = FileUpload(accept=\".txt\", multiple=False)\n",
        "            display(uploader)\n",
        "            input(\"Press Enter after uploading the prompt file or to skip...\")\n",
        "            if uploader.value:\n",
        "                filename = list(uploader.value.keys())[0]\n",
        "                file_path = os.path.join(UPLOAD_DIR, filename)\n",
        "                with open(file_path, \"wb\") as f:\n",
        "                    f.write(uploader.value[filename][\"content\"])\n",
        "                with open(file_path, \"r\") as f:\n",
        "                    lines = f.readlines()\n",
        "                    for line in lines:\n",
        "                        if line.startswith(\"domain:\"):\n",
        "                            domain = line.split(\":\")[1].strip().lower()\n",
        "                        elif line.startswith(\"prompt:\"):\n",
        "                            initial_prompt = line.split(\":\")[1].strip()\n",
        "        else:  # standalone\n",
        "            root = tk.Tk()\n",
        "            root.withdraw()\n",
        "            file_path = filedialog.askopenfilename(filetypes=[(\"Text files\", \"*.txt\")])\n",
        "            if file_path:\n",
        "                dest_path = os.path.join(UPLOAD_DIR, os.path.basename(file_path))\n",
        "                with open(file_path, \"rb\") as src, open(dest_path, \"wb\") as dst:\n",
        "                    dst.write(src.read())\n",
        "                with open(dest_path, \"r\") as f:\n",
        "                    lines = f.readlines()\n",
        "                    for line in lines:\n",
        "                        if line.startswith(\"domain:\"):\n",
        "                            domain = line.split(\":\")[1].strip().lower()\n",
        "                        elif line.startswith(\"prompt:\"):\n",
        "                            initial_prompt = line.split(\":\")[1].strip()\n",
        "\n",
        "        # Fallback to manual input\n",
        "        if not domain:\n",
        "            domain = input(\"Enter domain (e.g., clothing, food, electronics): \").lower()\n",
        "        if not initial_prompt:\n",
        "            initial_prompt = input(\"Enter initial prompt (e.g., 'Jacket on model, urban rooftop, modern vibe'): \")\n",
        "\n",
        "        return base_image_rgb, secondary_image_rgb, domain, initial_prompt\n",
        "    except Exception as e:\n",
        "        print(f\"Error collecting inputs: {e}\")\n",
        "        return None, None, None, None"
      ],
      "metadata": {
        "id": "px73_3ml7Cxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocess Images with Gemini\n",
        "def preprocess_images(base_image, secondary_image):\n",
        "    try:\n",
        "        # Normalize images to 512x512\n",
        "        def normalize(image, size=(512, 512)):\n",
        "            image = cv2.resize(image, size)\n",
        "            image = cv2.convertScaleAbs(image, alpha=1.1, beta=10)\n",
        "            return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        base_norm = normalize(base_image)\n",
        "        secondary_norm = normalize(secondary_image)\n",
        "        cv2.imwrite(os.path.join(OUTPUT_DIR, \"base_normalized.png\"), base_norm)\n",
        "        cv2.imwrite(os.path.join(OUTPUT_DIR, \"secondary_normalized.png\"), secondary_norm)\n",
        "\n",
        "        # Generate segmentation mask using Gemini\n",
        "        mask = None\n",
        "        if gemini_context:\n",
        "            _, buffer = cv2.imencode('.jpg', secondary_image)\n",
        "            secondary_b64 = base64.b64encode(buffer).decode('utf-8')\n",
        "            message = HumanMessage(content=[\n",
        "                {\"type\": \"text\", \"text\": \"Generate a binary segmentation mask for the main object in this image.\"},\n",
        "                {\"type\": \"image_url\", \"image_url\": f\"data:image/jpeg;base64,{secondary_b64}\"}\n",
        "            ])\n",
        "            response = gemini_context.invoke([message])\n",
        "            # Assume response contains a base64-encoded mask (simplified; adjust based on actual output)\n",
        "            try:\n",
        "                mask_b64 = response.content.split(',')[-1] if 'base64' in response.content else None\n",
        "                if mask_b64:\n",
        "                    mask_data = base64.b64decode(mask_b64)\n",
        "                    mask = cv2.imdecode(np.frombuffer(mask_data, np.uint8), cv2.IMREAD_GRAYSCALE)\n",
        "                    if mask.shape[:2] != base_norm.shape[:2]:\n",
        "                        mask = cv2.resize(mask, (base_norm.shape[1], base_norm.shape[0]))\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # Fallback to dummy mask if Gemini fails\n",
        "        if mask is None:\n",
        "            h, w = base_norm.shape[:2]\n",
        "            mask = np.ones((h, w), dtype=np.uint8) * 255\n",
        "        cv2.imwrite(os.path.join(OUTPUT_DIR, \"mask.png\"), mask)\n",
        "\n",
        "        return mask, base_norm, secondary_norm\n",
        "    except Exception as e:\n",
        "        print(f\"Error in preprocessing images: {e}\")\n",
        "        return None, None, None"
      ],
      "metadata": {
        "id": "ZESR9d-K7Czz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Context Analysis with Gemini\n",
        "def analyze_context(base_image, domain):\n",
        "    if not gemini_context:\n",
        "        return \"studio\", \"natural\", \"\"\n",
        "\n",
        "    try:\n",
        "        _, buffer = cv2.imencode('.jpg', base_image)\n",
        "        base_b64 = base64.b64encode(buffer).decode('utf-8')\n",
        "        message = HumanMessage(content=[\n",
        "            {\"type\": \"text\", \"text\": f\"Describe the setting and lighting for a {domain} marketing image based on this background.\"},\n",
        "            {\"type\": \"image_url\", \"image_url\": f\"data:image/jpeg;base64,{base_b64}\"}\n",
        "        ])\n",
        "        response = gemini_context.invoke([message])\n",
        "        setting = response.content.split(' ')[0] if response.content else \"studio\"\n",
        "        lighting = response.content.split(',')[-1].strip() if ',' in response.content else \"natural\"\n",
        "\n",
        "        # Use Google Search tool for external context (e.g., weather)\n",
        "        external_context = \"\"\n",
        "        if domain in [\"travel\", \"automotive\"]:\n",
        "            llm_with_tools = gemini_context.bind_tools([GenAITool(google_search={})])\n",
        "            weather_response = llm_with_tools.invoke(f\"What's the current weather for a {domain} marketing scene?\")\n",
        "            external_context = weather_response.content if weather_response.content else \"\"\n",
        "\n",
        "        return setting, lighting, external_context\n",
        "    except Exception as e:\n",
        "        print(f\"Context analysis error: {e}\")\n",
        "        return \"studio\", \"natural\", \"\""
      ],
      "metadata": {
        "id": "4uVNXvpF7C2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Prompt Refinement with Gemini and Groq\n",
        "def refine_prompt(domain, initial_prompt, base_image, setting, lighting, external_context):\n",
        "    try:\n",
        "        # Stage 1: Structured prompt with Gemini\n",
        "        if gemini_context:\n",
        "            structured_llm = gemini_context.with_structured_output(MarketingPrompt)\n",
        "            gemini_prompt = structured_llm.invoke(\n",
        "                f\"Create a structured marketing prompt for a {domain} image based on: {initial_prompt}, setting: {setting}, lighting: {lighting}\"\n",
        "            )\n",
        "            base_prompt = (\n",
        "                f\"{gemini_prompt.product} in {gemini_prompt.setting}, {gemini_prompt.style} aesthetic, \"\n",
        "                f\"{gemini_prompt.lighting} lighting, {gemini_prompt.caption}, {external_context}\"\n",
        "            )\n",
        "        else:\n",
        "            product = initial_prompt.split(\" \")[0]\n",
        "            style = initial_prompt.split(\",\")[1].strip() if len(initial_prompt.split(\",\")) > 1 else \"modern\"\n",
        "            base_prompt = f\"{product} in {setting}, {style} aesthetic, {lighting} lighting, high-quality {domain} marketing image, {external_context}\"\n",
        "\n",
        "        # Stage 2: Refine with Groq LLaMA 3\n",
        "        response = groq_client.chat.completions.create(\n",
        "            model=\"llama3-8b-8192\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": f\"Refine this prompt for a vibrant {domain} marketing image: {base_prompt}\"}\n",
        "            ],\n",
        "            response_format={\"type\": \"json_object\"},\n",
        "            max_tokens=200,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        refined_prompt = json.loads(response.choices[0].message.content).get(\"refined_prompt\", base_prompt)\n",
        "\n",
        "        # Allow user to approve or modify\n",
        "        print(\"Refined Prompt:\", refined_prompt)\n",
        "        user_input = input(\"Approve or enter new prompt (press Enter to approve): \")\n",
        "        return user_input.strip() if user_input.strip() else refined_prompt\n",
        "    except Exception as e:\n",
        "        print(f\"Prompt refinement error: {e}\")\n",
        "        return initial_prompt"
      ],
      "metadata": {
        "id": "Du7hi6n-7C4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Prompt Refinement with Gemini and Groq\n",
        "def refine_prompt(domain, initial_prompt, base_image, setting, lighting, external_context):\n",
        "    try:\n",
        "        # Stage 1: Structured prompt with Gemini\n",
        "        if gemini_context:\n",
        "            structured_llm = gemini_context.with_structured_output(MarketingPrompt)\n",
        "            gemini_prompt = structured_llm.invoke(\n",
        "                f\"Create a structured marketing prompt for a {domain} image based on: {initial_prompt}, setting: {setting}, lighting: {lighting}\"\n",
        "            )\n",
        "            base_prompt = (\n",
        "                f\"{gemini_prompt.product} in {gemini_prompt.setting}, {gemini_prompt.style} aesthetic, \"\n",
        "                f\"{gemini_prompt.lighting} lighting, {gemini_prompt.caption}, {external_context}\"\n",
        "            )\n",
        "        else:\n",
        "            product = initial_prompt.split(\" \")[0]\n",
        "            style = initial_prompt.split(\",\")[1].strip() if len(initial_prompt.split(\",\")) > 1 else \"modern\"\n",
        "            base_prompt = f\"{product} in {setting}, {style} aesthetic, {lighting} lighting, high-quality {domain} marketing image, {external_context}\"\n",
        "\n",
        "        # Stage 2: Refine with Groq LLaMA 3\n",
        "        response = groq_client.chat.completions.create(\n",
        "            model=\"llama3-8b-8192\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": f\"Refine this prompt for a vibrant {domain} marketing image: {base_prompt}\"}\n",
        "            ],\n",
        "            response_format={\"type\": \"json_object\"},\n",
        "            max_tokens=200,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        refined_prompt = json.loads(response.choices[0].message.content).get(\"refined_prompt\", base_prompt)\n",
        "\n",
        "        # Allow user to approve or modify\n",
        "        print(\"Refined Prompt:\", refined_prompt)\n",
        "        user_input = input(\"Approve or enter new prompt (press Enter to approve): \")\n",
        "        return user_input.strip() if user_input.strip() else refined_prompt\n",
        "    except Exception as e:\n",
        "        print(f\"Prompt refinement error: {e}\")\n",
        "        return initial_prompt\n",
        "\n",
        "# Step 5: Image Generation with Gemini\n",
        "def generate_with_gemini(prompt, domain, previous_image_b64=None):\n",
        "    try:\n",
        "        if not gemini_llm:\n",
        "            raise Exception(\"Gemini model not initialized\")\n",
        "\n",
        "        message = {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": f\"Generate a high-quality {domain} marketing image: {prompt}\"}\n",
        "            ]\n",
        "        }\n",
        "        if previous_image_b64:\n",
        "            message[\"content\"].append({\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": f\"data:image/png;base64,{previous_image_b64}\"\n",
        "            })\n",
        "\n",
        "        response = gemini_llm.invoke(\n",
        "            [message],\n",
        "            generation_config=dict(response_modalities=[\"TEXT\", \"IMAGE\"])\n",
        "        )\n",
        "\n",
        "        # Extract image from response\n",
        "        image_b64 = response.content[0].get(\"image_url\", {}).get(\"url\", \"\").split(\",\")[-1]\n",
        "        if not image_b64:\n",
        "            raise ValueError(\"No image generated\")\n",
        "\n",
        "        image_data = base64.b64decode(image_b64)\n",
        "        composite = cv2.imdecode(np.frombuffer(image_data, np.uint8), cv2.IMREAD_COLOR)\n",
        "        filename = os.path.join(OUTPUT_DIR, \"gemini_composite.png\")\n",
        "        cv2.imwrite(filename, composite)\n",
        "        return composite, image_b64\n",
        "    except Exception as e:\n",
        "        print(f\"Gemini image generation error: {e}\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "roEhtPZ27C6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Fallback Image Generation with Stable Diffusion\n",
        "def generate_with_stable_diffusion(base_image, mask, prompt, domain):\n",
        "    try:\n",
        "        if sd_pipeline is None:\n",
        "            raise Exception(\"Stable Diffusion pipeline not initialized\")\n",
        "\n",
        "        mask_img = Image.fromarray(mask).convert(\"L\")\n",
        "        base_pil = Image.fromarray(base_image)\n",
        "        sd_pipeline.enable_model_cpu_offload()\n",
        "        output = sd_pipeline(\n",
        "            prompt=prompt,\n",
        "            image=base_pil,\n",
        "            controlnet_conditioning_image=mask_img,\n",
        "            num_inference_steps=20,\n",
        "            guidance_scale=7.5\n",
        "        ).images[0]\n",
        "\n",
        "        filename = os.path.join(OUTPUT_DIR, \"sd_composite.png\")\n",
        "        output.save(filename)\n",
        "        composite = cv2.imread(filename)\n",
        "        _, buffer = cv2.imencode('.png', composite)\n",
        "        image_b64 = base64.b64encode(buffer).decode('utf-8')\n",
        "        return composite, image_b64\n",
        "    except Exception as e:\n",
        "        print(f\"Stable Diffusion image generation error: {e}\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "FsFCGFbm7C8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Iterative Refinement with Gemini\n",
        "def refine_image(image_b64, domain, modification):\n",
        "    try:\n",
        "        if not gemini_llm or not image_b64:\n",
        "            raise Exception(\"Gemini model or image not available\")\n",
        "\n",
        "        message = {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": f\"For a {domain} marketing image, apply this modification: {modification}\"},\n",
        "                {\"type\": \"image_url\", \"image_url\": f\"data:image/png;base64,{image_b64}\"}\n",
        "            ]\n",
        "        }\n",
        "        response = gemini_llm.invoke(\n",
        "            [message],\n",
        "            generation_config=dict(response_modalities=[\"TEXT\", \"IMAGE\"])\n",
        "        )\n",
        "\n",
        "        new_image_b64 = response.content[0].get(\"image_url\", {}).get(\"url\", \"\").split(\",\")[-1]\n",
        "        if not new_image_b64:\n",
        "            raise ValueError(\"No refined image generated\")\n",
        "\n",
        "        image_data = base64.b64decode(new_image_b64)\n",
        "        refined_image = cv2.imdecode(np.frombuffer(image_data, np.uint8), cv2.IMREAD_COLOR)\n",
        "        filename = os.path.join(OUTPUT_DIR, \"refined_image.png\")\n",
        "        cv2.imwrite(filename, refined_image)\n",
        "        return refined_image, new_image_b64\n",
        "    except Exception as e:\n",
        "        print(f\"Image refinement error: {e}\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "QVPilX-L7DAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Quality Evaluation\n",
        "def evaluate_quality(base_image, final_image):\n",
        "    try:\n",
        "        min_dim = (min(base_image.shape[1], final_image.shape[1]),\n",
        "                   min(base_image.shape[0], final_image.shape[0]))\n",
        "        base_resized = cv2.resize(base_image, min_dim)\n",
        "        final_resized = cv2.resize(final_image, min_dim)\n",
        "        ssim_score = ssim(base_resized, final_resized, channel_axis=2)\n",
        "        psnr_score = psnr(base_resized, final_resized)\n",
        "        feedback = \"Good quality\" if ssim_score > 0.7 and psnr_score > 30 else \"Low quality, consider revising prompt or image.\"\n",
        "        return ssim_score, psnr_score, feedback\n",
        "    except Exception as e:\n",
        "        print(f\"Quality evaluation error: {e}\")\n",
        "        return 0, 0, \"Evaluation failed\""
      ],
      "metadata": {
        "id": "Ni1TjQxE7oGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Main Pipeline\n",
        "def main():\n",
        "    try:\n",
        "        # Collect inputs\n",
        "        base_image_rgb, secondary_image_rgb, domain, initial_prompt = collect_inputs()\n",
        "        if base_image_rgb is None:\n",
        "            print(\"Input collection failed, exiting.\")\n",
        "            return\n",
        "\n",
        "        # Preprocess images\n",
        "        mask, base_normalized, secondary_normalized = preprocess_images(base_image_rgb, secondary_image_rgb)\n",
        "        if mask is None:\n",
        "            print(\"Preprocessing failed, exiting.\")\n",
        "            return\n",
        "\n",
        "        # Analyze context\n",
        "        setting, lighting, external_context = analyze_context(base_image_rgb, domain)\n",
        "\n",
        "        # Refine prompt\n",
        "        final_prompt = refine_prompt(domain, initial_prompt, base_image_rgb, setting, lighting, external_context)\n",
        "        print(f\"Final Prompt: {final_prompt}\")\n",
        "\n",
        "        # Generate image with Gemini\n",
        "        composite, image_b64 = generate_with_gemini(final_prompt, domain)\n",
        "        if composite is None:\n",
        "            print(\"Falling back to Stable Diffusion...\")\n",
        "            composite, image_b64 = generate_with_stable_diffusion(base_normalized, mask, final_prompt, domain)\n",
        "        if composite is None:\n",
        "            print(\"Image generation failed, exiting.\")\n",
        "            return\n",
        "\n",
        "        # Allow iterative refinement\n",
        "        modification = input(\"Enter modification (e.g., 'Make the product bright orange') or press Enter to skip: \")\n",
        "        if modification.strip() and image_b64:\n",
        "            refined_image, new_image_b64 = refine_image(image_b64, domain, modification)\n",
        "            if refined_image is not None:\n",
        "                composite = refined_image\n",
        "                image_b64 = new_image_b64\n",
        "                cv2.imwrite(os.path.join(OUTPUT_DIR, \"final_image.png\"), composite)\n",
        "            else:\n",
        "                print(\"Refinement failed, using original composite.\")\n",
        "\n",
        "        # Evaluate and display\n",
        "        fname = os.path.join(OUTPUT_DIR, \"final_image.png\")\n",
        "        cv2.imwrite(fname, composite)\n",
        "        ssim_score, psnr_score, feedback = evaluate_quality(base_image_rgb, composite)\n",
        "        print(f\"Final Image - SSIM: {ssim_score}, PSNR: {psnr_score}, Feedback: {feedback}\")\n",
        "\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(cv2.cvtColor(composite, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(\"Final Image\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Final output saved in the 'outputs' folder.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Pipeline failed: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "zE-FZrQf7sxk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}