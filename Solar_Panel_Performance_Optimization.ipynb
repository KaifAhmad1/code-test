{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Solar_Panel_Performance_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# â˜€ï¸ Solar Panel Performance Optimization Challenge â˜€ï¸\n",
        "\n",
        "**Predicting Degradation and Failures for a Sustainable Future**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ 1. The Challenge: Maximizing Solar Energy Output\n",
        "\n",
        "Solar energy is a cornerstone of sustainable power. However, the efficiency of Photovoltaic (PV) panels can degrade over time or due to unforeseen failures. Traditional maintenance is often reactive, leading to:\n",
        "\n",
        "*   ğŸ“‰ **Energy Loss:** Suboptimal performance means less clean energy generated.\n",
        "*   ğŸ’° **Increased Costs:** Reactive repairs and downtime are expensive.\n",
        "\n",
        "**Our Mission:** To develop a sophisticated Machine Learning model that predicts `efficiency` (our target variable), enabling **predictive maintenance**. This proactive approach will help maintain peak performance and reduce operational interruptions.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Š 2. Understanding Our Data\n",
        "\n",
        "We're provided with a rich dataset containing sensor readings and panel characteristics.\n",
        "\n",
        "*   **`train.csv`**: The training ground for our model (20,000 samples, 17 features including `efficiency`).\n",
        "*   **`test.csv`**: The unseen data where we'll make our predictions (12,000 samples, 16 features).\n",
        "*   **`sample_submission.csv`**: The blueprint for our final submission file.\n",
        "\n",
        "### Key Data Features at a Glance:\n",
        "\n",
        "| Feature Category    | Column Examples                                 | Description                                                                    |\n",
        "| :------------------ | :---------------------------------------------- | :----------------------------------------------------------------------------- |\n",
        "| ğŸ†” **Identifiers**   | `id`, `string_id`                               | Unique row and panel group identifiers.                                        |\n",
        "| ğŸŒ¡ï¸ **Environmental** | `temperature`, `irradiance`, `humidity`, `cloud_coverage`, `wind_speed`, `pressure` | Ambient conditions influencing panel operation.                |\n",
        "| ğŸ› ï¸ **Panel Specifics**| `panel_age`, `maintenance_count`, `soiling_ratio`, `module_temperature`, `error_code`, `installation_type` | Panel history, condition, and setup.                               |\n",
        "| âš¡ **Electrical**   | `voltage`, `current`                            | Measured electrical output.                                                    |\n",
        "| ğŸ† **Target**        | **`efficiency`**                                | **The crucial variable we need to predict!** (0.0 - 1.0 scale)             |\n",
        "\n",
        "*A detailed description of each column is available in the problem statement.*\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš€ 3. Our Game Plan: Building a Winning Model\n",
        "\n",
        "We'll follow a structured, iterative approach to tackle this prediction task:\n",
        "\n",
        "1.  **âš™ï¸ Initial Setup & Environment Configuration:**\n",
        "    *   Importing essential Python libraries (Pandas, NumPy, Scikit-learn, LightGBM, XGBoost, Plotly, Optuna).\n",
        "    *   Loading the datasets into our workspace.\n",
        "\n",
        "2.  **ğŸ” Exploratory Data Analysis (EDA) - Unveiling Insights:**\n",
        "    *   Deep dive into data distributions, missing values, and potential outliers.\n",
        "    *   Visualizing feature relationships and their correlation with `efficiency` using:\n",
        "        *   **Matplotlib & Seaborn:** For static, foundational plots.\n",
        "        *   **Plotly:** For dynamic, interactive visualizations to uncover subtle patterns.\n",
        "\n",
        "3.  **âœ¨ Feature Engineering - Crafting Predictive Power:**\n",
        "    *   Creating new, informative features from existing ones (e.g., interaction terms like `temperature * irradiance`, ratios like `module_temperature - temperature`). The goal is to provide the model with richer signals.\n",
        "\n",
        "4.  **ğŸ§¹ Data Preprocessing - Preparing for Modeling:**\n",
        "    *   **Missing Value Imputation:** Strategically filling in any data gaps.\n",
        "    *   **Categorical Encoding:** Transforming text-based features (like `string_id`, `error_code`) into a numerical format (One-Hot Encoding).\n",
        "    *   **Feature Scaling:** Normalizing numerical features (`StandardScaler`) to ensure fair contribution from all variables.\n",
        "\n",
        "5.  **ğŸ§  Model Building & Cross-Validation - The Core Engine:**\n",
        "    *   **Algorithm Selection:** Focusing on state-of-the-art gradient boosting models:\n",
        "        *   **LightGBM (LGBM):** Known for speed and efficiency.\n",
        "        *   **XGBoost:** A robust and widely-used powerhouse.\n",
        "    *   **K-Fold Cross-Validation:** Training and evaluating models on different subsets of the data to ensure robustness and get a reliable performance estimate. This helps prevent overfitting.\n",
        "\n",
        "6.  **ğŸ› ï¸ Hyperparameter Optimization - Fine-Tuning for Excellence:**\n",
        "    *   Leveraging **Optuna**, an automated hyperparameter optimization framework. Optuna will intelligently search for the best set of model settings (e.g., learning rate, tree depth) to maximize our chosen metric.\n",
        "\n",
        "7.  **ğŸ¤ Model Ensembling - The Power of Collaboration:**\n",
        "    *   **Blending:** Combining the predictions from our fine-tuned LGBM and XGBoost models. The idea is that different models capture different aspects of the data, and their combined wisdom is often superior to any single model. We'll optimize the blending weights.\n",
        "\n",
        "8.  **ğŸ“œ Prediction & Submission - Delivering Results:**\n",
        "    *   Applying our final, ensembled model to the `test.csv` data.\n",
        "    *   Generating the `submission.csv` file in the specified format.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ˆ 4. Measuring Success: The Evaluation Metric\n",
        "\n",
        "Our model's prowess will be judged by a custom scoring formula:\n",
        "\n",
        "**Score = 100 \\* (1 - RMSE)**\n",
        "\n",
        "Where `RMSE` (Root Mean Squared Error) is calculated as:\n",
        "`RMSE = sqrt(mean_squared_error(actual_efficiency, predicted_efficiency))`\n",
        "\n",
        "**A higher score indicates a more accurate model.** Our goal is to maximize this score!\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ Let's Begin the Journey!\n",
        "\n",
        "The code cells below will bring this plan to life. We'll document each step, share our findings, and strive for the best possible prediction model."
      ],
      "metadata": {
        "id": "8EhsLZdJnT3K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nOiQpK2KnETF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e4a05e-8105-4903-a5ef-783a40eac79c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy matplotlib seaborn plotly scikit-learn lightgbm xgboost optuna shap kaleido catboost -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plotly imports\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.experimental import enable_iterative_imputer # <--- ADD THIS LINE\n",
        "from sklearn.impute import SimpleImputer, IterativeImputer # <--- THIS LINE REMAINS\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import catboost as cb # Assuming CatBoost will be used\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import optuna\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "import shap\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "l35pfhy8HAmL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "RUN_OPTUNA = True\n",
        "OPTUNA_TRIALS_LGBM = 30     # Number of Optuna trials\n",
        "OPTUNA_TRIALS_XGB = 30\n",
        "OPTUNA_TRIALS_CATBOOST = 30 # Set to 0 to skip CatBoost\n",
        "N_SPLITS = 5\n",
        "RANDOM_STATE = 42\n",
        "USE_ITERATIVE_IMPUTER = False # Set to True to try (slower)\n",
        "SHAP_SAMPLE_SIZE = 500     # Sample size for SHAP explanations (faster) or use len(X_processed_df) for full"
      ],
      "metadata": {
        "id": "orjaMceSHf1a"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Directory Setup ---\n",
        "BASE_DIR = \"solar_panel_analysis_full_v3\"\n",
        "EDA_PLOTS_DIR = os.path.join(BASE_DIR, \"eda_plotly_plots\")\n",
        "OPTUNA_PLOTS_DIR = os.path.join(BASE_DIR, \"optuna_plots\")\n",
        "SHAP_PLOTS_DIR = os.path.join(BASE_DIR, \"shap_plots\")\n",
        "\n",
        "for D_path in [BASE_DIR, EDA_PLOTS_DIR, OPTUNA_PLOTS_DIR, SHAP_PLOTS_DIR]:\n",
        "    if not os.path.exists(D_path):\n",
        "        os.makedirs(D_path)\n",
        "print(f\"Outputs will be saved in '{BASE_DIR}' subdirectories.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQefk4C1HwSR",
        "outputId": "497fd3d0-caca-4d33-c6d3-78fba3f45822"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs will be saved in 'solar_panel_analysis_full_v3' subdirectories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOSgHLiTH3Kq",
        "outputId": "90ff7c7c-9539-4e80-aff9-0525bef47584"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 0. Data Loading ---\n",
        "print(\"\\n--- 0. Data Loading ---\")\n",
        "try:\n",
        "    # Assuming Google Drive is mounted at /content/drive\n",
        "    # Adjust path if your files are elsewhere\n",
        "    DRIVE_PATH = \"/content/drive/MyDrive/zelestra_data/\"\n",
        "    train_df_orig = pd.read_csv(os.path.join(DRIVE_PATH, \"train.csv\"))\n",
        "    test_df_orig = pd.read_csv(os.path.join(DRIVE_PATH, \"test.csv\"))\n",
        "    sample_submission_df = pd.read_csv(os.path.join(DRIVE_PATH, \"sample_submission.csv\"))\n",
        "    print(f\"Train data shape: {train_df_orig.shape}, Test data shape: {test_df_orig.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: CSV files not found in {DRIVE_PATH}. Please check the path.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "XsJp87FWINpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62bc7712-319b-4361-aaf1-68f0aff3789a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 0. Data Loading ---\n",
            "Train data shape: (20000, 17), Test data shape: (12000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Cleaning & Initial Type Conversion ---\n",
        "print(\"\\n--- 1. Data Cleaning & Initial Type Conversion ---\")\n",
        "def clean_data(df, df_name=\"DataFrame\"):\n",
        "    df_cleaned = df.copy()\n",
        "    cols_to_numeric = ['humidity', 'wind_speed', 'pressure']\n",
        "    print(f\"\\nCleaning {df_name}:\")\n",
        "    for col in cols_to_numeric:\n",
        "        if col in df_cleaned.columns:\n",
        "            original_dtype = df_cleaned[col].dtype\n",
        "            df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
        "            new_nans = df_cleaned[col].isnull().sum()\n",
        "            # print(f\"  Converted '{col}' from {original_dtype} to numeric. Introduced/confirmed {new_nans} NaNs.\")\n",
        "    return df_cleaned\n",
        "\n",
        "train_df_cleaned = clean_data(train_df_orig, \"Train Data\")\n",
        "test_df_cleaned = clean_data(test_df_orig, \"Test Data\")"
      ],
      "metadata": {
        "id": "-cWlv2xiQq9E",
        "outputId": "d5416b5d-a227-410c-9685-392cbd909416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 1. Data Cleaning & Initial Type Conversion ---\n",
            "\n",
            "Cleaning Train Data:\n",
            "\n",
            "Cleaning Test Data:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. In-Depth EDA (with Plotly) ---\n",
        "print(\"\\n--- 2. In-Depth EDA (Post-Cleaning) ---\")\n",
        "train_eda = train_df_cleaned.copy()\n",
        "test_eda = test_df_cleaned.copy()\n",
        "TARGET = 'efficiency'\n",
        "\n",
        "numerical_features_eda = train_eda.select_dtypes(include=np.number).columns.tolist()\n",
        "if TARGET in numerical_features_eda: numerical_features_eda.remove(TARGET)\n",
        "if 'id' in numerical_features_eda: numerical_features_eda.remove('id')\n",
        "\n",
        "categorical_features_eda = train_eda.select_dtypes(include='object').columns.tolist()\n",
        "if 'id' in categorical_features_eda: categorical_features_eda.remove('id')\n",
        "\n",
        "def plot_target_distribution(df, target_col, save_dir):\n",
        "    # ... (Plotting functions from previous response - keep them here)\n",
        "    fig = px.histogram(df, x=target_col, nbins=50, title=f'Distribution of Target ({target_col})',\n",
        "                       marginal=\"box\", color_discrete_sequence=['#636EFA'])\n",
        "    fig.update_layout(bargap=0.1)\n",
        "    if save_dir: fig.write_html(os.path.join(save_dir, \"plotly_target_distribution.html\"))\n",
        "\n",
        "def plot_numerical_distributions_train_test(train_df, test_df, num_cols, save_dir):\n",
        "    for col in num_cols:\n",
        "        if col not in train_df.columns or col not in test_df.columns: continue\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Histogram(x=train_df[col].dropna(), name='Train', nbinsx=40, marker_color='#EF553B', opacity=0.75))\n",
        "        fig.add_trace(go.Histogram(x=test_df[col].dropna(), name='Test', nbinsx=40, marker_color='#00CC96', opacity=0.75))\n",
        "        fig.update_layout(barmode='overlay', title_text=f'Distribution of {col} (Train vs Test)')\n",
        "        fig.update_traces(opacity=0.7)\n",
        "        if save_dir: fig.write_html(os.path.join(save_dir, f\"plotly_dist_{col}_train_test.html\"))\n",
        "\n",
        "def plot_correlation_heatmap(df, num_cols, target_col, save_dir):\n",
        "    valid_num_cols = [col for col in num_cols if col in df.columns]\n",
        "    if not valid_num_cols: return\n",
        "    # Ensure target_col is also numeric and present\n",
        "    cols_for_corr = valid_num_cols\n",
        "    if target_col in df.columns and pd.api.types.is_numeric_dtype(df[target_col]):\n",
        "        cols_for_corr = valid_num_cols + [target_col]\n",
        "    else:\n",
        "        print(f\"Warning: Target column '{target_col}' not found or not numeric for correlation heatmap.\")\n",
        "\n",
        "    correlation_matrix = df[cols_for_corr].corr()\n",
        "    fig = px.imshow(correlation_matrix, text_auto=\".2f\", aspect=\"auto\",\n",
        "                    color_continuous_scale='RdBu_r', title='Correlation Matrix')\n",
        "    if save_dir: fig.write_html(os.path.join(save_dir, \"plotly_correlation_heatmap.html\"))\n",
        "\n",
        "def plot_categorical_vs_target(df, cat_cols, target_col, save_dir):\n",
        "    for col in cat_cols:\n",
        "        if col not in df.columns or target_col not in df.columns : continue\n",
        "        df_to_plot = df[[col, target_col]].copy().dropna(subset=[col, target_col])\n",
        "        if df_to_plot.empty: continue\n",
        "\n",
        "        unique_cats = df_to_plot[col].nunique()\n",
        "        if unique_cats > 20:\n",
        "            top_categories = df_to_plot[col].value_counts().nlargest(20).index\n",
        "            df_filtered = df_to_plot[df_to_plot[col].isin(top_categories)]\n",
        "            title_suffix = \" (Top 20 Categories)\"\n",
        "        else:\n",
        "            df_filtered = df_to_plot\n",
        "            title_suffix = \"\"\n",
        "        if df_filtered.empty: continue\n",
        "\n",
        "        fig = px.box(df_filtered, x=col, y=target_col,\n",
        "                     title=f'{target_col} vs {col}{title_suffix}',\n",
        "                     color=col, color_discrete_sequence=px.colors.qualitative.Plotly)\n",
        "        if save_dir: fig.write_html(os.path.join(save_dir, f\"plotly_boxplot_{target_col}_vs_{col}.html\"))\n",
        "\n",
        "print(\"Generating EDA plots post-cleaning...\")\n",
        "plot_target_distribution(train_eda, TARGET, EDA_PLOTS_DIR)\n",
        "plot_numerical_distributions_train_test(train_eda, test_eda, numerical_features_eda, EDA_PLOTS_DIR)\n",
        "plot_correlation_heatmap(train_eda, numerical_features_eda, TARGET, EDA_PLOTS_DIR)\n",
        "plot_categorical_vs_target(train_eda, categorical_features_eda, TARGET, EDA_PLOTS_DIR)\n",
        "print(f\"EDA plots saved to {EDA_PLOTS_DIR}\")"
      ],
      "metadata": {
        "id": "yWOhwH6sQq_a",
        "outputId": "5906f420-c8ed-4b6c-a346-0af8d8315f12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 2. In-Depth EDA (Post-Cleaning) ---\n",
            "Generating EDA plots post-cleaning...\n",
            "EDA plots saved to solar_panel_analysis_full_v3/eda_plotly_plots\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Strategic Feature Engineering ---\n",
        "print(\"\\n--- 3. Strategic Feature Engineering ---\")\n",
        "def feature_engineer(df):\n",
        "    df_fe = df.copy()\n",
        "    # Interaction Features\n",
        "    if 'temperature' in df_fe and 'irradiance' in df_fe: df_fe['temp_x_irradiance'] = df_fe['temperature'] * df_fe['irradiance']\n",
        "    if 'voltage' in df_fe and 'current' in df_fe: df_fe['voltage_x_current'] = df_fe['voltage'] * df_fe['current']\n",
        "    if 'panel_age' in df_fe and 'maintenance_count' in df_fe: df_fe['age_x_maintenance'] = df_fe['panel_age'] * (df_fe['maintenance_count'].fillna(0) + 1e-6)\n",
        "    if 'irradiance' in df_fe and 'soiling_ratio' in df_fe: df_fe['irradiance_eff_soiling'] = df_fe['irradiance'] * df_fe['soiling_ratio']\n",
        "    # Ratio/Difference Features\n",
        "    if 'temperature' in df_fe and 'humidity' in df_fe: df_fe['temp_humidity_ratio'] = df_fe['temperature'] / (df_fe['humidity'].replace(0, 1e-6).fillna(1e-6) + 1e-6)\n",
        "    if 'module_temperature' in df_fe and 'temperature' in df_fe: df_fe['temp_diff_module_ambient'] = df_fe['module_temperature'] - df_fe['temperature']\n",
        "    if 'irradiance' in df_fe and 'cloud_coverage' in df_fe: df_fe['irradiance_per_cloud'] = df_fe['irradiance'] / (df_fe['cloud_coverage'].fillna(0) + 1)\n",
        "    # Polynomials\n",
        "    for col in ['irradiance', 'temperature', 'module_temperature', 'voltage', 'current', 'panel_age']:\n",
        "         if col in df_fe.columns: df_fe[f'{col}_sq'] = df_fe[col] ** 2\n",
        "    if 'module_temperature' in df_fe and 'temperature' in df_fe and 'irradiance' in df_fe:\n",
        "        df_fe['temp_rise_per_irradiance'] = (df_fe['module_temperature'] - df_fe['temperature']) / (df_fe['irradiance'].replace(0,1e-6).fillna(1e-6) + 1e-6)\n",
        "    return df_fe\n",
        "\n",
        "train_df_fe = feature_engineer(train_df_cleaned)\n",
        "test_df_fe = feature_engineer(test_df_cleaned)\n",
        "\n",
        "X = train_df_fe.drop([TARGET, 'id'], axis=1, errors='ignore')\n",
        "y_target = train_df_fe[TARGET]\n",
        "X_test_full = test_df_fe.drop('id', axis=1, errors='ignore')\n",
        "test_ids = test_df_orig['id']\n",
        "\n",
        "train_cols = X.columns; test_cols = X_test_full.columns\n",
        "common_cols = list(set(train_cols) & set(test_cols))\n",
        "X = X[common_cols]; X_test = X_test_full[common_cols]\n",
        "\n",
        "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "print(f\"Shape of X: {X.shape}, X_test: {X_test.shape}\")\n",
        "print(f\"Num features: {len(numerical_features)}, Cat features: {len(categorical_features)}\")"
      ],
      "metadata": {
        "id": "9iiFvZC0QrC8",
        "outputId": "54aad6d6-9ca2-4462-96be-ff8be61e3d4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3. Strategic Feature Engineering ---\n",
            "Shape of X: (20000, 29), X_test: (12000, 29)\n",
            "Num features: 26, Cat features: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Robust Data Preprocessing ---\n",
        "print(\"\\n--- 4. Robust Data Preprocessing ---\")\n",
        "numerical_imputer = IterativeImputer(max_iter=10, random_state=RANDOM_STATE) if USE_ITERATIVE_IMPUTER else SimpleImputer(strategy='median')\n",
        "numerical_pipeline = Pipeline([('imputer', numerical_imputer), ('scaler', StandardScaler())])\n",
        "categorical_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "                                 ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
        "preprocessor = ColumnTransformer(\n",
        "    [('num', numerical_pipeline, numerical_features),\n",
        "     ('cat', categorical_pipeline, categorical_features)],\n",
        "    remainder='drop', n_jobs=-1) # Drop any columns not specified to avoid errors\n",
        "\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "try:\n",
        "    ohe_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
        "    all_feature_names = numerical_features + list(ohe_feature_names)\n",
        "    X_processed_df = pd.DataFrame(X_processed, columns=all_feature_names, index=X.index)\n",
        "    X_test_processed_df = pd.DataFrame(X_test_processed, columns=all_feature_names, index=X_test.index)\n",
        "except Exception as e:\n",
        "    print(f\"Fallback: Using generic feature names due to: {e}\")\n",
        "    X_processed_df = pd.DataFrame(X_processed, index=X.index)\n",
        "    X_test_processed_df = pd.DataFrame(X_test_processed, index=X_test.index)\n",
        "    all_feature_names = [f\"feat_{i}\" for i in range(X_processed_df.shape[1])]\n",
        "    X_processed_df.columns = all_feature_names\n",
        "    X_test_processed_df.columns = all_feature_names\n",
        "print(f\"Processed data shapes: X_processed_df {X_processed_df.shape}, X_test_processed_df {X_test_processed_df.shape}\")"
      ],
      "metadata": {
        "id": "Ta-7_VDiRJ05",
        "outputId": "b68cd02b-cb89-4473-c92a-9dfe0e18bf52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 4. Robust Data Preprocessing ---\n",
            "Processed data shapes: X_processed_df (20000, 36), X_test_processed_df (12000, 36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Model Building & CV ---\n",
        "print(\"\\n--- 5. Model Building & CV ---\")\n",
        "def custom_score_func(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    return 100 * (1 - rmse)\n",
        "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "GE9rkfsAROEu",
        "outputId": "faa8add4-e211-459f-b7a4-41c36eedf1ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 5. Model Building & CV ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Hyperparameter Optimization (Optuna) & Training ---\n",
        "print(\"\\n--- 6. Hyperparameter Optimization & Training ---\")\n",
        "# --- LightGBM ---\n",
        "def objective_lgbm(trial, X_data, y_data):\n",
        "    # ... (LGBM objective params - same as before) ...\n",
        "    params = {\n",
        "        'objective': 'regression_l1', 'metric': 'rmse', 'random_state': RANDOM_STATE,\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 300, 2500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 150), 'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0), 'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-2, 10.0, log=True), 'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 10.0, log=True),\n",
        "        'verbose': -1, 'n_jobs': -1\n",
        "    }\n",
        "    fold_rmses = []\n",
        "    for train_idx, val_idx in kf.split(X_data, y_data):\n",
        "        model = lgb.LGBMRegressor(**params)\n",
        "        model.fit(X_data.iloc[train_idx], y_data.iloc[train_idx],\n",
        "                  eval_set=[(X_data.iloc[val_idx], y_data.iloc[val_idx])],\n",
        "                  eval_metric='rmse', callbacks=[lgb.early_stopping(100, verbose=False)])\n",
        "        preds_val = model.predict(X_data.iloc[val_idx])\n",
        "        fold_rmses.append(np.sqrt(mean_squared_error(y_data.iloc[val_idx], preds_val)))\n",
        "    return np.mean(fold_rmses)\n",
        "\n",
        "best_params_lgbm = {}\n",
        "if RUN_OPTUNA and OPTUNA_TRIALS_LGBM > 0:\n",
        "    study_lgbm = optuna.create_study(direction='minimize', study_name=\"LGBM_Opt\")\n",
        "    study_lgbm.optimize(lambda trial: objective_lgbm(trial, X_processed_df, y_target), n_trials=OPTUNA_TRIALS_LGBM, n_jobs=-1)\n",
        "    best_params_lgbm = study_lgbm.best_params\n",
        "    print(\"Best LGBM Params:\", best_params_lgbm)\n",
        "    if OPTUNA_PLOTS_DIR:\n",
        "        optuna.visualization.plot_optimization_history(study_lgbm).write_html(os.path.join(OPTUNA_PLOTS_DIR, \"optuna_lgbm_history.html\"))\n",
        "        optuna.visualization.plot_slice(study_lgbm).write_html(os.path.join(OPTUNA_PLOTS_DIR, \"optuna_lgbm_slice.html\"))\n",
        "else: best_params_lgbm = {'n_estimators': 1500, 'learning_rate': 0.01} # Basic default\n",
        "\n",
        "oof_lgbm = np.zeros(len(X_processed_df)); test_preds_lgbm = np.zeros(len(X_test_processed_df)); lgbm_models = []\n",
        "final_lgbm_params = {**{'objective': 'regression_l1', 'metric': 'rmse', 'random_state': RANDOM_STATE, 'verbose': -1, 'n_jobs': -1}, **best_params_lgbm}\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_processed_df, y_target)):\n",
        "    model = lgb.LGBMRegressor(**final_lgbm_params)\n",
        "    model.fit(X_processed_df.iloc[train_idx], y_target.iloc[train_idx],\n",
        "              eval_set=[(X_processed_df.iloc[val_idx], y_target.iloc[val_idx])],\n",
        "              eval_metric='rmse', callbacks=[lgb.early_stopping(100, verbose=False)])\n",
        "    oof_lgbm[val_idx] = model.predict(X_processed_df.iloc[val_idx])\n",
        "    test_preds_lgbm += model.predict(X_test_processed_df) / N_SPLITS\n",
        "    lgbm_models.append(model)\n",
        "lgbm_cv_score = custom_score_func(y_target, oof_lgbm)\n",
        "print(f\"LightGBM CV Custom Score: {lgbm_cv_score:.4f}\")\n",
        "\n",
        "# --- XGBoost ---\n",
        "def objective_xgb(trial, X_data, y_data):\n",
        "    # ... (XGB objective params - same as before) ...\n",
        "    params = {\n",
        "        'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'random_state': RANDOM_STATE,\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 300, 2500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10), 'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0), 'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 1e-2, 1.0, log=True),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-2, 10.0, log=True), 'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 10.0, log=True),\n",
        "        'n_jobs': -1, 'tree_method': 'hist'\n",
        "    }\n",
        "    fold_rmses = []\n",
        "    for train_idx, val_idx in kf.split(X_data, y_data):\n",
        "        model = xgb.XGBRegressor(**params)\n",
        "        model.fit(X_data.iloc[train_idx], y_data.iloc[train_idx],\n",
        "                  eval_set=[(X_data.iloc[val_idx], y_data.iloc[val_idx])],\n",
        "                  early_stopping_rounds=100, verbose=False)\n",
        "        preds_val = model.predict(X_data.iloc[val_idx])\n",
        "        fold_rmses.append(np.sqrt(mean_squared_error(y_data.iloc[val_idx], preds_val)))\n",
        "    return np.mean(fold_rmses)\n",
        "\n",
        "best_params_xgb = {}\n",
        "if RUN_OPTUNA and OPTUNA_TRIALS_XGB > 0:\n",
        "    study_xgb = optuna.create_study(direction='minimize', study_name=\"XGB_Opt\")\n",
        "    study_xgb.optimize(lambda trial: objective_xgb(trial, X_processed_df, y_target), n_trials=OPTUNA_TRIALS_XGB, n_jobs=-1)\n",
        "    best_params_xgb = study_xgb.best_params\n",
        "    print(\"Best XGB Params:\", best_params_xgb)\n",
        "    if OPTUNA_PLOTS_DIR:\n",
        "        optuna.visualization.plot_optimization_history(study_xgb).write_html(os.path.join(OPTUNA_PLOTS_DIR, \"optuna_xgb_history.html\"))\n",
        "        optuna.visualization.plot_slice(study_xgb).write_html(os.path.join(OPTUNA_PLOTS_DIR, \"optuna_xgb_slice.html\"))\n",
        "else: best_params_xgb = {'n_estimators': 1500, 'learning_rate': 0.01} # Basic default\n",
        "\n",
        "oof_xgb = np.zeros(len(X_processed_df)); test_preds_xgb = np.zeros(len(X_test_processed_df)); xgb_models = []\n",
        "final_xgb_params = {**{'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'random_state': RANDOM_STATE, 'n_jobs': -1, 'tree_method': 'hist'}, **best_params_xgb}\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_processed_df, y_target)):\n",
        "    model = xgb.XGBRegressor(**final_xgb_params)\n",
        "    model.fit(X_processed_df.iloc[train_idx], y_target.iloc[train_idx],\n",
        "              eval_set=[(X_processed_df.iloc[val_idx], y_target.iloc[val_idx])],\n",
        "              early_stopping_rounds=100, verbose=False)\n",
        "    oof_xgb[val_idx] = model.predict(X_processed_df.iloc[val_idx])\n",
        "    test_preds_xgb += model.predict(X_test_processed_df) / N_SPLITS\n",
        "    xgb_models.append(model)\n",
        "xgb_cv_score = custom_score_func(y_target, oof_xgb)\n",
        "print(f\"XGBoost CV Custom Score: {xgb_cv_score:.4f}\")\n",
        "\n",
        "# --- CatBoost ---\n",
        "oof_cat = np.zeros(len(X_processed_df)); test_preds_cat = np.zeros(len(X_test_processed_df)); cat_models = []\n",
        "catboost_cv_score = -np.inf\n",
        "if OPTUNA_TRIALS_CATBOOST > 0:\n",
        "    def objective_catboost(trial, X_data, y_data):\n",
        "        params = {\n",
        "            'objective': 'RMSE', 'eval_metric': 'RMSE', 'random_seed': RANDOM_STATE,\n",
        "            'iterations': trial.suggest_int('iterations', 300, 2500),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
        "            'depth': trial.suggest_int('depth', 4, 10), 'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 10.0, log=True),\n",
        "            'border_count': trial.suggest_int('border_count', 32, 255), 'verbose': 0\n",
        "        }\n",
        "        fold_rmses = []\n",
        "        # Note: If using CatBoost with original categorical features, pass cat_features_indices\n",
        "        # Here, data is OHE, so no cat_features needed for CatBoostRegressor\n",
        "        for train_idx, val_idx in kf.split(X_data, y_data):\n",
        "            model = cb.CatBoostRegressor(**params)\n",
        "            model.fit(X_data.iloc[train_idx], y_data.iloc[train_idx],\n",
        "                      eval_set=[(X_data.iloc[val_idx], y_data.iloc[val_idx])],\n",
        "                      early_stopping_rounds=100, verbose=0)\n",
        "            preds_val = model.predict(X_data.iloc[val_idx])\n",
        "            fold_rmses.append(np.sqrt(mean_squared_error(y_data.iloc[val_idx], preds_val)))\n",
        "        return np.mean(fold_rmses)\n",
        "\n",
        "    best_params_cat = {}\n",
        "    if RUN_OPTUNA:\n",
        "        study_cat = optuna.create_study(direction='minimize', study_name=\"CatBoost_Opt\")\n",
        "        study_cat.optimize(lambda trial: objective_catboost(trial, X_processed_df, y_target), n_trials=OPTUNA_TRIALS_CATBOOST, n_jobs=-1)\n",
        "        best_params_cat = study_cat.best_params\n",
        "        print(\"Best CatBoost Params:\", best_params_cat)\n",
        "        if OPTUNA_PLOTS_DIR:\n",
        "            optuna.visualization.plot_optimization_history(study_cat).write_html(os.path.join(OPTUNA_PLOTS_DIR, \"optuna_catboost_history.html\"))\n",
        "            optuna.visualization.plot_slice(study_cat).write_html(os.path.join(OPTUNA_PLOTS_DIR, \"optuna_catboost_slice.html\"))\n",
        "    else: best_params_cat = {'iterations': 1500, 'learning_rate': 0.01}\n",
        "\n",
        "    final_cat_params = {**{'objective': 'RMSE', 'eval_metric': 'RMSE', 'random_seed': RANDOM_STATE, 'verbose': 0}, **best_params_cat}\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_processed_df, y_target)):\n",
        "        model = cb.CatBoostRegressor(**final_cat_params)\n",
        "        model.fit(X_processed_df.iloc[train_idx], y_target.iloc[train_idx],\n",
        "                  eval_set=[(X_processed_df.iloc[val_idx], y_target.iloc[val_idx])],\n",
        "                  early_stopping_rounds=100, verbose=0)\n",
        "        oof_cat[val_idx] = model.predict(X_processed_df.iloc[val_idx])\n",
        "        test_preds_cat += model.predict(X_test_processed_df) / N_SPLITS\n",
        "        cat_models.append(model)\n",
        "    catboost_cv_score = custom_score_func(y_target, oof_cat)\n",
        "    print(f\"CatBoost CV Custom Score: {catboost_cv_score:.4f}\")"
      ],
      "metadata": {
        "id": "XTrZyvgPRVLu",
        "outputId": "3092ad8a-7ab5-4b05-f199-a02bd305a75d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 6. Hyperparameter Optimization & Training ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Explainable AI (XAI with SHAP) ---\n",
        "print(\"\\n--- 7. Explainable AI (XAI with SHAP) ---\")\n",
        "X_shap_sample_df = X_processed_df.sample(min(SHAP_SAMPLE_SIZE, len(X_processed_df)), random_state=RANDOM_STATE)\n",
        "shap_plot_data = {}\n",
        "\n",
        "if lgbm_models:\n",
        "    try:\n",
        "        explainer = shap.TreeExplainer(lgbm_models[0]) # Explain first fold model\n",
        "        shap_values = explainer.shap_values(X_shap_sample_df)\n",
        "        shap_plot_data['lgbm'] = (shap_values, X_shap_sample_df, explainer.expected_value)\n",
        "    except Exception as e: print(f\"SHAP for LGBM failed: {e}\")\n",
        "if xgb_models:\n",
        "    try:\n",
        "        explainer = shap.TreeExplainer(xgb_models[0])\n",
        "        shap_values = explainer.shap_values(X_shap_sample_df)\n",
        "        shap_plot_data['xgb'] = (shap_values, X_shap_sample_df, explainer.expected_value)\n",
        "    except Exception as e: print(f\"SHAP for XGBoost failed: {e}\")\n",
        "if cat_models:\n",
        "    try:\n",
        "        explainer = shap.TreeExplainer(cat_models[0])\n",
        "        shap_values = explainer.shap_values(X_shap_sample_df)\n",
        "        shap_plot_data['cat'] = (shap_values, X_shap_sample_df, explainer.expected_value)\n",
        "    except Exception as e: print(f\"SHAP for CatBoost failed: {e}\")\n",
        "\n",
        "for model_name, (s_values, s_df, exp_val) in shap_plot_data.items():\n",
        "    print(f\"Generating SHAP plots for {model_name.upper()}...\")\n",
        "    plt.figure(); shap.summary_plot(s_values, s_df, plot_type=\"bar\", show=False); plt.title(f\"SHAP Global Importance ({model_name.upper()})\")\n",
        "    plt.tight_layout(); plt.savefig(os.path.join(SHAP_PLOTS_DIR, f\"shap_{model_name}_global_bar.png\")); plt.close()\n",
        "\n",
        "    plt.figure(); shap.summary_plot(s_values, s_df, show=False); plt.title(f\"SHAP Summary Plot ({model_name.upper()})\")\n",
        "    plt.tight_layout(); plt.savefig(os.path.join(SHAP_PLOTS_DIR, f\"shap_{model_name}_summary_beeswarm.png\")); plt.close()\n",
        "\n",
        "    shap.initjs()\n",
        "    for i in range(min(3, len(s_df))):\n",
        "        try: # Force plot saving can be tricky\n",
        "            plt.figure() # Create a new figure for each force plot\n",
        "            shap.force_plot(exp_val, s_values[i,:], s_df.iloc[i,:], matplotlib=True, show=False)\n",
        "            # plt.title(f\"SHAP Force Plot ({model_name.upper()}) - Sample {i}\") # Title often overlaps\n",
        "            plt.savefig(os.path.join(SHAP_PLOTS_DIR, f\"shap_{model_name}_force_plot_sample_{i}.png\"), bbox_inches='tight', dpi=150)\n",
        "            plt.close()\n",
        "        except Exception as e_force:\n",
        "            print(f\"Could not save force plot for {model_name} sample {i}: {e_force}\")\n",
        "\n",
        "print(f\"SHAP plots saved to {SHAP_PLOTS_DIR}\")"
      ],
      "metadata": {
        "id": "vV69KEg0RecJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8. Sophisticated Ensembling ---\n",
        "print(\"\\n--- 8. Sophisticated Ensembling ---\")\n",
        "oof_models_dict = {'lgbm': oof_lgbm, 'xgb': oof_xgb}\n",
        "test_preds_models_dict = {'lgbm': test_preds_lgbm, 'xgb': test_preds_xgb}\n",
        "if OPTUNA_TRIALS_CATBOOST > 0 and catboost_cv_score > -np.inf:\n",
        "    oof_models_dict['cat'] = oof_cat\n",
        "    test_preds_models_dict['cat'] = test_preds_cat\n",
        "\n",
        "def blend_objective_multi(trial, oofs_dict, target):\n",
        "    weights = [trial.suggest_float(f\"w_{name}\", 0, 1) for name in oofs_dict.keys()]\n",
        "    total_weight = sum(weights);\n",
        "    if total_weight == 0: return 1e6\n",
        "    normalized_weights = [w / total_weight for w in weights]\n",
        "    blended_oof = sum(norm_w * oofs_dict[name] for norm_w, name in zip(normalized_weights, oofs_dict.keys()))\n",
        "    return np.sqrt(mean_squared_error(target, blended_oof))\n",
        "\n",
        "study_blend = optuna.create_study(direction='minimize', study_name=\"Blend_Opt_Multi\")\n",
        "study_blend.optimize(lambda trial: blend_objective_multi(trial, oof_models_dict, y_target), n_trials=50)\n",
        "best_blend_weights_raw = study_blend.best_params\n",
        "total_raw_blend_weight = sum(best_blend_weights_raw.values())\n",
        "optimized_blend_weights = {name: best_blend_weights_raw[f\"w_{name}\"] / total_raw_blend_weight for name in oof_models_dict.keys()}\n",
        "\n",
        "print(\"Optimized Blend Weights:\"); [print(f\"  {name.upper()}: {weight:.4f}\") for name, weight in optimized_blend_weights.items()]\n",
        "blended_test_preds = sum(w * test_preds_models_dict[name] for name, w in optimized_blend_weights.items())\n",
        "blended_oof_final = sum(w * oof_models_dict[name] for name, w in optimized_blend_weights.items())\n",
        "blended_cv_score = custom_score_func(y_target, blended_oof_final)\n",
        "print(f\"Blended OOF Custom Score: {blended_cv_score:.4f}\")\n",
        "final_test_predictions = blended_test_preds\n",
        "\n",
        "fig_oof_blend = px.scatter(x=y_target, y=blended_oof_final, labels={'x': 'Actual', 'y': 'Blended OOF Predicted'},\n",
        "                           title='Blended OOF vs. Actual', opacity=0.5, marginal_y='histogram', marginal_x='histogram')\n",
        "fig_oof_blend.add_shape(type=\"line\", x0=y_target.min(), y0=y_target.min(), x1=y_target.max(), y1=y_target.max(), line=dict(color=\"Red\", dash=\"dash\"))\n",
        "if BASE_DIR: fig_oof_blend.write_html(os.path.join(BASE_DIR, \"plotly_blended_oof_vs_actual.html\"))"
      ],
      "metadata": {
        "id": "TlCST85pSsI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 9. Prediction & Submission ---\n",
        "print(\"\\n--- 9. Prediction & Submission ---\")\n",
        "# Optional: Clip predictions\n",
        "# final_test_predictions = np.clip(final_test_predictions, y_target.min() * 0.9, y_target.max() * 1.1)\n",
        "# final_test_predictions = np.clip(final_test_predictions, 0.0, 1.0)\n",
        "\n",
        "submission_df = pd.DataFrame({'id': test_ids, TARGET: final_test_predictions})\n",
        "submission_df.columns = ['id', 'efficiency']\n",
        "submission_filename = os.path.join(BASE_DIR, \"submission_full_v3.csv\")\n",
        "submission_df.to_csv(submission_filename, index=False)\n",
        "print(f\"Submission file '{submission_filename}' created successfully.\")\n",
        "\n",
        "print(\"\\n--- Final CV Scores Summary ---\")\n",
        "print(f\"LGBM CV Custom Score: {lgbm_cv_score:.4f}\")\n",
        "print(f\"XGBoost CV Custom Score: {xgb_cv_score:.4f}\")\n",
        "if OPTUNA_TRIALS_CATBOOST > 0 and catboost_cv_score > -np.inf: print(f\"CatBoost CV Custom Score: {catboost_cv_score:.4f}\")\n",
        "print(f\"Blended OOF Custom Score: {blended_cv_score:.4f}\")\n",
        "print(f\"\\nAll outputs saved in '{BASE_DIR}' directory.\")"
      ],
      "metadata": {
        "id": "ML5FfwoPSxkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EnaJYoEvS21v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}