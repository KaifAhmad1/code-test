{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbABkqVfnXpmH+Q/qieToi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/code-test/blob/main/Search_Sources.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jQUT-suIDN0z",
        "outputId": "85cdd2b6-1baf-4483-f5e5-e0c07817d472",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m702.2/702.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyaes (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU telethon tweepy feedparser google-api-python-client requests tavily-python exa_py python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from typing import List, Dict, Any, Optional\n",
        "from pydantic import BaseModel\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "from dotenv import load_dotenv\n",
        "import nest_asyncio\n",
        "import os\n",
        "import requests\n",
        "from googleapiclient.discovery import build\n",
        "from exa_py import Exa\n",
        "from tavily import TavilyClient\n",
        "from telethon.sync import TelegramClient\n",
        "from telethon.errors.rpcerrorlist import PhoneNumberInvalidError, SessionPasswordNeededError\n",
        "import tweepy\n",
        "import feedparser\n",
        "from dateutil import parser\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import time\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# API Keys\n",
        "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\", \"d8e815ef6caa94dbef7b977a0ea7d505b43a5a06\")\n",
        "EXA_API_KEY = os.getenv(\"EXA_API_KEY\", \"953b5801-11be-4b37-a313-f8df8f37027c\")\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"AIzaSyBIQo9X6acoBazBfte9jF9Pl0QEZ9oe8pk\")\n",
        "GOOGLE_CSE_ID = os.getenv(\"GOOGLE_CSE_ID\", \"63053004a7e2445c3\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\", \"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\")\n",
        "\n",
        "# Telegram API Keys\n",
        "TELEGRAM_API_ID = 20441646\n",
        "TELEGRAM_API_HASH = \"d78a891287e9ba6a2a8c4bb0e4ca506a\"\n",
        "\n",
        "# Twitter API Keys\n",
        "TWITTER_API_KEY = \"WTIYHjD9r10EZKoUghhK6vqnh\"\n",
        "TWITTER_API_SECRET = \"0t4k1BiQnqa2RcZKFLUXMtka5t0BOc1F89eNWj8ee3AkNFyGRA\"\n",
        "TWITTER_ACCESS_TOKEN = \"1872197717612474368-CuATnNZBeXy7r3ymdSMnPW0MMkfVkf\"\n",
        "TWITTER_ACCESS_TOKEN_SECRET = \"wAfYioeyIpK0kpStzQFK5TxHeLCPVVwk6vtaAzjprYEFV\"\n",
        "TWITTER_BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAHMBxwEAAAAAXHty6DjTOsfJ0TXByHccMUqBK%2B0%3DYVCDqgobV2wQUr8WTAR3zVrmqsPU7PdPIQzyRMelPPYgawKEfh\""
      ],
      "metadata": {
        "id": "RfyEZQPAEBUr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "SECURITY_RSS_FEEDS = [\n",
        "    \"https://www.bleepingcomputer.com/feed/\",\n",
        "    \"https://feeds.feedburner.com/TheHackersNews\",\n",
        "    \"https://krebsonsecurity.com/feed/\",\n",
        "    \"https://www.darkreading.com/rss.xml\",\n",
        "    \"https://www.securityweek.com/feed/\",\n",
        "    \"https://www.csoonline.com/feed/\",\n",
        "    \"https://www.threatpost.com/feed/\",\n",
        "    \"https://www.helpnetsecurity.com/feed/\",\n",
        "    \"https://www.infosecurity-magazine.com/rss/news/\",\n",
        "    \"https://www.cybersecurity-insiders.com/feed/\",\n",
        "    \"https://www.zdnet.com/topic/security/rss.xml\",\n",
        "    \"https://www.schneier.com/feed/atom/\",\n",
        "    \"https://www.theregister.com/security/headlines.atom\",\n",
        "    \"https://www.govinfosecurity.com/rss/feeds/rss\",\n",
        "    \"https://www.crowdstrike.com/blog/feed/\"\n",
        "]\n",
        "\n",
        "TELEGRAM_CHANNELS = [\n",
        "    'cveNotify',\n",
        "    'ctinow',\n",
        "    'CyberSecurityTechnologies',\n",
        "    'cybersecurity_outlook',\n",
        "    'cibsecurity',\n",
        "    'thehackernews',\n",
        "    'Cyber_Security_Channel',\n",
        "    'cloudandcybersecurity',\n",
        "    'androidMalware',\n",
        "    'DarkfeedNews',\n",
        "    'PentestingNews',\n",
        "    'malwr'\n",
        "]"
      ],
      "metadata": {
        "id": "F-09ZjgtAQcX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize services\n",
        "exa = Exa(api_key=EXA_API_KEY)\n",
        "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n",
        "google_service = build(\"customsearch\", \"v1\", developerKey=GOOGLE_API_KEY)\n",
        "telegram_client = TelegramClient('session_name', TELEGRAM_API_ID, TELEGRAM_API_HASH)\n",
        "twitter_auth = tweepy.OAuth1UserHandler(TWITTER_API_KEY, TWITTER_API_SECRET, TWITTER_ACCESS_TOKEN, TWITTER_ACCESS_TOKEN_SECRET)\n",
        "twitter_api = tweepy.API(twitter_auth)"
      ],
      "metadata": {
        "id": "otVl9AaWEjDH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SearchResult(BaseModel):\n",
        "    source: str\n",
        "    title: str\n",
        "    snippet: str\n",
        "    url: str\n",
        "    date: Optional[str] = None\n",
        "    media: Optional[List[str]] = []\n",
        "    media_content: Optional[List[Dict[str, str]]] = []"
      ],
      "metadata": {
        "id": "s1Pt1QYFE9h0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def google_serper_search(query: str, start_date: str, end_date: str) -> List[SearchResult]:\n",
        "    print(\"Executing Google Serper Search\")\n",
        "    url = \"https://google.serper.dev/search\"\n",
        "    payload = {\n",
        "        \"q\": query,\n",
        "        \"gl\": \"us\",\n",
        "        \"hl\": \"en\",\n",
        "        \"autocorrect\": True,\n",
        "        \"time_range\": {\n",
        "            \"start\": start_date,\n",
        "            \"end\": end_date\n",
        "        }\n",
        "    }\n",
        "    headers = {\n",
        "        \"X-API-KEY\": SERPER_API_KEY,\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        print(f\"Google Serper Search Example Result: {data.get('organic', [])[0] if data.get('organic') else 'No results'}\")\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Google Serper\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "                url=result.get(\"link\", \"No link\"),\n",
        "                date=result.get(\"date\")\n",
        "            ) for result in data.get(\"organic\", [])\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Google Serper Search: {e}\")\n",
        "        return []\n",
        "\n",
        "def google_programmable_search(query: str, start_date: str, end_date: str) -> List[SearchResult]:\n",
        "    print(\"Executing Google Programmable Search\")\n",
        "    try:\n",
        "        search_results = google_service.cse().list(\n",
        "            q=query,\n",
        "            cx=GOOGLE_CSE_ID,\n",
        "            num=5,\n",
        "            sort=f\"date:r:{start_date}:{end_date}\"\n",
        "        ).execute()\n",
        "        print(f\"Google Programmable Search Example Result: {search_results.get('items', [])[0] if search_results.get('items') else 'No results'}\")\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Google Programmable Search\",\n",
        "                title=item.get(\"title\", \"No title\"),\n",
        "                snippet=item.get(\"snippet\", \"No snippet\"),\n",
        "                url=item.get(\"link\", \"No link\"),\n",
        "                date=item.get(\"pagemap\", {}).get(\"metatags\", [{}])[0].get(\"article:published_time\")\n",
        "            ) for item in search_results.get(\"items\", [])\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Google Programmable Search: {e}\")\n",
        "        return []\n",
        "\n",
        "def google_serper_image_search(query: str) -> List[SearchResult]:\n",
        "    print(\"Executing Google Serper Image Search\")\n",
        "    url = \"https://google.serper.dev/images\"\n",
        "    payload = {\n",
        "        \"q\": query,\n",
        "        \"gl\": \"us\",\n",
        "        \"hl\": \"en\"\n",
        "    }\n",
        "    headers = {\n",
        "        \"X-API-KEY\": SERPER_API_KEY,\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        print(f\"Google Serper Image Search Example Result: {data.get('images', [])[0] if data.get('images') else 'No results'}\")\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Google Serper Image Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"snippet\", \"No snippet\"),\n",
        "                url=result.get(\"imageUrl\", \"No link\"),\n",
        "                media=[result.get(\"imageUrl\", \"No link\")],\n",
        "                media_content=[{\"image_url\": result.get(\"imageUrl\", \"No link\")}]\n",
        "            ) for result in data.get(\"images\", [])\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Google Serper Image Search: {e}\")\n",
        "        return []\n",
        "\n",
        "def google_programmable_image_search(query: str) -> List[SearchResult]:\n",
        "    print(\"Executing Google Programmable Image Search\")\n",
        "    try:\n",
        "        search_results = google_service.cse().list(\n",
        "            q=query,\n",
        "            cx=GOOGLE_CSE_ID,\n",
        "            num=5,\n",
        "            searchType=\"image\"\n",
        "        ).execute()\n",
        "        print(f\"Google Programmable Image Search Example Result: {search_results.get('items', [])[0] if search_results.get('items') else 'No results'}\")\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Google Programmable Image Search\",\n",
        "                title=item.get(\"title\", \"No title\"),\n",
        "                snippet=item.get(\"snippet\", \"No snippet\"),\n",
        "                url=item.get(\"link\", \"No link\"),\n",
        "                media=[item.get(\"link\", \"No link\")],\n",
        "                media_content=[{\"image_url\": item.get(\"link\", \"No link\")}]\n",
        "            ) for item in search_results.get(\"items\", [])\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Google Programmable Image Search: {e}\")\n",
        "        return []\n",
        "\n",
        "def exa_search(query: str) -> List[SearchResult]:\n",
        "    print(\"Executing Exa Search\")\n",
        "    try:\n",
        "        response = exa.search_and_contents(\n",
        "            query,\n",
        "            use_autoprompt=True,\n",
        "            num_results=5,\n",
        "            text=True,\n",
        "            highlights=True\n",
        "        )\n",
        "        results = response.results\n",
        "        print(f\"Exa Search Example Result: {results[0] if results else 'No results'}\")\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Exa Search\",\n",
        "                title=result.title,\n",
        "                snippet=result.highlights[0] if result.highlights else \"No snippet\",\n",
        "                url=result.url,\n",
        "                date=result.publishedDate if hasattr(result, 'publishedDate') else None,\n",
        "                media_content=[{\"image_url\": result.url}] if result.url else []\n",
        "            ) for result in results\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Exa Search: {e}\")\n",
        "        return []\n",
        "\n",
        "def tavily_search(query: str) -> List[SearchResult]:\n",
        "    print(\"Executing Tavily Search\")\n",
        "    try:\n",
        "        response = tavily_client.search(\n",
        "            query,\n",
        "            search_depth=\"advanced\",\n",
        "            include_answer=True,\n",
        "            include_raw_content=True,\n",
        "            include_images=True,\n",
        "            max_results=5\n",
        "        )\n",
        "        print(f\"Tavily Search Example Result: {response.get('results', [])[0] if response.get('results') else 'No results'}\")\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Tavily Search\",\n",
        "                title=result.get(\"title\", \"No title\"),\n",
        "                snippet=result.get(\"content\", \"No snippet\"),\n",
        "                url=result.get(\"url\", \"No link\"),\n",
        "                date=result.get(\"published_date\"),\n",
        "                media=[result.get(\"url\", \"No link\")] if result.get(\"url\") else [],\n",
        "                media_content=[{\"image_url\": result.get(\"url\", \"No link\")}] if result.get(\"url\") else []\n",
        "            ) for result in response.get(\"results\", [])\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Tavily Search: {e}\")\n",
        "        return []\n",
        "\n",
        "async def telegram_search(query: str) -> List[SearchResult]:\n",
        "    print(\"Executing Telegram Search\")\n",
        "    try:\n",
        "        await telegram_client.start(phone=lambda: input('Please enter your phone number: '))\n",
        "        if not await telegram_client.is_user_authorized():\n",
        "            await telegram_client.send_code_request(input('Please enter your phone number: '))\n",
        "            await telegram_client.sign_in(input('Please enter the code you received: '))\n",
        "        print(\"Telegram client started successfully\")\n",
        "        all_results = []\n",
        "        for channel in TELEGRAM_CHANNELS:\n",
        "            print(f\"Searching in channel: {channel}\")\n",
        "            results = await telegram_client.get_messages(channel, search=query, limit=5)\n",
        "            if results:\n",
        "                all_results.extend([\n",
        "                    SearchResult(\n",
        "                        source=f\"Telegram ({channel})\",\n",
        "                        title=result.message,\n",
        "                        snippet=result.message,\n",
        "                        url=f\"https://t.me/{channel}/{result.id}\",\n",
        "                        date=result.date.isoformat()\n",
        "                    ) for result in results\n",
        "                ])\n",
        "                print(f\"Found {len(results)} results in channel: {channel}\")\n",
        "            else:\n",
        "                print(f\"No results found in channel: {channel}\")\n",
        "        print(f\"Telegram Search Example Result: {all_results[0] if all_results else 'No results'}\")\n",
        "        return all_results\n",
        "    except PhoneNumberInvalidError as e:\n",
        "        print(f\"Error in Telegram Search: {e}\")\n",
        "        return []\n",
        "    except SessionPasswordNeededError as e:\n",
        "        print(f\"Error in Telegram Search: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Telegram Search: {e}\")\n",
        "        return []\n",
        "\n",
        "def twitter_search(query: str) -> List[SearchResult]:\n",
        "    print(\"Executing Twitter Search\")\n",
        "    try:\n",
        "        tweets = twitter_api.search_tweets(q=query, count=5)\n",
        "        print(f\"Twitter Search Example Result: {tweets[0] if tweets else 'No results'}\")\n",
        "        return [\n",
        "            SearchResult(\n",
        "                source=\"Twitter\",\n",
        "                title=tweet.user.name,\n",
        "                snippet=tweet.text,\n",
        "                url=f\"https://twitter.com/{tweet.user.screen_name}/status/{tweet.id}\",\n",
        "                date=tweet.created_at.isoformat()\n",
        "            ) for tweet in tweets\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Twitter Search: {e}\")\n",
        "        return []\n",
        "\n",
        "def rss_feed_search(query: str) -> List[SearchResult]:\n",
        "    print(\"Executing RSS Feed Search\")\n",
        "    all_results = []\n",
        "    for feed_url in SECURITY_RSS_FEEDS:\n",
        "        try:\n",
        "            feed = feedparser.parse(feed_url)\n",
        "            if feed.entries:\n",
        "                all_results.extend([\n",
        "                    SearchResult(\n",
        "                        source=f\"RSS Feed ({feed_url})\",\n",
        "                        title=entry.title,\n",
        "                        snippet=entry.get(\"summary\", \"No summary available\"),\n",
        "                        url=entry.link,\n",
        "                        date=entry.published\n",
        "                    ) for entry in feed.entries if query.lower() in entry.title.lower() or query.lower() in entry.get(\"summary\", \"\").lower()\n",
        "                ])\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing RSS feed {feed_url}: {e}\")\n",
        "            time.sleep(2)  # Wait before retrying\n",
        "            continue\n",
        "    print(f\"RSS Feed Search Example Result: {all_results[0] if all_results else 'No results'}\")\n",
        "    return all_results\n",
        "\n",
        "def parse_date(date_str: str) -> datetime:\n",
        "    if date_str:\n",
        "        try:\n",
        "            return parser.parse(date_str).replace(tzinfo=None)  # Make all dates naive\n",
        "        except parser.ParserError:\n",
        "            if \"days ago\" in date_str:\n",
        "                days = int(date_str.split()[0])\n",
        "                return (datetime.now() - timedelta(days=days)).replace(tzinfo=None)\n",
        "            elif \"months ago\" in date_str:\n",
        "                months = int(date_str.split()[0])\n",
        "                return (datetime.now() - relativedelta(months=months)).replace(tzinfo=None)\n",
        "            elif \"years ago\" in date_str:\n",
        "                years = int(date_str.split()[0])\n",
        "                return (datetime.now() - relativedelta(years=years)).replace(tzinfo=None)\n",
        "    return datetime.min\n",
        "\n",
        "def filter_by_date(results: List[SearchResult], start_date: str, end_date: str) -> List[SearchResult]:\n",
        "    start_date = parse_date(start_date)\n",
        "    end_date = parse_date(end_date)\n",
        "    return [result for result in results if result.date and start_date <= parse_date(result.date) <= end_date]"
      ],
      "metadata": {
        "id": "z6w_36f9FRIV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_search_results(*args: List[SearchResult]) -> Dict[str, List[str]]:\n",
        "    all_results = []\n",
        "    urls = []\n",
        "    images = []\n",
        "\n",
        "    for results in args:\n",
        "        all_results.extend(results)\n",
        "        for result in results:\n",
        "            urls.append(result.url)\n",
        "            if result.media_content:\n",
        "                images.extend([media[\"image_url\"] for media in result.media_content])\n",
        "\n",
        "    seen_urls = set()\n",
        "    unique_results = []\n",
        "\n",
        "    for result in all_results:\n",
        "        if result.url not in seen_urls:\n",
        "            seen_urls.add(result.url)\n",
        "            unique_results.append(result)\n",
        "\n",
        "    # Sort results by date (most recent first)\n",
        "    unique_results.sort(key=lambda x: parse_date(x.date) if x.date else datetime.min, reverse=True)\n",
        "\n",
        "    return {\n",
        "        \"results\": unique_results,\n",
        "        \"urls\": list(set(urls)),  # Deduplicate URLs\n",
        "        \"images\": list(set(images))  # Deduplicate image URLs\n",
        "    }"
      ],
      "metadata": {
        "id": "upLiGPDEGHcy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def execute_searches(query: str, search_type: str = \"normal\", start_date: str = None, end_date: str = None) -> Dict[str, Any]:\n",
        "    search_functions = [\n",
        "        google_serper_search if search_type == \"normal\" else None,\n",
        "        google_programmable_search if search_type == \"normal\" else None,\n",
        "        exa_search if search_type == \"normal\" else None,\n",
        "        tavily_search if search_type == \"normal\" else None,\n",
        "        google_serper_image_search if search_type == \"image\" else None,\n",
        "        google_programmable_image_search if search_type == \"image\" else None,\n",
        "        telegram_search if search_type == \"normal\" else None,\n",
        "        lambda q: twitter_search(q) if search_type == \"normal\" else None,\n",
        "        lambda q: rss_feed_search(q) if search_type == \"normal\" else None\n",
        "    ]\n",
        "    search_functions = [func for func in search_functions if func is not None]  # Remove None values\n",
        "\n",
        "    search_tasks = [asyncio.to_thread(func, query, start_date, end_date) if callable(func) and not asyncio.iscoroutinefunction(func) else func(query) for func in search_functions]\n",
        "    search_results = await asyncio.gather(*search_tasks, return_exceptions=True)\n",
        "\n",
        "    successful_results = []\n",
        "    for results in search_results:\n",
        "        if not isinstance(results, Exception):\n",
        "            successful_results.append(results)\n",
        "\n",
        "    combined_results = aggregate_search_results(*successful_results)\n",
        "    combined_results[\"results\"] = filter_by_date(combined_results[\"results\"], start_date, end_date)\n",
        "\n",
        "    return combined_results\n",
        "\n",
        "async def scrape_telegram_channel(channel_name: str, start_date: str, end_date: str):\n",
        "    try:\n",
        "        await telegram_client.start(phone=lambda: input('Please enter your phone number: '))\n",
        "        if not await telegram_client.is_user_authorized():\n",
        "            await telegram_client.send_code_request(input('Please enter your phone number: '))\n",
        "            await telegram_client.sign_in(input('Please enter the code you received: '))\n",
        "        print(\"Telegram client started successfully\")\n",
        "\n",
        "        # Fetch messages from the channel\n",
        "        messages = []\n",
        "        async for message in telegram_client.iter_messages(channel_name):\n",
        "            if start_date and end_date:\n",
        "                message_date = parse_date(message.date.isoformat())\n",
        "                if parse_date(start_date) <= message_date <= parse_date(end_date):\n",
        "                    messages.append({\n",
        "                        'id': message.id,\n",
        "                        'date': message.date.isoformat(),\n",
        "                        'message': message.message,\n",
        "                        'media': message.media,\n",
        "                        'views': message.views,\n",
        "                        'forwards': message.forwards\n",
        "                    })\n",
        "            else:\n",
        "                messages.append({\n",
        "                    'id': message.id,\n",
        "                    'date': message.date.isoformat(),\n",
        "                    'message': message.message,\n",
        "                    'media': message.media,\n",
        "                    'views': message.views,\n",
        "                    'forwards': message.forwards\n",
        "                })\n",
        "\n",
        "        return messages\n",
        "    except PhoneNumberInvalidError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return []\n",
        "    except SessionPasswordNeededError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return []\n",
        "\n",
        "def get_telegram_channel_data(channel_name: str, start_date: str, end_date: str):\n",
        "    messages = asyncio.run(scrape_telegram_channel(channel_name, start_date, end_date))\n",
        "    return messages"
      ],
      "metadata": {
        "id": "AcAJdBQhOIO0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage within the existing pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    query = \"Blackbasta Ransomware Group?\"\n",
        "    start_date = \"2023-01-01\"\n",
        "    end_date = \"2023-12-31\"\n",
        "    results = asyncio.run(execute_searches(query, search_type=\"normal\", start_date=start_date, end_date=end_date))\n",
        "\n",
        "    print(\"\\nTextual URLs List:\")\n",
        "    print(results[\"urls\"])\n",
        "\n",
        "    print(\"\\nImage URLs List:\")\n",
        "    print(results[\"images\"])\n",
        "\n",
        "    print(\"\\nSearch Results:\")\n",
        "    for result in results[\"results\"]:\n",
        "        print(f\"Source: {result.source}\")\n",
        "        print(f\"Title: {result.title}\")\n",
        "        print(f\"Snippet: {result.snippet}\")\n",
        "        print(f\"URL: {result.url}\")\n",
        "        print(f\"Date: {result.date}\")\n",
        "        print(f\"Media: {result.media}\")\n",
        "        print(f\"Media Content: {result.media_content}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Get data from all specified Telegram channels\n",
        "    all_telegram_data = []\n",
        "    for channel_name in TELEGRAM_CHANNELS:\n",
        "        telegram_data = get_telegram_channel_data(channel_name, start_date, end_date)\n",
        "        all_telegram_data.extend(telegram_data)\n",
        "\n",
        "    print(\"\\nAll Telegram Channel Data:\")\n",
        "    for message in all_telegram_data:\n",
        "        print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih6PPHvQGPfs",
        "outputId": "279794ca-12e9-450e-b0c3-b498a100a487"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Google Serper SearchExecuting Google Programmable Search\n",
            "\n",
            "Executing Telegram Search\n",
            "Google Programmable Search Example Result: No results\n",
            "Google Serper Search Example Result: {'title': 'Who Is Black Basta? - BlackBerry', 'link': 'https://www.blackberry.com/us/en/solutions/endpoint-security/ransomware-protection/black-basta', 'snippet': 'Black Basta (AKA BlackBasta) is a ransomware operator and Ransomware-as-a-Service (RaaS) criminal enterprise that first emerged in early 2022.', 'position': 1}\n",
            "Please enter your phone number: +91 8755714681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KS3r64URGeDo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}